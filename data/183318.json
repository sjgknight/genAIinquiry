[{"id":1,"order":"1.00000000000000000000","submission_number":"1","Submitter":"Mx Joel MacKay","Type of org":{"id":977280,"value":"Individual","color":"gray"},"Notes":"Provides general overview of area.","Recommendations":[{"id":1,"value":"Teacher Professional Development"},{"id":69,"value":"Comprehensive ethical guidelines and regulations need to be established to govern the use of generative AI in the education system and protect the rights and well-being of students."}],"Uses-opportunities":[{"id":11,"value":"Personalized learning"},{"id":12,"value":"Intelligent Tutoring"},{"id":13,"value":"Curriculum Enhancement"},{"id":14,"value":"Data Analytics and Predictive Insights"},{"id":15,"value":"Efficient Administrative Processes;"}],"Risks-challenges":[{"id":6,"value":"Data Privacy and Security,"},{"id":7,"value":"Algorithmic bias and fairness,"},{"id":8,"value":"Lack of Human Interaction and Social Skills Development,"},{"id":9,"value":"Dependency on Technology"}],"References-footnotes":[],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":1,"database_table_184385":1},"value":{"id":980196,"value":"PD","color":"light-red"}},{"ids":{"database_table_183319":69,"database_table_184385":2},"value":{"id":980180,"value":"guidelines","color":"light-yellow"}}],"Lookup":[{"id":1,"value":"Teacher Professional Development"},{"id":69,"value":"Comprehensive ethical guidelines and regulations need to be established to govern the use of generative AI in the education system and protect the rights and well-being of students."}]},{"id":2,"order":"2.00000000000000000000","submission_number":"2","Submitter":"SA Dept of Education","Type of org":{"id":977282,"value":"Govt","color":"orange"},"Notes":"","Recommendations":[{"id":2,"value":"education ministers from all Australian states and territories have agreed that responding to the risks and harnessing opportunities from generative AI technologies is a national education priority. [...] agreed to develop the Australian Framework for Generative Artificial Intelligence in Schools, which will cover elements of human and social wellbeing, transparency, fairness, accountability and privacy and security. [...] The Inquiry should factor the work of the taskforce and the framework it has developed in making its recommendations."}],"Uses-opportunities":[{"id":16,"value":"Supporting equity via adapting materials for groups,"},{"id":17,"value":"supporting personalised learning,"},{"id":18,"value":"streamlining teaching tasks and school administration"}],"Risks-challenges":[{"id":10,"value":"Access control and age restriction,"},{"id":11,"value":"content hallucination-bias-and-moderation,"},{"id":12,"value":"data privacy and security,"},{"id":13,"value":"integrity and plagiarism,"},{"id":14,"value":"broad impacts on issues such as wellbeing"}],"References-footnotes":[],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":2,"database_table_184385":3},"value":{"id":980182,"value":"situate-with-existing-policy","color":"darker-red"}}],"Lookup":[{"id":2,"value":"education ministers from all Australian states and territories have agreed that responding to the risks and harnessing opportunities from generative AI technologies is a national education priority. [...] agreed to develop the Australian Framework for Generative Artificial Intelligence in Schools, which will cover elements of human and social wellbeing, transparency, fairness, accountability and privacy and security. [...] The Inquiry should factor the work of the taskforce and the framework it has developed in making its recommendations."}]},{"id":3,"order":"3.00000000000000000000","submission_number":"3","Submitter":"Monash University","Type of org":{"id":977279,"value":"University","color":"darker-blue"},"Notes":"","Recommendations":[{"id":3,"value":"While there will undoubtedly be generally accepted standards and practices across the education sector nationally and globally, many of the opportunities and risks of GenAI in education fall within existing policies and procedures of individual institutions."},{"id":4,"value":"The principle of institutional autonomy should be consistent with other risks in education.  The principle of institutional autonomy should be consistent with other risks in education. GenAI is new but we recommend the government response is consistent with other issues in education such as academic integrity, cyber security, etc, by setting a threshold and allowing institutions to respond in a way that best supports their own operations and communities. This does not preclude facilitated cross-sector engagement and the hosting of sector-wide working groups to discuss and prepare best practice guidelines, both for responsible use and for incorporating GenAI into existing policies and practices."},{"id":5,"value":"It is recommended that a responsible use approach to the incorporation of GenAI is encouraged. Beyond a desire to encourage responsible experimentation and the development of an informed and critical awareness of the benefits and risks of GenAI, an important factor in taking this position is that detection of AI-generated content is unlikely to be feasible. Emerging evidence suggests that humans are not reliable in detecting AI- generated content. Equally, AI detection tools are non-transparent and unreliable in their testing and reporting of their own accuracy, and are likely to generate an intolerably high proportion of both false positives and false negatives. The exception to detection difficulties is where watermarks are injected. Watermarks are coded patterns of output that are intentionally detectable to AI detection systems. To make this system feasible would require the regulation of all GenAI technologies to mandate the injection of watermarks into their content. Unregulated GenAI technologies would allow students to avoid this. Other GenAI technologies can be used to parse watermarked content to remove the watermark. Humans can inject watermarks into human-generated content to discredit detection technologies."},{"id":6,"value":"Clarity around the responsible use of GenAI in assessment is necessary to help students navigate uncertainty and to make them responsible for their own academic conduct."},{"id":7,"value":"Alternative approaches to assessment will be needed, in which a combination of assessment of process, closer working relationships with students, and more complex assessments will need to be developed. As a related issue, care should be taken when adapting GenAI into marking or feedback practices. Use of GenAI in assessing student work and/or providing feedback without specialist training entails a reduction in established human expertise and, potentially, a reduction in human connection and trust relations. Thus, institutions need a clear framework for making decisions about how to incorporate GenAI into these powerful practices."},{"id":8,"value":"We see GenAI as an opportunity for greater engagement with students in the design of learning. To facilitate AI literacies, Monash will use a Students as Partners approach, in which student representatives work directly with academics to collaboratively co-design learning and teaching approaches and assessments. There may be scope to develop generic course-level outcomes which align with Monash Graduate Attributes, in recognition of the importance to invest in teaching students about AI literacy."},{"id":9,"value":"In relation to academic misconduct, recognising GenAI as a collaboration tool intentionally separates it from plagiarism, collusion and contract cheating. At the same time, we need to maintain mechanisms to restrict GenAI use in assessments that require students to demonstrate human capacities. Therefore, we are exploring a â€˜restorative practiceâ€™ approach to suspected academic integrity breaches."},{"id":10,"value":"Institutional governance and policy positions need to consider the context of use, responsibility for errors and consider alternative definitions, or categorisation of attributes, such as â€˜authorâ€™ â€˜collaboratorâ€™ which have an inherent meaning and subject position that may not be appropriate to apply to GenAI content.\n\nIn light of the above, we are confident that managing the risks and seizing the opportunities can be accomplished within ards Framework (Threshold Standards) 2021 and our own institutional policies."}],"Uses-opportunities":[{"id":19,"value":"Act as collaborator across range of types of task"}],"Risks-challenges":[{"id":15,"value":"Overuse, underuse and misuse, including inappropriate shortcuts,"},{"id":16,"value":"automation bias (failing to check outputs)"}],"References-footnotes":[],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":6,"database_table_184385":2},"value":{"id":980180,"value":"guidelines","color":"light-yellow"}},{"ids":{"database_table_183319":3,"database_table_184385":3},"value":{"id":980182,"value":"situate-with-existing-policy","color":"darker-red"}},{"ids":{"database_table_183319":10,"database_table_184385":3},"value":{"id":980182,"value":"situate-with-existing-policy","color":"darker-red"}},{"ids":{"database_table_183319":4,"database_table_184385":4},"value":{"id":980183,"value":"local-responses-and-autonomy","color":"dark-cyan"}},{"ids":{"database_table_183319":10,"database_table_184385":4},"value":{"id":980183,"value":"local-responses-and-autonomy","color":"dark-cyan"}},{"ids":{"database_table_183319":5,"database_table_184385":5},"value":{"id":980175,"value":"mandatory-watermarking","color":"brown"}},{"ids":{"database_table_183319":7,"database_table_184385":6},"value":{"id":980185,"value":"new-assessment-models","color":"darker-pink"}},{"ids":{"database_table_183319":9,"database_table_184385":6},"value":{"id":980185,"value":"new-assessment-models","color":"darker-pink"}},{"ids":{"database_table_183319":8,"database_table_184385":7},"value":{"id":980187,"value":"stakeholder-engagement","color":"dark-green"}}],"Lookup":[{"id":3,"value":"While there will undoubtedly be generally accepted standards and practices across the education sector nationally and globally, many of the opportunities and risks of GenAI in education fall within existing policies and procedures of individual institutions."},{"id":4,"value":"The principle of institutional autonomy should be consistent with other risks in education.  The principle of institutional autonomy should be consistent with other risks in education. GenAI is new but we recommend the government response is consistent with other issues in education such as academic integrity, cyber security, etc, by setting a threshold and allowing institutions to respond in a way that best supports their own operations and communities. This does not preclude facilitated cross-sector engagement and the hosting of sector-wide working groups to discuss and prepare best practice guidelines, both for responsible use and for incorporating GenAI into existing policies and practices."},{"id":5,"value":"It is recommended that a responsible use approach to the incorporation of GenAI is encouraged. Beyond a desire to encourage responsible experimentation and the development of an informed and critical awareness of the benefits and risks of GenAI, an important factor in taking this position is that detection of AI-generated content is unlikely to be feasible. Emerging evidence suggests that humans are not reliable in detecting AI- generated content. Equally, AI detection tools are non-transparent and unreliable in their testing and reporting of their own accuracy, and are likely to generate an intolerably high proportion of both false positives and false negatives. The exception to detection difficulties is where watermarks are injected. Watermarks are coded patterns of output that are intentionally detectable to AI detection systems. To make this system feasible would require the regulation of all GenAI technologies to mandate the injection of watermarks into their content. Unregulated GenAI technologies would allow students to avoid this. Other GenAI technologies can be used to parse watermarked content to remove the watermark. Humans can inject watermarks into human-generated content to discredit detection technologies."},{"id":6,"value":"Clarity around the responsible use of GenAI in assessment is necessary to help students navigate uncertainty and to make them responsible for their own academic conduct."},{"id":7,"value":"Alternative approaches to assessment will be needed, in which a combination of assessment of process, closer working relationships with students, and more complex assessments will need to be developed. As a related issue, care should be taken when adapting GenAI into marking or feedback practices. Use of GenAI in assessing student work and/or providing feedback without specialist training entails a reduction in established human expertise and, potentially, a reduction in human connection and trust relations. Thus, institutions need a clear framework for making decisions about how to incorporate GenAI into these powerful practices."},{"id":8,"value":"We see GenAI as an opportunity for greater engagement with students in the design of learning. To facilitate AI literacies, Monash will use a Students as Partners approach, in which student representatives work directly with academics to collaboratively co-design learning and teaching approaches and assessments. There may be scope to develop generic course-level outcomes which align with Monash Graduate Attributes, in recognition of the importance to invest in teaching students about AI literacy."},{"id":9,"value":"In relation to academic misconduct, recognising GenAI as a collaboration tool intentionally separates it from plagiarism, collusion and contract cheating. At the same time, we need to maintain mechanisms to restrict GenAI use in assessments that require students to demonstrate human capacities. Therefore, we are exploring a â€˜restorative practiceâ€™ approach to suspected academic integrity breaches."},{"id":10,"value":"Institutional governance and policy positions need to consider the context of use, responsibility for errors and consider alternative definitions, or categorisation of attributes, such as â€˜authorâ€™ â€˜collaboratorâ€™ which have an inherent meaning and subject position that may not be appropriate to apply to GenAI content.\n\nIn light of the above, we are confident that managing the risks and seizing the opportunities can be accomplished within ards Framework (Threshold Standards) 2021 and our own institutional policies."}]},{"id":4,"order":"4.00000000000000000000","submission_number":"4","Submitter":"Deakin University","Type of org":{"id":977279,"value":"University","color":"darker-blue"},"Notes":"Provides general overview of area.","Recommendations":[],"Uses-opportunities":[],"Risks-challenges":[],"References-footnotes":[],"Processed":true,"Recco_tags":[],"Lookup":[]},{"id":5,"order":"5.00000000000000000000","submission_number":"5","Submitter":"Australian Association for the Teaching of English","Type of org":{"id":977281,"value":"Peak body","color":"green"},"Notes":"","Recommendations":[],"Uses-opportunities":[{"id":20,"value":"Teaching of writing"}],"Risks-challenges":[{"id":17,"value":"Limits to creativity,"},{"id":18,"value":"loss of personal voice,"},{"id":19,"value":"commercial interests and IP concerns,"},{"id":20,"value":"equity issues in access and benefits from tools,"}],"References-footnotes":[],"Processed":true,"Recco_tags":[],"Lookup":[]},{"id":6,"order":"6.00000000000000000000","submission_number":"6","Submitter":"University of Southern Queensland","Type of org":{"id":977279,"value":"University","color":"darker-blue"},"Notes":"Provides concise bullet pointed overview.","Recommendations":[{"id":11,"value":"Usage guidelines, preferably consistent throughout the sector;"},{"id":12,"value":"Clear internal use policies;"},{"id":13,"value":"Education/professional development;"},{"id":14,"value":"Privacy and data protection â€“ need a clear understanding of whether data is used to improve the AI and where data is stored."}],"Uses-opportunities":[{"id":21,"value":"Personalised learning,"},{"id":22,"value":"immediate AI tutoring,"},{"id":23,"value":"presentation support,"},{"id":24,"value":"guidance and advice regarding studies,"},{"id":25,"value":"enhanced online learning,"},{"id":26,"value":"supporting learning for a future world,"},{"id":27,"value":"content creation,"},{"id":28,"value":"formative feedback,"},{"id":29,"value":"administrative offloading"}],"Risks-challenges":[{"id":21,"value":"Assurance of learning, data bias,"},{"id":22,"value":"adequate understanding of the materials being generated (particularly for PhD research contexts),"},{"id":23,"value":"regulatory lag,"},{"id":24,"value":"accessibility for all students,"},{"id":25,"value":"training adequacy,"},{"id":26,"value":"intellectual property,"},{"id":27,"value":"AI accuracy and hallucinations"}],"References-footnotes":[],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":13,"database_table_184385":1},"value":{"id":980196,"value":"PD","color":"light-red"}},{"ids":{"database_table_183319":11,"database_table_184385":2},"value":{"id":980180,"value":"guidelines","color":"light-yellow"}},{"ids":{"database_table_183319":14,"database_table_184385":2},"value":{"id":980180,"value":"guidelines","color":"light-yellow"}},{"ids":{"database_table_183319":12,"database_table_184385":3},"value":{"id":980182,"value":"situate-with-existing-policy","color":"darker-red"}}],"Lookup":[{"id":11,"value":"Usage guidelines, preferably consistent throughout the sector;"},{"id":12,"value":"Clear internal use policies;"},{"id":13,"value":"Education/professional development;"},{"id":14,"value":"Privacy and data protection â€“ need a clear understanding of whether data is used to improve the AI and where data is stored."}]},{"id":7,"order":"7.00000000000000000000","submission_number":"7","Submitter":"Dr. Pethigamage Perera","Type of org":{"id":977286,"value":"individual-academic","color":"dark-blue"},"Notes":"","Recommendations":[{"id":15,"value":"â–ª  Raise awareness of generative AI's potential uses and limitations."},{"id":16,"value":"â–ª  Use Generative AI as a complementary tool, not a substitute for human researchers."},{"id":17,"value":"â–ª  Incorporate proctored, in-person assessments alongside AI tools."},{"id":18,"value":"â–ª  Develop ethical principles and guidelines for Generative AI in higher education."},{"id":19,"value":"â–ª  Promote originality and creativity in assignments."},{"id":20,"value":"â–ª  Implement strategies to prevent plagiarism when using Generative AI."},{"id":21,"value":"â–ª  Provide personalized feedback to students."},{"id":22,"value":"â–ª  Use formative assessment practices like self-assessment and peer feedback."},{"id":23,"value":"â–ª  By addressing ethical issues and limitations, educators can harness Generative AI as a valuable educational resource."}],"Uses-opportunities":[{"id":30,"value":"improve student-teacher interaction,"},{"id":31,"value":"benefits to non-English speaking students via translation and editing abilitiy,"},{"id":32,"value":"timely feedback"}],"Risks-challenges":[{"id":28,"value":"decrease critical thinking,"},{"id":29,"value":"plagiarism"}],"References-footnotes":[],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":18,"database_table_184385":2},"value":{"id":980180,"value":"guidelines","color":"light-yellow"}},{"ids":{"database_table_183319":23,"database_table_184385":2},"value":{"id":980180,"value":"guidelines","color":"light-yellow"}},{"ids":{"database_table_183319":17,"database_table_184385":6},"value":{"id":980185,"value":"new-assessment-models","color":"darker-pink"}},{"ids":{"database_table_183319":19,"database_table_184385":6},"value":{"id":980185,"value":"new-assessment-models","color":"darker-pink"}},{"ids":{"database_table_183319":20,"database_table_184385":6},"value":{"id":980185,"value":"new-assessment-models","color":"darker-pink"}},{"ids":{"database_table_183319":21,"database_table_184385":6},"value":{"id":980185,"value":"new-assessment-models","color":"darker-pink"}},{"ids":{"database_table_183319":22,"database_table_184385":6},"value":{"id":980185,"value":"new-assessment-models","color":"darker-pink"}},{"ids":{"database_table_183319":16,"database_table_184385":8},"value":{"id":980188,"value":"new-workforce-model","color":"light-brown"}},{"ids":{"database_table_183319":15,"database_table_184385":16},"value":{"id":980194,"value":"communications","color":"darker-brown"}}],"Lookup":[{"id":15,"value":"â–ª  Raise awareness of generative AI's potential uses and limitations."},{"id":16,"value":"â–ª  Use Generative AI as a complementary tool, not a substitute for human researchers."},{"id":17,"value":"â–ª  Incorporate proctored, in-person assessments alongside AI tools."},{"id":18,"value":"â–ª  Develop ethical principles and guidelines for Generative AI in higher education."},{"id":19,"value":"â–ª  Promote originality and creativity in assignments."},{"id":20,"value":"â–ª  Implement strategies to prevent plagiarism when using Generative AI."},{"id":21,"value":"â–ª  Provide personalized feedback to students."},{"id":22,"value":"â–ª  Use formative assessment practices like self-assessment and peer feedback."},{"id":23,"value":"â–ª  By addressing ethical issues and limitations, educators can harness Generative AI as a valuable educational resource."}]},{"id":8,"order":"8.00000000000000000000","submission_number":"8","Submitter":"Australian Secondary Principals' Association","Type of org":{"id":977281,"value":"Peak body","color":"green"},"Notes":"Opens with advocating for public education in Aus context","Recommendations":[{"id":24,"value":"â—    that teachers, school leaders and principals be educated about the risks and opportunities presented by AI through a nationally consistent approach."},{"id":25,"value":"â—    That any intent to implement AI in schools be accompanied by appropriate and realistic timeframes, resourcing and training. It should not be added to existing curriculum must be explicit licensing from ACCARA to â€˜make roomâ€™ for any new content."},{"id":26,"value":"â—   That Principals be involved in the design of national guidelines, policy and protocol related to this issue and its implementation in schools."}],"Uses-opportunities":[],"Risks-challenges":[{"id":30,"value":"Assurance of learning,"},{"id":31,"value":"bias,"},{"id":32,"value":"privacy"}],"References-footnotes":[],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":24,"database_table_184385":1},"value":{"id":980196,"value":"PD","color":"light-red"}},{"ids":{"database_table_183319":26,"database_table_184385":2},"value":{"id":980180,"value":"guidelines","color":"light-yellow"}},{"ids":{"database_table_183319":26,"database_table_184385":7},"value":{"id":980187,"value":"stakeholder-engagement","color":"dark-green"}},{"ids":{"database_table_183319":25,"database_table_184385":10},"value":{"id":980190,"value":"curricula-changes","color":"light-green"}}],"Lookup":[{"id":24,"value":"â—    that teachers, school leaders and principals be educated about the risks and opportunities presented by AI through a nationally consistent approach."},{"id":25,"value":"â—    That any intent to implement AI in schools be accompanied by appropriate and realistic timeframes, resourcing and training. It should not be added to existing curriculum must be explicit licensing from ACCARA to â€˜make roomâ€™ for any new content."},{"id":26,"value":"â—   That Principals be involved in the design of national guidelines, policy and protocol related to this issue and its implementation in schools."}]},{"id":9,"order":"9.00000000000000000000","submission_number":"9","Submitter":"Bond University","Type of org":{"id":977279,"value":"University","color":"darker-blue"},"Notes":"Provides general overview of area.","Recommendations":[],"Uses-opportunities":[],"Risks-challenges":[],"References-footnotes":[],"Processed":true,"Recco_tags":[],"Lookup":[]},{"id":10,"order":"10.00000000000000000000","submission_number":"10","Submitter":"Victorian Association for the Teaching of English","Type of org":{"id":977281,"value":"Peak body","color":"green"},"Notes":"Used an online survey of 7500 members to support, with 44 responses.\nResults are synthesised on p.14 and I've extracted that, it's quite hard to get overview otherwise (although the comments are interesting in raw form).","Recommendations":[{"id":27,"value":"Suggestion of guidelines needed"}],"Uses-opportunities":[],"Risks-challenges":[{"id":33,"value":"â€¢  However, Victorian English teachers noted that currently there is insufficient support and direction available in curriculum documentation for them to confidently engage with and use Generative AI in the English classroom."},{"id":34,"value":"â€¢  In addition, teachers noted that there are few policies in place in their teaching context, nor direction or guidance from key leadership bodies around the use of Generative AI, for them to confidently engage with the use of these tools in the English classroom. This raises concerns about the ethical and just use of these tools."},{"id":35,"value":"â€¢  English teachers are concerned about the way Generative AI can be consciously or unconsciously misused by students, adversely impacting their literary competence and development and the joyful experience of learning."},{"id":36,"value":"â€¢  English teachers see their role in the classroom as integral to the development of civic-minded, critical-thinking, confident, and compassionate young people; Generative AI in its current form is viewed as a tool not able to replicate the role of the classroom teacher."}],"References-footnotes":[],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":27,"database_table_184385":2},"value":{"id":980180,"value":"guidelines","color":"light-yellow"}}],"Lookup":[{"id":27,"value":"Suggestion of guidelines needed"}]},{"id":11,"order":"11.00000000000000000000","submission_number":"11","Submitter":"Association for Academic Language and Learning","Type of org":{"id":977281,"value":"Peak body","color":"green"},"Notes":"","Recommendations":[],"Uses-opportunities":[],"Risks-challenges":[],"References-footnotes":[],"Processed":true,"Recco_tags":[],"Lookup":[]},{"id":12,"order":"12.00000000000000000000","submission_number":"12","Submitter":"Name Withheld","Type of org":{"id":980120,"value":"withheld","color":"green"},"Notes":"","Recommendations":[{"id":28,"value":"Many duties of teachers and resource developers can be separated into a special department where a limited number of persons supervise/ coordinate AI in those duties;"},{"id":29,"value":"Higher level of centralisation of the curriculum with specific norms (not guidelines) still with a focus on modern practices of student-centered education;"},{"id":30,"value":"To have a governing body around the use of AI technology in Education Sectors;"},{"id":31,"value":"Compulsory curriculum around AI use for all;"},{"id":32,"value":"Bank of approved tasks developed by AI"}],"Uses-opportunities":[{"id":33,"value":"Saves time by automating;"},{"id":34,"value":"educative tool by helping with feedback;"},{"id":35,"value":"personalised learning;"},{"id":36,"value":"automate administrative tasks;"},{"id":37,"value":"create eduational resources;"}],"Risks-challenges":[{"id":37,"value":"plagiarism and copyright infringement;"},{"id":38,"value":"unethical conduct from educators and students;"},{"id":39,"value":"bias and discrimination;"},{"id":40,"value":"concerns about academic integrity generally;"},{"id":41,"value":"privacy of data accessed by AI;"},{"id":42,"value":"lack of transparency/ explainabiity;"},{"id":43,"value":"ongoing monitoring and evaluation"}],"References-footnotes":[],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":32,"database_table_184385":6},"value":{"id":980185,"value":"new-assessment-models","color":"darker-pink"}},{"ids":{"database_table_183319":28,"database_table_184385":8},"value":{"id":980188,"value":"new-workforce-model","color":"light-brown"}},{"ids":{"database_table_183319":28,"database_table_184385":9},"value":{"id":980189,"value":"DISTINCTIVE","color":"dark-green"}},{"ids":{"database_table_183319":29,"database_table_184385":10},"value":{"id":980190,"value":"curricula-changes","color":"light-green"}},{"ids":{"database_table_183319":31,"database_table_184385":10},"value":{"id":980190,"value":"curricula-changes","color":"light-green"}},{"ids":{"database_table_183319":30,"database_table_184385":11},"value":{"id":980191,"value":"new-policy","color":"dark-purple"}}],"Lookup":[{"id":28,"value":"Many duties of teachers and resource developers can be separated into a special department where a limited number of persons supervise/ coordinate AI in those duties;"},{"id":29,"value":"Higher level of centralisation of the curriculum with specific norms (not guidelines) still with a focus on modern practices of student-centered education;"},{"id":30,"value":"To have a governing body around the use of AI technology in Education Sectors;"},{"id":31,"value":"Compulsory curriculum around AI use for all;"},{"id":32,"value":"Bank of approved tasks developed by AI"}]},{"id":13,"order":"13.00000000000000000000","submission_number":"13","Submitter":"Australian Research Council Centre of Excellence for the Digital Child","Type of org":{"id":977287,"value":"University-centre","color":"orange"},"Notes":"","Recommendations":[{"id":416,"value":"Support students to develop critical literacy"},{"id":417,"value":"Provide professional learning and development to educators"},{"id":418,"value":"Maintain an open dialogue on use of generative AI"},{"id":419,"value":"Age-appropriate access and design"},{"id":420,"value":"Transparency"},{"id":421,"value":"Sustainability/Environmental Costs"}],"Uses-opportunities":[{"id":357,"value":"The use of generative AI in\neducational settings should be designed to support and empower children, parents and\ncarers, and educators to engage with the role of digital media and technologies and enable\nstudents to be proficient users."},{"id":358,"value":"Students could be supported to use AI generated texts as a springboard to develop or\nfurther their own critical literacies, e.g., developing skills in validating claims/facts, identifying\nplagiarism, identifying silences, and/or skewed arguments."}],"Risks-challenges":[{"id":286,"value":"Legal risks and challenges:Terms and conditions applicable to these tools may preclude the use by certain agegroups (e.g., under 13s) or require parental consent where a person is under 18"},{"id":287,"value":"Companies providing generative AI tools can reserve the right to change terms and\nconditions from time to time, often without notice."},{"id":288,"value":"Use of generative AI tools in teaching or assessment may present issues if a student\n(or parent/carer, where consent is required) is not willing to accept the applicable\nterms and conditions, privacy policy, and so on."},{"id":289,"value":"Inputting content into a generative AI tool could constitute an infringement of\ncopyright or intellectual property rights"},{"id":296,"value":"Helping children judge the veracity of content"},{"id":297,"value":"The risk of plagiarism"},{"id":298,"value":"Reinforcing socio-economic barriers and disadvantages"}],"References-footnotes":[],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":417,"database_table_184385":1},"value":{"id":980196,"value":"PD","color":"light-red"}},{"ids":{"database_table_183319":416,"database_table_184385":10},"value":{"id":980190,"value":"curricula-changes","color":"light-green"}},{"ids":{"database_table_183319":418,"database_table_184385":16},"value":{"id":980194,"value":"communications","color":"darker-brown"}},{"ids":{"database_table_183319":419,"database_table_184385":39},"value":{"id":991258,"value":"foster-responsible-aied","color":"red"}},{"ids":{"database_table_183319":420,"database_table_184385":39},"value":{"id":991258,"value":"foster-responsible-aied","color":"red"}},{"ids":{"database_table_183319":421,"database_table_184385":39},"value":{"id":991258,"value":"foster-responsible-aied","color":"red"}}],"Lookup":[{"id":416,"value":"Support students to develop critical literacy"},{"id":417,"value":"Provide professional learning and development to educators"},{"id":418,"value":"Maintain an open dialogue on use of generative AI"},{"id":419,"value":"Age-appropriate access and design"},{"id":420,"value":"Transparency"},{"id":421,"value":"Sustainability/Environmental Costs"}]},{"id":14,"order":"14.00000000000000000000","submission_number":"14","Submitter":"Australian Academy of Technological Sciences and Engineering","Type of org":{"id":977281,"value":"Peak body","color":"green"},"Notes":"","Recommendations":[{"id":162,"value":"Recommendation 1: Reverse bans on generative AI systems in schools introduced by state education departments and establish institutional access licencing agreements across the education sector."},{"id":163,"value":"Recommendation 2: Introduce age-appropriate AI instruction in Australian classrooms, supported by appropriate educator training and purpose-built AI tools or institutional access licences for commercial AI products."},{"id":164,"value":"Recommendation 3: Provide professional development opportunities, supported by professional development leave and other incentives, to teach existing educators how to engage with AI both inside and outside the classroom."},{"id":165,"value":"Recommendation 4: Require the inclusion of AI literacy training as part of initial teacher training programs."},{"id":166,"value":"Recommendation 5: Encourage the development of assessment guidance by education departments that is both resilient to AI developments and embraces opportunities presented by AI."},{"id":167,"value":"Recommendation 6: Develop and provide ethics and AI data privacy training for educators."},{"id":168,"value":"Recommendation 7: Develop appropriate interventions to protect young peopleâ€™s mental health, and deeply sensitive information."}],"Uses-opportunities":[{"id":99,"value":"Allowing generative AI in schools may help to establish more personalised teaching methods and real-time feedback that would otherwise be impractical in a traditional classroom. For example, the University of Queensland is already embracing this through their RiPPLE tool that leverages both crowd sourcing and AI systems to develop and recommend learning resources to make learning more personalised and engaging (University of Queensland n.d.)."},{"id":100,"value":"Beyond the opportunities in the classroom, AI has the potential to completely change the way we work and live. It is vital that we not only prepare students for this, but give them - and by extension, the nation - a competitive advantage by training the next generation of AI leaders who can both use and improve AI to build a stronger nation. Students will need a firm foundation of knowledge in how AI systems work and how they can be used, requiring that these skills be integrated within the curriculum, at all education levels. Current content on programming and coding within the Australian Curriculum, needs to be supplemented with specific AI education. Grok Academy is one example of a program already working to integrate digital and AI skills into classrooms and provides free support for Australian teachers with teaching digital"},{"id":101,"value":"While aspects of assessments will need to be managed during the emerging AI revolution, generative AI, and AI more generally, has the opportunity to enhance formative assessment. Generative AI can help to provide real-time feedback for students on a scale not otherwise practical in a classroom and may also help educators to provide more detailed and useful feedback on assessments. The Productivity Commission has found that for every four hours a schoolteacher spends teaching, they spend one hour marking (Productivity Commission 2023), while markers in higher education are often paid on piece rates that understate the time taken to mark assessments (Schneiders 14 April 2023). These tools should therefore be embraced to help educators reduce workloads and provide an enhanced educational experience for students. Support and guidance will be needed to do this, including comprehensive guidelines around how AI can be ethically and productively used to improve assessment mechanisms and assessment feedback."}],"Risks-challenges":[{"id":127,"value":"Knee-jerk bans on generative AI systems in public have the potential to produce an AI divide. If private and independent schools can teach their teachers and students how to get the most out of AI systems, while this is banned in the public system, two tiers of digital literacy will emerge. This will impact students beyond the primary and secondary school systems, putting public school graduates behind when they enter the workforce or further education. This two-tiered system will disproportionally impact those from disadvantaged backgrounds, with public students more than twice as likely to come from a disadvantaged background3, further entrenching their disadvantage. It must not be the case that only wealthy students from private schools are given the opportunity to develop AI literacy and gain the advantages that come with that."},{"id":128,"value":"The fee-for-features model of many of the most popular generative AI services, where key features or priority processing is placed behind a paywall also has the potential to exacerbate inequalities in education. Schools and higher education providers will need to explore acquiring institutional licences for these products that can enable an equality of access for their students. Alternatively, education departments or higher education providers could develop their own generative AI tools using the GPT-44 (or similar generative AI models) Application Programming Interface (API) to create a custom environment specifically designed for learning and teaching (for example, the Khanmigo AI-powered learning system). Governments may also wish to consider providing access to more sophisticated existing US models, with the addition of gateways for the purposes of auditing student behaviour, and allowing teachers to access and monitor channels."},{"id":129,"value":"The inclusion of generative AI within education systems will require rethinking of how assessments are conducted, presenting an opportunity to improve assessment practices. Educators have raised concerns that the rise of generative AI will lead to increased cheating and plagiarism and reduce the validity of assessment items. One solution is to take an archaic approach by returning assessments to supervised pen and paper examinations or oral examinations, that exclude the possibility of using AI systems. While this may be appealing and have a role in certain situations, this approach alone will likely fail to meet the needs of many students, rolling back many of the positive changes (like online learning) that have helped expand access to education, and would miss an opportunity to embrace this technological revolution. Instead, education providers should be supported to embrace and resource multiple forms of assessments for key learning outcomes, providing multiple opportunities and multiple methods of assessing studentâ€™s knowledge and abilities. Research shows that assessments that relate to authentic tasks, apply knowledge in a realistic context, and emphasise and assess a range of skills, are perceived by students to have long-term benefits and are reasonable in their demands as being positive for their learning (Struyven et al. 2006). The types of assessments to which generative AI systems may pose academic integrity risks (e.g. essays and traditional examinations) have previously received criticism for being poor measures of a studentsâ€™ knowledge and abilities (Rudolph et al. 2023). This presents an opportunity to reevaluate how Australian educational institutions at all levels can redesign assessments to allow them to not only survive in the AI age, but also work better to promote deep understanding and learning in Australian students."},{"id":130,"value":"The widespread use of generative AI, particularly around student learning and performance also raises concerns around data privacy. These concerns include privacy of the underlying data upon which AI applications are trained, but also concerns around the use of information entered into these systems, particularly for AI systems that could help to provide educators feedback on how students are faring. Data privacy more broadly will be addressed by the ongoing consultation into the safe and responsible use of AI being conducted by the Department of Industry, Science and Resources, to which ATSE will be making a submission. Australian student data (such as contact details or grades) is currently stored internationally (for example via Google Classrooms), but given the nature of generative AI and emerging interaction patterns, the risk that very personal and potentially more risky data is stored about Australian students offshore is real and growing."},{"id":131,"value":"As generative AI becomes increasingly sophisticated, it will be more difficult to ensure student interactions are focused on the intended learning area. There is an emerging risk that generative AI tools are interacting conversationally with users around mental health and wellbeing. This leads to risks that students may be encouraged to talk to an AI system rather than a human. While for some students discussing mental health issues with an AI may make them more comfortable to seek help for mental health issues, some students may be less likely to access timely interventions, might receive poor advice, or mental ill health may even be exacerbated by such interactions. Systems with high levels of human intervention will still be necessary to identify students at risk and intervene swiftly and appropriately."}],"References-footnotes":[{"id":325,"value":"Bell G, Burgess J, Thomas J and Sadiq S (2023) Rapid Response Information Report: Generative AI - language models (LLMs) and multimodal foundation models (MFMs), https://www.chiefscientist.gov.au/GenerativeAI, accessed 27 June 2023."},{"id":326,"value":"Cobbold T (2021) The Disadvantage Burden of Public Schools is Three Times That of Private Schools, https://www.acsso.org.au/application/files/9916/2314/0367/The_Disadvantage_Burden_of_Public_Schools_   is_Three_Times_That_of_Private_Schools.pdf, accessed 9 June 2023."},{"id":327,"value":"Harper R (5 June 2023) â€˜An academic governance perspective.â€™, in Tertiary Education Qualifications & Standards Agency webinar: Implications of Generative Artificial Intelligence for Higher Education, https://www.youtube.com/watch?v=1V0f3pw2B_0, accessed 13 June 2023."},{"id":328,"value":"Jaeger C (1 February 2023) â€˜AI tool banned in Victorian state schoolsâ€™, The Age, accessed 13 June 2023, https://www.theage.com.au/national/victoria/ai-tool-banned-in-victorian-schools-as-implications-examined-   20230201-p5ch8h.html, accessed 13 June 2023."},{"id":329,"value":"Liu D, Ho E, Weeks R and Bridgeman A (2023) How AI can be used meaningfully by teachers and students in 2023, University of Sydney, https://educational-innovation.sydney.edu.au/teaching@sydney/how-ai-can- be-used-meaningfully-by-teachers-and-students-in-2023/, accessed 9 June 2023."},{"id":330,"value":"Longoni C, Fradkin A, Cian L and Pennycook G (21 June 2022) â€˜News from Generative Artificial Intelligence Is Believed Lessâ€™, in ACM International Conference Proceeding Series, Association for Computing Machinery, doi:10.1145/3531146.3533077."},{"id":331,"value":"Productivity Commission (2023) 5-year productivity inquiry: from learning to growth, https://www.pc.gov.au/inquiries/completed/productivity/report/productivity-volume8-education-skills.pdf,   accessed 15 June 2023."},{"id":332,"value":"Rudolph J, Tan Samson and Tan Shannon (2023) â€˜ChatGPT: Bullshit spewer or the end of traditional assessments in higher education?â€™, Journal of Applied Learning & Teaching, 6(1), doi:10.37074/jalt.2023.6.1.9."},{"id":333,"value":"Schneiders B (14 April 2023) â€˜Inside Australiaâ€™s university wage theft machineâ€™, The Sydney Morning Herald, accessed 15 June 2023, https://www.smh.com.au/business/workplace/inside-australia-s-university-"},{"id":334,"value":"wage-theft-machine-20230411-p5czn6.html, accessed 15 June 2023."},{"id":335,"value":"Struyven K, Dochy F and Janssens S (2006) â€˜Studentsâ€™ Perceptions about New Modes of Assessment in Higher Education: A Reviewâ€™, in Optimising New Modes of Assessment: In Search of Qualities and Standards, Kluwer Academic Publishers, doi:10.1007/0-306-48125-1_8."},{"id":336,"value":"Swiecki Z, Khosravi H, Chen G, Martinez-Maldonado R, Lodge JM, Milligan S, Selwyn N and GaÅ¡eviÄ‡ D (2022) â€˜Assessment in the age of artificial intelligenceâ€™, Computers and Education: Artificial Intelligence, 3, doi:10.1016/j.caeai.2022.100075."},{"id":337,"value":"University of Queensland (n.d.) RiPPLE An active, social and personalised learning platform, https://itali.uq.edu.au/digital-learning/learning-analytics/ripple, accessed 15 June 2023."}],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":164,"database_table_184385":1},"value":{"id":980196,"value":"PD","color":"light-red"}},{"ids":{"database_table_183319":165,"database_table_184385":1},"value":{"id":980196,"value":"PD","color":"light-red"}},{"ids":{"database_table_183319":167,"database_table_184385":1},"value":{"id":980196,"value":"PD","color":"light-red"}},{"ids":{"database_table_183319":166,"database_table_184385":2},"value":{"id":980180,"value":"guidelines","color":"light-yellow"}},{"ids":{"database_table_183319":163,"database_table_184385":10},"value":{"id":980190,"value":"curricula-changes","color":"light-green"}},{"ids":{"database_table_183319":162,"database_table_184385":11},"value":{"id":980191,"value":"new-policy","color":"dark-purple"}},{"ids":{"database_table_183319":168,"database_table_184385":38},"value":{"id":986019,"value":"respect-rights","color":"light-blue"}}],"Lookup":[{"id":162,"value":"Recommendation 1: Reverse bans on generative AI systems in schools introduced by state education departments and establish institutional access licencing agreements across the education sector."},{"id":163,"value":"Recommendation 2: Introduce age-appropriate AI instruction in Australian classrooms, supported by appropriate educator training and purpose-built AI tools or institutional access licences for commercial AI products."},{"id":164,"value":"Recommendation 3: Provide professional development opportunities, supported by professional development leave and other incentives, to teach existing educators how to engage with AI both inside and outside the classroom."},{"id":165,"value":"Recommendation 4: Require the inclusion of AI literacy training as part of initial teacher training programs."},{"id":166,"value":"Recommendation 5: Encourage the development of assessment guidance by education departments that is both resilient to AI developments and embraces opportunities presented by AI."},{"id":167,"value":"Recommendation 6: Develop and provide ethics and AI data privacy training for educators."},{"id":168,"value":"Recommendation 7: Develop appropriate interventions to protect young peopleâ€™s mental health, and deeply sensitive information."}]},{"id":15,"order":"15.00000000000000000000","submission_number":"15","Submitter":"Research for Educational Impact Strategic Research Centre, Deakin University","Type of org":{"id":977287,"value":"University-centre","color":"orange"},"Notes":"","Recommendations":[{"id":422,"value":"Fund social sciences research into how generative AI is altering knowledge making"},{"id":423,"value":"Counter ethical risks through regulation of governance and policies: these should promote ethical engagement with generative AI first and foremost, as a priority, rather than an add-on"},{"id":424,"value":"Teach (and assess) critical digital literacies to our students and educators across all curricula"},{"id":425,"value":"Promote educational experiences that promote open horizons and allow students to flourish"}],"Uses-opportunities":[],"Risks-challenges":[{"id":299,"value":"generative AI may draw from datasets that harvest artistic and intellectual works without permission or\nacknowledgement, denying the rights of and threatening the jobs of those who create this work\nboth now and into the future"},{"id":300,"value":"generative AI may be implemented by corporations and other bodies in ways that are profoundly unethical, for\nexample, through labour exploitation or data manipulation"},{"id":301,"value":"generative AI may exacerbate the threats already presented within a digital society: including the spread of\nmisinformation at scale, unacceptable environmental costs through computational requirements\nand the rising inequality of wealth distribution"}],"References-footnotes":[],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":424,"database_table_184385":10},"value":{"id":980190,"value":"curricula-changes","color":"light-green"}},{"ids":{"database_table_183319":425,"database_table_184385":10},"value":{"id":980190,"value":"curricula-changes","color":"light-green"}},{"ids":{"database_table_183319":423,"database_table_184385":11},"value":{"id":980191,"value":"new-policy","color":"dark-purple"}},{"ids":{"database_table_183319":422,"database_table_184385":12},"value":{"id":980192,"value":"research-investment","color":"orange"}}],"Lookup":[{"id":422,"value":"Fund social sciences research into how generative AI is altering knowledge making"},{"id":423,"value":"Counter ethical risks through regulation of governance and policies: these should promote ethical engagement with generative AI first and foremost, as a priority, rather than an add-on"},{"id":424,"value":"Teach (and assess) critical digital literacies to our students and educators across all curricula"},{"id":425,"value":"Promote educational experiences that promote open horizons and allow students to flourish"}]},{"id":16,"order":"16.00000000000000000000","submission_number":"16","Submitter":"Australian Curriculum, Assessment and Reporting Authority","Type of org":{"id":977282,"value":"Govt","color":"orange"},"Notes":"","Recommendations":[{"id":169,"value":"ACARA understands the parallels that exist between curriculum implementation and teacher professional development in building capacity for teaching and learning with and about AI. Through the provision of professional development, with a focus on the intent of the curriculum, teachers will gain an equivalent understanding to that of their students about the purpose, use, structure and risks of using generative AI and other types of AI more broadly. ACARA will be developing some professional learning modules and would be keen to partner with jurisdictions and sectors and teacher professional associations to support teachers to plan and implement the curriculum relevant to understanding AI"},{"id":170,"value":"ACARA recommends that all materials designed to guide educators about the use of AI should provide clear definitions of what we mean by AI and generative AI, and make it clear that there are a range of AI types; for example, Chat GPT is only one example of generative AI."},{"id":171,"value":"Students have preferences for using digital tools creatively and responsibly, to try new things and to fail as part of personal growth. This should be considered in the context of how the curriculum supports them to do this and how using and designing AI may play an important part in engaging students in their learning and providing opportunities for their future lives."},{"id":172,"value":"ACARA is currently providing information to key educational stakeholders to support them with questions about AI in the Australian Curriculum and is planning to develop more detailed information to show why it is important to teach about AI while recognising that teachers and students are using it, in and out of the classroom. The ability to have discussions about the ethical consideration (eg cheating) and the potential limitations (eg if you donâ€™t know the content how will you know whether Chat GPT is correct), but also the benefits of AI (eg retrieving and synthesising a large volume of information) is essential."},{"id":173,"value":"There is considerable concern about students using AI to cheat on tasks set by the teacher, and particularly assessment tasks. ACARA as the assessment authority could consider developing a range of strategies/suggestions to use AI without the concern about cheating."},{"id":174,"value":"ACARA has been tasked with exploring the development and delivery of optional support resources to implement the national curriculum as part of Action 19 in the National Teacher Workforce Action Plan. There may be the opportunity to look at the synergies between future work related to AI and activities related to Action 19."},{"id":175,"value":"ACARA could provide more explicit advice on how the English curriculum can support students to be more critical of information they read and are exposed to when using digital systems. This could also include highlighting how the critical and creative thinking general capability can be addressed as part of this approach."}],"Uses-opportunities":[],"Risks-challenges":[],"References-footnotes":[],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":169,"database_table_184385":1},"value":{"id":980196,"value":"PD","color":"light-red"}},{"ids":{"database_table_183319":172,"database_table_184385":1},"value":{"id":980196,"value":"PD","color":"light-red"}},{"ids":{"database_table_183319":170,"database_table_184385":2},"value":{"id":980180,"value":"guidelines","color":"light-yellow"}},{"ids":{"database_table_183319":173,"database_table_184385":6},"value":{"id":980185,"value":"new-assessment-models","color":"darker-pink"}},{"ids":{"database_table_183319":175,"database_table_184385":10},"value":{"id":980190,"value":"curricula-changes","color":"light-green"}},{"ids":{"database_table_183319":171,"database_table_184385":14},"value":{"id":980193,"value":"prepare-learners","color":"dark-gray"}},{"ids":{"database_table_183319":174,"database_table_184385":19},"value":{"id":980186,"value":"capacity-building","color":"light-yellow"}}],"Lookup":[{"id":169,"value":"ACARA understands the parallels that exist between curriculum implementation and teacher professional development in building capacity for teaching and learning with and about AI. Through the provision of professional development, with a focus on the intent of the curriculum, teachers will gain an equivalent understanding to that of their students about the purpose, use, structure and risks of using generative AI and other types of AI more broadly. ACARA will be developing some professional learning modules and would be keen to partner with jurisdictions and sectors and teacher professional associations to support teachers to plan and implement the curriculum relevant to understanding AI"},{"id":170,"value":"ACARA recommends that all materials designed to guide educators about the use of AI should provide clear definitions of what we mean by AI and generative AI, and make it clear that there are a range of AI types; for example, Chat GPT is only one example of generative AI."},{"id":171,"value":"Students have preferences for using digital tools creatively and responsibly, to try new things and to fail as part of personal growth. This should be considered in the context of how the curriculum supports them to do this and how using and designing AI may play an important part in engaging students in their learning and providing opportunities for their future lives."},{"id":172,"value":"ACARA is currently providing information to key educational stakeholders to support them with questions about AI in the Australian Curriculum and is planning to develop more detailed information to show why it is important to teach about AI while recognising that teachers and students are using it, in and out of the classroom. The ability to have discussions about the ethical consideration (eg cheating) and the potential limitations (eg if you donâ€™t know the content how will you know whether Chat GPT is correct), but also the benefits of AI (eg retrieving and synthesising a large volume of information) is essential."},{"id":173,"value":"There is considerable concern about students using AI to cheat on tasks set by the teacher, and particularly assessment tasks. ACARA as the assessment authority could consider developing a range of strategies/suggestions to use AI without the concern about cheating."},{"id":174,"value":"ACARA has been tasked with exploring the development and delivery of optional support resources to implement the national curriculum as part of Action 19 in the National Teacher Workforce Action Plan. There may be the opportunity to look at the synergies between future work related to AI and activities related to Action 19."},{"id":175,"value":"ACARA could provide more explicit advice on how the English curriculum can support students to be more critical of information they read and are exposed to when using digital systems. This could also include highlighting how the critical and creative thinking general capability can be addressed as part of this approach."}]},{"id":17,"order":"17.00000000000000000000","submission_number":"17","Submitter":"Edith Cowan University","Type of org":{"id":977279,"value":"University","color":"darker-blue"},"Notes":"","Recommendations":[{"id":109,"value":"1. Universities should be supported to lead public debate about the ethics of AI, as university graduates should be equipped not just as users of AI, but future leaders of ethical AI development and adoption. Educational programs for educators and students should therefore include all known ethical issues, risks and challenges."},{"id":110,"value":"2. Investments will need to be made in the higher education workforce to: â€¢ develop their knowledge and skills in the productive and ethical use of AI to enable them to create relevant curricula for students; â€¢ enhance their teaching capabilities to enable the use of intentional pedagogies that develop uniquely human skills,  and â€¢ build their assessment design abilities so they can reconceptualise assessment to maintain course integrity."},{"id":111,"value":"3. The Australian Qualifications Framework must be capable of enabling the necessary curriculum renewal, particularly in its framings, definitions and specifications for knowledge and skills."},{"id":112,"value":"4. Professional accreditation bodies, industry and universities will need to be aligned in their positions in order to enable responsive and coherent courses."},{"id":113,"value":"5. Federal sponsorship would best enable the sector-wide collaboration needed to conceptualise and guide assessment renewal while maintaining the quality and reputation of Australian higher education."}],"Uses-opportunities":[{"id":74,"value":"Curriculum shift from knowledge to skills - Many educational researchers predict that Generative AI will prompt significant transformation of university curriculum, teaching, and assessment in the short, medium and longer term. The likely shifts are outlined below. These shifts have been underway for some time, but they will likely accelerate and be required at scale in response to AI."},{"id":75,"value":"Teaching shift towards new pedagogies - Many educational researchers predict that Generative AI will prompt significant transformation of university curriculum, teaching, and assessment in the short, medium and longer term. The likely shifts are outlined below. These shifts have been underway for some time, but they will likely accelerate and be required at scale in response to AI."},{"id":76,"value":"Assessment shift towards authentic, integrative tasks - Many educational researchers predict that Generative AI will prompt significant transformation of university curriculum, teaching, and assessment in the short, medium and longer term. The likely shifts are outlined below. These shifts have been underway for some time, but they will likely accelerate and be required at scale in response to AI."}],"Risks-challenges":[{"id":95,"value":"In the ECU student survey, only about 30% of students who had used AI expressed someconfidence in using AI ethically. Over 50% of students were not at all confident, had mixed feelings,or felt unable to judge. With this in mind, the biggest risks to society are perhaps posed not by Generative AI but by its uncritical adoption."},{"id":96,"value":"Bias and a lack of transparency."},{"id":97,"value":"Privacy"},{"id":98,"value":"Human exploitation, including copyright and Intellectual Property infringement."}],"References-footnotes":[{"id":213,"value":"https://news.harvard.edu/gazette/story/2020/10/ethical-concerns-mount-as-ai-takes-bigger-decision-making-role/2"},{"id":214,"value":"https://www.theverge.com/features/23764584/ai-artificial-intelligence-data-notation-labor-scale-surge-remotasks-openaichatbots3"},{"id":215,"value":"https://time.com/6247678/openai-chatgpt-kenya-workers/4"},{"id":216,"value":"https://www.technologyreview.com/2022/04/19/1049378/ai-inequality-problem/5"},{"id":217,"value":"https://www.newyorker.com/science/annals-of-artificial-intelligence/will-ai-become-the-new-mckinsey6"},{"id":218,"value":"https://www.unesco.org/en/artificial-intelligence/recommendation-ethics?hub=32618"}],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":112,"database_table_184385":8},"value":{"id":980188,"value":"new-workforce-model","color":"light-brown"}},{"ids":{"database_table_183319":109,"database_table_184385":10},"value":{"id":980190,"value":"curricula-changes","color":"light-green"}},{"ids":{"database_table_183319":112,"database_table_184385":10},"value":{"id":980190,"value":"curricula-changes","color":"light-green"}},{"ids":{"database_table_183319":111,"database_table_184385":11},"value":{"id":980191,"value":"new-policy","color":"dark-purple"}},{"ids":{"database_table_183319":113,"database_table_184385":17},"value":{"id":980195,"value":"resourcing","color":"dark-cyan"}},{"ids":{"database_table_183319":110,"database_table_184385":19},"value":{"id":980186,"value":"capacity-building","color":"light-yellow"}}],"Lookup":[{"id":109,"value":"1. Universities should be supported to lead public debate about the ethics of AI, as university graduates should be equipped not just as users of AI, but future leaders of ethical AI development and adoption. Educational programs for educators and students should therefore include all known ethical issues, risks and challenges."},{"id":110,"value":"2. Investments will need to be made in the higher education workforce to: â€¢ develop their knowledge and skills in the productive and ethical use of AI to enable them to create relevant curricula for students; â€¢ enhance their teaching capabilities to enable the use of intentional pedagogies that develop uniquely human skills,  and â€¢ build their assessment design abilities so they can reconceptualise assessment to maintain course integrity."},{"id":111,"value":"3. The Australian Qualifications Framework must be capable of enabling the necessary curriculum renewal, particularly in its framings, definitions and specifications for knowledge and skills."},{"id":112,"value":"4. Professional accreditation bodies, industry and universities will need to be aligned in their positions in order to enable responsive and coherent courses."},{"id":113,"value":"5. Federal sponsorship would best enable the sector-wide collaboration needed to conceptualise and guide assessment renewal while maintaining the quality and reputation of Australian higher education."}]},{"id":18,"order":"18.00000000000000000000","submission_number":"18","Submitter":"RMIT Blockchain Innovation Hub Researchers","Type of org":{"id":977287,"value":"University-centre","color":"orange"},"Notes":"","Recommendations":[],"Uses-opportunities":[{"id":359,"value":"Increased productivity of workers"},{"id":360,"value":"Creation of more robust research"},{"id":361,"value":"Provision of more bespoke learning opportunities for students"},{"id":362,"value":"Realization of additional benefits through combination with other frontier technologies, such as data analytics and new decentralised credentialing infrastructure."},{"id":363,"value":"Development of more robust research through the use of generative AI as a writing tool"},{"id":364,"value":"Utilization of generative AI as an analytic tool alongside other scholarly methods"},{"id":365,"value":"Guidance and feedback from generative AI models acting as mentors for researchers"},{"id":367,"value":"Improved productivity and quality in research"},{"id":368,"value":"Revelation of patterns in case studies through generative AI analysis"},{"id":369,"value":"Assistance in overcoming writer's block and generating new ideas"},{"id":370,"value":"Provision of bespoke tutorial content and multiple perspectives through generative AI models in the peer review process"},{"id":371,"value":"Designing bespoke case studies."},{"id":372,"value":"Creating assessment tasks."},{"id":373,"value":"Generating rubrics"},{"id":374,"value":"Giving detailed feedback to students"}],"Risks-challenges":[],"References-footnotes":[{"id":703,"value":"https://www.youtube.com/watch?v=Awsw3oN03oo"}],"Processed":true,"Recco_tags":[],"Lookup":[],"FLAG":""},{"id":19,"order":"19.00000000000000000000","submission_number":"19","Submitter":"University of Technology Sydney (UTS), Centre for Research on Education in a Digital Society","Type of org":{"id":977287,"value":"University-centre","color":"orange"},"Notes":"","Recommendations":[{"id":153,"value":"Understanding the potential and risks of genAI is a cross-sector, cross-discipline, societal concern; national priorities should reflect this through recognition of and support for interdisciplinarity and the social sciences in genAI innovation across sectors. - Recommendation 1: support interdisciplinary and cross -sector learning for ethical engagement with genAI, in the short term through support for targeted professional learning or microcredentials, and in the mid-term through addressing concerns raised regarding the jobs ready graduates package of reforms"},{"id":154,"value":"Evidence is a central requirement of ethical AI (merit in the National Statement; justification and transparency in many AI ethics frameworks). It is crucial that investments in EdTech are underpinned by evidence that any tools used will support the outcomes they claim to target. Support the critique, creation, and dissemination of evidence regarding claims of genAI supporting learning through: - Recommendation 2: Development of funding streams, and support for innovative approaches to evidence development and sharing across sectors, regarding genAI. By its nature this work must include social scientists which may require new funding streams, or/and reform of the R&D tax credit."},{"id":155,"value":"Recommendation 3: Support of interdisciplinary teams for genAI research both on fundamental evaluation of tool uses, and the dissemination of this evidence with and across education systems (including educators, learners, and developers)."},{"id":156,"value":"Learning environments are one space where genAI will clearly have significant impact; understanding this impact and appropriate (dis)engagement with genAI in learning requires a focus on the fundamental purposes and processes of learning. - Recommendation 4: Values underpin both our aims in education, and our aims for genAI, shaping what we learn (e.g., â€˜AI literacyâ€™), and how we learn (e.g., new AI tools). Support the convening of public fora and engagement activities to develop collective, democratic, values-led responses regarding the kinds of futures Australians want in use of genAI in education."},{"id":157,"value":"Recommendation 5: Understanding, evaluating, and sharing effective practices: There can be no strengths of genAI in education without teachers who will work with, create approaches for, and thus need to learn about genAI. This has implications, drawing on our other recommendations. o Any consideration of and planning cycles towards use of genAI in education should be with respect to the values and aims identified in Recommendation 4 o Resourcing should be provided to develop models to assess AI literacy across the range of stakeholders, and identify needs and strategies to develop this literacy; resources derived from this activity can feed into guidelines to help navigate the ethics of genAI (Recommendation 6) o Support should be provided for bespoke professional learning for teachers from all sectors, to develop algorithmic literacy to learn to engage with genAI and capacity for designing to learn with genAI tools Recommendation 1; Recommendation 7). o Evidence should underpin any incorporation of genAI (see Recommendation 3). This evidence should be shared and co-developed with and by teachers, informed by student voice, and in mentoring and partnerships with research universities and education institutions. It may also be appropriate to target resourcing to creation of evidence-informed models that encode shared values (Recommendation 4), and the body of existing evidence regarding learning technologies, to create tuned models or/and educationally-tailored system prompts (prompts that modify user input to provide context). Sharing among teachers has been shown to be an effective mechanism for supporting innovative approaches, particularly through creation of toolkit resources that provide practical guidance for design for learning alongside evidence and high-level principles."},{"id":158,"value":"Recommendation 6: The concerns of applying genAI in education in Australia specifically are unclear, with few practical guidelines available for stakeholders to understand or navigate these issues. Support should be provided for development of practical guidelines for a range of stakeholders regarding use of genAI in Australian learning contexts."},{"id":159,"value":"Recommendation 7: Provide support for Professional Learning to target skills for staff across institutions serving diverse communities, to support communities in effectively (dis)engaging with tools, and to target support of vulnerable populations and specific risks"},{"id":160,"value":"Recommendation 8: Ensure equitable access to genAI through tackling digital divides in affordability, accessibility, and capability. Target schools that are most impacted by digital divides"}],"Uses-opportunities":[{"id":96,"value":"Provide customised feedback and guidance"},{"id":97,"value":"because genAI produces digital materials that can be shared, and digitally discussed, the potential for new kinds of collective prototyping and knowledge building is significant, with potential to connect us and our world in new ways. For example, genAI can stimulate creative thinking and improve innovation through helping to identify open areas to explore. In terms of design, it can enable much faster iteration cycles for product/service design."},{"id":98,"value":"GenAI must not be treated as a panacea for wider concerns in education systems, including teacher shortages (Hunter et al., 2022). The mantra â€˜Always Center Educators (ACE)â€™ (Cardona et al., 2023, p. 25) has been suggested as a way to drive AI for enhancement of teaching and learning. In this approach, AI is seen as not only a way to make teachersâ€™ jobs easy, or to speed up administrative tasks, but as a tool for understanding students better, and supporting teachers in directing their creative responsiveness to learners effectively (Cardona et al., 2023)."}],"Risks-challenges":[{"id":110,"value":"AI, and generative AI, have potential to disrupt many aspects of our lives. How this disruption unfolds, and to whom the benefits and costs accrue is fundamentally a social problem."},{"id":111,"value":"It is crucial that investments in EdTech are underpinned by evidence that any tools used will support the outcomes they claim to target. Failure to do so is at best an opportunity cost, and at worst misinformation that could lead to significant harms. However, the evidence base for many EdTech tools and their uses in particular contexts is not strong. A recent review of the 100 most frequently used EdTech tools in US schools found that 26/100 met any level on a formal evidence scale, where the lowest level requires just that there is some formalised background evidence synthesis that supports a theory of change for the tool use. This aligns with other evidence indicating that principles derived from research on learning are often not adhered to in app development (Meyer et al., 2021) and that in the specific context of ebook apps targeting children, app features may distract from comprehension (Furenes et al., 2021; Kucirkova, 2023). This may lead to underuse, poor use, or simply poor procurement of technologies (ITSE, 2019). Australian values and the specific needs and contexts here should be an important consideration in the evaluation for particular uses of global products that are trained on web data that may not represent Australian values or experiences"},{"id":112,"value":"Assurance of learning is the most commonly discussed concern in current media coverage of genAIin higher education (Sullivan et al., 2023), this comprises two features: 1. Integrity â€“ i.e., assuring that learners are engaging in the activities they say they are. A number of helpful documents have been produced A number of helpful documents have been produced including from the UKâ€™s QAA (QAA, 2023) and JISC (Webb, 2023), the European Network for Academic Integrity (Foltynek et al., 2023), and the Australian Academic Integrity Network (AAIN) Generative AI Working Group, (AAIN, 2023a), alongside individual institutional responses (see, AAIN, 2023b) with UTS developing five student-centred principles to guide use of genAI (LX at UTS, 2023) 2. Validity â€“ i.e., assuring that the tasks we ask learners to engage with are good indicators of the outcomes claimed when gaining an accredited qualification. This feature of genAI is less explored, although see UTS principles below (LX at UTS, 2023)"},{"id":113,"value":"Learning processes and outcomes â€“ may be impacted by genGPT; it was this â€“ the concern that chatGPT would hamper critical thinking â€“ that underpinned New York City Department of Educationâ€™s ban on chatGPT in early 2023 (later lifted). Threshold concepts describe the key knowledge or concepts required in order to progress to a deeper level of understanding regarding a topic; once we grasp them, they change our understanding. They interact with particular methods and tools, such that sometimes new technologies mean we no longer need to learn a particular skill. For example, tools for calculating, from the abacus to the pocket calculator, through obviating understanding of manual use of log tables. It is not yet clear what impact being able to â€˜shortcutâ€™ via genAI will have, and where we should still require learning of the underlying composite skills in order to assure understanding of the higher-level skill."},{"id":114,"value":"Normative features of learning â€“ are about values, or the kinds of learning we think are important. Technologies may shift these values (Heersmink & Knight, 2018), and particular domains â€“ including the professions â€“ may make value judgements regarding the skills and knowledge it is important to â€˜haveâ€™ manually, and those we can augment with technology. Understanding both these values, and what different communities are doing is important. Aspects of this concern are addressed through analyses of employer needs and university offerings (Kitto, 2022), however the impact of genAI, and the potential for genAI to support learners in navigating professional needs, is not yet clear."},{"id":115,"value":"Human dignity and rights â€“ are expressions of fundamental values and rights, which may be impacted by genAI in a range of ways (Fergusson et al., 2023). Issues in this space include concerns regarding the right to privacy, creation and spread of misinformation, exacerbation of discrimination, impacts on intellectual property and related access to cultural heritage, and impacts on labour relations (Fergusson et al., 2023). It was this concern that appeared to underpin NSW and QLD Departments of Education from restricting chatGPT access in public schools, due to safeguarding concerns regarding potential access to explicit and harmful content (Cassidy, 2023). Understanding these issues in the particular contexts of learning environments is important for tackling them, with consideration of both the legal context â€“ as yet unclear â€“ and ethical concerns. The Electronic Privacy Information Centre (EPIC) (Fergusson et al., 2023) provide a recent overview (contextualised to US law) of genAI and fundamental rights. These risks derive from three issues: (1) harms in the nature of genAI models, their data, and use (e.g., environmental impacts); (2) harms in unintentional inappropriate use (e.g., lack of awareness regarding poor ability for certain tasks); (3) harms through intentional maleficent use (e.g., creation of misinformation). Across these, genAI has potential to foster a breakdown in trust between people, and biases in representation of people and cultures that may lead to Inquiry into the use of generative artificial intelligence in the Australian education system Submission 19 13 inequitable outcomes. It is important that learners and educators understand this context, including any legal obligations. Three particular areas of concern are: Privacy, Intellectual Property, and Information manipulation and representation."},{"id":116,"value":"Challenge: Misalignment of professional needs â€“ that education institutions, professional bodies, and professional practice become misaligned in terms of how genAI is used and what is taught, in ways that hamper professional sectors or their learning."},{"id":117,"value":"Challenge: Breakdowns in capacity â€“ that genAI may hamper human capacity, through (1) overreliance thus hampering human capacity through reduction in individual capabilities, (2) workforce restructuring that reduces human autonomy and input into decision processes, or (3) overwhelming systems through mass production of content."},{"id":118,"value":"A set of skills, including technical and social skills, will underpin the effective use of genAI; correspondingly, there is a risk that failure to cultivate this capacity in Australia, or in specific sectors, or parts of the population, will lead to harms and inequities."},{"id":119,"value":"Justice and inequitable experience of benefits and harms in genAI use: The potential of genAI to further exacerbate existing issues relating to marginalisation and poorer outcomes must be considered, alongside any potential benefits of genAI and ensuring that access to these benefits follows a justice principle; that the greatest benefits should flow to the most marginalised. Ample evidence exists that while existing technologies provide significant benefits across communities, there is inequitable exposure to harms including for Aboriginal and Torres Strait Islander families (eSafety Commissioner, 2023a), LGBTIQ+ people (eSafety Commissioner, 2021; Johns et al., 2022), culturally and linguistically diverse communities (eSafety Commissioner, 2020; Harris & Johns, 2021), and women (eSafety Commissioner, 2022c), with negative online experiences common across communities (eSafety Commissioner, 2022a), and young people keen for support in navigating eSafety (eSafety Commissioner, 2023b). Teachers face particular risk of harms, with high numbers reporting abuse (Burns et al., 2019; Williams, 2010) and emerging indications of new kinds of online abuse (Schultz, 2023)."},{"id":120,"value":"Justice and inequities in the burdens of data scraping and model outcomes: the burden of your data being scraped should not lead to inequitable outcomes in the benefits of models trained on that data. In a report commissioned by UNESCO in 2021, Johns et al. (2022) found that the safety of LGBTQ+ young people across the Asia Pacific region had been hampered by a rising tide of hate speech and misinformation during the COVID-19 pandemic, which targeted LGBTQ+ youth. Platform regulation, user tools and safety education designed to address these harms were regarded ambivalently by some young people in the study who spoke of the importance of social media in providing forums for community building and connection, while acknowledging that platform algorithms and business models also promote and exacerbate hate speech and harm (Johns et al., 2022, p. 30)."},{"id":121,"value":"Justice and inequities in access to opportunities to learn with and about genAI: Digital divides are comprised of inequities in affordability of devices and connectivity, accessibility across learners with diverse needs, and the abilities to engage effectively with these tools as both educators and learners. Australia has a significant digital divide, associated particularly with income and regional and remote location, and their intersection (Ingrid, 2020). Compounding concerns regarding exacerbation of digital divides is the challenge that those in regional and remote communities may have less access to professional learning opportunities, impacting capacity to support learning in schools."},{"id":122,"value":"Accessibility and learning support: GenAI may also afford opportunities for supporting accessibility of materials, helping learners with disabilities (Marino et al., 2023). Potential uses include checking for structure and clarity of definitions, visual accessibility and genAI-automated modifications for different kinds of visual needs (e.g. variations in colour perception), video captioning, etc. (McMurtrie, 2023; Young & Maher, forthcoming). However, there is also potential for these tools to have different impacts on disabled students (Guo et al., 2020), for example through impacts on learning processes, and different intersections with existing learning needs, neither of which are currently well understood. Outside of formal learning contexts, there are also concerns that tools provided to support people may also expose that data inappropriately, for example in hiring processes that provide accessibility options, but without making it clear if that data will be visible to the hiring organisation (Wall & Schellmann, 2021). This concern of justice could exacerbate existing negative online experiences of people with intellectual disability (eSafety Commissioner, 2022b). Moreover, although there are some potentials in this space, caution must be taken that genAI does not substitute for appropriate resourcing to fulfil statutory obligations, particularly where the worth of the tools is not well established with respect to efficacy."},{"id":123,"value":"Australian values: In the context of genAI itâ€™s also important to consider the particular values and context of Australia, which may not be well represented in the underlying data on which generative AI is trained, nor respect fundamental concerns of justice in Australia. While Nature has set out principles of genAI use in scholarship, as has COPE, they focus on authorship issues (Nature, 2023) rather than broader issues of justice in research. Uses of generative AI should not result in any diluting of information regarding Australia and our commitments and challenges. For example, there should be protections for Indigenous Cultural and Intellectual Property (ICIP). â€œThose who could be exploited by AI should be shaping its projectsâ€ (Kalluri, 2020)."}],"References-footnotes":[{"id":229,"value":"AAIN. (2023a). AAIN Generative Artificial Intelligence Guidelines. https://www.teqsa.gov.au/sites/default/files/2023-04/aain-generative-ai-guidelines.pdf"},{"id":230,"value":"AAIN. (2023b). Summary of Institutional Responses to the use of Generative Artificial Intelligence. https://cdn.csu.edu.au/__data/assets/pdf_file/0007/4187851/AAIN-Institutional-Responses-to-the-use-of-Generative-Artificial-Intelligence.pdf"},{"id":231,"value":"Academy of the Social Sciences. (2023). Submission to the Australian Universities Accord Panel. https://socialsciences.org.au/publications/submission-universities-accord/"},{"id":232,"value":"Academy of the Social Sciences. (2021). State of the Social Sciences. State of the Social Sciences. https://stateofthesocialsciences.org.au/research/"},{"id":233,"value":"ADA Lovelace Institute. (2021). JUST AI. https://www.adalovelaceinstitute.org/just-ai/"},{"id":234,"value":"AI Incidents. (2023). Artificial Intelligence Incident Database search for chatGPT. https://incidentdatabase.ai/apps/discover/"},{"id":235,"value":"Bak-Coleman, J., Bergstrom, C. T., Jacquet, J., Mickens, J., Tufekci, Z., & Roberts, T. (2023). Create an IPCC-like body to harness benefits and combat harms of digital tech. Nature, 617(7961), 462â€“464. https://doi.org/10.1038/d41586-023-01606-9"},{"id":236,"value":"Better Sharing for Generative AI. (2023, February 6). Creative Commons. https://creativecommons.org/2023/02/06/better-sharing-for-generative-ai/"},{"id":237,"value":"Bossu, C., Fountain, W., Smyth, R., & Brown, N. (2016). Developing Australian Academicsâ€™ Capacity: Supporting the Adoption of Open Educational Practices in Curriculum Design."},{"id":238,"value":"British Academy. (2022). Digital Society. The British Academy. https://www.thebritishacademy.ac.uk/programmes/digital-society/"},{"id":239,"value":"Bromham, L., Dinnage, R., & Hua, X. (2016). Interdisciplinary research has consistently lower funding success. Nature, 534(7609), Article 7609. https://doi.org/10.1038/nature18315"},{"id":240,"value":"Buckingham Shum, S. (2022). The UTS â€œEdTech Ethicsâ€ Deliberative Democracy Consultation: Rationale, Process and Outcomes. https://cic.uts.edu.au/projects/edtech-ethics/"},{"id":241,"value":"Burden, K., & Kearney, M. (2018). Designing an educator toolkit for the mobile learning age. International Journal of Mobile and Blended Learning, 10(2), 88â€“99. https://doi.org/10.4018/ijmbl.2018040108"},{"id":242,"value":"Burns, E., Billett, P., & Fogelgarn, R. (2019, May 5). Almost every Australian teacher has been bullied by students or their parents, and itâ€™s taking a toll. The Conversation. http://theconversation.com/almost-every-australian-teacher-has-been-bullied-by-students-or-their-parents-and-its-taking-a-toll-116058"},{"id":243,"value":"Cardona, M. A., RodrÃ­guez, R. J., & Ishmael, K. (2023). Artificial Intelligence and the Future of Teaching and Learning: Insights and Recommendations. U.S. Department of Education, Office of Educational Technology. https://www2.ed.gov/documents/ai-report/ai-report.pdf"},{"id":244,"value":"Cassidy, C. (2023, January 22). Queensland public schools to join NSW in banning students from ChatGPT. The Guardian. https://www.theguardian.com/australia-news/2023/jan/23/queensland-public-schools-to-join-nsw-in-banning-students-from-chatgpt"},{"id":245,"value":"Cetindamar, D., Kitto, K., Wu, M., Zhang, Y., Abedin, B., & Knight, S. (2022). Explicating AI literacy of employees at digital workplaces. IEEE Transactions on Engineering Management, 1â€“14. https://doi.org/10.1109/TEM.2021.3138503"},{"id":246,"value":"Department for Education (DfE). (2023). Generative artificial intelligence in education. Department for Education, UK Government. https://www.gov.uk/government/publications/generative-artificial-intelligence-in-education"},{"id":247,"value":"Department of Business. (2023, May 22). Assess if your R&D activities are eligible for the R&D Tax Incentive | business.gov.au [101 page]. https://business.gov.au/grants-and-programs/research-and-development-tax-incentive/assess-if-your-randd-activities-are-eligible"},{"id":248,"value":"Digital Futures Commission. (2023). A Blueprint for Education Data. 5Rights Foundation. https://digitalfuturescommission.org.uk/wp-content/uploads/2023/03/A-Blueprint-for-Education-Data-FINAL-Online.pdf"},{"id":249,"value":"EdTech Labs. (2020). UCL EdTech Labs Programmes. UCL EdTech Labs. https://www.ucledtechlabs.com"},{"id":250,"value":"EDUCATE. (2020). UCL EDUCATE Accelerator | EdTech Accelerator | London. UCL EDUCATE Accelerator | EdTech Accelerator | London. https://www.ucleducate.com/"},{"id":251,"value":"Education Council. (2019). Alice Springs (Mparntwe) Declaration."},{"id":252,"value":"EduGrowth. (2020). Australian EdTech ecosystem snapshot 2020. https://edugrowth.org.au/programs/ecosystem/edtech-snapshot/"},{"id":253,"value":"eSafety Commissioner. (2020). Online hate speech. ESafety Commissioner. https://www.esafety.gov.au/research/online-hate-speecha"},{"id":254,"value":"eSafety Commissioner. (2021). Protecting LGBTIQ+ voices online. ESafety Commissioner. https://www.esafety.gov.au/research/protecting-lgbtiq-voices-online"},{"id":255,"value":"eSafety Commissioner. (2022a). Australiansâ€™ negative online experiences 2022. ESafety Commissioner. https://www.esafety.gov.au/research/australians-negative-online-experiences-2022"},{"id":256,"value":"eSafety Commissioner. (2022b). How adults with intellectual disability experience online abuse. ESafety Commissioner. https://www.esafety.gov.au/research/how-adults-intellectual-disability-experience-online-abuse"},{"id":257,"value":"eSafety Commissioner. (2022c). Women In The Spotlight: How online abuse impacts women in their working lives. ESafety Commissioner. https://www.esafety.gov.au/research/how-online-abuse-impacts-women-working-lives"},{"id":258,"value":"eSafety Commissioner. (2023a). Cool, beautiful, strange and scary: The online experiences of Aboriginal and Torres Strait Islander children and their parents and caregivers. ESafety Commissioner. https://www.esafety.gov.au/research/online-experiences-aboriginal-torres-strait-islander-children-parents-caregivers"},{"id":259,"value":"eSafety Commissioner. (2023b). Youth engagement and online safety. ESafety Commissioner. https://www.esafety.gov.au/research/youth-engagement-and-online-safety"},{"id":260,"value":"European Commission. (2022). Ethical guidelines on the use of artificial intelligence and data in teaching and learning for educators | European Education Area. European Commission. https://education.ec.europa.eu/node/2285"},{"id":261,"value":"European Commission. Joint Research Centre. & Organisation for Economic Co operation and Development. (2021). AI watch, national strategies on artificial intelligence: A European perspective. Publications Office. https://data.europa.eu/doi/10.2760/069178"},{"id":262,"value":"Fergusson, G., Fitzgerald, C., Frascella, C., Ioro, M., McBrein, T., Schroeder, C., Winters, B., & Zhou, E. (2023). Generating Harms: Generative AIâ€™s Impact & Paths Forward (G. Fergusson, B. Winters, & E. Zhou, Eds.). Electronic Privacy Information Centre (EPIC). https://epic.org/wp-content/uploads/2023/05/EPIC-Generative-AI-White-Paper-May2023.pdf"},{"id":263,"value":"Foltynek, T., Bjelobaba, S., Glendinning, I., Khan, Z. R., Santos, R., Pavletic, P., & Kravjar, J. (2023). ENAI Recommendations on the ethical use of Artificial Intelligence in Education. International Journal for Educational Integrity, 19(1), Article 1. https://doi.org/10.1007/s40979-023-00133-4"},{"id":264,"value":"Furenes, M. I., Kucirkova, N., & Bus, A. G. (2021). A Comparison of Childrenâ€™s Reading on Paper Versus Screen: A Meta-Analysis. Review of Educational Research, 91(4), 483â€“517. https://doi.org/10.3102/0034654321998074"},{"id":265,"value":"Go8. (2022). Essential decisions for national success Supporting Australian research. Go8. https://go8.edu.au/report-supporting-australian-research"},{"id":266,"value":"Gulson, K., Swist, T., Knight, S., & Kitto, K. (2021). Technical democracy, fairness and the UK exam algorithm: Making a â€˜design Thingâ€™ to explore bias in automated grading systems [Conference presentation]. AARE. https://www.aare.edu.au/events/2021-conference/"},{"id":267,"value":"Gulson, K., Thompson, G., Swist, T., Kitto, K., Rutkowski, L., Rutkowski, D., Hogan, A., Zhang, V., & Knight, S. (2022). Automated Essay Scoring in Australian Schools: Collective Policymaking (2653-6757 No. 2653â€“6757; Education Innovations Policy Brief Series). Sydney Social Sciences and Humanities Advanced Research Centre (SSSHARC). https://opus.lib.uts.edu.au/handle/10453/163616"},{"id":268,"value":"Guo, A., Kamar, E., Vaughan, J. W., Wallach, H., & Morris, M. R. (2020). Toward fairness in AI for people with disabilities SBG@a research roadmap. ACM SIGACCESS Accessibility and Computing, 125, 2:1. https://doi.org/10.1145/3386296.3386298"},{"id":269,"value":"Haering, M., Bano, M., Zowghi, D., Kearney, M., & Maalej, W. (2021). Automating the evaluation of education apps with app store data. IEEE Transactions on Learning Technologies, 14(1), 16â€“27. https://doi.org/10.1109/tlt.2021.3055121"},{"id":270,"value":"Harris, A., & Johns, A. (2021). Youth, social cohesion and digital life: From risk and resilience to a global digital citizenship approach. Journal of Sociology, 57(2), 394â€“411. https://doi.org/10.1177/1440783320919173"},{"id":271,"value":"Harrison, S. (2023, January 12). Should ChatGPT Be Used to Write Wikipedia Articles? Slate. https://slate.com/technology/2023/01/chatgpt-wikipedia-articles.html"},{"id":272,"value":"HaÃŸler, B., Hennessy, S., Knight, S., & Connolly, T. (2014). Developing an Open Resource Bank for Interactive Teaching of STEM: Perspectives of school teachers and teacher educators. Journal of Interactive Media in Education, 1. https://doi.org/10.5334/2014-09"},{"id":273,"value":"Heersmink, R., & Knight, S. (2018). Distributed learning: Educating and assessing extended cognitive systems. Philosophical Psychology, 31(6), 969â€“990. https://doi.org/10.1080/09515089.2018.1469122"},{"id":274,"value":"Hicks, M. (2016). Impact evaluation of key themes funded by the Office for Learning and Teaching 2012-2016. Office for Learning and Teaching."},{"id":275,"value":"Hunter, J. (2021). High Possibility STEM Classrooms: Integrated STEM Learning in Research and Practice. Routledge. https://opus.lib.uts.edu.au/handle/10453/145453"},{"id":276,"value":"Hunter, J., Yasukawa, K., Kearney, M., Eckert, G., Heggart, K., Carter, D., Bates, K., Maher, D., & Patterson, C. (2022). UTS School of International Studies and Education: Submission to the Upper House Inquiry into teacher shortages in NSW [Report]. UTSâ€¯: FASS. https://opus.lib.uts.edu.au/handle/10453/159477"},{"id":277,"value":"IEEE Standards Association. (2022). Autonomous and Intelligent Systems (AIS). IEEE Standards Association. https://standards.ieee.org/initiatives/autonomous-intelligence-systems/"},{"id":278,"value":"Ingrid. (2020, August 1). Case study: Digital inclusion, low-income families, and online education in the wake of the COVID-19 pandemic. Australian Digital Inclusion Index. https://www.digitalinclusionindex.org.au/case-study-digital-inclusion-low-income-families-and-online-education-in-the-wake-of-the-covid-19-pandemic/"},{"id":279,"value":"IRU. (2016). Research and Development Tax Incentive Review: #NISA 2. Innovative Research Universities. https://iru.edu.au/policy_submissions/nisa-2-research-and-development-tax-incentive-review/"},{"id":280,"value":"ITSE. (2019). The ï¬ve pillars of edtech procurement. https://www.iste.org/explore/empowered-learner/five-pillars-edtech-procurement"},{"id":281,"value":"Johns, A., Byron, P., Cheong, N., Wijaya, H. Y., & Afifi, N. (2022). Mapping and review of resources for, and needs of vulnerable and marginalized young people in the Asia-Pacific region on digital literacy, safety and participation. UNESCO. https://unesdoc.unesco.org/ark:/48223/pf0000381551"},{"id":282,"value":"Johns, A., Matamoros-Fernandez, A., & Baulch, E. (2023). WhatsApp From a one-to-one Messaging App to a Global Communication Platform. Polity."},{"id":283,"value":"Johnson, L., Kift, S., & Lodge, J. (2023). A big idea for Australian higher education: The National Centre for Student Success. Submission to the Universities Accord Panel. https://www.education.gov.au/system/files/documents/submission-file/2023-04/AUA_tranche2_Liz%20Johnson.pdf"},{"id":284,"value":"Kalluri, P. (2020). Donâ€™t ask if artificial intelligence is good or fair, ask how it shifts power. Nature, 583(7815), 169â€“169. https://doi.org/10.1038/d41586-020-02003-2"},{"id":285,"value":"Kearney, M., Maher, D., & Pham, L. (2020). Investigating pre-service teachersâ€™ informally-developed online professional learning networks. Australasian Journal of Educational Technology. https://doi.org/10.14742/ajet.4766"},{"id":286,"value":"Khosravi, H., Denny, P., Moore, S., & Stamper, J. (2023). Learnersourcing in the Age of AI: Student, Educator and Machine Partnerships for Content Creation (arXiv:2306.06386). arXiv. http://arxiv.org/abs/2306.06386"},{"id":287,"value":"Khosravi, H., Shum, S. B., Chen, G., Conati, C., Gasevic, D., Kay, J., Knight, S., Martinez-Maldonado, R., Sadiq, S., & Tsai, Y.-S. (2022). Explainable Artificial Intelligence in education. Computers and Education: Artificial Intelligence, 3, 100074. https://doi.org/10.1016/j.caeai.2022.100074"},{"id":288,"value":"Kitto, K. (2022). How can EdTech support graduate employability? ASCILITE Publications, Proceedings of ASCILITE 2022 in Sydney, e22184â€“e22184. https://doi.org/10.14742/apubs.2022.184"},{"id":289,"value":"Knight, S. (2020). Section introduction: Dialogic education and digital technology. In N. Mercer, R. Wegerif, & L. Major (Eds.), Handbook of Research on Dialogic Education (pp. 389â€“393). Routledge. https://doi.org/10.4324/9780429441677"},{"id":290,"value":"Knight, S. (2023). Professional learning for ethical AI. https://www.ucl.ac.uk/ioe/events/2023/jun/professional-learning-ethical-ai"},{"id":291,"value":"Knight, S., & Buckingham Shum, S. (2017). Artificial intelligence holds great potential for both students and teachers â€“ but only if used wisely. The Conversation. http://theconversation.com/artificial-intelligence-holds-great-potential-for-both-students-and-teachers-but-only-if-used-wisely-81024"},{"id":292,"value":"Knight, S., & Littleton, K. (2016). Learning through Collaborative Information Seeking. In P. Hansen, C. Shah, & C.-P. Klas (Eds.), Collaborative Information Seeking: Best practices, New Domains, New Thoughts (pp. 101â€“116). Springer. https://doi.org/10.1007/978-3-319-18988-8_6"},{"id":293,"value":"Kolber, S., & Heggart, K. (2022). Education focused pracademics on twitter: Building democratic fora. Journal of Professional Capital and Community, 7(1), 26â€“44. https://doi.org/10.1108/JPCC-11-2020-0090"},{"id":294,"value":"Kucirkova, N. (2023). Debate: Response to â€œShould academics collaborate with digital companies to improve young peopleâ€™s mental healthâ€. Child and Adolescent Mental Health, 28(2), 336â€“337. https://doi.org/10.1111/camh.12648"},{"id":295,"value":"LX at UTS. (2023). Five principles for the effective ethical use of generative AI. LX at UTS. https://lx.uts.edu.au/collections/artificial-intelligence-in-learning-and-teaching/resources/five-principles-for-effective-ethical-use-generative-ai/"},{"id":296,"value":"Marino, M. T., Vasquez, E., Dieker, L., Basham, J., & Blackorby, J. (2023). The Future of Artificial Intelligence in Special Education Technology. Journal of Special Education Technology, 01626434231165977. https://doi.org/10.1177/01626434231165977"},{"id":297,"value":"Markauskaite, L., Marrone, R., Poquet, O., Knight, S., Martinez-Maldonado, R., Howard, S., Tondeur, J., De Laat, M., Buckingham Shum, S., GaÅ¡eviÄ‡, D., & Siemens, G. (2022). Rethinking the entwinement between artificial intelligence and human learning: What capabilities do learners need for a world with AI? Computers and Education: Artificial Intelligence, 3, 100056. https://doi.org/10.1016/j.caeai.2022.100056"},{"id":298,"value":"McMurtrie, B. (2023, May 26). How ChatGPT Could Help or Hurt Students With Disabilities. The Chronicle of Higher Education. https://www.chronicle.com/article/how-chatgpt-could-help-or-hurt-students-with-disabilities"},{"id":299,"value":"Meyer, M., Zosh, J. M., McLaren, C., Robb, M., McCaffery, H., Golinkoff, R. M., Hirsh-Pasek, K., & Radesky, J. (2021). How educational are â€œeducationalâ€ apps for young children? App store content analysis using the Four Pillars of Learning framework. Journal of Children and Media, 15(4), 526â€“548. https://doi.org/10.1080/17482798.2021.1882516"},{"id":300,"value":"Mills, A. (2023). AI Text Generators: Sources to Stimulate Discussion Among Teachers. Writing Across the Curriculum Clearinghouse. https://docs.google.com/document/d/1V1drRG1XlWTBrEwgGqd-cCySUB12JrcoamB5i16-Ezw/edit?usp=embed_facebook"},{"id":301,"value":"Nascimbeni, F., & Vosloo, S. (n.d.). Digital literacy for children: Exploring definitions and frameworks."},{"id":302,"value":"Nature. (2023). Tools such as ChatGPT threaten transparent science; here are our ground rules for their use. Nature, 613(7945), 612â€“612. https://doi.org/10.1038/d41586-023-00191-1"},{"id":303,"value":"Nerantzi, C., Abegglen, S., Karatsiori, M., & Martinez-Arboleda, A. (Eds.). (2023). AI Text Generators: Sources to Stimulate Discussion Among Teachers. Creative HE Community. https://docs.google.com/document/d/1V1drRG1XlWTBrEwgGqd-cCySUB12JrcoamB5i16-Ezw/edit#heading=h.sot8caygc8jr"},{"id":304,"value":"Nous. (2023). Submissions on priorities for the Australian Universities Accord Prepared by Nous Group. Australian Government: Department of Education. https://www.education.gov.au/australian-universities-accord/consultations/higher-education-review"},{"id":305,"value":"Pingo, Z., & Narayan, B. (2019). Privacy Literacy and the Everyday Use of Social Technologies. In S. KurbanoÄŸlu, S. Å piranec, Y. Ãœnal, J. Boustany, M. L. Huotari, E. Grassian, D. Mizrachi, & L. Roy (Eds.), Information Literacy in Everyday Life (pp. 33â€“49). Springer International Publishing. https://doi.org/10.1007/978-3-030-13472-3_4"},{"id":306,"value":"QAA. (2023). Maintaining quality and standards in the ChatGPT era: QAA advice on the opportunities and challenges posed by Generative Artificial Intelligence. https://www.qaa.ac.uk/docs/qaa/members/maintaining-quality-and-standards-in-the-chatgpt-era.pdf?sfvrsn=2408aa81_10"},{"id":307,"value":"Sabzalieva, E., & Valentini, A. (2023). ChatGPT and Artificial Intelligence in higher education Quick Start Guide (ED/HE/IESALC/IP/2023/12). UNESCO. https://www.iesalc.unesco.org/wp-content/uploads/2023/04/ChatGPT-and-Artificial-Intelligence-in-higher-education-Quick-Start-guide_EN_FINAL.pdf"},{"id":308,"value":"Schuck, S., Aubusson, P., Burden, K., & Brindley, S. (2018). Uncertainty in teacher education futures: Scenarios, politics and STEM. https://opus.lib.uts.edu.au/handle/10453/128795"},{"id":309,"value":"Schultz, A. (2023, June 24). Cyber bullying, sexual content against teachers on the rise, eSafety commissioner warns. The Sydney Morning Herald. https://www.smh.com.au/education/teachers-are-vulnerable-online-bullying-sexualised-abuse-on-the-rise-20230623-p5dj0v.html"},{"id":310,"value":"Science and Technology Australia. (2023). Policy Submission: Australian Universities Accord. Science and Technology Australia. https://scienceandtechnologyaustralia.org.au/wp-content/uploads/2023/04/STA-Submission-Australian-Universities-Accord.pdf"},{"id":311,"value":"Shibani, A., Knight, S., & Buckingham Shum, S. (2022). Questioning learning analytics? Cultivating critical engagement as student automated feedback literacy. In A. F. Wise, R. Martinez-Maldonado, & I. Hilliger (Eds.), 12th International Learning Analytics and Knowledge Conference (pp. 326â€“335). ACM. https://doi.org/10.1145/3506860.3506912"},{"id":312,"value":"Sinpeng, A., Martin, F. R., Gelber, K., & Shields, K. (2021). Facebook: Regulating Hate Speech in the Asia Pacific. Department of Media and Communications, The University of Sydney. https://doi.org/10.25910/j09v-sq57"},{"id":313,"value":"Sullivan, M., Kelly, A., & McLaughlan, P. (2023). ChatGPT in higher education: Considerations for academic integrity and student learning. Journal of Applied Learning and Teaching, 6(1), Article 1. https://doi.org/10.37074/jalt.2023.6.1.17"},{"id":314,"value":"Swiecki, Z., Khosravi, H., Chen, G., Martinez-Maldonado, R., Lodge, J. M., Milligan, S., Selwyn, N., & GaÅ¡eviÄ‡, D. (2022). Assessment in the age of artificial intelligence. Computers and Education: Artificial Intelligence, 3, 100075. https://doi.org/10.1016/j.caeai.2022.100075"},{"id":315,"value":"Tlili, A., Zhang, J., Papamitsiou, Z., Manske, S., Huang, R., Kinshuk, & Hoppe, H. U. (2021). Towards utilising emerging technologies to address the challenges of using Open Educational Resources: A vision of the future. Educational Technology Research and Development, 69(2), 515â€“532. https://doi.org/10.1007/s11423-021-09993-4"},{"id":316,"value":"Universities Australia. (2016). Submission to the Review of the R&D Tax Incentive. Universities Australia. https://www.universitiesaustralia.edu.au/wp-content/uploads/2019/05/RD-Tax-Incentive-Review.pdf"},{"id":317,"value":"UTS. (2018). AHRC Human Rights and Technology Issues Paper: UTS Response and Submission. University of Technology Sydney. https://www.uts.edu.au/sites/default/files/2018-12/Human%20Rights%20%26%20Technology%20Issues%20Paper_UTS%20submission.pdf"},{"id":318,"value":"Wall, S., & Schellmann, H. (2021). Disability rights advocates are worried about discrimination in AI hiring tools. MIT Technology Review. https://www.technologyreview.com/2021/07/21/1029860/disability-rights-employment-discrimination-ai-hiring/"},{"id":319,"value":"Warschauer, M., Tseng, W., Yim, S., Webster, T., Jacob, S., Du, Q., & Tate, T. (2023). The Affordances and Contradictions of AI-Generated Text for Second Language Writers (SSRN Scholarly Paper No. 4404380). https://doi.org/10.2139/ssrn.4404380"},{"id":320,"value":"Webb, M. (2023, May 11). A Generative AI Primer. National Centre for AI. https://nationalcentreforai.jiscinvolve.org/wp/2023/05/11/generative-ai-primer/"},{"id":321,"value":"Williams, R. (2010, March 30). Teachers suffer cyberbullying by pupils and parents. The Guardian. https://www.theguardian.com/education/2010/mar/30/teachers-bullied-online"},{"id":322,"value":"Wise, A. F., Knight, S., & Ochoa, X. (2021). What Makes Learning Analytics Research Matter. Journal of Learning Analytics, 8(3), 1â€“9. https://doi.org/10.18608/jla.2021.7647"},{"id":323,"value":"Woelert, P., & Millar, V. (2013). The â€˜paradox of interdisciplinarityâ€™ in Australian research governance. Higher Education, 66(6), 755â€“767. https://doi.org/10.1007/s10734-013-9634-8"},{"id":324,"value":"Young, K., & Maher, D. (forthcoming). Generative AI technology to support high school students experiencing challenges with writing. In R. E. Ferdig, R. Hartshorne, E. Baumgartner, R. Kaplan-Rakowski, & C. Mouza (Eds.), What PreK-12 Teachers Should Know about  Educational Technology in 2023: A Research-to-Practice Anthology. Association for the Advancement of Computing in Education."}],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":153,"database_table_184385":1},"value":{"id":980196,"value":"PD","color":"light-red"}},{"ids":{"database_table_183319":159,"database_table_184385":1},"value":{"id":980196,"value":"PD","color":"light-red"}},{"ids":{"database_table_183319":158,"database_table_184385":2},"value":{"id":980180,"value":"guidelines","color":"light-yellow"}},{"ids":{"database_table_183319":156,"database_table_184385":7},"value":{"id":980187,"value":"stakeholder-engagement","color":"dark-green"}},{"ids":{"database_table_183319":157,"database_table_184385":7},"value":{"id":980187,"value":"stakeholder-engagement","color":"dark-green"}},{"ids":{"database_table_183319":154,"database_table_184385":12},"value":{"id":980192,"value":"research-investment","color":"orange"}},{"ids":{"database_table_183319":155,"database_table_184385":12},"value":{"id":980192,"value":"research-investment","color":"orange"}},{"ids":{"database_table_183319":160,"database_table_184385":17},"value":{"id":980195,"value":"resourcing","color":"dark-cyan"}},{"ids":{"database_table_183319":157,"database_table_184385":19},"value":{"id":980186,"value":"capacity-building","color":"light-yellow"}},{"ids":{"database_table_183319":154,"database_table_184385":21},"value":{"id":980197,"value":"evidence-generation","color":"brown"}},{"ids":{"database_table_183319":155,"database_table_184385":21},"value":{"id":980197,"value":"evidence-generation","color":"brown"}}],"Lookup":[{"id":153,"value":"Understanding the potential and risks of genAI is a cross-sector, cross-discipline, societal concern; national priorities should reflect this through recognition of and support for interdisciplinarity and the social sciences in genAI innovation across sectors. - Recommendation 1: support interdisciplinary and cross -sector learning for ethical engagement with genAI, in the short term through support for targeted professional learning or microcredentials, and in the mid-term through addressing concerns raised regarding the jobs ready graduates package of reforms"},{"id":154,"value":"Evidence is a central requirement of ethical AI (merit in the National Statement; justification and transparency in many AI ethics frameworks). It is crucial that investments in EdTech are underpinned by evidence that any tools used will support the outcomes they claim to target. Support the critique, creation, and dissemination of evidence regarding claims of genAI supporting learning through: - Recommendation 2: Development of funding streams, and support for innovative approaches to evidence development and sharing across sectors, regarding genAI. By its nature this work must include social scientists which may require new funding streams, or/and reform of the R&D tax credit."},{"id":155,"value":"Recommendation 3: Support of interdisciplinary teams for genAI research both on fundamental evaluation of tool uses, and the dissemination of this evidence with and across education systems (including educators, learners, and developers)."},{"id":156,"value":"Learning environments are one space where genAI will clearly have significant impact; understanding this impact and appropriate (dis)engagement with genAI in learning requires a focus on the fundamental purposes and processes of learning. - Recommendation 4: Values underpin both our aims in education, and our aims for genAI, shaping what we learn (e.g., â€˜AI literacyâ€™), and how we learn (e.g., new AI tools). Support the convening of public fora and engagement activities to develop collective, democratic, values-led responses regarding the kinds of futures Australians want in use of genAI in education."},{"id":157,"value":"Recommendation 5: Understanding, evaluating, and sharing effective practices: There can be no strengths of genAI in education without teachers who will work with, create approaches for, and thus need to learn about genAI. This has implications, drawing on our other recommendations. o Any consideration of and planning cycles towards use of genAI in education should be with respect to the values and aims identified in Recommendation 4 o Resourcing should be provided to develop models to assess AI literacy across the range of stakeholders, and identify needs and strategies to develop this literacy; resources derived from this activity can feed into guidelines to help navigate the ethics of genAI (Recommendation 6) o Support should be provided for bespoke professional learning for teachers from all sectors, to develop algorithmic literacy to learn to engage with genAI and capacity for designing to learn with genAI tools Recommendation 1; Recommendation 7). o Evidence should underpin any incorporation of genAI (see Recommendation 3). This evidence should be shared and co-developed with and by teachers, informed by student voice, and in mentoring and partnerships with research universities and education institutions. It may also be appropriate to target resourcing to creation of evidence-informed models that encode shared values (Recommendation 4), and the body of existing evidence regarding learning technologies, to create tuned models or/and educationally-tailored system prompts (prompts that modify user input to provide context). Sharing among teachers has been shown to be an effective mechanism for supporting innovative approaches, particularly through creation of toolkit resources that provide practical guidance for design for learning alongside evidence and high-level principles."},{"id":158,"value":"Recommendation 6: The concerns of applying genAI in education in Australia specifically are unclear, with few practical guidelines available for stakeholders to understand or navigate these issues. Support should be provided for development of practical guidelines for a range of stakeholders regarding use of genAI in Australian learning contexts."},{"id":159,"value":"Recommendation 7: Provide support for Professional Learning to target skills for staff across institutions serving diverse communities, to support communities in effectively (dis)engaging with tools, and to target support of vulnerable populations and specific risks"},{"id":160,"value":"Recommendation 8: Ensure equitable access to genAI through tackling digital divides in affordability, accessibility, and capability. Target schools that are most impacted by digital divides"}]},{"id":20,"order":"20.00000000000000000000","submission_number":"20","Submitter":"Education Futures Studio/Sydney Policy Lab","Type of org":{"id":977287,"value":"University-centre","color":"orange"},"Notes":"","Recommendations":[{"id":103,"value":"Recommendation 1: Policy making should be both anticipatory and responsive to systemically manage the risks and seize the opportunities facing the Australian education sector AI technology is being introduced before there are adequate policies for guiding productive use and mitigating harms in education. This means a lag time between the introduction of AI and policy development, which also contributes to largely reactive policy making. There needs to be both anticipatory policy making (to assess both development and potential harms and opportunities) and responsive policy making (to guide existing use). Attention to future possibilities - based on past and present needs â€“ has the potential to address the systemic risks and opportunities which the education sector currently faces at a time of unprecedented uncertainty."},{"id":104,"value":"Recommendation 2: There needs to be meaningful, participatory and collective approaches to address the complexity of AI in education policy making Involving a diverse range of community members and education stakeholders at all stages of policy development and implementation will help to anticipate risks, build trust and co-create principles to inform complex decision-making measures. This is particularly important in anticipatory policymaking which must be responsive to local, regional, and national needs. This genuinely multi-scalar and multi-stakeholder approach throughout the entire process will lead to more timely decisions in the future. Part of this will require distributing socio-technical expertise and embedding opportunities for collective learning, experimentation, and policymaking about the development and use of AI and emerging technologies in education. In particular, there is a need to distribute expertise and embed these opportunities in a way that is accessible to and involves those from underrepresented backgrounds who might otherwise lack the opportunity and resources to participate in policy co-creation processes. To ensure that this collaborative work (which is systemic, collective, and cross-sectoral) becomes embedded across research, policy, and practice - there is a need for long-term government funding to sustain this initiative."},{"id":105,"value":"Recommendation 3: Establish a cross-sector representative body and knowledgesharing hub which embeds a research-policy-practice approach toward the governance of AI across all Australian education contexts. All areas of education are already and likely to be impacted by the use of AI and all stakeholders need opportunities to shape the implementation of AI in Australian education systems. A representative cross-sector independent body should include members from government, departmental agencies (e.g. Department of Education, Department of Industry, Science and Resources), regulatory bodies relating to education (e.g. TEQSA, ASQA and ACECQA), higher education (both STEM and HASS disciplines), schooling and early childhood sectors (including diverse range of students for all sectors), the education technology industry, teacher associations and parent groups. The body should be established to: (1) oversee the development of AI in Australian education with a focus on the risks and possibilities of open A.I. development; (2) produce regular issue-specific publications and events for the groups it represents; and, (3) maintain a set of iteratively revised guidelines and learning resources for the field."}],"Uses-opportunities":[],"Risks-challenges":[],"References-footnotes":[],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":104,"database_table_184385":7},"value":{"id":980187,"value":"stakeholder-engagement","color":"dark-green"}},{"ids":{"database_table_183319":105,"database_table_184385":19},"value":{"id":980186,"value":"capacity-building","color":"light-yellow"}},{"ids":{"database_table_183319":103,"database_table_184385":20},"value":{"id":980179,"value":"ongoing-and-global-monitoring","color":"dark-brown"}}],"Lookup":[{"id":103,"value":"Recommendation 1: Policy making should be both anticipatory and responsive to systemically manage the risks and seize the opportunities facing the Australian education sector AI technology is being introduced before there are adequate policies for guiding productive use and mitigating harms in education. This means a lag time between the introduction of AI and policy development, which also contributes to largely reactive policy making. There needs to be both anticipatory policy making (to assess both development and potential harms and opportunities) and responsive policy making (to guide existing use). Attention to future possibilities - based on past and present needs â€“ has the potential to address the systemic risks and opportunities which the education sector currently faces at a time of unprecedented uncertainty."},{"id":104,"value":"Recommendation 2: There needs to be meaningful, participatory and collective approaches to address the complexity of AI in education policy making Involving a diverse range of community members and education stakeholders at all stages of policy development and implementation will help to anticipate risks, build trust and co-create principles to inform complex decision-making measures. This is particularly important in anticipatory policymaking which must be responsive to local, regional, and national needs. This genuinely multi-scalar and multi-stakeholder approach throughout the entire process will lead to more timely decisions in the future. Part of this will require distributing socio-technical expertise and embedding opportunities for collective learning, experimentation, and policymaking about the development and use of AI and emerging technologies in education. In particular, there is a need to distribute expertise and embed these opportunities in a way that is accessible to and involves those from underrepresented backgrounds who might otherwise lack the opportunity and resources to participate in policy co-creation processes. To ensure that this collaborative work (which is systemic, collective, and cross-sectoral) becomes embedded across research, policy, and practice - there is a need for long-term government funding to sustain this initiative."},{"id":105,"value":"Recommendation 3: Establish a cross-sector representative body and knowledgesharing hub which embeds a research-policy-practice approach toward the governance of AI across all Australian education contexts. All areas of education are already and likely to be impacted by the use of AI and all stakeholders need opportunities to shape the implementation of AI in Australian education systems. A representative cross-sector independent body should include members from government, departmental agencies (e.g. Department of Education, Department of Industry, Science and Resources), regulatory bodies relating to education (e.g. TEQSA, ASQA and ACECQA), higher education (both STEM and HASS disciplines), schooling and early childhood sectors (including diverse range of students for all sectors), the education technology industry, teacher associations and parent groups. The body should be established to: (1) oversee the development of AI in Australian education with a focus on the risks and possibilities of open A.I. development; (2) produce regular issue-specific publications and events for the groups it represents; and, (3) maintain a set of iteratively revised guidelines and learning resources for the field."}]},{"id":21,"order":"21.00000000000000000000","submission_number":"21","Submitter":"The Australian Council of TESOL Associations","Type of org":{"id":977281,"value":"Peak body","color":"green"},"Notes":"","Recommendations":[{"id":427,"value":"Access: It is important to ensure access to generative Al amongst EAL/0 communities. We recommend avoiding approaches which ban the use of generative Al in schools. This is particularly important for public schools which cater for the majority of EAL/D students in Australia. We also recommend increasing access, including financial support, to Al in local libraries and community centres."},{"id":428,"value":"Learning programs specifically tailored to the needs of EAL/D learners are essential for helping them to become confident and capable to access benefits and mitigate the risks of generative Al. Such programs need to focus on Al literacies which we define as a set of technical, linguistic and socio-cultural capabilities required for meaningful, creative, ethical and critical use of Al for different purposes and in different settings. These programs need to be age and sector appropriate. We recommend that institutions, teachers and educational researchers with expertise in EAL/D approaches are included in shaping these programs, considering the needs and strengths of EAL/D students as well as the specificities of learning contexts."},{"id":429,"value":"Awareness: There is a need to increase broader awareness, constructive attitudes and levels of confidence about generative Al , its benefits, possibilities, and applications as well as limitations, challenges and biases. Given emerging language and literacy levels of this group both in English and sometimes in home languages, information needs to be accessible, presented in various forms (e.g. brochures, posters, videos, invited presentations, etc.) and/or translated into home languages. These resources need to be easily accessible through community centres, schools and online platforms. To promote such awareness, we recommend that different stakeholders with EAL/D expertise and experience are included in important decision making and initiatives"},{"id":444,"value":"Pedagogic Resources: Educational institutions and teachers need to be supported in the implementation of learning programs dedicated to Al literacies in settings with EAL/D learners. Such support entails the development of relevant policies, syllabuses and teaching/learning resources. We recommend collaboration between industry, academia, policymakers, and the wider public to develop resources and guidelines for the deployment of generative Al with EAL/D learners."},{"id":446,"value":"Professional Learning: Educators working with EAL/D cohorts need access to high-quality professional learning programs related to the use of generative Al in educational settings. We recommend that professional learning programs familiarise and develop teachers' expertise with Al tools and relevant pedagogies. It is particularly important to consider the changing role of EAL/D teachers given the enormous potential of Al for new and creative ways for learning languages"},{"id":536,"value":"Future research: There is an urgent need to support research exploring the use of generative Al by EAL/D learners and their teachers. Such research would enhance understanding about EAL/D learners' experiences, attitudes, innovative uses and challenges which, in turn, would allow the development of evidence-based research-informed policies, frameworks, approaches and practices for educational settings that specifically address their needs. Supporting research collaborations and partnerships between universities, government and educational institutions remains crucial for generation of new knowledge and pedagogical innovations associated with the use of generative Al in EAL/D settings."}],"Uses-opportunities":[],"Risks-challenges":[{"id":302,"value":"Students who lack the skills to use such models will be severely disadvantaged when they enter the workforce. To remain competitive in the workforce, students must learn how to effectively use LLMs, even if just effectively prompting them to get a good output and assessing the outputâ€™s quality, accuracy, and originality"},{"id":303,"value":"people from culturally and linguistically diverse backgrounds as well as those with lower household income and lower levels of formal education are less likely to know about the tool and to use it for different purposesAs a result, EAL/D learners, both adults and children, are most likely to miss out on important language learning opportunities which have been widely documented in the research literature: oral and written conversational speaking practice; correcting errors in grammar; providing writing assistance; enriching vocabulary; development of fluency in pronunciation; personalised tutoring and feedback; enhancement of language learning motivation"},{"id":304,"value":"EAL/D learners, both adults and children, are most likely to miss out on a valuable tool which can significantly assist their settlement experiences through translation and simplifying information"},{"id":305,"value":"EAL/D learners, both adults and children, are most likely to miss out on opportunities to develop AI literacies, which involve the diverse skills, knowledge, understandings and attitudes required for meaningful, creative and critical use of generative AI for different purposes and in different contexts"},{"id":306,"value":"A new kind of \"digital divideâ€ is in process"}],"References-footnotes":[{"id":704,"value":"Ahmad, N., Murugesan, S., & Kshetri, N. (2023). Generative Artificial Intelligence and the Education Sector. Computer, 56(6), 72-76."},{"id":705,"value":"Godwin-Jones, R. (2023). Emerging spaces for language learning: AI bots, ambient intelligence, and the metaverse. Language Learning & Technology, 27(2), 6-27. https://doi.org//10125/73501"},{"id":706,"value":"Huang, J. X., Lee, K. S., Kwon, O. W., & Kim, Y. K. (2017). A chatbot for a dialogue-based second language learning system. CALL in a climate of change. adapting to turbulent global conditionsâ€”shortpapers from EUROCALL, 151-156."},{"id":707,"value":"Miao, F., & Holmes, W. (2021). International forum on AI and the futures of education.\nDeveloping competencies for the AI era. Synthesis Report. UNESCO."},{"id":708,"value":"Mehr, H., Ash, H., & Fellow, D. (2017). Artificial intelligence for citizen services and government. Ash Center for Democratic Governance and Innovation. https://ash.harvard.edu/files/ash/files/artificial_intelligence_for_citizen_services.pdf"},{"id":709,"value":"Ng, D. T. K., Leung, J. K. L., Chu, S. K. W., & Qiao, M. S. (2021). Conceptualizing AI literacy: An exploratory review. Computers and Education: Artificial Intelligence, 2."},{"id":710,"value":"Pegrum, M. (2023). Generative AI. Digital Learning. https://markpegrum.com/tools-for-digital- learning/generative-ai/"},{"id":711,"value":"Pegrum, M., Hockly, N., & Dudeney, G. (2022). Digital literacies (2nd ed.). Routledge."},{"id":712,"value":"Pew Research Center (2023). A majority of Americans have heard of ChatGPT, but few have tried it themselves. https://www.pewresearch.org/short-reads/2023/05/24/a- majority-of-americans-have-heard-of-chatgpt-but-few-have-tried-it-themselves/"},{"id":713,"value":"Selwyn, N. (2023). Teaching in the age of artificial intelligence. Education into the 2030s: The big education challenges of our times. Faculty of Education Working Paper #2. https://research.monash.edu/en/publications/education-into-the-2030s-the-big- education-challenges-of-our-time"},{"id":714,"value":"Su, J., & Yang, W. (2023). Unlocking the power of ChatGPT: A framework for applying generative AI in education. ECNU Review of Education. https://doi.org/10.1177/20965311231168423"},{"id":715,"value":"Woo, J. H., & Choi, H. (2021). Systematic review for AI-based language learning tools. https://arxiv.org/abs/2111.04455."}],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":446,"database_table_184385":1},"value":{"id":980196,"value":"PD","color":"light-red"}},{"ids":{"database_table_183319":444,"database_table_184385":2},"value":{"id":980180,"value":"guidelines","color":"light-yellow"}},{"ids":{"database_table_183319":444,"database_table_184385":7},"value":{"id":980187,"value":"stakeholder-engagement","color":"dark-green"}},{"ids":{"database_table_183319":428,"database_table_184385":10},"value":{"id":980190,"value":"curricula-changes","color":"light-green"}},{"ids":{"database_table_183319":536,"database_table_184385":12},"value":{"id":980192,"value":"research-investment","color":"orange"}},{"ids":{"database_table_183319":429,"database_table_184385":16},"value":{"id":980194,"value":"communications","color":"darker-brown"}},{"ids":{"database_table_183319":427,"database_table_184385":17},"value":{"id":980195,"value":"resourcing","color":"dark-cyan"}},{"ids":{"database_table_183319":536,"database_table_184385":19},"value":{"id":980186,"value":"capacity-building","color":"light-yellow"}},{"ids":{"database_table_183319":536,"database_table_184385":21},"value":{"id":980197,"value":"evidence-generation","color":"brown"}},{"ids":{"database_table_183319":429,"database_table_184385":22},"value":{"id":980198,"value":"marginalised-group-engagement","color":"light-pink"}},{"ids":{"database_table_183319":427,"database_table_184385":27},"value":{"id":980178,"value":"equitable-access","color":"yellow"}}],"Lookup":[{"id":427,"value":"Access: It is important to ensure access to generative Al amongst EAL/0 communities. We recommend avoiding approaches which ban the use of generative Al in schools. This is particularly important for public schools which cater for the majority of EAL/D students in Australia. We also recommend increasing access, including financial support, to Al in local libraries and community centres."},{"id":428,"value":"Learning programs specifically tailored to the needs of EAL/D learners are essential for helping them to become confident and capable to access benefits and mitigate the risks of generative Al. Such programs need to focus on Al literacies which we define as a set of technical, linguistic and socio-cultural capabilities required for meaningful, creative, ethical and critical use of Al for different purposes and in different settings. These programs need to be age and sector appropriate. We recommend that institutions, teachers and educational researchers with expertise in EAL/D approaches are included in shaping these programs, considering the needs and strengths of EAL/D students as well as the specificities of learning contexts."},{"id":429,"value":"Awareness: There is a need to increase broader awareness, constructive attitudes and levels of confidence about generative Al , its benefits, possibilities, and applications as well as limitations, challenges and biases. Given emerging language and literacy levels of this group both in English and sometimes in home languages, information needs to be accessible, presented in various forms (e.g. brochures, posters, videos, invited presentations, etc.) and/or translated into home languages. These resources need to be easily accessible through community centres, schools and online platforms. To promote such awareness, we recommend that different stakeholders with EAL/D expertise and experience are included in important decision making and initiatives"},{"id":444,"value":"Pedagogic Resources: Educational institutions and teachers need to be supported in the implementation of learning programs dedicated to Al literacies in settings with EAL/D learners. Such support entails the development of relevant policies, syllabuses and teaching/learning resources. We recommend collaboration between industry, academia, policymakers, and the wider public to develop resources and guidelines for the deployment of generative Al with EAL/D learners."},{"id":446,"value":"Professional Learning: Educators working with EAL/D cohorts need access to high-quality professional learning programs related to the use of generative Al in educational settings. We recommend that professional learning programs familiarise and develop teachers' expertise with Al tools and relevant pedagogies. It is particularly important to consider the changing role of EAL/D teachers given the enormous potential of Al for new and creative ways for learning languages"},{"id":536,"value":"Future research: There is an urgent need to support research exploring the use of generative Al by EAL/D learners and their teachers. Such research would enhance understanding about EAL/D learners' experiences, attitudes, innovative uses and challenges which, in turn, would allow the development of evidence-based research-informed policies, frameworks, approaches and practices for educational settings that specifically address their needs. Supporting research collaborations and partnerships between universities, government and educational institutions remains crucial for generation of new knowledge and pedagogical innovations associated with the use of generative Al in EAL/D settings."}]},{"id":22,"order":"22.00000000000000000000","submission_number":"22","Submitter":"Independent Schools Australia","Type of org":{"id":977873,"value":"School-network","color":"brown"},"Notes":"","Recommendations":[{"id":448,"value":"ISA recommends the formation of a federal education advisory body of key stakeholders and cross sectoral school education representatives and academics to examine the benefits and risk of generative AI to inform education policy."},{"id":449,"value":"ISA recommends investigation and implementation of funded initiatives to support the national teacher workforce in all education sectors in the effective use of AI technology."},{"id":450,"value":"ISA recommends the implementation of funded programs to develop and deliver safe, effective educational AI technologies which can reduce educational disadvantage and improve outcomes for students by supporting individual learning needs."},{"id":451,"value":"ISA recommends that safeguarding, ethical use,\nequity and integrity are core principles of a national AI framework for education."},{"id":452,"value":"ISA recommends the creation of a national generative AI in education website that is freely accessible to all educators to increase their knowledge base"},{"id":453,"value":"ISA recommends that the importance of culture, play-based learning, social connection, teacher/student relationships and protecting the holistic development of children and young people informs and is at the core of generative AI education policy"},{"id":454,"value":"ISA strongly recommends that funding be provided to AISs to ensure that schools in all sectors have the necessary support to implement effective and ethical generative AI strategies."},{"id":455,"value":"Independent schools need to continue to educate students about the ethical use of AI tools and implement more robust plagiarism detection strategies to maintain academic integrity. T"},{"id":456,"value":"Independent schools continue to teach students media literacy and critical evaluation techniques but need to be explicit in teaching generative AI discernment between authentic and manipulated generative AI content."},{"id":457,"value":"Independent schools are aware of these biases and are actively engaged in finding ways to teach students how to be critical when utilising and interpreting outputs from generative AI tools."},{"id":458,"value":"Independent schools will require support to ensure adequate measures are in place to safeguard personal information and comply with relevant privacy regulations."},{"id":459,"value":"Independent schools promote digital well-being and provide support mechanisms to address any negative impacts on students, but generative AI adds another level of complexity to this role."},{"id":460,"value":"Independent schools are seeking clear guidelines and sample policies to govern the use of generative AI tools in schools."}],"Uses-opportunities":[{"id":375,"value":"Personalized learning opportunities for students through the use of generative AI tools"},{"id":376,"value":"Improved accessibility for students with learning needs"},{"id":377,"value":"Personalized extension activities for academically gifted students"},{"id":378,"value":"Potential for reducing labor and time-intensive administrative processes for educators"},{"id":379,"value":"Support for lesson planning and curriculum design through generative AI tools"},{"id":380,"value":"Creation of engaging and tailored resources for individual students and schools"},{"id":381,"value":"Reflective practice for educators through AI feedback and analysis"},{"id":382,"value":"Real-time data analytics to inform teachers and school leaders about student progress"},{"id":383,"value":"Reduction of workload and increased efficiency in various areas such as assessment, grading, data collection, and administrative tasks"},{"id":384,"value":"Detection of plagiarism through advanced software"},{"id":385,"value":"Identification of students needing support and development of intervention programs"},{"id":386,"value":"Determination of professional learning needs and recommendation of resources"},{"id":387,"value":"Development of skills matrix for effective use and management of AI-generated resources"},{"id":388,"value":"Upskilling of the teaching workforce to integrate generative AI into teaching and assessment practices"},{"id":389,"value":"Use of generative AI for writing comments in reports and generating educational content"},{"id":390,"value":"Creation of interactive quizzes to enhance student engagement and learning."},{"id":391,"value":"Offer text to speech tools"},{"id":392,"value":"Provide audio for visually impaired\nstudents"},{"id":393,"value":"Provide memory aids"},{"id":394,"value":"Provide multi-sensory learning"},{"id":395,"value":"Dictation support"},{"id":396,"value":"Teach sign language"},{"id":397,"value":"Transcribe in real time for the hearing\nimpaired"},{"id":398,"value":"Use colour coding strategies"},{"id":399,"value":"Visualise concepts graphically"},{"id":400,"value":"Offer personalised learning"},{"id":401,"value":"Adapt content for colour blind students"},{"id":402,"value":"Adapt text size and colour for dyslexia"},{"id":403,"value":"Assist with notetaking"},{"id":404,"value":"Auto generate captions for video content"},{"id":405,"value":"Clarify complex instructions"},{"id":406,"value":"Convert lectures to written notes"},{"id":407,"value":"Create social narratives"},{"id":408,"value":"Create step-by-step visual instruction"},{"id":409,"value":"Help establish a daily routine"},{"id":410,"value":"Implement visual timers"}],"Risks-challenges":[{"id":307,"value":"Potential exacerbation of existing inequities in access to education and technology"},{"id":308,"value":"Risk of unethical human use of generative AI, including the creation of deep fakes and plagiarism"},{"id":309,"value":"Algorithmic bias in generative AI software favoring certain ideologies and perspectives"},{"id":310,"value":"Difficulty in detecting relevance and accuracy in generated AI products"},{"id":311,"value":"Inaccurate or incomplete information being considered as accurate by users"},{"id":312,"value":"Potential for generative AI to be used as a single source of truth without applying a critical lens"},{"id":313,"value":"Concerns about assessment integrity and the need for advanced anti-plagiarism tools"},{"id":314,"value":"Potential increase in educator workload when incorporating generative AI tools"},{"id":315,"value":"Rapid pace of AI development requiring ongoing training and support for educators"},{"id":316,"value":"Financial investment considerations and the risk of rapid technological advancements superseding current versions of generative AI"},{"id":317,"value":"Generative AI tools have the potential to bridge the educational divide that impacts students and\nfamilies experiencing disadvantage."},{"id":318,"value":"the cost and equitable access of generative AI tools so as not to\nexacerbate the digital divide. It is highly likely that superior versions of generative AI will be more\nexpensive"},{"id":319,"value":"disadvantaged students are  marginalised through lack\nof access to the same educational tools, including generative AI, as their peers."},{"id":320,"value":"Disadvantaged communities may lack the necessary infrastructure and resources required to access,\nimplement and maintain relevant education technologies"},{"id":321,"value":"Indiscriminate implementation and use, without appropriate\nsafeguarding structures around accountability and quality control may prove problematic and amplify\ndisadvantage in some communities."}],"References-footnotes":[{"id":716,"value":"â€œGenerative AI and the Future of Education - UNESCO Digital Library.â€"},{"id":717,"value":"Blair Levin and Larry Downes, â€œWho Is Going to Regulate AI?,â€ Harvard Business Review, May 19, 2023,\nhttps //hbr.org/2023/05/who-is-going-to-regulate-ai."},{"id":718,"value":"â€œMeet â€˜Stretch,â€™ a New Chatbot Just for Schools,â€ Education Week, June 26, 2023, sec. Technology, Classroom\nTechnology, https://www.edweek.org/technology/meet-stretch-a-new-chatbot-just-for-schools/2023/06."},{"id":719,"value":"Dawson and Kovanovic, â€œHigh School Students Are Using a ChatGPT-Style App in an Australia-First Trial"},{"id":720,"value":"â€œUNESCO Publishes Beijing Consensus on Artificial Intelligence and Education - Ministry of Education of the\nPeopleâ€™s Republic of China,â€ accessed June 29, 2023,\nhttp://en.moe.gov.cn/news/press_releases/201909/t20190902_396913.html."},{"id":721,"value":"â€œFinland: AI, Policy Innovation and the Future of Work and Learning | Digital Skills & Jobs Platform,â€ accessed\nJune 29, 2023, https://digital-skills-jobs.europa.eu/en/inspiration/research/finland-ai-policy-innovation-andfuture-work-and-learning-2022."},{"id":722,"value":"â€œExamining Singaporeâ€™s AI Progress,â€ Center for Security and Emerging Technology (blog), accessed June 29,\n2023, https://cset.georgetown.edu/publication/examining-singapores-ai-progress/."},{"id":723,"value":"â€œCentre for Data Ethics and Innovation,â€ GOV.UK, June 14, 2023,\nhttps //www.gov.uk/government/organisations/centre-for-data-ethics-and-innovation."},{"id":724,"value":"â€œGenerative AI and the Future of Education - UNESCO Digital Library,â€ accessed July 3, 2023,\nhttps //unesdoc.unesco.org/ark:/48223/pf0000385877."},{"id":725,"value":"L. Loble and A. Hawcroft, â€œShaping AI and Edtech to Tackle Australiaâ€™s Learning Divide,â€ Report (University of\nTechnology Sydney, December 6, 2022), https://opus.lib.uts.edu.au/handle/10453/162604."},{"id":726,"value":"â€œMinisterial Roundtable on Generative AI in Education | UNESCO,â€ May 25, 2023,\nhttps //www.unesco.org/en/articles/ministerial-roundtable-generative-ai-education."},{"id":727,"value":"â€œFor Educators, ChatGPT Poses Big Questionsâ€”and Big Possibilities."},{"id":728,"value":"Ahmed Tlili et al., â€œWhat If the Devil Is My Guardian Angel: ChatGPT as a Case Study of Using Chatbots in\nEducation,â€ Smart Learning Environments 10, no. 1 (February 22, 2023): 15, https://doi.org/10.1186/s40561-023-\n00237-x."},{"id":729,"value":"Education & AI | Scottybreaksitdown,â€ accessed June 27, 2023, https://scottybreaksitdown.com/ai/."},{"id":730,"value":"Mhlanga, â€œOpen AI in Education, the Responsible and Ethical Use of ChatGPT Towards Lifelong Learning.â€"},{"id":731,"value":"Shane Dawson and Vitomir Kovanovic, â€œHigh School Students Are Using a ChatGPT-Style App in an AustraliaFirst Trial,â€ The Conversation, July 6, 2023, http://theconversation.com/high-school-students-are-using-achatgpt-style-app-in-an-australia-first-trial-209215."},{"id":732,"value":"â€œFuture Tools - Find The Exact AI Tool For Your Needs,â€ accessed June 27, 2023, https://www.futuretools.io/."},{"id":733,"value":"â€œBest AI Tools and Services List,â€ accessed June 27, 2023, https://topai.tools/."},{"id":734,"value":"â€œFuturepedia - The Largest AI Tools Directory | Home,â€ accessed June 27, 2023, https://www.futurepedia.io/."},{"id":735,"value":"Embedding the General Capabilities,â€ 2022."},{"id":736,"value":"â€œFor Educators, ChatGPT Poses Big Questionsâ€”and Big Possibilities,â€ ASCD, accessed June 27, 2023,\nhttps //www.ascd.org/blogs/for-educators-chatgpt-poses-big-questions-and-big-possibilities."},{"id":737,"value":"ChatGPT Writing Reports, 2023, https://www.youtube.com/watch?v=FH38EVsXO0c."},{"id":738,"value":"â€œProfessional Development For Teachers | Edthena,â€ May 11, 2023, https://www.edthena.com/"},{"id":739,"value":"A Teacherâ€™s Prompt Guide to ChatGPT Aligned with â€˜What Works Bestâ€™.Pdf,â€ Google Docs, accessed June 27,\n2023, https://drive.google.com/file/d/15qAxnUzOwAPwHzoaKBJd8FAgiOZYcIxq/view?usp=embed_facebook."},{"id":740,"value":"David Mhlanga, â€œOpen AI in Education, the Responsible and Ethical Use of ChatGPT Towards Lifelong\nLearning,â€ SSRN Scholarly Paper (Rochester, NY, February 11, 2023), https://doi.org/10.2139/ssrn.4354422."}],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":449,"database_table_184385":1},"value":{"id":980196,"value":"PD","color":"light-red"}},{"ids":{"database_table_183319":451,"database_table_184385":2},"value":{"id":980180,"value":"guidelines","color":"light-yellow"}},{"ids":{"database_table_183319":460,"database_table_184385":2},"value":{"id":980180,"value":"guidelines","color":"light-yellow"}},{"ids":{"database_table_183319":458,"database_table_184385":3},"value":{"id":980182,"value":"situate-with-existing-policy","color":"darker-red"}},{"ids":{"database_table_183319":459,"database_table_184385":3},"value":{"id":980182,"value":"situate-with-existing-policy","color":"darker-red"}},{"ids":{"database_table_183319":448,"database_table_184385":7},"value":{"id":980187,"value":"stakeholder-engagement","color":"dark-green"}},{"ids":{"database_table_183319":453,"database_table_184385":10},"value":{"id":980190,"value":"curricula-changes","color":"light-green"}},{"ids":{"database_table_183319":455,"database_table_184385":10},"value":{"id":980190,"value":"curricula-changes","color":"light-green"}},{"ids":{"database_table_183319":456,"database_table_184385":10},"value":{"id":980190,"value":"curricula-changes","color":"light-green"}},{"ids":{"database_table_183319":457,"database_table_184385":10},"value":{"id":980190,"value":"curricula-changes","color":"light-green"}},{"ids":{"database_table_183319":454,"database_table_184385":17},"value":{"id":980195,"value":"resourcing","color":"dark-cyan"}},{"ids":{"database_table_183319":452,"database_table_184385":19},"value":{"id":980186,"value":"capacity-building","color":"light-yellow"}},{"ids":{"database_table_183319":450,"database_table_184385":27},"value":{"id":980178,"value":"equitable-access","color":"yellow"}},{"ids":{"database_table_183319":450,"database_table_184385":39},"value":{"id":991258,"value":"foster-responsible-aied","color":"red"}}],"Lookup":[{"id":448,"value":"ISA recommends the formation of a federal education advisory body of key stakeholders and cross sectoral school education representatives and academics to examine the benefits and risk of generative AI to inform education policy."},{"id":449,"value":"ISA recommends investigation and implementation of funded initiatives to support the national teacher workforce in all education sectors in the effective use of AI technology."},{"id":450,"value":"ISA recommends the implementation of funded programs to develop and deliver safe, effective educational AI technologies which can reduce educational disadvantage and improve outcomes for students by supporting individual learning needs."},{"id":451,"value":"ISA recommends that safeguarding, ethical use,\nequity and integrity are core principles of a national AI framework for education."},{"id":452,"value":"ISA recommends the creation of a national generative AI in education website that is freely accessible to all educators to increase their knowledge base"},{"id":453,"value":"ISA recommends that the importance of culture, play-based learning, social connection, teacher/student relationships and protecting the holistic development of children and young people informs and is at the core of generative AI education policy"},{"id":454,"value":"ISA strongly recommends that funding be provided to AISs to ensure that schools in all sectors have the necessary support to implement effective and ethical generative AI strategies."},{"id":455,"value":"Independent schools need to continue to educate students about the ethical use of AI tools and implement more robust plagiarism detection strategies to maintain academic integrity. T"},{"id":456,"value":"Independent schools continue to teach students media literacy and critical evaluation techniques but need to be explicit in teaching generative AI discernment between authentic and manipulated generative AI content."},{"id":457,"value":"Independent schools are aware of these biases and are actively engaged in finding ways to teach students how to be critical when utilising and interpreting outputs from generative AI tools."},{"id":458,"value":"Independent schools will require support to ensure adequate measures are in place to safeguard personal information and comply with relevant privacy regulations."},{"id":459,"value":"Independent schools promote digital well-being and provide support mechanisms to address any negative impacts on students, but generative AI adds another level of complexity to this role."},{"id":460,"value":"Independent schools are seeking clear guidelines and sample policies to govern the use of generative AI tools in schools."}]},{"id":23,"order":"23.00000000000000000000","submission_number":"23","Submitter":"Mr Joel Davis","Type of org":{"id":977280,"value":"Individual","color":"gray"},"Notes":"","Recommendations":[{"id":33,"value":"AI Literacy for Teachers;"},{"id":34,"value":"Focus on ITE"}],"Uses-opportunities":[{"id":38,"value":"1:1 personalised learning experiences for students wanting to check the accuracy of their work or wanting to extend their knowledge beyond what is being presented in the classroom"},{"id":39,"value":"â— Quick feedback allowing the learning to move forward"},{"id":40,"value":"â— Analysis of difficult or lengthy content"},{"id":41,"value":"â— Distraction free interaction - currently, interacting with many AI tools is an â€˜ad-freeâ€™ experience - the student is interacting only with the AI and not prone to distractions (such as clickbait)"},{"id":42,"value":"â— Fast tracking of idea generation and/or arduous repetitive tasks to free up time for higher order thinking/concept development/project work"},{"id":43,"value":"â— Interacting with technology that is current and been utilised by industry"},{"id":44,"value":"â—Lesson Planning; Curriculum analysis"},{"id":45,"value":"â— Generation of ideas for activities targeting specific outcomes or needs of students"},{"id":46,"value":"â— Templating of administrative tasks (presentations, emails, letters, etc.)"},{"id":47,"value":"â— Analysing data within specific contexts relevant to the school to better identify needs and opportunities within the student cohort"},{"id":48,"value":"â— Locating of resources specific to the content being taught or learning needs of students"},{"id":49,"value":"â— Resource generation across all subject areas"}],"Risks-challenges":[{"id":44,"value":"AI Literacy; Ethics; Changes to assessment practices: Less emphasis on the need for knowledge to be remembered/retained at a certain point (exams) but more emphasis on its construction and use (projects)\nâ— Requirement for learning journals, prompt histories, screenshots of interactions with AI as part of assignment or essay submissions\nâ— Rethinking what â€˜open bookâ€™ exams looks like - could/should they include AI?\nâ— Shifting some assessment tasks to become more authentic tasks by assessing a studentâ€™s application of skills as opposed to the content they produce."}],"References-footnotes":[],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":33,"database_table_184385":1},"value":{"id":980196,"value":"PD","color":"light-red"}},{"ids":{"database_table_183319":34,"database_table_184385":1},"value":{"id":980196,"value":"PD","color":"light-red"}}],"Lookup":[{"id":33,"value":"AI Literacy for Teachers;"},{"id":34,"value":"Focus on ITE"}]},{"id":24,"order":"24.00000000000000000000","submission_number":"24","Submitter":"A/Prof Jason Lodge","Type of org":{"id":977286,"value":"individual-academic","color":"dark-blue"},"Notes":"This response will be frank. The answer to most of the Inquiryâ€™s terms of reference (particularly 1, 2, 4 and 5) is that we simply donâ€™t know at this stage. While there are some suggestions about how generative AI can be used effectively to assist with the learning and assessment of Australian students, we only have clues and foundational principles. Many of these clues and principles will be alluded to in other submissions to this Inquiry, so, I will not reiterate them here. There are, as yet, no tried and tested solutions. Anyone claiming to have clear, scalable answers at this stage should be doubted.","Recommendations":[{"id":35,"value":"I strongly recommend a significant and rapid investment in research capability to provide evidence to inform responses to the issues raised in this Inquiry."}],"Uses-opportunities":[],"Risks-challenges":[{"id":45,"value":"Lack of funding for AI research in Australia compared with other countries"}],"References-footnotes":[],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":35,"database_table_184385":12},"value":{"id":980192,"value":"research-investment","color":"orange"}}],"Lookup":[{"id":35,"value":"I strongly recommend a significant and rapid investment in research capability to provide evidence to inform responses to the issues raised in this Inquiry."}]},{"id":25,"order":"25.00000000000000000000","submission_number":"25","Submitter":"Australian Council of State School Organisations","Type of org":{"id":977873,"value":"School-network","color":"brown"},"Notes":"","Recommendations":[{"id":461,"value":"Maintain a balance between leveraging AI insights and the value of teacher instruction and support"},{"id":462,"value":"Exercise caution when relying solely on AI-generated data and consider other factors in decision-making"},{"id":463,"value":"Develop data literacy skills to effectively analyze and interpret AI-generated data"},{"id":464,"value":"Use AI-generated assessments as a complement to in-person assessments and qualitative feedback from educators"},{"id":465,"value":"Monitor collaborative learning environments to ensure students develop essential teamwork and communication skills"},{"id":466,"value":"Focus on cultivating higher-order cognitive skills alongside AI tools, emphasizing limitations and ethical considerations"},{"id":467,"value":"Provide ongoing professional development for educators to integrate AI tools effectively"},{"id":468,"value":"Address ethical considerations such as data privacy, algorithmic bias, and the impact on human relationships in education"},{"id":469,"value":"Address inequities in access to AI tools, particularly for students in rural or remote areas and those facing financial constraints."}],"Uses-opportunities":[{"id":411,"value":"Personalized learning experience catering to students' unique needs"},{"id":412,"value":"Enhancement of creativity through prompts and suggestions"},{"id":413,"value":"Engaging and enjoyable interactive learning through simulations and games"},{"id":414,"value":"Instant feedback and assessment for timely guidance"},{"id":415,"value":"Language learning support through real-time translation and pronunciation assistance"},{"id":416,"value":"Promotion of accessibility and inclusivity in education"},{"id":417,"value":"Analysis of educational data for valuable insights and informed decision-making"}],"Risks-challenges":[{"id":322,"value":"Potential reinforcement of biases and stereotypes present in the data used for training"},{"id":323,"value":"Risks to fairness and exacerbation of discrimination and systemic inequalities"},{"id":324,"value":"Concerns about the safety and privacy of personal data used by AI tools"},{"id":325,"value":"Need for robust privacy policies, security measures, and compliance with data protection laws"},{"id":326,"value":"Potential for plagiarism and unethical use of AI-generated content"},{"id":329,"value":"Challenges with understanding the underlying processes and decision-making mechanisms of AI tools"},{"id":330,"value":"Risks to trust and accountability and the need for transparency and explainability from researchers and developers"}],"References-footnotes":[{"id":741,"value":"htps://www2.ed.gov/documents/ai-report/aireport.pdf?utm_content=&utm_medium=email&utm_name=&utm_source=govdelivery&utm_term="},{"id":742,"value":"http://www.europarl.europa.eu/RegData/etudes/STUD/2020/641530/EPRS_STU(2020)641530_EN.pdf"},{"id":743,"value":"htps://gazete.education.govt.nz/articles/how-chatgpt-can-be-a-valuable-asset-to-education/"},{"id":744,"value":"htps://www.esafety.gov.au/"},{"id":745,"value":"htps://www.tech.gov.sg/media/technews/tech-and-education-how-automation-and-ai-is-powering-learning-in-singapore"}],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":463,"database_table_184385":1},"value":{"id":980196,"value":"PD","color":"light-red"}},{"ids":{"database_table_183319":467,"database_table_184385":1},"value":{"id":980196,"value":"PD","color":"light-red"}},{"ids":{"database_table_183319":464,"database_table_184385":6},"value":{"id":980185,"value":"new-assessment-models","color":"darker-pink"}},{"ids":{"database_table_183319":465,"database_table_184385":6},"value":{"id":980185,"value":"new-assessment-models","color":"darker-pink"}},{"ids":{"database_table_183319":466,"database_table_184385":6},"value":{"id":980185,"value":"new-assessment-models","color":"darker-pink"}},{"ids":{"database_table_183319":461,"database_table_184385":8},"value":{"id":980188,"value":"new-workforce-model","color":"light-brown"}},{"ids":{"database_table_183319":462,"database_table_184385":8},"value":{"id":980188,"value":"new-workforce-model","color":"light-brown"}},{"ids":{"database_table_183319":468,"database_table_184385":10},"value":{"id":980190,"value":"curricula-changes","color":"light-green"}},{"ids":{"database_table_183319":469,"database_table_184385":27},"value":{"id":980178,"value":"equitable-access","color":"yellow"}}],"Lookup":[{"id":461,"value":"Maintain a balance between leveraging AI insights and the value of teacher instruction and support"},{"id":462,"value":"Exercise caution when relying solely on AI-generated data and consider other factors in decision-making"},{"id":463,"value":"Develop data literacy skills to effectively analyze and interpret AI-generated data"},{"id":464,"value":"Use AI-generated assessments as a complement to in-person assessments and qualitative feedback from educators"},{"id":465,"value":"Monitor collaborative learning environments to ensure students develop essential teamwork and communication skills"},{"id":466,"value":"Focus on cultivating higher-order cognitive skills alongside AI tools, emphasizing limitations and ethical considerations"},{"id":467,"value":"Provide ongoing professional development for educators to integrate AI tools effectively"},{"id":468,"value":"Address ethical considerations such as data privacy, algorithmic bias, and the impact on human relationships in education"},{"id":469,"value":"Address inequities in access to AI tools, particularly for students in rural or remote areas and those facing financial constraints."}]},{"id":26,"order":"26.00000000000000000000","submission_number":"26","Submitter":"Independent Education Union of Australia","Type of org":{"id":977284,"value":"Union","color":"darker-green"},"Notes":"Integrated submission, makes it harder to draw apart the respective components","Recommendations":[{"id":36,"value":"Timely and ongoing consultation with the profession in their workplaces and through their unions is critical to establishing guidelines that protect both teachers and students, without diminishing the educative potential of AI;"},{"id":37,"value":"A cohesive and collaborative approach to the development of AI guidelines is critical to ensure adequate school and sector-wide safeguards for teachers and students."},{"id":470,"value":"The learning programs they deliver must support diversity and generate equitable outcomes that are independent of socioeconomic status, school location, or the wealth of the local school community. Any utilisation of AI within the education system must ensure that these principles are not undermined."},{"id":471,"value":"it is incumbent upon governments and school systems to provide this infrastructure and ensure that equitable access is a paramount consideration. This will require increased and sustained investment from the state and federal governments to ensure 21st century classrooms are available to all."},{"id":472,"value":"Student learning, teaching/assessment processes and academic integrity must remain central considerations in decision making. Business models that outsource learning to for-profit providers or edu-tech platforms are not a feature of these decision-making frameworks."},{"id":473,"value":"It is critical to acknowledge that equity is not realised through access to digital resources and programs alone.There is a need for careful and considered selection and curation of the resources and to blend these with real-world interactions in ways that facilitate and enable meaningful engagement with the broader educational process."},{"id":474,"value":"ensure that decisions made related to new and emerging digital technologies are undertaken after rigorous consultation with the teaching profession. Given the rapid pace of change in digital technologies, consultation processes must be ongoing, to ensure the approaches adopted meet the needs of the profession."},{"id":475,"value":"There is an onus on both state and federal governments to ensure that the curriculum itself is contemporary in terms of content and delivery options"},{"id":476,"value":"Pedagogical decisions regarding resources and learning experiences provided for any given cohort of students must rest with classroom teachers and, crucially, cannot be replicated by AI or other technologies."},{"id":477,"value":"academic integrity must be maintained, with a particular focus upon the assessment cycle. Teachers must be resourced with sufficient time to interrogate the learning process and the assess the artifacts produced by their students"},{"id":478,"value":"The use of digital technology in this process must take place under the oversight of the teaching profession. Any deployment of technology must not undermine teachersâ€™ central role in assessment, moderation and reporting, and must not inhibit beginning teachers from developing the professional knowledge and skills required to make sound pedagogical and assessment decisions."},{"id":479,"value":"It is critically important that education systems provide the resourcing that supports teachersâ€™ access to appropriate, high-quality and ongoing professional development (PD) regarding use of new and emerging digital technologies."},{"id":480,"value":"consideration needs to be given to whether the educational use of these products/platforms has the capacity to detrimentally impact upon teaching and learning processes. The interests of private, profit-seeking providers must not be given precedence over education considerations."},{"id":481,"value":"Government and school systems have a responsibility to ensure that educational systems operate in ways that advance the interests of schools, students, teachers and education leaders, and not those of product and platform providers."},{"id":482,"value":"Legislative protection is required to limit the activities of for-profit enterprises and restrict their capacity to take profit from government funding."},{"id":483,"value":"Schools and teachers must have access to various products and platforms. The cost associated must be factored into system budgets, rather than passed on to schools, students, parents or teachers and education leaders as individuals."},{"id":484,"value":"School systems must ensure that that the sharing of personal data meets the highest privacy thresholds"},{"id":485,"value":"Education leaders and teachers should leverage their expertise to evaluate technologies in the education sector, strengthening and preserving their trusted professional roles instead of relying on private entities."},{"id":486,"value":"Consideration is needed of the degree to which governments and school systems invest in technologies designed to detect inappropriate use of digital technologies by students"},{"id":487,"value":"Under the Workplace Health and Safety (WH&S) Act, education systems must engage in active consultation with workers and develop ongoing systems of review and consultation to address the impacts of new digital technologies and AI on education leaders, teachers, and students, as mandated by the Act."},{"id":488,"value":"adoption of technology  should be carefully considered to avoid exacerbating workload issues and should include considerations of time, professional development, and workplace health and safety implications."},{"id":489,"value":"The decision to adopt new practices should prioritize their relevance to teaching and learning, and careful consideration should be given to the necessary resources and support for implementation."},{"id":490,"value":"Government and education systems must establish policies and protocols to provide adequate and appropriate protections against cyber attack, ensuring that safety measures are not solely dependent on individuals."},{"id":491,"value":"These workplace health and safety concerns must be taken into account when developing and reviewing work systems that incorporate AI."}],"Uses-opportunities":[],"Risks-challenges":[{"id":46,"value":"The primacy of relationships in education outcomes must not be undermined by AI technologies.\nIn consultation with teachers, careful review of current curriculums should be undertaken to ensure the sequential and age-appropriate development of ethics and critical literacy skills in students.\nTeachers need timely and ongoing access to high-quality professional development related to AI in education.\nCommercial interests must be subservient to the over-riding interest of teacher and student wellbeing.\nThe professional judgement of the teacher is fundamental to the learning and assessment process. It must be respected and protected."}],"References-footnotes":[],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":479,"database_table_184385":1},"value":{"id":980196,"value":"PD","color":"light-red"}},{"ids":{"database_table_183319":37,"database_table_184385":2},"value":{"id":980180,"value":"guidelines","color":"light-yellow"}},{"ids":{"database_table_183319":487,"database_table_184385":3},"value":{"id":980182,"value":"situate-with-existing-policy","color":"darker-red"}},{"ids":{"database_table_183319":491,"database_table_184385":3},"value":{"id":980182,"value":"situate-with-existing-policy","color":"darker-red"}},{"ids":{"database_table_183319":36,"database_table_184385":7},"value":{"id":980187,"value":"stakeholder-engagement","color":"dark-green"}},{"ids":{"database_table_183319":37,"database_table_184385":7},"value":{"id":980187,"value":"stakeholder-engagement","color":"dark-green"}},{"ids":{"database_table_183319":474,"database_table_184385":7},"value":{"id":980187,"value":"stakeholder-engagement","color":"dark-green"}},{"ids":{"database_table_183319":487,"database_table_184385":7},"value":{"id":980187,"value":"stakeholder-engagement","color":"dark-green"}},{"ids":{"database_table_183319":472,"database_table_184385":8},"value":{"id":980188,"value":"new-workforce-model","color":"light-brown"}},{"ids":{"database_table_183319":473,"database_table_184385":8},"value":{"id":980188,"value":"new-workforce-model","color":"light-brown"}},{"ids":{"database_table_183319":476,"database_table_184385":8},"value":{"id":980188,"value":"new-workforce-model","color":"light-brown"}},{"ids":{"database_table_183319":477,"database_table_184385":8},"value":{"id":980188,"value":"new-workforce-model","color":"light-brown"}},{"ids":{"database_table_183319":478,"database_table_184385":8},"value":{"id":980188,"value":"new-workforce-model","color":"light-brown"}},{"ids":{"database_table_183319":488,"database_table_184385":8},"value":{"id":980188,"value":"new-workforce-model","color":"light-brown"}},{"ids":{"database_table_183319":475,"database_table_184385":10},"value":{"id":980190,"value":"curricula-changes","color":"light-green"}},{"ids":{"database_table_183319":486,"database_table_184385":11},"value":{"id":980191,"value":"new-policy","color":"dark-purple"}},{"ids":{"database_table_183319":483,"database_table_184385":17},"value":{"id":980195,"value":"resourcing","color":"dark-cyan"}},{"ids":{"database_table_183319":489,"database_table_184385":17},"value":{"id":980195,"value":"resourcing","color":"dark-cyan"}},{"ids":{"database_table_183319":485,"database_table_184385":21},"value":{"id":980197,"value":"evidence-generation","color":"brown"}},{"ids":{"database_table_183319":470,"database_table_184385":27},"value":{"id":980178,"value":"equitable-access","color":"yellow"}},{"ids":{"database_table_183319":471,"database_table_184385":27},"value":{"id":980178,"value":"equitable-access","color":"yellow"}},{"ids":{"database_table_183319":480,"database_table_184385":38},"value":{"id":986019,"value":"respect-rights","color":"light-blue"}},{"ids":{"database_table_183319":481,"database_table_184385":38},"value":{"id":986019,"value":"respect-rights","color":"light-blue"}},{"ids":{"database_table_183319":482,"database_table_184385":38},"value":{"id":986019,"value":"respect-rights","color":"light-blue"}},{"ids":{"database_table_183319":484,"database_table_184385":38},"value":{"id":986019,"value":"respect-rights","color":"light-blue"}},{"ids":{"database_table_183319":490,"database_table_184385":38},"value":{"id":986019,"value":"respect-rights","color":"light-blue"}}],"Lookup":[{"id":36,"value":"Timely and ongoing consultation with the profession in their workplaces and through their unions is critical to establishing guidelines that protect both teachers and students, without diminishing the educative potential of AI;"},{"id":37,"value":"A cohesive and collaborative approach to the development of AI guidelines is critical to ensure adequate school and sector-wide safeguards for teachers and students."},{"id":470,"value":"The learning programs they deliver must support diversity and generate equitable outcomes that are independent of socioeconomic status, school location, or the wealth of the local school community. Any utilisation of AI within the education system must ensure that these principles are not undermined."},{"id":471,"value":"it is incumbent upon governments and school systems to provide this infrastructure and ensure that equitable access is a paramount consideration. This will require increased and sustained investment from the state and federal governments to ensure 21st century classrooms are available to all."},{"id":472,"value":"Student learning, teaching/assessment processes and academic integrity must remain central considerations in decision making. Business models that outsource learning to for-profit providers or edu-tech platforms are not a feature of these decision-making frameworks."},{"id":473,"value":"It is critical to acknowledge that equity is not realised through access to digital resources and programs alone.There is a need for careful and considered selection and curation of the resources and to blend these with real-world interactions in ways that facilitate and enable meaningful engagement with the broader educational process."},{"id":474,"value":"ensure that decisions made related to new and emerging digital technologies are undertaken after rigorous consultation with the teaching profession. Given the rapid pace of change in digital technologies, consultation processes must be ongoing, to ensure the approaches adopted meet the needs of the profession."},{"id":475,"value":"There is an onus on both state and federal governments to ensure that the curriculum itself is contemporary in terms of content and delivery options"},{"id":476,"value":"Pedagogical decisions regarding resources and learning experiences provided for any given cohort of students must rest with classroom teachers and, crucially, cannot be replicated by AI or other technologies."},{"id":477,"value":"academic integrity must be maintained, with a particular focus upon the assessment cycle. Teachers must be resourced with sufficient time to interrogate the learning process and the assess the artifacts produced by their students"},{"id":478,"value":"The use of digital technology in this process must take place under the oversight of the teaching profession. Any deployment of technology must not undermine teachersâ€™ central role in assessment, moderation and reporting, and must not inhibit beginning teachers from developing the professional knowledge and skills required to make sound pedagogical and assessment decisions."},{"id":479,"value":"It is critically important that education systems provide the resourcing that supports teachersâ€™ access to appropriate, high-quality and ongoing professional development (PD) regarding use of new and emerging digital technologies."},{"id":480,"value":"consideration needs to be given to whether the educational use of these products/platforms has the capacity to detrimentally impact upon teaching and learning processes. The interests of private, profit-seeking providers must not be given precedence over education considerations."},{"id":481,"value":"Government and school systems have a responsibility to ensure that educational systems operate in ways that advance the interests of schools, students, teachers and education leaders, and not those of product and platform providers."},{"id":482,"value":"Legislative protection is required to limit the activities of for-profit enterprises and restrict their capacity to take profit from government funding."},{"id":483,"value":"Schools and teachers must have access to various products and platforms. The cost associated must be factored into system budgets, rather than passed on to schools, students, parents or teachers and education leaders as individuals."},{"id":484,"value":"School systems must ensure that that the sharing of personal data meets the highest privacy thresholds"},{"id":485,"value":"Education leaders and teachers should leverage their expertise to evaluate technologies in the education sector, strengthening and preserving their trusted professional roles instead of relying on private entities."},{"id":486,"value":"Consideration is needed of the degree to which governments and school systems invest in technologies designed to detect inappropriate use of digital technologies by students"},{"id":487,"value":"Under the Workplace Health and Safety (WH&S) Act, education systems must engage in active consultation with workers and develop ongoing systems of review and consultation to address the impacts of new digital technologies and AI on education leaders, teachers, and students, as mandated by the Act."},{"id":488,"value":"adoption of technology  should be carefully considered to avoid exacerbating workload issues and should include considerations of time, professional development, and workplace health and safety implications."},{"id":489,"value":"The decision to adopt new practices should prioritize their relevance to teaching and learning, and careful consideration should be given to the necessary resources and support for implementation."},{"id":490,"value":"Government and education systems must establish policies and protocols to provide adequate and appropriate protections against cyber attack, ensuring that safety measures are not solely dependent on individuals."},{"id":491,"value":"These workplace health and safety concerns must be taken into account when developing and reviewing work systems that incorporate AI."}]},{"id":27,"order":"27.00000000000000000000","submission_number":"27","Submitter":"Studiosity","Type of org":{"id":977288,"value":"Company","color":"dark-purple"},"Notes":"","Recommendations":[{"id":492,"value":"It is clear that the strengths and benefits of GAI will need to be combined with the creative input, lived experience, and personal accountability of humans. We need to understand and articulate the potential and evolving role that GAI can play in the teaching and learning experience."},{"id":537,"value":"To maintain learning standards, GAI must be provided within a framework of human oversight. This includes: management of quality inputs and foundations for large learning models; quality assurances for ethical use, content, and academic integrity; human accountability for the technologyâ€™s appropriate and fair function; and, continual review of outputs, including continual vigilance for replication of bias."},{"id":493,"value":"GAI will form part of a wider system of assessment that collectively gives educatorsâ€™ evidence of each studentâ€™s authentic, multi-faceted learning journey. Studentsâ€™ use of GAI in education settings will therefore need to be scaffolded with new skills, including universal delivery of: critical thinking, digital literacy, personal communication and writing style, and opportunities to develop higher-order thinking skills. Teachers will also need to be (re)skilled to provide this scaffolding. In higher education, there is a need for the sector to work closely with professional and accreditation bodies to understand current and future learning and assessment requirements in the context of competency certification."},{"id":494,"value":"The Australian Government needs to hold developers of publicly-used GAI resources accountable for the veracity of output in education settings. As for the use of any new technology, it will be necessary to think through regulatory compliance and broader ethical considerations. Developments internationally should be monitored carefully, particularly for regulatory responses applicable to education providers.\nQuality, ethical outputs from GAI require quality inputs. Australian higher education can help ensure GAI is fit for purpose - avoiding inaccurate, irrelevant, biased, or deceptive outputs, or information that is counter to either regulatory or teachersâ€™ pedagogical design. This can be done by undertaking ongoing due diligence to ensure the inputs of GAI are relevant to educational settings, and that the outputs of GAI in education settings are robust, ethical, increase the quality of learning outcomes, and are protecting the reputation of Australian education. GAI systems will need appropriate controls to allow educational institutions to undertake this work. Misconduct is also a known risk, where some students may pass off AI-generated work as their own. Widespread evidence from within the field of academic integrity suggests that students are well-intentioned but may be opportunistic when under pressure. Misconduct - both unintentional and intentional - can be mitigated when education institutions provide students and teachers with clear advice and guidance and sanctioned alternatives, including appropriately-trained GAI, as trusted, readily-accessible options. Risks and challenges can be mitigated with transparency of use. Policy should dictate that where a student or researcher uses GAI tools this should be disclosed to assessors, reviewers, and other audiences, just as referencing is used to disclose access to archive materials."},{"id":495,"value":"Implemented well, GAI has the potential to improve access to and the accessibility of learning and enhanced learning outcomes for disadvantaged learners. It has the potential to complement classroom teaching with smart, adaptive, and personalised formative feedback at scale and high frequency for individual learners, in modes that suit individual circumstances. It will be important to work with experts, advocates, and communities to understand the potential for different groups of students experiencing disadvantage. GAI is best delivered at scale via Australiaâ€™s strong, existing education infrastructure as part of enrolment. Australiaâ€™s education institutions already include a wide ecosystem of expertise and resourcing that comes from teachers, administrators, student mentors, families, and scaffolding by others, including education scholarship programs. Students in Australian education institutions should receive equal access to quality-assured GAI tools via these existing channels, including equal-access to the associated personal scaffolding required to use GAI ethically and effectively, including critical and digital literacy. Further, partners in Australian education - including scholarship managers, advocates, and community leaders for First Nations students, refugees, learners with disability, and socio-economically disadvantaged groups - can provide valuable connections to studentsâ€™ communities in combination with teaching and learning ecosystems within institutions."},{"id":496,"value":"There is extensive evidence in the Australian context for the impact of personal feedback on student confidence and other academic success metrics. Studiosity can offer the Minister for Education this evidence, and access to early evidence within the higher education sector for the use of GAI on student engagement, confidence, and outcomes."},{"id":497,"value":"Australian education is already globally renowned. There is an urgent need to adjust standards to incorporate the use of GAI to protect and augment those high standards. Use of GAI in Australian education settings should include: 1. Human oversight and quality assurance, ongoing due diligence of GAI outputs, including proactive management of associated large language models. 2. Access at scale - including investment in digital and critical literacy skills; authentic learning opportunities; higher-order thinking skills; and, peer-based learning - to ensure students donâ€™t simply have â€˜accessâ€™ to GAI but are equipped for a lifetime of considered and appropriate use as citizens."}],"Uses-opportunities":[],"Risks-challenges":[],"References-footnotes":[{"id":746,"value":"https://beta.jisc.ac.uk/innovation/national-centre-for-ai"},{"id":747,"value":"https://beta.jisc.ac.uk/reports/a-pathway-towards-responsible-ethical-ai"},{"id":748,"value":"https://beta.jisc.ac.uk/reports/artificial-intelligence-in-tertiary-education"}],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":495,"database_table_184385":3},"value":{"id":980182,"value":"situate-with-existing-policy","color":"darker-red"}},{"ids":{"database_table_183319":493,"database_table_184385":6},"value":{"id":980185,"value":"new-assessment-models","color":"darker-pink"}},{"ids":{"database_table_183319":496,"database_table_184385":6},"value":{"id":980185,"value":"new-assessment-models","color":"darker-pink"}},{"ids":{"database_table_183319":492,"database_table_184385":10},"value":{"id":980190,"value":"curricula-changes","color":"light-green"}},{"ids":{"database_table_183319":497,"database_table_184385":14},"value":{"id":980193,"value":"prepare-learners","color":"dark-gray"}},{"ids":{"database_table_183319":494,"database_table_184385":21},"value":{"id":980197,"value":"evidence-generation","color":"brown"}},{"ids":{"database_table_183319":495,"database_table_184385":22},"value":{"id":980198,"value":"marginalised-group-engagement","color":"light-pink"}},{"ids":{"database_table_183319":494,"database_table_184385":25},"value":{"id":980202,"value":"monitoring-impacts","color":"darker-red"}},{"ids":{"database_table_183319":495,"database_table_184385":27},"value":{"id":980178,"value":"equitable-access","color":"yellow"}},{"ids":{"database_table_183319":497,"database_table_184385":27},"value":{"id":980178,"value":"equitable-access","color":"yellow"}},{"ids":{"database_table_183319":537,"database_table_184385":39},"value":{"id":991258,"value":"foster-responsible-aied","color":"red"}},{"ids":{"database_table_183319":497,"database_table_184385":39},"value":{"id":991258,"value":"foster-responsible-aied","color":"red"}}],"Lookup":[{"id":492,"value":"It is clear that the strengths and benefits of GAI will need to be combined with the creative input, lived experience, and personal accountability of humans. We need to understand and articulate the potential and evolving role that GAI can play in the teaching and learning experience."},{"id":537,"value":"To maintain learning standards, GAI must be provided within a framework of human oversight. This includes: management of quality inputs and foundations for large learning models; quality assurances for ethical use, content, and academic integrity; human accountability for the technologyâ€™s appropriate and fair function; and, continual review of outputs, including continual vigilance for replication of bias."},{"id":493,"value":"GAI will form part of a wider system of assessment that collectively gives educatorsâ€™ evidence of each studentâ€™s authentic, multi-faceted learning journey. Studentsâ€™ use of GAI in education settings will therefore need to be scaffolded with new skills, including universal delivery of: critical thinking, digital literacy, personal communication and writing style, and opportunities to develop higher-order thinking skills. Teachers will also need to be (re)skilled to provide this scaffolding. In higher education, there is a need for the sector to work closely with professional and accreditation bodies to understand current and future learning and assessment requirements in the context of competency certification."},{"id":494,"value":"The Australian Government needs to hold developers of publicly-used GAI resources accountable for the veracity of output in education settings. As for the use of any new technology, it will be necessary to think through regulatory compliance and broader ethical considerations. Developments internationally should be monitored carefully, particularly for regulatory responses applicable to education providers.\nQuality, ethical outputs from GAI require quality inputs. Australian higher education can help ensure GAI is fit for purpose - avoiding inaccurate, irrelevant, biased, or deceptive outputs, or information that is counter to either regulatory or teachersâ€™ pedagogical design. This can be done by undertaking ongoing due diligence to ensure the inputs of GAI are relevant to educational settings, and that the outputs of GAI in education settings are robust, ethical, increase the quality of learning outcomes, and are protecting the reputation of Australian education. GAI systems will need appropriate controls to allow educational institutions to undertake this work. Misconduct is also a known risk, where some students may pass off AI-generated work as their own. Widespread evidence from within the field of academic integrity suggests that students are well-intentioned but may be opportunistic when under pressure. Misconduct - both unintentional and intentional - can be mitigated when education institutions provide students and teachers with clear advice and guidance and sanctioned alternatives, including appropriately-trained GAI, as trusted, readily-accessible options. Risks and challenges can be mitigated with transparency of use. Policy should dictate that where a student or researcher uses GAI tools this should be disclosed to assessors, reviewers, and other audiences, just as referencing is used to disclose access to archive materials."},{"id":495,"value":"Implemented well, GAI has the potential to improve access to and the accessibility of learning and enhanced learning outcomes for disadvantaged learners. It has the potential to complement classroom teaching with smart, adaptive, and personalised formative feedback at scale and high frequency for individual learners, in modes that suit individual circumstances. It will be important to work with experts, advocates, and communities to understand the potential for different groups of students experiencing disadvantage. GAI is best delivered at scale via Australiaâ€™s strong, existing education infrastructure as part of enrolment. Australiaâ€™s education institutions already include a wide ecosystem of expertise and resourcing that comes from teachers, administrators, student mentors, families, and scaffolding by others, including education scholarship programs. Students in Australian education institutions should receive equal access to quality-assured GAI tools via these existing channels, including equal-access to the associated personal scaffolding required to use GAI ethically and effectively, including critical and digital literacy. Further, partners in Australian education - including scholarship managers, advocates, and community leaders for First Nations students, refugees, learners with disability, and socio-economically disadvantaged groups - can provide valuable connections to studentsâ€™ communities in combination with teaching and learning ecosystems within institutions."},{"id":496,"value":"There is extensive evidence in the Australian context for the impact of personal feedback on student confidence and other academic success metrics. Studiosity can offer the Minister for Education this evidence, and access to early evidence within the higher education sector for the use of GAI on student engagement, confidence, and outcomes."},{"id":497,"value":"Australian education is already globally renowned. There is an urgent need to adjust standards to incorporate the use of GAI to protect and augment those high standards. Use of GAI in Australian education settings should include: 1. Human oversight and quality assurance, ongoing due diligence of GAI outputs, including proactive management of associated large language models. 2. Access at scale - including investment in digital and critical literacy skills; authentic learning opportunities; higher-order thinking skills; and, peer-based learning - to ensure students donâ€™t simply have â€˜accessâ€™ to GAI but are equipped for a lifetime of considered and appropriate use as citizens."}]},{"id":28,"order":"28.00000000000000000000","submission_number":"28","Submitter":"Charles Sturt University","Type of org":{"id":977279,"value":"University","color":"darker-blue"},"Notes":"","Recommendations":[{"id":114,"value":"appropriate use of generative AI, including open acknowledgement that it has been used (and why). Most students (and staff) will come to appreciate that moderate use of generative AI (for example, producing literature summaries) is appropriate, but blanket use (such as churning out an entire essay) is not â€“ though even moderate use should, for the foreseeable future, be acknowledged even in situations where the use of AI is sanctioned. A comparable situation is the use of online tools like Wikipedia: good students know, or quickly realise, that it should be regarded as a source of information, and not necessarily a definitive one."},{"id":115,"value":"â€¢ ensuring that users understand the limitations and risks of generative AI, including, for example, the recognition that some tools could involve the intentional or unintentional sharing of personal, private, or confidential information. There are also risks, at least at present, with the accuracy of AI tools. Their results â€“ including those provided by so-called â€˜expert systemsâ€™ â€“ can be very convincing, even when wrong. The limitations of facial recognition tools, for example, are well known, and are, in part, a consequence of the way they are â€˜trainedâ€™ (see below). Generative AI is subject to similar shortcomings and raises the possibility not only of inaccurate information but intentionally or unintentionally created and convincing misinformation."},{"id":117,"value":"â€¢ user anonymity, except in cases where the AI may be part of a subscription or fee-for-service system (in which case this will need to be made clear to users)"},{"id":119,"value":"â€¢ equity of access, as a way to help minimise algorithmic bias but also to ensure the widest possible benefit from these tools"},{"id":120,"value":"â€¢ transparency about inputs, including those used to â€˜trainâ€™ the AI engine, those employed by the AI engine to generate outputs, and those provided by the user, especially when, in either case, proprietary content may be involved (though this would not extend to revealing information about the AIâ€™s underlying algorithms or system architecture)"}],"Uses-opportunities":[{"id":77,"value":"â€¢ preparation of course materials, such as by summarising reading material or providing digests of lectures or presentations,"},{"id":78,"value":"â€¢ creating course content tailored to individual studentsâ€™ needs, reading ability or language skills"},{"id":79,"value":"â€¢ creating abstracts or literature surveys,"},{"id":80,"value":"â€¢ generating summaries for inclusion in essays, theses and other forms of assessment or publication,"},{"id":81,"value":"â€¢ helping researchers stay up-to-date with publications in high-volume or rapidly evolving fields, again through the generation of summaries,â€¢ some administrative tasks, and"},{"id":82,"value":"â€¢ managing workloads."}],"Risks-challenges":[{"id":99,"value":"Students acquire knowledge and skills through human interaction with staff and other students, in group assignments, practicums, assessment, and casual interactions, all of which cannot be replaced by AI. Those human skills will be even more critical in future careers. In health and medicine, for example, AI-enabled diagnostic tools could mean earlier diagnosis of serious and chronic disease, but treatment will still require well-trained health and medical personnel able to interpret the results and what they will mean for the patient. Similarly in law, generative AI could quickly summarise the relevant case law for a trial, but it will be the lawyer who decides how that information should be applied to the case in hand. In these situations, critical thinking â€“ the â€˜know whyâ€™ as well as the â€˜know what and howâ€™ â€“ will be even more important, with clear implications for course content and assessment."}],"References-footnotes":[],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":114,"database_table_184385":6},"value":{"id":980185,"value":"new-assessment-models","color":"darker-pink"}},{"ids":{"database_table_183319":115,"database_table_184385":16},"value":{"id":980194,"value":"communications","color":"darker-brown"}},{"ids":{"database_table_183319":119,"database_table_184385":27},"value":{"id":980178,"value":"equitable-access","color":"yellow"}},{"ids":{"database_table_183319":117,"database_table_184385":38},"value":{"id":986019,"value":"respect-rights","color":"light-blue"}},{"ids":{"database_table_183319":120,"database_table_184385":38},"value":{"id":986019,"value":"respect-rights","color":"light-blue"}}],"Lookup":[{"id":114,"value":"appropriate use of generative AI, including open acknowledgement that it has been used (and why). Most students (and staff) will come to appreciate that moderate use of generative AI (for example, producing literature summaries) is appropriate, but blanket use (such as churning out an entire essay) is not â€“ though even moderate use should, for the foreseeable future, be acknowledged even in situations where the use of AI is sanctioned. A comparable situation is the use of online tools like Wikipedia: good students know, or quickly realise, that it should be regarded as a source of information, and not necessarily a definitive one."},{"id":115,"value":"â€¢ ensuring that users understand the limitations and risks of generative AI, including, for example, the recognition that some tools could involve the intentional or unintentional sharing of personal, private, or confidential information. There are also risks, at least at present, with the accuracy of AI tools. Their results â€“ including those provided by so-called â€˜expert systemsâ€™ â€“ can be very convincing, even when wrong. The limitations of facial recognition tools, for example, are well known, and are, in part, a consequence of the way they are â€˜trainedâ€™ (see below). Generative AI is subject to similar shortcomings and raises the possibility not only of inaccurate information but intentionally or unintentionally created and convincing misinformation."},{"id":117,"value":"â€¢ user anonymity, except in cases where the AI may be part of a subscription or fee-for-service system (in which case this will need to be made clear to users)"},{"id":119,"value":"â€¢ equity of access, as a way to help minimise algorithmic bias but also to ensure the widest possible benefit from these tools"},{"id":120,"value":"â€¢ transparency about inputs, including those used to â€˜trainâ€™ the AI engine, those employed by the AI engine to generate outputs, and those provided by the user, especially when, in either case, proprietary content may be involved (though this would not extend to revealing information about the AIâ€™s underlying algorithms or system architecture)"}]},{"id":29,"order":"29.00000000000000000000","submission_number":"29","Submitter":"University of South Australia","Type of org":{"id":977279,"value":"University","color":"darker-blue"},"Notes":"","Recommendations":[{"id":121,"value":"more work is required to understand how such tools can be best leveraged to improve outcomes. To facilitate this transition, further and significant investment in comprehensive professional development programs for educators,is necessary to equip them with the necessary skills in data analysis and digital and AI literacy."},{"id":122,"value":"By implementing robust regulations and transparent practices, the government can foster a responsible and trustworthy educational environment that maximises the benefits of AI while preserving academic and research integrity."},{"id":123,"value":"International collaborations help align regulations and processes and share best practices and learnings."}],"Uses-opportunities":[{"id":83,"value":"The introduction of generative AI (GenAI) holds the potential to bridge this gap to at least equal, if not exceed, the outcomes achieved with human teachers. GenAI can offer personalised feedback and transform the learning experience. AI presents an opportunity to provide tailored guidance and support to learners, offering a level of personalisation that was previously challenging to achieve."}],"Risks-challenges":[{"id":100,"value":"The use of GenAI tools in education poses risks and challenges, particularly regarding the safe andethical use of these technologies and the preservation of academic and research integrity. It is crucial to address these concerns to maintain a responsible and trustworthy educational environment. Research in AI in education and Learning Analytics has shown that the mere adoption of AI algorithms can introduce potential biases, perpetuating or amplifying existing inequalities or discriminatory practices. Therefore, safeguards must be implemented to ensure fairness and mitigate biases in thedata used for training these AI tools. Additionally, privacy and data security are of utmost importancewhen utilising AI systems that collect and analyse sensitive student information.  Prioritising transparency and accountability is essential to ensure the ethical use of AI systems, and avoid compromising the integrity of academic work or research. Establishing proper protocols and guidelines is necessary to govern the use, interpretation, and reporting of AI-generated outputs. Addressing these risks and challenges through robust regulations, transparent practices, and ongoing monitoring provides the necessary guardrails for implementation and maximises the benefits of generative AI tools in the education sector."}],"References-footnotes":[{"id":219,"value":"1 Bloom, B. S. (1984). The 2 sigma problem: The search for methods of group instruction as effective as one-toone tutoring. Educational researcher, 13(6), 4-16."},{"id":220,"value":"2 Ma, W., et al. (2014). Intelligent tutoring systems and learning outcomes: A meta-analysis. Journal of Educational Psychology, 106(4), 901â€“918. https://doi.org/10.1037/a0037123"},{"id":221,"value":"3 VanLehn, K. (2011). The relative effectiveness of human tutoring, intelligent tutoring systems, and other tutoring systems. Educational psychologist, 46(4), 197-221."}],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":121,"database_table_184385":1},"value":{"id":980196,"value":"PD","color":"light-red"}},{"ids":{"database_table_183319":121,"database_table_184385":17},"value":{"id":980195,"value":"resourcing","color":"dark-cyan"}},{"ids":{"database_table_183319":123,"database_table_184385":20},"value":{"id":980179,"value":"ongoing-and-global-monitoring","color":"dark-brown"}},{"ids":{"database_table_183319":121,"database_table_184385":21},"value":{"id":980197,"value":"evidence-generation","color":"brown"}},{"ids":{"database_table_183319":122,"database_table_184385":39},"value":{"id":991258,"value":"foster-responsible-aied","color":"red"}}],"Lookup":[{"id":121,"value":"more work is required to understand how such tools can be best leveraged to improve outcomes. To facilitate this transition, further and significant investment in comprehensive professional development programs for educators,is necessary to equip them with the necessary skills in data analysis and digital and AI literacy."},{"id":122,"value":"By implementing robust regulations and transparent practices, the government can foster a responsible and trustworthy educational environment that maximises the benefits of AI while preserving academic and research integrity."},{"id":123,"value":"International collaborations help align regulations and processes and share best practices and learnings."}]},{"id":30,"order":"30.00000000000000000000","submission_number":"30","Submitter":"Universities Australia","Type of org":{"id":977283,"value":"HE-network","color":"dark-green"},"Notes":"","Recommendations":[{"id":176,"value":"UA recommends that universities retain the autonomy to manage the opportunities and risks associated with generative AI within their own institutions. Coordination across the sector could be encouraged through the development of best practice guidance and sector-specific standards for the use of generative AI in academia. Importantly, students need to be educated in the practical and ethical implications of generative AI to be adequately prepared for the future workforce. Work to equip students with these skills is already underway across UAâ€™s member institutions."}],"Uses-opportunities":[],"Risks-challenges":[],"References-footnotes":[],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":176,"database_table_184385":4},"value":{"id":980183,"value":"local-responses-and-autonomy","color":"dark-cyan"}}],"Lookup":[{"id":176,"value":"UA recommends that universities retain the autonomy to manage the opportunities and risks associated with generative AI within their own institutions. Coordination across the sector could be encouraged through the development of best practice guidance and sector-specific standards for the use of generative AI in academia. Importantly, students need to be educated in the practical and ethical implications of generative AI to be adequately prepared for the future workforce. Work to equip students with these skills is already underway across UAâ€™s member institutions."}]},{"id":31,"order":"31.00000000000000000000","submission_number":"31","Submitter":"Australian Science and Mathematics School","Type of org":{"id":977281,"value":"Peak body","color":"green"},"Notes":"","Recommendations":[{"id":498,"value":"Learning activities and assessment must be designed with AI in mind, so that AI is less able to be used to do all the thinking for students."},{"id":499,"value":"Allow increased flexibility in assessments (particularly at higher grade levels, as lower ones are quite flexible) so schools have the freedom to design assessments and conditions to reduce unethical use of generative AI by students."},{"id":500,"value":"there will need to be an education campaign highlighting the benefits of AI as a work and education tool but also the importance of independent, critical and creative thought of being a human."},{"id":501,"value":"Publish resources that support students and teachers to become proficient users of AI, including understanding the benefits and limitations."},{"id":502,"value":"Support schools with standards of use for AI."}],"Uses-opportunities":[{"id":418,"value":"Personalised tutoring-students with access to written generative AI can ask for\nexplanations of concepts in multiple styles"},{"id":419,"value":"Accessibility - students can ask questions of AI any time they have access to\ntechnology"},{"id":420,"value":"Time saving - generative AIâ€™s ability to summarise long texts means research can be\nshortened significantly by identifying relevant texts more quickly"},{"id":421,"value":"Creating learning activities - students can generate additional learning activities for\nthemselves, such as quizzes or flashcards"},{"id":422,"value":"Feedback - Generative AI can be another source of feedback for students on the\nquality of their work.\nImproves: student learning"},{"id":423,"value":"Polishing, editing, condensing or adapting appropriate tone: Students have another\ntool to polish and edit work as part of their revision and drafting processes."},{"id":424,"value":"Improves: teacher time and student resources-teachers are able to create exemplars for students to evaluate the\nstrength and weaknesses thereof, allowing deeper analysis of text types and\nexpectations and saving significant teacher time in creating these exemplars\nthemselves"}],"Risks-challenges":[{"id":327,"value":"Some AI bypasses paywalls (theyâ€™re limiting that as I type) which is unethical."},{"id":328,"value":"Students are using generative AI to write assessments for them, in direct contradiction\nto SACE and school policies about not receiving undue assistance with assessed\nwork"},{"id":331,"value":"Students do not always have the knowledge or critical thinking skills to identify AIgenerated falsehoods and can learn incorrect information from it."},{"id":332,"value":"Students are using generative AI to shortcut learning activities, and in the process not\ndoing the thinking and learning the activity was designed to promote."},{"id":333,"value":"Generative AI tools often have age-restricted terms and conditions. Schools cannot\nuse them as the sole option for activities without parental permission."},{"id":334,"value":"Generative AI tools may be trained on 18+ or other inappropriate content that would\nnot usually be permitted in a school setting, and may generate answers based on that\ncontent"},{"id":335,"value":"Idea generation - some students use generative AI to create lists of ideas. This may\nlimit their creative skills in developing their own ideas and limit the outcome of their\nwork if the ideas from AI are overly generic and do not match what the student would\nhave been able to do without AI use."}],"References-footnotes":[],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":502,"database_table_184385":2},"value":{"id":980180,"value":"guidelines","color":"light-yellow"}},{"ids":{"database_table_183319":498,"database_table_184385":6},"value":{"id":980185,"value":"new-assessment-models","color":"darker-pink"}},{"ids":{"database_table_183319":499,"database_table_184385":6},"value":{"id":980185,"value":"new-assessment-models","color":"darker-pink"}},{"ids":{"database_table_183319":500,"database_table_184385":16},"value":{"id":980194,"value":"communications","color":"darker-brown"}},{"ids":{"database_table_183319":501,"database_table_184385":19},"value":{"id":980186,"value":"capacity-building","color":"light-yellow"}}],"Lookup":[{"id":498,"value":"Learning activities and assessment must be designed with AI in mind, so that AI is less able to be used to do all the thinking for students."},{"id":499,"value":"Allow increased flexibility in assessments (particularly at higher grade levels, as lower ones are quite flexible) so schools have the freedom to design assessments and conditions to reduce unethical use of generative AI by students."},{"id":500,"value":"there will need to be an education campaign highlighting the benefits of AI as a work and education tool but also the importance of independent, critical and creative thought of being a human."},{"id":501,"value":"Publish resources that support students and teachers to become proficient users of AI, including understanding the benefits and limitations."},{"id":502,"value":"Support schools with standards of use for AI."}]},{"id":32,"order":"32.00000000000000000000","submission_number":"32","Submitter":"Tech for Social Good","Type of org":{"id":977289,"value":"nonprofit","color":"darker-gray"},"Notes":"","Recommendations":[{"id":503,"value":"Invest in structured training for classroom staff on the use of GenAI in the classroom and how to educate students about using the technology."},{"id":504,"value":"Invest in training and demonstrations for students in the classroom to build literacy and understanding about the benefits and limitations of GenAI and how to best use GenAI tools responsibly."},{"id":505,"value":"Formulate strategic priorities and policy for GenAI at the Department level and school level to provide tailored guidance to staff and students."},{"id":506,"value":"Upskill and train regulators and policymakers about the opportunities and risks of AI in education, as well as best practice policy and regulatory approaches."},{"id":507,"value":"Initiate strong strategic partnerships with relevant government and private stakeholders to codesign solutions for deploying responsible GenAI in classrooms"},{"id":508,"value":"Consult widely on education system reform with a focus on the impact of emerging technologies on education delivery and assessment."},{"id":509,"value":"Ensure existing policy and regulatory frameworks are fit-for-purpose and are able to deliver adequate protections for the use of GenAI in the education system. This should be underpinned by the regulatory principles of harmonisation, diversity, and necessity."},{"id":510,"value":"Build a repository of current and emerging educational technology (EdTech) tools to understand the spectrum of capabilities, limitations, and impacts."},{"id":511,"value":"Establish regulatory sandboxes for GenAI solutions to be deployed in test educational environments before being rolled out more widely."},{"id":512,"value":"Direct additional investment to incentivise the deployment of GenAI, as well as to boost research and development to build a strong ecosystem of responsible GenAI that can help achieve beneficial educational outcomes."},{"id":513,"value":"Students â— Require an understanding of the risks, limitations and potential of GenAI in both the education context, but also beyond it. It is critical to build literacy and familiarity as a fundamental digital skill"},{"id":514,"value":"Studentsâ— Require an understanding of the idea that GenAI has incredible potential as a tool to enhance and augment\nlearning, but not replace fundamental skills in literacy and critical thinking"},{"id":515,"value":"Parentsâ— Require assurances that the education system is taking appropriate measures around GenAI in the classroom, and that it is being deployed in a safe and responsible way."},{"id":516,"value":"Teachersâ— Require guidance on how assessment and teaching can be delivered in a way which achieves the desired educational outcomes, but also ensures that students use GenAI in a productive way."},{"id":517,"value":"School\nleadershipâ— Requires capacity building\nand strategic expertise in\nAI."},{"id":518,"value":"School\nleadershipâ— Requires a fit-for-purpose AI\nstrategy for the school."},{"id":519,"value":"School\nleadershipâ— Requires an integrated,\ncomprehensive AI\ngovernance system within\nthe school."},{"id":520,"value":"School\nleadershipâ— Requires a human-centred\nAI culture."},{"id":521,"value":"Policymakers and regulators â— Require upskilling regarding the risks and opportunities presented by GenAI, and the specific implications it has for the education system."},{"id":522,"value":"Any regulation that is developed should be consistent with existing state and federal laws, as well as education-specific laws and frameworks."},{"id":523,"value":"Consider soft law"},{"id":524,"value":"New regulation only where necessary"},{"id":525,"value":"Funding and investment There are a number of initiatives which can be established with a view to enhancing innovation, adoption, and practice at the level of the ecosystem to support the longer-term sustainment of GenAI in education."},{"id":526,"value":"Funding deployment of GenAI systems Increased funding for schools would enable them to invest in and deploy responsible Artificial Intelligence for Education (AIED) technologies. This would be especially beneficial for disadvantaged schools"},{"id":527,"value":"We recommend the Government create a repository of current EdTech tools and use cases and their capabilities, limitations and impacts to improve school decision-making around EdTech procurement and use."},{"id":528,"value":"There should be a significant increase in investment in research, development, and innovation in education technologies (particularly AI-driven EdTech), as well as quality impact and implementation research."},{"id":529,"value":"GenAI sandboxes Sandboxes enable governments and businesses to develop and test tools in a safe and controlled environment with students, teachers, and other stakeholders before they are released."},{"id":530,"value":"In the long term, we recommend the Government undertake a detailed review of Australiaâ€™s education system to identify challenges and gaps posed by emerging technologies such as GenAI, the impacts such technologies have on the education system and ways to ensure the system remains prepared and fit-for-purpose."},{"id":531,"value":"To promote responsible innovation and use of GenAI, we recommend the Government consider outlining requirements that these tools must reach based on risk mitigation and education research before these tools are deployed widely and used by teachers and students."}],"Uses-opportunities":[{"id":425,"value":"Learning\npersonalisation: systems can generate content\nand interactions that are attune to\nstudent needs, adapting based on the\nstudent prompts and feedback. This\nenables more personalised and\nengaging experiences for students,\nparticularly those who might have\notherwise been disengaged with their\nlearning. In effect, these tools provide\none-on-one tutoring which is an\neffective way to close learning gaps"},{"id":426,"value":"Promote\ncreative and\ncritical thinking\nskills"},{"id":427,"value":"Reduce\nadministrative\nburdens for teachers"},{"id":428,"value":"Customising\neducational\nexperiences\nfor students:Teachers can better cater to\nindividual students by using GenAI\ntools to generate personalised\nlearning experiences for individual\nstudents based on ability, needs and\ninterests."}],"Risks-challenges":[{"id":336,"value":"False information and hallucinations in generated content"},{"id":337,"value":"Problematic biases in outputs"},{"id":338,"value":"Data privacy and security"},{"id":339,"value":"Risks of government inaction"}],"References-footnotes":[{"id":749,"value":"Adrian J. Wallbank, Prompt engineering as academic skill: a model for effective ChatGPT interactions."},{"id":751,"value":"Julie Hare, You canâ€™t ban the bot, educators say as they struggle with ChatGPT."},{"id":754,"value":"UNESCO, UNESCO survey: Less than 10% of schools and universities have formal guidance on AI."},{"id":755,"value":"PECB, Generative AI and Data Privacy"},{"id":756,"value":"Alex Hern, OpenAI says new model GPT-4 is more creative and less likely to invent facts"},{"id":758,"value":"Fiona Longmuir, Australia's teacher shortage is a generational crisis in the making. How can we turn things around?."},{"id":761,"value":"Leslie Loble, Shaping AI and edtech to tackle Australiaâ€™s learning divide."},{"id":762,"value":"Adam Carey, Victoria banned ChatGPT in state schools. But Catholic schools took a surprising stance."},{"id":763,"value":"Australian Government Department of Foreign Affairs and Trade, Education Learning and Development Module."},{"id":765,"value":"Tom Smalley, Ending Australia's lesson lottery: why we invested in Cleverbean"},{"id":766,"value":"Duolingo, Introducing Duolingo Max, a learning experience powered by GPT-4"},{"id":767,"value":"Lisa Bonos, Say hello to your new tutor: Itâ€™s ChatGPT."},{"id":768,"value":"Erik Ofgang, What Is Khanmigo? The GPT-4 Learning Tool Explained by Sal Khan"},{"id":769,"value":"Khan Academy, World-class AI for education"},{"id":770,"value":"Doug Aamoth, 5 free AI-powered creativity tools worth checking out."},{"id":771,"value":"Allens, The AI-generated picture becomes clearer: key legal considerations emerging for generative AI developers and their\ncustomers."},{"id":772,"value":"Australian Government, Review to Inform a Better and Fairer Education System Consultation"},{"id":773,"value":"Grattan Institute, Widening gaps: What NAPLAN tells us about student progress"},{"id":774,"value":"Productivity Commission, 5-Year Productivity Inquiry Report"}],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":503,"database_table_184385":1},"value":{"id":980196,"value":"PD","color":"light-red"}},{"ids":{"database_table_183319":506,"database_table_184385":1},"value":{"id":980196,"value":"PD","color":"light-red"}},{"ids":{"database_table_183319":516,"database_table_184385":1},"value":{"id":980196,"value":"PD","color":"light-red"}},{"ids":{"database_table_183319":521,"database_table_184385":1},"value":{"id":980196,"value":"PD","color":"light-red"}},{"ids":{"database_table_183319":505,"database_table_184385":2},"value":{"id":980180,"value":"guidelines","color":"light-yellow"}},{"ids":{"database_table_183319":516,"database_table_184385":2},"value":{"id":980180,"value":"guidelines","color":"light-yellow"}},{"ids":{"database_table_183319":523,"database_table_184385":2},"value":{"id":980180,"value":"guidelines","color":"light-yellow"}},{"ids":{"database_table_183319":509,"database_table_184385":3},"value":{"id":980182,"value":"situate-with-existing-policy","color":"darker-red"}},{"ids":{"database_table_183319":518,"database_table_184385":3},"value":{"id":980182,"value":"situate-with-existing-policy","color":"darker-red"}},{"ids":{"database_table_183319":519,"database_table_184385":3},"value":{"id":980182,"value":"situate-with-existing-policy","color":"darker-red"}},{"ids":{"database_table_183319":522,"database_table_184385":3},"value":{"id":980182,"value":"situate-with-existing-policy","color":"darker-red"}},{"ids":{"database_table_183319":524,"database_table_184385":3},"value":{"id":980182,"value":"situate-with-existing-policy","color":"darker-red"}},{"ids":{"database_table_183319":507,"database_table_184385":7},"value":{"id":980187,"value":"stakeholder-engagement","color":"dark-green"}},{"ids":{"database_table_183319":508,"database_table_184385":7},"value":{"id":980187,"value":"stakeholder-engagement","color":"dark-green"}},{"ids":{"database_table_183319":504,"database_table_184385":10},"value":{"id":980190,"value":"curricula-changes","color":"light-green"}},{"ids":{"database_table_183319":513,"database_table_184385":10},"value":{"id":980190,"value":"curricula-changes","color":"light-green"}},{"ids":{"database_table_183319":514,"database_table_184385":10},"value":{"id":980190,"value":"curricula-changes","color":"light-green"}},{"ids":{"database_table_183319":530,"database_table_184385":10},"value":{"id":980190,"value":"curricula-changes","color":"light-green"}},{"ids":{"database_table_183319":505,"database_table_184385":11},"value":{"id":980191,"value":"new-policy","color":"dark-purple"}},{"ids":{"database_table_183319":509,"database_table_184385":11},"value":{"id":980191,"value":"new-policy","color":"dark-purple"}},{"ids":{"database_table_183319":511,"database_table_184385":11},"value":{"id":980191,"value":"new-policy","color":"dark-purple"}},{"ids":{"database_table_183319":529,"database_table_184385":11},"value":{"id":980191,"value":"new-policy","color":"dark-purple"}},{"ids":{"database_table_183319":530,"database_table_184385":11},"value":{"id":980191,"value":"new-policy","color":"dark-purple"}},{"ids":{"database_table_183319":528,"database_table_184385":12},"value":{"id":980192,"value":"research-investment","color":"orange"}},{"ids":{"database_table_183319":515,"database_table_184385":16},"value":{"id":980194,"value":"communications","color":"darker-brown"}},{"ids":{"database_table_183319":512,"database_table_184385":17},"value":{"id":980195,"value":"resourcing","color":"dark-cyan"}},{"ids":{"database_table_183319":525,"database_table_184385":17},"value":{"id":980195,"value":"resourcing","color":"dark-cyan"}},{"ids":{"database_table_183319":526,"database_table_184385":17},"value":{"id":980195,"value":"resourcing","color":"dark-cyan"}},{"ids":{"database_table_183319":506,"database_table_184385":19},"value":{"id":980186,"value":"capacity-building","color":"light-yellow"}},{"ids":{"database_table_183319":510,"database_table_184385":19},"value":{"id":980186,"value":"capacity-building","color":"light-yellow"}},{"ids":{"database_table_183319":517,"database_table_184385":19},"value":{"id":980186,"value":"capacity-building","color":"light-yellow"}},{"ids":{"database_table_183319":527,"database_table_184385":19},"value":{"id":980186,"value":"capacity-building","color":"light-yellow"}},{"ids":{"database_table_183319":509,"database_table_184385":20},"value":{"id":980179,"value":"ongoing-and-global-monitoring","color":"dark-brown"}},{"ids":{"database_table_183319":527,"database_table_184385":21},"value":{"id":980197,"value":"evidence-generation","color":"brown"}},{"ids":{"database_table_183319":526,"database_table_184385":27},"value":{"id":980178,"value":"equitable-access","color":"yellow"}},{"ids":{"database_table_183319":512,"database_table_184385":39},"value":{"id":991258,"value":"foster-responsible-aied","color":"red"}},{"ids":{"database_table_183319":520,"database_table_184385":39},"value":{"id":991258,"value":"foster-responsible-aied","color":"red"}},{"ids":{"database_table_183319":531,"database_table_184385":39},"value":{"id":991258,"value":"foster-responsible-aied","color":"red"}}],"Lookup":[{"id":503,"value":"Invest in structured training for classroom staff on the use of GenAI in the classroom and how to educate students about using the technology."},{"id":504,"value":"Invest in training and demonstrations for students in the classroom to build literacy and understanding about the benefits and limitations of GenAI and how to best use GenAI tools responsibly."},{"id":505,"value":"Formulate strategic priorities and policy for GenAI at the Department level and school level to provide tailored guidance to staff and students."},{"id":506,"value":"Upskill and train regulators and policymakers about the opportunities and risks of AI in education, as well as best practice policy and regulatory approaches."},{"id":507,"value":"Initiate strong strategic partnerships with relevant government and private stakeholders to codesign solutions for deploying responsible GenAI in classrooms"},{"id":508,"value":"Consult widely on education system reform with a focus on the impact of emerging technologies on education delivery and assessment."},{"id":509,"value":"Ensure existing policy and regulatory frameworks are fit-for-purpose and are able to deliver adequate protections for the use of GenAI in the education system. This should be underpinned by the regulatory principles of harmonisation, diversity, and necessity."},{"id":510,"value":"Build a repository of current and emerging educational technology (EdTech) tools to understand the spectrum of capabilities, limitations, and impacts."},{"id":511,"value":"Establish regulatory sandboxes for GenAI solutions to be deployed in test educational environments before being rolled out more widely."},{"id":512,"value":"Direct additional investment to incentivise the deployment of GenAI, as well as to boost research and development to build a strong ecosystem of responsible GenAI that can help achieve beneficial educational outcomes."},{"id":513,"value":"Students â— Require an understanding of the risks, limitations and potential of GenAI in both the education context, but also beyond it. It is critical to build literacy and familiarity as a fundamental digital skill"},{"id":514,"value":"Studentsâ— Require an understanding of the idea that GenAI has incredible potential as a tool to enhance and augment\nlearning, but not replace fundamental skills in literacy and critical thinking"},{"id":515,"value":"Parentsâ— Require assurances that the education system is taking appropriate measures around GenAI in the classroom, and that it is being deployed in a safe and responsible way."},{"id":516,"value":"Teachersâ— Require guidance on how assessment and teaching can be delivered in a way which achieves the desired educational outcomes, but also ensures that students use GenAI in a productive way."},{"id":517,"value":"School\nleadershipâ— Requires capacity building\nand strategic expertise in\nAI."},{"id":518,"value":"School\nleadershipâ— Requires a fit-for-purpose AI\nstrategy for the school."},{"id":519,"value":"School\nleadershipâ— Requires an integrated,\ncomprehensive AI\ngovernance system within\nthe school."},{"id":520,"value":"School\nleadershipâ— Requires a human-centred\nAI culture."},{"id":521,"value":"Policymakers and regulators â— Require upskilling regarding the risks and opportunities presented by GenAI, and the specific implications it has for the education system."},{"id":522,"value":"Any regulation that is developed should be consistent with existing state and federal laws, as well as education-specific laws and frameworks."},{"id":523,"value":"Consider soft law"},{"id":524,"value":"New regulation only where necessary"},{"id":525,"value":"Funding and investment There are a number of initiatives which can be established with a view to enhancing innovation, adoption, and practice at the level of the ecosystem to support the longer-term sustainment of GenAI in education."},{"id":526,"value":"Funding deployment of GenAI systems Increased funding for schools would enable them to invest in and deploy responsible Artificial Intelligence for Education (AIED) technologies. This would be especially beneficial for disadvantaged schools"},{"id":527,"value":"We recommend the Government create a repository of current EdTech tools and use cases and their capabilities, limitations and impacts to improve school decision-making around EdTech procurement and use."},{"id":528,"value":"There should be a significant increase in investment in research, development, and innovation in education technologies (particularly AI-driven EdTech), as well as quality impact and implementation research."},{"id":529,"value":"GenAI sandboxes Sandboxes enable governments and businesses to develop and test tools in a safe and controlled environment with students, teachers, and other stakeholders before they are released."},{"id":530,"value":"In the long term, we recommend the Government undertake a detailed review of Australiaâ€™s education system to identify challenges and gaps posed by emerging technologies such as GenAI, the impacts such technologies have on the education system and ways to ensure the system remains prepared and fit-for-purpose."},{"id":531,"value":"To promote responsible innovation and use of GenAI, we recommend the Government consider outlining requirements that these tools must reach based on risk mitigation and education research before these tools are deployed widely and used by teachers and students."}]},{"id":33,"order":"33.00000000000000000000","submission_number":"33","Submitter":"TEQSA","Type of org":{"id":977282,"value":"Govt","color":"orange"},"Notes":"","Recommendations":[{"id":177,"value":"Within the field of education, the crafting of any regulatory framework should be mindful of specific risks and impacts for educational uses, such as: â€¢ the need for transparent disclosure of the training data and algorithms that underpin educational products so that they can be genuinely evaluated by government and educational institutions to ensure they are free of bias. The onus should be on EdTech developers to make this information intelligible â€¢ a requirement for humans to remain accountable for all AI-assisted decision making. That is, AI can provide input and information and even recommendations, but decision making and accountability can not be delegated to a non-human and recommendations must be able to be over-ridden by a human â€¢ an absolute requirement to respect and protect student and staff privacy, with clear legal requirements for appropriate data handling, storage and disposal to be applied in all models and uses. This requirement should be crafted in such a way as to also provide protection against surveillance usage â€¢ intellectual property considerations, particularly as they relate to sensitive research data and proposals as well as assessment design â€¢ the need for developers to ensure that they are mindful of, and seek to eliminate, bias and discrimination through the data the model is trained on, the design of the model and its suggested applications â€¢ a requirement for educational administrators and institutions to ensure models and their applications are evaluated for bias and that their use is governed by institutional policies, and that adherence is monitored. As a final point, TEQSA notes that consideration should be given the data on which AI is trained to ensure local contexts are adequately represented. This is important to avoid erasing Australian and indigenous culture in a sea of US-centric internet content. Setting down requirements for those creating AI models to be purposeful and considered about the training data can help create inclusive and diverse AI systems."}],"Uses-opportunities":[{"id":108,"value":"Personalised learning experiences Generative AI tools can enable more frequent, rapid, and detailed analysis of student outcomes and performance, as well as student engagement. Through a combination of automation and teacher reflection, these tools can help educators provide regular and personalised feedback to help students improve their understanding and performance. By utilising machine learning, AI tools are capable of acting as tutors for individual students, by identifying concepts that require further explanation or refreshing, and offering different ways of presenting the information to the student to support learning. Of particular relevance to the school sector, AI can help present the analysis in appropriate ways to different audiences â€“ such as crafting separate summaries for teachers, parents, and students. Such capability would increase the capacity for students to receive immediate and targeted support from both teachers and parents as soon as any concerns arise"},{"id":109,"value":"Reducing administrative burden for educators Educators can leverage AI for support in designing lesson plans, creating exemplars of course material, providing feedback on assessment tasks, identifying concepts that individuals or groups of students are struggling to master, and analysing performance of students. By reducing the administrative burden, generative AI tools have the capacity to free up valuable educator time for more meaningful engagement with students, colleagues, and professional development."},{"id":110,"value":"Supporting education systems The Higher Education Standards Framework sets out requirements for institutions to have processes for identifying individual students at risk of unsatisfactory progress (Standard 1.3.4) and for ensuing that trends in student outcomes are used to enable review and improvement (Standard 1.3.5). Such â€˜systems levelâ€™ requirements can benefit from the application of generative AI tools to streamline data analysis and presentation. AI can also contribute to more effective allocation of resources, whether they are human, physical, or electronic. By leveraging data and analytics, educational institutions can optimise their resource distribution, and potentially move to a shared-infrastructure model, ensuring resources are utilised efficiently and effectively. In the school sector, this may minimise disruptions caused by teacher absences or discipline-specific shortages. Generative AI tools also have the potential to facilitate more effective and targeted regulation in education. By analysing vast amounts of data, these tools can identify patterns, trends, and areas for improvement, enabling policymakers and administrators to make evidence-based decisions to enhance the overall quality of education."},{"id":111,"value":"Mitigating disadvantage Of relevance to the school sector, generative AI tools could provide additional support to disadvantaged cohorts as an â€œAI butler or buddyâ€. Acting as a career counsellor, the AI buddy conducts conversations that individuals without social capital often miss out on. For example, these tools can help students understand potential career paths based on their interests and capabilities, as well as the study paths required to pursue those careers, and associated admissions processes. This support bridges the gap in access to valuable information and guidance, empowering disadvantaged students to make informed decisions about their futures. Generative AI tools could be used to develop augmented reality experiences, which could be particularly beneficial for remote and low socioeconomic status (SES) schools. Virtual field trips could be facilitated, offering students immersive learning opportunities that would otherwise be inaccessible. Given historical challenges with equitable resource allocation, especially with emerging technologies, it would be essential to ensure that those schools most in need receive both the technology and the necessary infrastructure and teacher training to make best use of it."},{"id":112,"value":"there is tremendous scope for AI to benefit the educational journey of students and families experiencing disadvantage, and to create efficiencies for institutions in delivering tailored services. By leveraging the concept of social capital, AI can provide invaluable support to students from disadvantaged backgrounds through the provision of an AI buddy or butler. These AI companions can answer their questions and provide guidance and support, offering personalised assistance that helps level the playing field. AI can contribute to better cataloguing and linkages for lifelong learning. Through intelligent algorithms and appropriate data input, individuals can access a vast array of resources, courses, and knowledge, tailored to their specific needs and interests, enabling continuous learning throughout their lives. A significant potential benefit of AI in education is the provision of tailored, instant support that is not constrained by geographical limitations or fixed timetables. Students can receive personalised assistance and guidance whenever they need it, enhancing their learning experience. However, targeted AI interventions that â€œspeed upâ€ or â€œslow downâ€ content delivery based on student achievement could inadvertently widen achievement gaps. AI has the potential to offer relatively low-cost individual support, which can be highly beneficial. However, it is crucial to acknowledge that there is a risk of price differentiation (reflecting differences in the sophistication and reliability of the algorithm) becoming part of the AI ecosystem, potentially"}],"Risks-challenges":[{"id":132,"value":"The rapid advancement of large language models is forcing educators to think carefully about what knowledge still needs to be taught when so much information can be so readily synthesised by AI. Some courses, particularly in tertiary education and specific disciplines, may quickly become outdated and require regular review and updates. This will only be enabled through the development of more agile systems of governance that are capable of being more responsive to changing context while upholding the integrity of the qualification. It is critical that the process of course design and review engages carefully setting the learning objectives, to ensure they are contemporary and appropriate in the age of AI, and will produce graduates with both discipline-expertise and the ability to use technology effectively and ethically."},{"id":133,"value":"The emergence of AI tools capable of completing a substantial portion of traditional assessment tasks necessitates a re-evaluation of the purposes of assessment. While AI presents the opportunity to assess students on higher order cognitive skills, it is important to recognise that foundational content knowledge will continue to hold significance, especially in certain disciplines. It is crucial that the education sector develops new methods of assessment that can ensure learning outcomes in an age of AI tools to prevent an uncoupling of learning and assessment, which could have far-reaching consequences."},{"id":134,"value":"The student/AI hybrid model also presents potential challenges for teachers, as they may need to assess the extent to which a student has modified the output of AI-generated work. This could increase the workload for teachers and require additional evaluation measures. While generative AI tools have the potential to revolutionize teaching and assessment practices, careful consideration of the purpose of education, the role of educators, and the evolving landscape of knowledge will be critical in harnessing the benefits of AI in a way that is inclusive and mitigates potential negative consequences. To effectively navigate an AIdependent environment, ongoing professional development will be essential for teachers, school support staff, administrative personnel, and policymakers."},{"id":135,"value":"The increasing sophistication of AI poses diverse risks to research integrity, and TEQSA is engaging with the higher education sector to ensure that these risks are being recognised and reflected in updated institutional policy frameworks and the associated practices. AI has the capability to generate not just fake data, including false or doctored images, but entirely manufactured studies and journal articles. Images generated by AI are becoming increasingly difficult to detect and can compromise the integrity of research findings."},{"id":136,"value":"Additionally, the administrative burden of the scientific peer-review process may result in reviewers outsourcing the review to AI systems to either provider the reviewer with a summary or provide feedback. AI systems do not hold the same level of detailed expertise of a human discipline expert, which may result in fewer erroneous or misleading research findings being identified prior to publication. Decreasing genuine engagement by experts with novel research in their field also presents a risk to innovation and collaboration"},{"id":137,"value":"There are significant risks to intellectual property where sensitive pre-published research findings, doctoral theses presented for examination or grant applications are uploaded to a third-party platform, and TEQSA is working with institutions to ensure they are proactively managing these risks through their policies and contracts."},{"id":138,"value":"It not appropriately managed, AI has the potential to dilute the quality of published research, obscure genuine research in a sea of AI-generated content and ultimately undermine the publicâ€™s trust in the scientific process."},{"id":139,"value":"The current crop of large language models can produce many of the artefacts that institutions have historically relied on for that assurance of learning, such as essays, coding tasks and both worded and numerical maths problems. As a result, without a transformation in how institutions assess student achievement of learning outcomes, there is a risk to the integrity of the system. While some commentators have welcomed the fact that AI can replace lower-level tasks that require content recall and allow for assessment of higher order cognition, there are several fundamental principles to consider. â€¢ The accuracy of current language models is not reliable, and their output needs to be scrutinised for errors. If the education system were to shift entirely to a â€œStudent/AI hybridâ€ model, it raises concerns about how future students will acquire the necessary content knowledge to effectively evaluate AI-generated output. â€¢ Completion of tasks such as essays holds pedagogical value that is unrelated to assessment purposes. For example, through writing essays, students learn to research, structure and defend arguments, and communicate their ideas in a written form. Motivating students to engage in these tasks may become challenging without the incentive of assessmentbased evaluation. Assessing the process of creating the artefact while employing the use of AI tools can provide an effective assessment process, but requires a greater investment of academic time in the marking process. These opportunities and impacts need to be recognised and appropriately resourced by institutions. â€¢ The use of AI in education raises serious concerns about data sovereignty and privacy. It is essential to address these issues and ensure that the use of AI tools does not compromise student, staff or institutional data and intellectual property. â€¢ Humanity will continue to require future generations of creative thinkers with discipline expertise. Because generative AI is trained on data, and all data is by definition historical, an over-reliance on AI may limit innovation, insight, and discovery. It is therefore crucial that society scaffolds in the introduction of AI tools through a studentâ€™s education journey, to ensure all students develop critical thinking skills and to defend the pipeline of students who can reach expert levels. â€¢ There is a risk of AI systems becoming self-contained and self-referential. An illustrative example is an educator using AI to write the lesson plans, design the assessment task and marking rubric. The student then uses AI to produce the assessment tasks, and the educator then uses AI to grade the assessment and provide feedback. In such a situation, the limited human involvement in the process undermines not just the educational experience but the very process of learning. Ultimately, AI is necessitating a rethink of how institutions of higher education can assure themselves that students have met the learning outcomes of a degree when the artefacts that have historically been relied on in current forms of assessment can be completed to a passing level with minimal student engagement."},{"id":140,"value":"Current large language models are reflective of the enormous data sets they are trained on, resulting in a reflection of the biases and discrimination already present in those data sets. AI also has the potential to reinforce bias and disadvantage when algorithms are misused or poorly designed. Further, the risk of automation bias, with humans tending to place higher trust in an automated decision-making system, must be recognised and mitigated."}],"References-footnotes":[],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":177,"database_table_184385":37},"value":{"id":980209,"value":"Indigenous-ICIP-IDIP","color":"dark-orange"}}],"Lookup":[{"id":177,"value":"Within the field of education, the crafting of any regulatory framework should be mindful of specific risks and impacts for educational uses, such as: â€¢ the need for transparent disclosure of the training data and algorithms that underpin educational products so that they can be genuinely evaluated by government and educational institutions to ensure they are free of bias. The onus should be on EdTech developers to make this information intelligible â€¢ a requirement for humans to remain accountable for all AI-assisted decision making. That is, AI can provide input and information and even recommendations, but decision making and accountability can not be delegated to a non-human and recommendations must be able to be over-ridden by a human â€¢ an absolute requirement to respect and protect student and staff privacy, with clear legal requirements for appropriate data handling, storage and disposal to be applied in all models and uses. This requirement should be crafted in such a way as to also provide protection against surveillance usage â€¢ intellectual property considerations, particularly as they relate to sensitive research data and proposals as well as assessment design â€¢ the need for developers to ensure that they are mindful of, and seek to eliminate, bias and discrimination through the data the model is trained on, the design of the model and its suggested applications â€¢ a requirement for educational administrators and institutions to ensure models and their applications are evaluated for bias and that their use is governed by institutional policies, and that adherence is monitored. As a final point, TEQSA notes that consideration should be given the data on which AI is trained to ensure local contexts are adequately represented. This is important to avoid erasing Australian and indigenous culture in a sea of US-centric internet content. Setting down requirements for those creating AI models to be purposeful and considered about the training data can help create inclusive and diverse AI systems."}]},{"id":34,"order":"34.00000000000000000000","submission_number":"34","Submitter":"The University of Melbourne","Type of org":{"id":977279,"value":"University","color":"darker-blue"},"Notes":"","Recommendations":[{"id":124,"value":"Universities will inevitably need to adapt their offerings to respond to generative AI. This will include reconsidering assessment to include more authentic, continuous forms of assessment where the opportunity for academic misconduct is reduced. Universities will need to ensure Higher Degree by Research (HDR) candidates, for example, understand the importance of generating their own content, noting that writing is intimately linked with cognition. Universities will also need to ensure their students and staff are AI literate."}],"Uses-opportunities":[{"id":84,"value":"Generative AI can be a helpful tool for teaching, allowing students to develop their critical thinking and evaluative judgement skills by generating outputs from platforms such as ChatGPT and then improving and critiquing that output. Already, some subjects at the University of Melbourne involve the use of generative AI in their assessments. There are also opportunities for researchers to use these tools when undertaking their research, using them to develop code, help design surveys, and test methodologies."}],"Risks-challenges":[{"id":101,"value":"the use of generative AI tools to produce work that is subsequently submitted forassessment is considered academic misconduct, unless permission to use such tools has been given by academic staffand their use has been acknowledged by the student. Similarly, generative AI can only be used in research outputswhere the material generated is acknowledged. generative AI tools such as ChatGPT are known to produce convincing but false information, a tendency that is referred to by developers as â€œhallucinatingâ€. Additionally, generative AI tools are fundamentally biased, replicating and reinforcing the biases present in the human-created materials on which they are trained."}],"References-footnotes":[{"id":222,"value":"18 Holmes, W., et al. (2022), Artificial Intelligence and Education: A critical view through the lens of human rights,democracy and the rule of law, Council of Europe, p. 19 19 ibid., p. 26."},{"id":223,"value":"20 Bell, G., Burgess, J., Thomas, J., and Sadiq, S. (2023), Rapid Response Information Report: Generative AI - language models (LLMs) and multimodal foundation models (MFMs), Australian Council of Learned Academies, p.8"}],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":124,"database_table_184385":10},"value":{"id":980190,"value":"curricula-changes","color":"light-green"}}],"Lookup":[{"id":124,"value":"Universities will inevitably need to adapt their offerings to respond to generative AI. This will include reconsidering assessment to include more authentic, continuous forms of assessment where the opportunity for academic misconduct is reduced. Universities will need to ensure Higher Degree by Research (HDR) candidates, for example, understand the importance of generating their own content, noting that writing is intimately linked with cognition. Universities will also need to ensure their students and staff are AI literate."}]},{"id":35,"order":"35.00000000000000000000","submission_number":"35","Submitter":"Western Sydney University","Type of org":{"id":977279,"value":"University","color":"darker-blue"},"Notes":"","Recommendations":[{"id":532,"value":"Establish clear legal standards and algorithmic accountability standards - Privacy, ethical use and e-safety"},{"id":533,"value":"Establish regulations and centres of excellence for data governance"},{"id":534,"value":"Develop and implement ethical frameworks and guidelines in consultation with Learned Academies, and accreditation and sector peak bodies including Indigenous Australian peak bodies and organisations â€“ e.g Maiam nayri Wingara"},{"id":535,"value":"Use standard terms and definitions and expand definitions of research and research codes of conduct to include â€˜originalityâ€™ and â€˜reproducibilityâ€™"},{"id":538,"value":"Ensure institutional and sector support for developing artificial intelligence literacy among students, educators and researchers"},{"id":539,"value":"Address inequities in access to digital devices and opportunities to address AI and digital literacy across the school and higher education sectors."},{"id":540,"value":"Develop risk frameworks and undertake risk assessment and impact analysis"},{"id":541,"value":"Establish a panel of experts including diverse users and a library of use cases, good practice examples and diverse user experiences"},{"id":542,"value":"Prioritise resourcing at institution and sector levels"},{"id":543,"value":"Provide funding to support research and policy development"},{"id":544,"value":"Adopt ACODE recommendations: https://publications.ascilite.org/index.php/APUB/article/view/401 \nRecommendations1.Embrace AI in learning, teaching, and assessment, but consider potential risks and challenges that come with it, such as academic integrity concerns and workload issues.2.Foster a culture of transparency, collaboration, and partnership between educators, students, and AI experts, to ensure that AI is used ethically and effectively.3.Develop evidence-based support systems and guidelines for AI use in education, and regularly update them to keep up with the latest developments and challenges.4.Identify and provide appropriate training and professional development opportunities for educators to build their AI competencies, confidence and fluency.5.Consider the potential impact of AI on equity and accessibility and ensure that AI solutions are designed to benefit all students, regardless of their background or circumstances.6.Collaborate with external bodies, such as accrediting bodies and regulatory agencies, to align educational responses to AI across primary, secondary, and tertiary education sectors.7.Continuously monitor and evaluate the impact of AI on learning, teaching, and assessment, and be open to making necessary adjustments based on the evidence.8.Institutions prioritise assessment redesign, by adopting more authentic forms of assessment to minimise the option for students to use AI based tools in generating assessment content"}],"Uses-opportunities":[{"id":429,"value":"Open access to educational opportunities"},{"id":430,"value":"alternative\nlearning pathways"},{"id":431,"value":"potential for higher-order learning"},{"id":432,"value":"learner engagement"},{"id":433,"value":"personalisation of\nlearning"},{"id":434,"value":"Learning analytics â€“ more effective use of data to optimise learning experiences"},{"id":435,"value":"raise teaching quality; learning resources â€“ ability to create bespoke learning resources quickly"},{"id":436,"value":"increased teacher productivity â€“ more time available for teaching; consultation, scholarship of teaching"},{"id":437,"value":"increased\nadministrative productivity â€“ improved student satisfaction, ability to act on student feedback and better handling of\ntransactional data with reduced errors"}],"Risks-challenges":[{"id":340,"value":"AI literacy is a priority across the educational workforce to prepare staff and students for effective and ethical\nuse of generative AI"},{"id":341,"value":"Digital Capabilities, of which AI literacy will become one, are already uneven across providers and\nthe sector and there are disparities across the school and higher education sectors in staff and studentsâ€™ opportunities to\ndevelop digital capabilities and the new AI literacy"},{"id":342,"value":"Safe and ethical use: Bias and misinformation are widespread; intellectual property â€“ potential for copyright infringement\n(including course content) and incomplete IP claims"},{"id":343,"value":"Academic, research and graduate research integrity: Authorship; outsourcing; integrity of qualifications; assurance of\nlearning for accreditation standards"},{"id":344,"value":"Research data management and analysis: Generated â€˜dataâ€™ drawing on previous published research lacks integrity â€“cannot\nbe treated as credible representations of phenomena; generated â€˜dataâ€™ are not representative of the population being\nstudied"},{"id":345,"value":"Scholarly publishing: Insufficient detail on information sourced from generative AI for license and copyright agreements;\ngenerative AI tools do not meet authorship requirements, cannot take responsibility for a manuscript, will have difficulty\nmanaging changes in writing conventions that capitalise words in Indigenous writing"}],"References-footnotes":[{"id":775,"value":"https://www.education.gov.au/australian-universities-accord/resources/australian-universities-accord-panel-discussion-paper"}],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":544,"database_table_184385":1},"value":{"id":980196,"value":"PD","color":"light-red"}},{"ids":{"database_table_183319":534,"database_table_184385":2},"value":{"id":980180,"value":"guidelines","color":"light-yellow"}},{"ids":{"database_table_183319":540,"database_table_184385":3},"value":{"id":980182,"value":"situate-with-existing-policy","color":"darker-red"}},{"ids":{"database_table_183319":534,"database_table_184385":12},"value":{"id":980192,"value":"research-investment","color":"orange"}},{"ids":{"database_table_183319":543,"database_table_184385":12},"value":{"id":980192,"value":"research-investment","color":"orange"}},{"ids":{"database_table_183319":538,"database_table_184385":14},"value":{"id":980193,"value":"prepare-learners","color":"dark-gray"}},{"ids":{"database_table_183319":544,"database_table_184385":14},"value":{"id":980193,"value":"prepare-learners","color":"dark-gray"}},{"ids":{"database_table_183319":534,"database_table_184385":15},"value":{"id":980181,"value":"Indigenous-leadership","color":"darker-pink"}},{"ids":{"database_table_183319":542,"database_table_184385":17},"value":{"id":980195,"value":"resourcing","color":"dark-cyan"}},{"ids":{"database_table_183319":541,"database_table_184385":19},"value":{"id":980186,"value":"capacity-building","color":"light-yellow"}},{"ids":{"database_table_183319":535,"database_table_184385":21},"value":{"id":980197,"value":"evidence-generation","color":"brown"}},{"ids":{"database_table_183319":544,"database_table_184385":25},"value":{"id":980202,"value":"monitoring-impacts","color":"darker-red"}},{"ids":{"database_table_183319":539,"database_table_184385":27},"value":{"id":980178,"value":"equitable-access","color":"yellow"}},{"ids":{"database_table_183319":532,"database_table_184385":38},"value":{"id":986019,"value":"respect-rights","color":"light-blue"}},{"ids":{"database_table_183319":533,"database_table_184385":39},"value":{"id":991258,"value":"foster-responsible-aied","color":"red"}}],"Lookup":[{"id":532,"value":"Establish clear legal standards and algorithmic accountability standards - Privacy, ethical use and e-safety"},{"id":533,"value":"Establish regulations and centres of excellence for data governance"},{"id":534,"value":"Develop and implement ethical frameworks and guidelines in consultation with Learned Academies, and accreditation and sector peak bodies including Indigenous Australian peak bodies and organisations â€“ e.g Maiam nayri Wingara"},{"id":535,"value":"Use standard terms and definitions and expand definitions of research and research codes of conduct to include â€˜originalityâ€™ and â€˜reproducibilityâ€™"},{"id":538,"value":"Ensure institutional and sector support for developing artificial intelligence literacy among students, educators and researchers"},{"id":539,"value":"Address inequities in access to digital devices and opportunities to address AI and digital literacy across the school and higher education sectors."},{"id":540,"value":"Develop risk frameworks and undertake risk assessment and impact analysis"},{"id":541,"value":"Establish a panel of experts including diverse users and a library of use cases, good practice examples and diverse user experiences"},{"id":542,"value":"Prioritise resourcing at institution and sector levels"},{"id":543,"value":"Provide funding to support research and policy development"},{"id":544,"value":"Adopt ACODE recommendations: https://publications.ascilite.org/index.php/APUB/article/view/401 \nRecommendations1.Embrace AI in learning, teaching, and assessment, but consider potential risks and challenges that come with it, such as academic integrity concerns and workload issues.2.Foster a culture of transparency, collaboration, and partnership between educators, students, and AI experts, to ensure that AI is used ethically and effectively.3.Develop evidence-based support systems and guidelines for AI use in education, and regularly update them to keep up with the latest developments and challenges.4.Identify and provide appropriate training and professional development opportunities for educators to build their AI competencies, confidence and fluency.5.Consider the potential impact of AI on equity and accessibility and ensure that AI solutions are designed to benefit all students, regardless of their background or circumstances.6.Collaborate with external bodies, such as accrediting bodies and regulatory agencies, to align educational responses to AI across primary, secondary, and tertiary education sectors.7.Continuously monitor and evaluate the impact of AI on learning, teaching, and assessment, and be open to making necessary adjustments based on the evidence.8.Institutions prioritise assessment redesign, by adopting more authentic forms of assessment to minimise the option for students to use AI based tools in generating assessment content"}]},{"id":36,"order":"36.00000000000000000000","submission_number":"36","Submitter":"Copyright Advisory Group","Type of org":{"id":977289,"value":"nonprofit","color":"darker-gray"},"Notes":"","Recommendations":[{"id":545,"value":"That the Copyright Act 1968 be amended to provide appropriate public interest\nexceptions to support the use of machine learning and data and text mining in\nAustralia."},{"id":558,"value":"That the Copyright Act 1968 be updated to ensure that the laws for the use of\nmaterial in the physical classroom are equally applicable to a digital classroom\nsetting, including remote learning and the sharing of material on digital platforms."},{"id":559,"value":"That the Copyright Act 1968 be amended to provide for an express exception for\nthe use of freely available internet material in education"}],"Uses-opportunities":[{"id":438,"value":"Generative AI highly likely to exacerbate current problems with the Copyright Act"}],"Risks-challenges":[{"id":346,"value":"Uncertainty regarding the development of AI systems and tools by innovators and\nteachers"},{"id":347,"value":"Uncertainty regarding the use of the outputs of AI by students and teachers"},{"id":348,"value":"Lack of clear permission for using copyright material in machine learning in Australian law, making the use of AI in education risky."},{"id":349,"value":"Administrative complexities and burden of obtaining licenses for every input to AI systems, hindering practical and legal access to rich datasets for training."},{"id":350,"value":"Absence of public interest exceptions for schools and TAFEs to engage in machine learning for educational purposes, raising doubts about the legality of teaching and using AI models in these institutions."},{"id":351,"value":"Clear public interest exceptions needed for educational noncommercial use of generative AI to create learning resources and provide tailored learning opportunities"},{"id":352,"value":"The current problem with freely available internet materials in education is likely to worsen with the use of generative AI systems."},{"id":353,"value":"Updating copyright laws to enable broader use of digital technologies in education, including the adoption of generative AI."}],"References-footnotes":[{"id":776,"value":"https://www.google.com/url?q=https://www.wipo.int/wipolex/en/text/295166&sa=D&source=docs&ust=168"},{"id":777,"value":"Artificial Intelligence and Intellectual Property, World Intellectual Property Organisation (WIPO),\nhttps://www.wipo.int/aboutip/en/frontier technologies/ai and ip.html#:~:text=Machine%20learning%20uses%20examples%20of,by\n%2Dstep%20sequence%20of%20instructions."},{"id":778,"value":"Machine learning uses examples of input and expected output (so called â€œstructured dataâ€ or â€œtraining\ndataâ€), in order to continually improve and make decisions without being programmed how to do so in a\nstep-by-step sequence of instructions. See https://www.wipo.int/aboutip/en/frontier technologies/ai and ip.html#:~:text=Machine%20learning%20uses%20examples%20of,by\n%2Dstep%20sequence%20of%20instructions."},{"id":779,"value":"For example, the NSW Institute of Applied Technology has recently introduced an â€˜Introduction to\nArtificial Intelligenceâ€™ course, see https://store.training.tafensw.edu.au/product/introduction-to-artificialintelligence/. See also their microskill course â€˜Responsible Artificial Intelligence:\nhttps://store.training.tafensw.edu.au/product/responsible-artificialintelligence/? ga=2.234301150.1344238210.1688526259-497552872.1688526255."},{"id":780,"value":"For example, in its 2013 report, â€˜Copyright in the Digital Economyâ€™ the ALRC noted that â€˜there is no\nexception in the Copyright Act that covers data and text mining. Where the data or text mining processes\ninvolve the copying, digitisation, or reformatting of copyright material without permission, it may give rise\nto copyright infringementâ€™, p 262."},{"id":781,"value":"ALRC, Copyright and the Digital Economy"},{"id":782,"value":"Productivity Commission inquiry report no 78, Intellectual Property Arrangements (2016), Overview of\nReport 27"},{"id":783,"value":"Department of Education and Training, Through Growth to Achievement: Report of the Review to\nAchieve Educational Excellence in Australian Schools (2018) 13"},{"id":784,"value":"The Exposure Draft Copyright Amendment (Access Reform) Bill 2021 was released for public\nconsultation prior to the last election. The Bill would have addressed some of the issues raised by the\nALRC and Productivity Commission, but did not address many of the issues raised in this submission and\nby the ALRC and Productivity Commission"},{"id":785,"value":"Safe and Responsible AI in Australia - Discussion Paper. Department of Industry, Science and\nResources pg.7-8."},{"id":786,"value":"https://www.google.com/url?q=https://slate.com/business/2018/10/amazon-artificial-intelligence-hiring-discrimination-women.html&sa=D&source=docs&ust=1688097650940485&usg=AOvVaw044ILLdWUlVJGhd5DAcsjv"},{"id":787,"value":"https://news.mit.edu/2018/study-finds-gender-skin-type-bias-artificial-intelligence-systems-0212"},{"id":788,"value":"https://creativecommons.org/2021/03/04/should-cc-licensed-content-be-used-to-train-ai-it-depends/"},{"id":789,"value":"https://www.afr.com/companies/media-and-marketing/news-corp-in-talks-with-ai-firm-about-compensation-20230308-p5cqcp"},{"id":790,"value":"https://www.alrc.gov.au/publication/copyright-and-the-digital-economy-alrc-report-122/"},{"id":792,"value":"Ibid pp 262-263, citing I Hargreaves, Digital Opportunity: A Review of Intellectual Property and Growth\n(2011), p 47."},{"id":793,"value":"Robert Burrell, Michael Handler, Emily Hudson and Kimberlee Weatherall, ALRC Inquiry into Copyright\nand the Digital Economy Submission in response to Issues Paper No. 42 (14 December 2012), p 10."},{"id":794,"value":"https://www.google.com/url?q=https://www.wipo.int/wipolex/en/text/295166&sa=D&source=docs&ust=168"},{"id":795,"value":"Australian Law Reform Commission, Copyright and the Digital Economy, Report No 122 (2013) Terms\nof Reference."},{"id":796,"value":"Australian Law Reform Commission, Copyright and the Digital Economy, Report No 122 (2013) 194."},{"id":797,"value":"https://sso.agc.gov.sg/Acts-Supp/22-2021/Published/20211007?DocDate=20211007"},{"id":798,"value":"https://consult.industry.gov.au/supporting-responsible-ai"},{"id":799,"value":"https://www.ag.gov.au/sites/default/files/2023-03/ministerial-roundtable-on-copyright-high-level-summary.PDF"},{"id":800,"value":"https://www.ag.gov.au/rights-and-protections/copyright/ministerial-roundtable-copyright"},{"id":801,"value":"https://www.northmetrotafe.wa.edu.au/courses/diploma-information-technology-games-and-intelligent-systems"},{"id":802,"value":"https://store.training.tafensw.edu.au/product/introduction-to-artificial-intelligence/"},{"id":803,"value":"https://www.tastafe.tas.edu.au/news-folder/tastafe-releases-ambitious-10-year-strategic-plan"},{"id":804,"value":"https://library.tafeqld.edu.au/AI"}],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":545,"database_table_184385":11},"value":{"id":980191,"value":"new-policy","color":"dark-purple"}},{"ids":{"database_table_183319":558,"database_table_184385":11},"value":{"id":980191,"value":"new-policy","color":"dark-purple"}},{"ids":{"database_table_183319":559,"database_table_184385":11},"value":{"id":980191,"value":"new-policy","color":"dark-purple"}},{"ids":{"database_table_183319":545,"database_table_184385":38},"value":{"id":986019,"value":"respect-rights","color":"light-blue"}},{"ids":{"database_table_183319":558,"database_table_184385":38},"value":{"id":986019,"value":"respect-rights","color":"light-blue"}},{"ids":{"database_table_183319":559,"database_table_184385":38},"value":{"id":986019,"value":"respect-rights","color":"light-blue"}}],"Lookup":[{"id":545,"value":"That the Copyright Act 1968 be amended to provide appropriate public interest\nexceptions to support the use of machine learning and data and text mining in\nAustralia."},{"id":558,"value":"That the Copyright Act 1968 be updated to ensure that the laws for the use of\nmaterial in the physical classroom are equally applicable to a digital classroom\nsetting, including remote learning and the sharing of material on digital platforms."},{"id":559,"value":"That the Copyright Act 1968 be amended to provide for an express exception for\nthe use of freely available internet material in education"}],"FLAG":""},{"id":37,"order":"37.00000000000000000000","submission_number":"37","Submitter":"Engineers Australia","Type of org":{"id":977281,"value":"Peak body","color":"green"},"Notes":"","Recommendations":[{"id":560,"value":"Engineers Australia recommends the development of standards on how Generative Al can be used to develop critical thinking and evaluative judgement should be an immediate focus. Unfortunately, the pace of change will make it hard for these standards to be maintained. Therefore, it would seem essential to develop a standards framework that has adaptability asits core, some examples of what could be included:\nâ€¢  Development of education around generative Al:\no  fundamental principles on effective and ethical engagement with generative Al\no  appropriate acknowledgement of, and guidance on how to evidence critical engagement with generative Al tools\no  development of prompt engineering skills to enable generative Al to be used to develop critical  thinking skills and evaluative judgement,\no  tuning learning outcome specifications to the generative Al era,\no  assessment designed to test human capability. ie. why would something that can be generated by Al be assessed? - a more robust assessment might require the student to critique the responses from a tool like ChatGPT.\nâ€¢  Ethical implications of uploading student work for assessment.\n\nwe are likely to see the development of discipline-specific Generative Al tools, which are not only trained on a generalised large language model, but specifically in a discipline ecosystem. The development of guidelines on how these tools should be developed and utilised to ensure some standardisation would be useful. For example, appropriately declared use/acknowledgement of Generative Al tools, just as is the case with referencing the use of published work of others, needs to be a critical element in the developing ethical attitudes and practices for graduates entering any field of professional practice."},{"id":561,"value":"The student voice will enable the development of standards that meets their needs, therefore the establishment of a student reference group to help define and maintain the standards is crucial."}],"Uses-opportunities":[{"id":439,"value":"Generative AI supports people from all backgrounds in their education journey."},{"id":440,"value":"Potential for generative AI to provide tutoring experiences to all, regardless of socio-economic background."},{"id":441,"value":"Use of generative AI in implementing effective teaching strategies, such as producing varied examples, providing multiple explanations, developing low-stakes tests, assessing student learning, and distributing practice of important ideas."},{"id":442,"value":"Enhancing critical thinking skills in students and allowing under-resourced educators to create more activities and problems for students."},{"id":443,"value":"Potential opportunities for using generative AI, like ChatGPT, in engineering education to support learning and critical thinking development."}],"Risks-challenges":[{"id":354,"value":"Misleading, biased, incorrect or inaccurate information"},{"id":355,"value":"Academic integrity"},{"id":356,"value":"Risks and challenges around privacy and data protection"},{"id":357,"value":"The future use of the data is not known, with the potential for future systems to use input data for further upskilling"}],"References-footnotes":[{"id":806,"value":"Menekse, Muhsin. 2023. â€˜Envisioning the future of earning and teaching engineering in the artificia inte igence era: Opportunities and Cha enges Journal of engineering education (accessed 3 June 2023)"},{"id":807,"value":"Mo ick, E and Mo ick, L. 2023 â€˜Using AI to Imp ement Effective Teaching Strategies in C assrooms: Five Strategies, Inc uding Prompts Wharton School of the University of Pennsylvania & Wharton Interactive (accessed 3 June 2023) https://papers.ssrn.com/so 3/papers.cfm?abstract id=4391243"},{"id":808,"value":"5\tSasha Niko ic, Scott Danie , Rezwanu Haque, Marina Be kina, Ghu am M. Hassan, Sarah Grundy, Sarah Lyden, Peter Nea & Caz Sandison. 2023 â€˜ChatGPT versus engineering education assessment: a mu tidiscip inary and mu ti-institutiona benchmarking and ana ysis of this generative artificia inte igence too to investigate assessment integrity European Journal of Engineering Education (accessed 2 June 2023) https://doi.org/10.1080/03043797.2023.2213169"},{"id":809,"value":"6\tEmi y M. Bender, Timnit Gebru, Ange ina McMi an-Major, and Shmar-garet Shmitche . 2021. â€˜On the Dangers of Stochastic Parrots: Can Language Mode s Be Too Big? . In Conference on Fairness, Accountabi ity, and Transparency (FAccT 21) , March 3â€“10, 2021, Virtua Event, Canada. ACM, New York, NY, USA, 14 pages. https://doi.org/10.1145/3442188.3445922"},{"id":810,"value":"Dastin, J. 2018. â€˜Amazon scraps secret AI recruiting too that showed bias against women Reuters (accessed 5 June 2023) https://www.reuters.com/artic e/us-amazon-com-jobs-automation-insight-idUSKCN1MK08G"},{"id":811,"value":"Heaven, W. â€˜The education of ChatGPT MIT Technology Review Volume 126 Number 3 (May/June 2023)"},{"id":812,"value":"10\tSasha Niko ic, Scott Danie , Rezwanu Haque, Marina Be kina, Ghu am M. Hassan, Sarah Grundy, Sarah Lyden, Peter Nea & Caz Sandison. 2023 â€˜ChatGPT versus engineering education assessment: a mu tidiscip inary and mu ti-institutiona benchmarking and ana ysis of this generative artificia inte igence too to investigate assessment integrity European Journal of Engineering Education (accessed 2 June 2023) https://doi.org/10.1080/03043797.2023.2213169"},{"id":813,"value":"Oded Nov, Nina Singh, Devin M. Mann. 2023. â€˜Putting ChatGPT s Medica Advice to the (Turing) Test. medRxiv https://doi.org/10.1101/2023.01.23.23284735"},{"id":814,"value":"Adam Hu man, PhD, O e LindgÃ¥rd Do erup, PhD, Jesper Friis Mortensen, MSc Matthew Fenech, PhD, Kasper Norman, MSc , Henrik StÃ¸vring DMSc, Troe s Krarup Hansen, DMSc. 2023 â€˜ChatGPT versus human-generated answers to frequent y asked questions about diabetes: a Turning test-inspried survey among emp oyees of a Danish diabetes center medRxiv (accessed 5 June 2023) https://doi.org/10.1101/2023.02.13.23285745"},{"id":815,"value":"Sasha Niko ic, Scott Danie , Rezwanu Haque, Marina Be kina, Ghu am M. Hassan, Sarah Grundy, Sarah Lyden, Peter Nea & Caz Sandison. 2023 â€˜ChatGPT versus engineering education assessment: a mu tidiscip inary and mu ti-institutiona benchmarking and ana ysis of this generative artificia inte igence too to investigate assessment integrity European Journa of Engineering Education (accessed 2 June 2023) https://doi.org/10.1080/03043797.2023.2213169"},{"id":816,"value":"Menekse, Muhsin. 2023. â€˜Envisioning the future of earning and teaching engineering in the artificia inte igence era: Opportunities and Cha enges Journal of engineering education (accessed 3 June 2023)"},{"id":817,"value":"Heaven, W. â€˜The education of ChatGPT MIT Technology Review Volume 126 Number 3 (May/June 2023)"},{"id":819,"value":"Exploring teacher and student attitudes toward ChatGPT Walton family Foundation (4 May 2023)\nhttps://www.wa tonfami yfoundation.org/stories/k-12-education/exp oring-teacher-and-student-attitudes"}],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":560,"database_table_184385":2},"value":{"id":980180,"value":"guidelines","color":"light-yellow"}},{"ids":{"database_table_183319":560,"database_table_184385":6},"value":{"id":980185,"value":"new-assessment-models","color":"darker-pink"}},{"ids":{"database_table_183319":561,"database_table_184385":7},"value":{"id":980187,"value":"stakeholder-engagement","color":"dark-green"}},{"ids":{"database_table_183319":560,"database_table_184385":10},"value":{"id":980190,"value":"curricula-changes","color":"light-green"}}],"Lookup":[{"id":560,"value":"Engineers Australia recommends the development of standards on how Generative Al can be used to develop critical thinking and evaluative judgement should be an immediate focus. Unfortunately, the pace of change will make it hard for these standards to be maintained. Therefore, it would seem essential to develop a standards framework that has adaptability asits core, some examples of what could be included:\nâ€¢  Development of education around generative Al:\no  fundamental principles on effective and ethical engagement with generative Al\no  appropriate acknowledgement of, and guidance on how to evidence critical engagement with generative Al tools\no  development of prompt engineering skills to enable generative Al to be used to develop critical  thinking skills and evaluative judgement,\no  tuning learning outcome specifications to the generative Al era,\no  assessment designed to test human capability. ie. why would something that can be generated by Al be assessed? - a more robust assessment might require the student to critique the responses from a tool like ChatGPT.\nâ€¢  Ethical implications of uploading student work for assessment.\n\nwe are likely to see the development of discipline-specific Generative Al tools, which are not only trained on a generalised large language model, but specifically in a discipline ecosystem. The development of guidelines on how these tools should be developed and utilised to ensure some standardisation would be useful. For example, appropriately declared use/acknowledgement of Generative Al tools, just as is the case with referencing the use of published work of others, needs to be a critical element in the developing ethical attitudes and practices for graduates entering any field of professional practice."},{"id":561,"value":"The student voice will enable the development of standards that meets their needs, therefore the establishment of a student reference group to help define and maintain the standards is crucial."}]},{"id":38,"order":"38.00000000000000000000","submission_number":"38","Submitter":"Open Access Australasia","Type of org":{"id":977289,"value":"nonprofit","color":"darker-gray"},"Notes":"","Recommendations":[{"id":562,"value":"We recommend that Australia embrace a considered and leading role in the region with regards to the responsible use of Al in higher education."},{"id":563,"value":"We support a robust, inclusive approach to developing further recommendations and guidelines in this area - libraries and open access advocates can play a key role in this due to our provision of both content and information skills, and our experience in the complex landscape of open access."},{"id":564,"value":"We believe that Al can make responsible reuse of open access scholarly research, but it is critical that licensing and acknowledgement issues around Al are  clarified."},{"id":565,"value":"We emphasise that the success of LLMs' contributions to higher education depends on the quality of their training data."},{"id":566,"value":"Any national approach to open access will need to consider the implications for Al/GAi."}],"Uses-opportunities":[{"id":444,"value":"Al-assisted technologies can improve the quality of open educational resources and support the synthesising of information for a non-technical audience."},{"id":445,"value":"Al-assisted technologies can improve the discoverability and! accessibillity of resources - especially open access resources - through Al assisted search engines and automated metadata creation."}],"Risks-challenges":[{"id":358,"value":"Copyright and licensing\n\nGAi relies on copyright and text and data mining (TOM) provisions that are not fully incorporated into Australian copyright law at the present time"},{"id":359,"value":"Open source vs commercial Al/GAi systems\n\nThe importance of supporting open source systems which enable the code and model to be more easily interrogated, allowing for greater transparency.\nOpen Access Australasia shares concerns raised in the US and elsewhere about the risks to competition if power and usage of Al/GAi platforms and tools is concentrated among a handful!of commercial players."},{"id":360,"value":"Lack of transparency in Al/GAi processes and systems\n\nMany widely used LLM training datasets are not fully detailed or transparent"},{"id":361,"value":"Implications for the integrity of research\n\nThere are fears that the proliferation of Al tools for academic research may result i11 decline in the quality of academic output"},{"id":362,"value":"Indigenous research and data\n\nIndigenous peoples' control of their data, culture and language is threatened when data is scraped en masse from the web without knowledge and co11sent"}],"References-footnotes":[{"id":820,"value":"Berlin Declaration on Open Access to Knowledge in the Sciences and Humanities. Max Planck Society. October 22, 2003. Accessed July 13, 2023. https://openaccess.mpg.de/Berlin-Declaration"},{"id":821,"value":"The Relationship Between Open Access Science and Al. March 20, 2023. Azorobotics. Accessed July 10, 2023 https://www.azorobotics.com/Article.aspx?Artide1D=588"},{"id":822,"value":"Bradley, F. Representation of libraries in artificial intelligence regulations and implications for ethics and practice. J Aus Libr Inf Assoc. 2022;71(3} doi:10.1080/24750158.2022.2101911"},{"id":823,"value":"Milmo D. Sarah Silverman sues OpenAI and Meta claimiing Al training infringed copyright. The\nGuardian. July 10, 2023. Accessed July 12, 2023. https://www.theguardian.com/technology/2023/jul/10/sarah-silverman-sues-openai-meta-copyrightÂ­     infringement"},{"id":824,"value":"Google calls for relaxing of Australia's copyright laws so Al can mine websites for information. The\nGuardian. April 19, 2023. Accessed July 10, 2023 https://www.theguardian.com/technology/2023/apr/19/google-calls-for-relaxing-of-australiasÂ­   copyrigh t-1aws-so-ai-ca n-min e-we bsites-for-inform ation"},{"id":825,"value":"Generative Al Raises Competition Concerns. Federal Trade Commission. June 29, 2023.. Accessed July 10, 2023. https://www.ftc.gov/policy/advocacy-research/tech-at-ftc/2023/06/generative-ai-raisesÂ­ com petition-concerns"},{"id":826,"value":"Venturebeat. Generative Al's secret sat.1ce - data scraping- comes under attack. Cisco. July 6, 2023. Accessed July 10, 2023. https://venturebeat.com/ai/generative-ai-secret-sauce-data-scraping-underÂ­ attack/"},{"id":827,"value":"@OpenAI. [tweet] July 4, 2023. Accessed July 10, 2023. https://twitter.com/OpenAl/status/1676072388436594688"},{"id":828,"value":"Australian Research Council. Policy on Use of Generative Artificial Intelligence in tine ARC's grants\nprograms. July 7, 2023. Accessed July 12, 2023. https://www.arc.gov.au/sites/default/files/2023- 07/Policy%20on%20Use%20of%20Generative%20Artificial%20lntelligence%20in%20the%20ARCs%20  grants%20programs%202023.pdf"},{"id":829,"value":"Humane Ingenuity 47: Al Is Coming for Scholarship Next. July 10, 2023. Accessed July 12, 2023. https://newsletter.dancohen .org/arch ive/humane-ingen uity-47-ai-is-comi ng-for-scholarship/"},{"id":830,"value":"Chandran R. FEATURE-Indigenous groups in NZ, US fear colonisation as Al learns their languages. April 3, 2023. Accessed July 12, 2023. https://www.reuters.com/artide/newzealand-tech-lawmakingÂ­ idUSL8N2UOOEC"}],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":563,"database_table_184385":2},"value":{"id":980180,"value":"guidelines","color":"light-yellow"}},{"ids":{"database_table_183319":564,"database_table_184385":3},"value":{"id":980182,"value":"situate-with-existing-policy","color":"darker-red"}},{"ids":{"database_table_183319":566,"database_table_184385":3},"value":{"id":980182,"value":"situate-with-existing-policy","color":"darker-red"}},{"ids":{"database_table_183319":562,"database_table_184385":23},"value":{"id":980201,"value":"Australian-tech-and-models","color":"light-orange"}},{"ids":{"database_table_183319":565,"database_table_184385":39},"value":{"id":991258,"value":"foster-responsible-aied","color":"red"}}],"Lookup":[{"id":562,"value":"We recommend that Australia embrace a considered and leading role in the region with regards to the responsible use of Al in higher education."},{"id":563,"value":"We support a robust, inclusive approach to developing further recommendations and guidelines in this area - libraries and open access advocates can play a key role in this due to our provision of both content and information skills, and our experience in the complex landscape of open access."},{"id":564,"value":"We believe that Al can make responsible reuse of open access scholarly research, but it is critical that licensing and acknowledgement issues around Al are  clarified."},{"id":565,"value":"We emphasise that the success of LLMs' contributions to higher education depends on the quality of their training data."},{"id":566,"value":"Any national approach to open access will need to consider the implications for Al/GAi."}]},{"id":39,"order":"39.00000000000000000000","submission_number":"39","Submitter":"Swinburne University of Technology","Type of org":{"id":977279,"value":"University","color":"darker-blue"},"Notes":"","Recommendations":[{"id":567,"value":"Use of generative AI tools should be a key component of student learning and thus fostered through targeted WIL pedagogy that embeds opportunities for students to experience general as well as discipline-specific generative AI workplace applications."},{"id":568,"value":"Universities and regulatory bodies track emerging trends in the use of generative AI and its impact on workplace practices across all sectors and reflect these in course curricula"},{"id":569,"value":"Universities, as educators of the future workforce, must equip graduates with the critical thinking skills and reflective practices required to navigate the effective, responsible and ethical use of generative AI in the future workplace. This reflects both the need of industry for AI-literate graduates and the influential role such graduates will have on future workplace practices involving the use of generative AI."},{"id":570,"value":"Universities should be required to work with both students and staff to co-create approaches to the ethical use of generative AI tools with a focus on academic integrity."},{"id":571,"value":"An agreed higher education response to communicating expectations regarding the use of AI in assessments, supported by broader professional learning opportunities for educators and clear guidelines for students, should be developed."},{"id":572,"value":"Universities should re-evaluate existing assessments to ensure that they are aligned with desired student learning outcomes and are responsive to the capabilities of generative AI tools."},{"id":573,"value":"TEQSA, as the regulator of higher education, should continue to provide timely resources for institutional use on academic integrity as generative AI evolves"},{"id":574,"value":"State and federal governments should support equity of access to generative AI across educational sectors, in line with the provision of computers and the internet in primary and secondary schools. In Victoria, this should include specific funding to generate programs for Tech Schools."},{"id":575,"value":"Ensure inclusive and equitable use of generative AI in education through national/state secondary curricula that support equitable access to generative AI tools."},{"id":576,"value":"Support research about generative AI in education to provide an evidence base for future development of AI that supports fairness, equity and safety."},{"id":577,"value":"Jobs and Skills Australia to investigate and develop a national skills framework for students working with generative AI."},{"id":578,"value":"Regulatory bodies to develop processes that take in to account generative AI when accredited training packages are updated and to enable vocational education providers to include local learning outcomes that respond to rapid technological change."},{"id":579,"value":"Development of resources to support upskilling of educators to take in to account generative AI in learning and assessments."},{"id":580,"value":"Swinburne values resources such as Country Education Profiles. The Country Education Profiles needs to be maintained. Nations, including Australia, need to ensure that education systems are up front about how they are managing artificial intelligence in their context"}],"Uses-opportunities":[{"id":446,"value":"Developing outreach programs to the community, industry and other education sectors which\nfocuses on generative AI and equipping diverse groups to use generative AI. In doing so\nconsideration would need to be given to ethics, access, use and consent."},{"id":447,"value":"Preparing students from all backgrounds to engage successfully in higher education. As part of the\ntransition of students to universities, providing support for students from socio, cultural and\nlinguistically diverse backgrounds in the understanding of basic concepts which provide for richer\nlearning experiences."},{"id":448,"value":"Using generative AI tools to provide personalised support and services to students. Generative AI is\nexpected to provide opportunities to students with learning challenges, enhancing their\nexperience, and improving their chances of success."},{"id":449,"value":"Working in partnership with generative AI providers to develop ethical, safe, equitable and fair tools\nthat support learning and teaching."}],"Risks-challenges":[],"References-footnotes":[],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":579,"database_table_184385":1},"value":{"id":980196,"value":"PD","color":"light-red"}},{"ids":{"database_table_183319":571,"database_table_184385":2},"value":{"id":980180,"value":"guidelines","color":"light-yellow"}},{"ids":{"database_table_183319":577,"database_table_184385":2},"value":{"id":980180,"value":"guidelines","color":"light-yellow"}},{"ids":{"database_table_183319":573,"database_table_184385":3},"value":{"id":980182,"value":"situate-with-existing-policy","color":"darker-red"}},{"ids":{"database_table_183319":580,"database_table_184385":3},"value":{"id":980182,"value":"situate-with-existing-policy","color":"darker-red"}},{"ids":{"database_table_183319":572,"database_table_184385":6},"value":{"id":980185,"value":"new-assessment-models","color":"darker-pink"}},{"ids":{"database_table_183319":570,"database_table_184385":7},"value":{"id":980187,"value":"stakeholder-engagement","color":"dark-green"}},{"ids":{"database_table_183319":569,"database_table_184385":10},"value":{"id":980190,"value":"curricula-changes","color":"light-green"}},{"ids":{"database_table_183319":578,"database_table_184385":10},"value":{"id":980190,"value":"curricula-changes","color":"light-green"}},{"ids":{"database_table_183319":567,"database_table_184385":14},"value":{"id":980193,"value":"prepare-learners","color":"dark-gray"}},{"ids":{"database_table_183319":568,"database_table_184385":14},"value":{"id":980193,"value":"prepare-learners","color":"dark-gray"}},{"ids":{"database_table_183319":569,"database_table_184385":14},"value":{"id":980193,"value":"prepare-learners","color":"dark-gray"}},{"ids":{"database_table_183319":576,"database_table_184385":21},"value":{"id":980197,"value":"evidence-generation","color":"brown"}},{"ids":{"database_table_183319":574,"database_table_184385":27},"value":{"id":980178,"value":"equitable-access","color":"yellow"}},{"ids":{"database_table_183319":575,"database_table_184385":27},"value":{"id":980178,"value":"equitable-access","color":"yellow"}},{"ids":{"database_table_183319":576,"database_table_184385":39},"value":{"id":991258,"value":"foster-responsible-aied","color":"red"}}],"Lookup":[{"id":567,"value":"Use of generative AI tools should be a key component of student learning and thus fostered through targeted WIL pedagogy that embeds opportunities for students to experience general as well as discipline-specific generative AI workplace applications."},{"id":568,"value":"Universities and regulatory bodies track emerging trends in the use of generative AI and its impact on workplace practices across all sectors and reflect these in course curricula"},{"id":569,"value":"Universities, as educators of the future workforce, must equip graduates with the critical thinking skills and reflective practices required to navigate the effective, responsible and ethical use of generative AI in the future workplace. This reflects both the need of industry for AI-literate graduates and the influential role such graduates will have on future workplace practices involving the use of generative AI."},{"id":570,"value":"Universities should be required to work with both students and staff to co-create approaches to the ethical use of generative AI tools with a focus on academic integrity."},{"id":571,"value":"An agreed higher education response to communicating expectations regarding the use of AI in assessments, supported by broader professional learning opportunities for educators and clear guidelines for students, should be developed."},{"id":572,"value":"Universities should re-evaluate existing assessments to ensure that they are aligned with desired student learning outcomes and are responsive to the capabilities of generative AI tools."},{"id":573,"value":"TEQSA, as the regulator of higher education, should continue to provide timely resources for institutional use on academic integrity as generative AI evolves"},{"id":574,"value":"State and federal governments should support equity of access to generative AI across educational sectors, in line with the provision of computers and the internet in primary and secondary schools. In Victoria, this should include specific funding to generate programs for Tech Schools."},{"id":575,"value":"Ensure inclusive and equitable use of generative AI in education through national/state secondary curricula that support equitable access to generative AI tools."},{"id":576,"value":"Support research about generative AI in education to provide an evidence base for future development of AI that supports fairness, equity and safety."},{"id":577,"value":"Jobs and Skills Australia to investigate and develop a national skills framework for students working with generative AI."},{"id":578,"value":"Regulatory bodies to develop processes that take in to account generative AI when accredited training packages are updated and to enable vocational education providers to include local learning outcomes that respond to rapid technological change."},{"id":579,"value":"Development of resources to support upskilling of educators to take in to account generative AI in learning and assessments."},{"id":580,"value":"Swinburne values resources such as Country Education Profiles. The Country Education Profiles needs to be maintained. Nations, including Australia, need to ensure that education systems are up front about how they are managing artificial intelligence in their context"}]},{"id":40,"order":"40.00000000000000000000","submission_number":"40","Submitter":"Regional Universities Network","Type of org":{"id":977283,"value":"HE-network","color":"dark-green"},"Notes":"","Recommendations":[{"id":581,"value":"Universities should educate students and staff on the safe and ethical use of generative AI tools and ensure the integrity and authenticity of assessments."},{"id":582,"value":"Provision of best practice guidelines and advice through TEQSA would support universities in implementing proactive approaches, particularly in assessment, academic integrity, ethics, and data security."},{"id":583,"value":"Institutions should have the flexibility and autonomy to make decisions regarding generative AI without strict regulation specific to higher education environments."},{"id":584,"value":"A broad, society-wide regulatory framework for AI, such as the risk-based model proposed in the EU, can help mitigate challenges and risks associated with generative AI technology."}],"Uses-opportunities":[{"id":450,"value":"Enhancing student experiences in learning and teaching"},{"id":451,"value":"Improving productivity for academic and professional staff"},{"id":452,"value":"Guiding students through enrollment processes"},{"id":453,"value":"Providing instant and natural language responses to inquiries"},{"id":454,"value":"Automating routine tasks, like answering frequently asked questions"},{"id":455,"value":"Alleviating workload for staff members"},{"id":456,"value":"Allowing more time for higher-level work"},{"id":457,"value":"Assisting students as a study aid"},{"id":458,"value":"Helping teaching staff tailor course materials"},{"id":459,"value":"Meeting the expectations of students entering the workforce"},{"id":460,"value":"Widely applicable across various sectors, such as health, engineering, social services, and creative industries"},{"id":461,"value":"Education around generative AI ensures effective and ethical use"},{"id":462,"value":"Developing critical thinking and analysis skills in students"},{"id":463,"value":"Integrating generative AI at the course level for discussion and critical analysis"},{"id":464,"value":"University-wide education programs for the ethical use and integration of generative AI"}],"Risks-challenges":[{"id":363,"value":"reproduction of false, biased, or misleading information by generative AI"},{"id":364,"value":"biases exhibited by AI systems due to programming and training datasets"},{"id":365,"value":"risks associated with generative AI in learning and assessment approaches"},{"id":366,"value":"fabricated details or sources generated by AI systems"},{"id":367,"value":"legal and ethical issues regarding privacy, defamation, and intellectual property"}],"References-footnotes":[{"id":831,"value":"Australiaâ€™s Chief Scientist, \"Generative AI: Language Models and Multimodal Foundation Models,\" Rapid\nResponse Report, accessed July 11, 2023, https://www.chiefscientist.gov.au/sites/default/files/2023-06/Rapid%20\nResponse%20Information%20Report%20-%20Generative%20AI%20v1_1.pdf."},{"id":832,"value":"Selasi Kwashie, \"Artificial Intelligence Needs Legislation, Standards and Society-Wide Education,\" Charles\nSturt University, May 2023, accessed June 26, 2023, https://news.csu.edu.au/opinion/artificial-intelligence-needslegislation,-standards-and-society-wide-education."},{"id":833,"value":"McKinsey, \"The Economic Potential of Generative AI: The Next Productivity Frontier,\" June 2023, accessed June\n26, 2023, https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generativeai-the-next-productivity-frontier."},{"id":834,"value":"Stephen Dobson, \"Why Universities Should Return to Oral Exams in the AI and ChatGPT Era,\" CQUniversity\nAustralia, accessed June 26, 2023, https://www.cqu.edu.au/ news/863161/whv-universities-should-return-to-oral-exams- in-the-ai-and-chatqpt-era."},{"id":835,"value":"Weise, Karen, and Cade Metz. \"The Issue with AI Chatbots Hallucinating.\" New York Times. May 1, 2023, accessed June 26, 2023, httos //www nvtimes com/2023/05/01/ business/ai-chatbots-hallucination html"},{"id":837,"value":"OpenAl, \"How should AI systems behave?\" OpenAt Blog. Accessed July 10, 2023, httos'//openai com/bIoo/how- should-ai-svstems-benave."},{"id":838,"value":"Australian Digital Inclusion Index: 2021, Melbourne: RMIT, Swinburne University of Technology, and Telstra, accessed July 10, 2023, https://www.digitalinclusionindex.org.au/download-reports/ https://h3e6r2c4.rocketcdn.me/ wp-content/uploads/2021/10/ADII_2021_Summary-report_V1.pdf"}],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":582,"database_table_184385":2},"value":{"id":980180,"value":"guidelines","color":"light-yellow"}},{"ids":{"database_table_183319":583,"database_table_184385":4},"value":{"id":980183,"value":"local-responses-and-autonomy","color":"dark-cyan"}},{"ids":{"database_table_183319":581,"database_table_184385":10},"value":{"id":980190,"value":"curricula-changes","color":"light-green"}},{"ids":{"database_table_183319":584,"database_table_184385":11},"value":{"id":980191,"value":"new-policy","color":"dark-purple"}}],"Lookup":[{"id":581,"value":"Universities should educate students and staff on the safe and ethical use of generative AI tools and ensure the integrity and authenticity of assessments."},{"id":582,"value":"Provision of best practice guidelines and advice through TEQSA would support universities in implementing proactive approaches, particularly in assessment, academic integrity, ethics, and data security."},{"id":583,"value":"Institutions should have the flexibility and autonomy to make decisions regarding generative AI without strict regulation specific to higher education environments."},{"id":584,"value":"A broad, society-wide regulatory framework for AI, such as the risk-based model proposed in the EU, can help mitigate challenges and risks associated with generative AI technology."}]},{"id":41,"order":"41.00000000000000000000","submission_number":"41","Submitter":"Curtin University","Type of org":{"id":977279,"value":"University","color":"darker-blue"},"Notes":"","Recommendations":[{"id":125,"value":"â€¢ Universities and industry need to agree on a set of guidelines on the use of Gen-AI."},{"id":126,"value":"â€¢ Universities should help direct what agencies are going to be responsible for implementing some of these guidelines."},{"id":127,"value":"â€¢ In the short-term focus more on education and prevention programs to help learners and educators understand ethical, legal and responsible use of Gen-AI."},{"id":128,"value":"â€¢ Work collaboratively with high schools who are already encouraging students to use Gen-AI so we can build upon the already developed capabilities is critical. o However, note that not all schools do encourage students to use Gen-AI and student may therefore come to tertiary education with different levels of competence and understanding of Gen-AI tools. This makes things even more complex for educators."},{"id":130,"value":"â€¢ Have measures in place to prevent and detect misuses of Gen-AI."},{"id":131,"value":"â€¢ Promote exchange of experience and success stories across the education sector as we navigate through this new challenge."},{"id":132,"value":"â€¢ Establish training/fellowship programs specific to Gen-AI to help staff upskills and innovate."},{"id":133,"value":"â€¢ Promote the collaboration between AI researchers and other areas."}],"Uses-opportunities":[{"id":85,"value":"â€¢ Providing individualised tutoring and student feedback on learning through a 24/7 virtual assistant o can be used for mulô€†Ÿmodal images, videos, avatar, audio, etc."},{"id":86,"value":"â€¢ Wriô€†Ÿng, proofreading and communicaô€†Ÿon aid for students with low levels or literacy or English language skills. o LLMs can correct errors but also explain why."},{"id":87,"value":"â€¢ Potenô€†Ÿal help with research such as finding relevant papers for literature review."},{"id":88,"value":"â€¢ Potenô€†Ÿally engage and help support neurodivergent students."},{"id":89,"value":"â€¢ Streamlining work for staff o Examples include providing assistance with grading and feedback, make the tone of feedback more supporô€†Ÿve, add variety to comments, help to explain a rubric. o Assist with design of learning acô€†Ÿviô€†Ÿes and rubrics for given learning outcomes. o Remove mundane wriô€†Ÿng tasks."}],"Risks-challenges":[],"References-footnotes":[],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":132,"database_table_184385":1},"value":{"id":980196,"value":"PD","color":"light-red"}},{"ids":{"database_table_183319":125,"database_table_184385":2},"value":{"id":980180,"value":"guidelines","color":"light-yellow"}},{"ids":{"database_table_183319":126,"database_table_184385":2},"value":{"id":980180,"value":"guidelines","color":"light-yellow"}},{"ids":{"database_table_183319":127,"database_table_184385":10},"value":{"id":980190,"value":"curricula-changes","color":"light-green"}},{"ids":{"database_table_183319":128,"database_table_184385":19},"value":{"id":980186,"value":"capacity-building","color":"light-yellow"}},{"ids":{"database_table_183319":131,"database_table_184385":19},"value":{"id":980186,"value":"capacity-building","color":"light-yellow"}},{"ids":{"database_table_183319":133,"database_table_184385":19},"value":{"id":980186,"value":"capacity-building","color":"light-yellow"}},{"ids":{"database_table_183319":130,"database_table_184385":25},"value":{"id":980202,"value":"monitoring-impacts","color":"darker-red"}}],"Lookup":[{"id":125,"value":"â€¢ Universities and industry need to agree on a set of guidelines on the use of Gen-AI."},{"id":126,"value":"â€¢ Universities should help direct what agencies are going to be responsible for implementing some of these guidelines."},{"id":127,"value":"â€¢ In the short-term focus more on education and prevention programs to help learners and educators understand ethical, legal and responsible use of Gen-AI."},{"id":128,"value":"â€¢ Work collaboratively with high schools who are already encouraging students to use Gen-AI so we can build upon the already developed capabilities is critical. o However, note that not all schools do encourage students to use Gen-AI and student may therefore come to tertiary education with different levels of competence and understanding of Gen-AI tools. This makes things even more complex for educators."},{"id":130,"value":"â€¢ Have measures in place to prevent and detect misuses of Gen-AI."},{"id":131,"value":"â€¢ Promote exchange of experience and success stories across the education sector as we navigate through this new challenge."},{"id":132,"value":"â€¢ Establish training/fellowship programs specific to Gen-AI to help staff upskills and innovate."},{"id":133,"value":"â€¢ Promote the collaboration between AI researchers and other areas."}]},{"id":42,"order":"42.00000000000000000000","submission_number":"42","Submitter":"Australian Education Union Federal Office","Type of org":{"id":977284,"value":"Union","color":"darker-green"},"Notes":"","Recommendations":[{"id":585,"value":"that progress towards the use of generative artificial intelligence in the Australian education system must be human-centred, teacher-led and education department controlled, with a pedagogic focus and a diverse and inclusive social justice lens."},{"id":586,"value":"Implementation must be across all public education settings, whilst concurrently commissioning research into the impact on teaching and learning."},{"id":587,"value":"suitable controls are required for equitable provision across public schools and TAFE, for ethical considerations, addressing privacy concerns, environmental considerations and legal protection for teachers."},{"id":588,"value":"Develop a national government policy framework to provide students with broad, equal access to technology and learning and to equally protect students from any potential harm for the use of such technologies."},{"id":589,"value":"Ensure that the Department of Education engages with the teaching profession via their union to develop this national policy framework to address the use of technology and AI in teaching and learning."},{"id":590,"value":"This policy framework must: â€¢ consider the ethics, curriculum and pedagogical issues; â€¢ address occupational, health, welfare and safety issues; â€¢ ensure that the implementation of AI is equitable, accessible and inclusive; â€¢ ensure that AI tools and their implementation is free of cultural, racial and gender biases and that they should not perpetuate or amplify existing biases or discrimination; â€¢ ensure that private for-profit operators are prevented from exerting inappropriate influence via platforms and products, on the processes of teaching and learning in educational settings and systems; â€¢ ensure that a digital equity audit is undertaken to ascertain the extent of digital inequality experienced by students and educational settings; â€¢ consider the issues of data sovereignty and copyright and that the use of AI in public education must be transparent, including its applications, what data is collected and how that data is used; â€¢ ensure that the teaching profession is provided with high quality professional development, systemic support and professional autonomy; â€¢ ensure that the teaching profession and students are provided with guidance and training on the ethical use of AI tools; â€¢ ensure equitable and fair resourcing for all students, including digital access; and â€¢ undertake ongoing evaluation of AI implementation to ensure that it supports the needs of students and the teaching profession and aligns with the appropriate ethical standards and guidelines that govern teaching and learning practices."}],"Uses-opportunities":[{"id":465,"value":"AI technologies have the potential to enrich educational activities"},{"id":466,"value":"Information and communication technology (ICT) plays a crucial role in providing quality public education for all"},{"id":467,"value":"Integration of AI and education can lead to advancements in digital learning, especially during remote learning situations like the COVID-19 pandemic"}],"Risks-challenges":[{"id":368,"value":"Lack of diversity in all aspects of AI, including research, development, tools design, information and content design, and learning"},{"id":369,"value":"Risk of perpetuating stereotypes, single perspective, and misinformation due to AI generating based on popular or dominant thinking"},{"id":370,"value":"High risk of misinformation, particularly regarding perspectives on gender, non-Anglo cultures, First Nations cultures, non-binary and queerness, disability, people living outside urban centers, and intersectionality within underrepresented groups"},{"id":371,"value":"Insufficient action being taken to address the lack of diversity in AI"},{"id":372,"value":"Potential for AI systems to lead to outcomes entailing prohibited discrimination"},{"id":373,"value":"AI bias having a larger effect and discriminating many people without the social control mechanisms that govern human behavior"},{"id":374,"value":"Possibility of AI systems learning biases while in operation"}],"References-footnotes":[{"id":869,"value":"https://sdgs.un.org/goals/goal4"},{"id":870,"value":"Denejkina, A. (2023). Young Peopleâ€™s Perception and Use of Generative AI, YouthInsight, Student Edge."},{"id":871,"value":"European Commission (2020). On Artificial Intelligence - A European approach to excellence and trust."},{"id":872,"value":"Manasi, A; Panchanadeswaran, S; Sours, E; Ju Lee, S. (2022). Mirroring the bias: gender and artificial\nintelligence, Gender, Technology and Development, 26:3, 295-305"},{"id":873,"value":"EQUALS and UNESCO (2019). I'd blush if I could: closing gender divides in digital skills through education."},{"id":874,"value":"UNESCO, OECD, IDB (2022). The Effects of AI on the Working Lives of Women."},{"id":876,"value":"Das, S; Kotikula, A; Carranza, E. (2019). Gender-Based Employment Segregation: Understanding Causes and\nPolicy Interventions. Jobs Working Paper No. 26. World Bank, Washington, DC."}],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":589,"database_table_184385":7},"value":{"id":980187,"value":"stakeholder-engagement","color":"dark-green"}},{"ids":{"database_table_183319":587,"database_table_184385":11},"value":{"id":980191,"value":"new-policy","color":"dark-purple"}},{"ids":{"database_table_183319":590,"database_table_184385":11},"value":{"id":980191,"value":"new-policy","color":"dark-purple"}},{"ids":{"database_table_183319":586,"database_table_184385":21},"value":{"id":980197,"value":"evidence-generation","color":"brown"}},{"ids":{"database_table_183319":588,"database_table_184385":21},"value":{"id":980197,"value":"evidence-generation","color":"brown"}},{"ids":{"database_table_183319":590,"database_table_184385":21},"value":{"id":980197,"value":"evidence-generation","color":"brown"}},{"ids":{"database_table_183319":588,"database_table_184385":27},"value":{"id":980178,"value":"equitable-access","color":"yellow"}},{"ids":{"database_table_183319":590,"database_table_184385":27},"value":{"id":980178,"value":"equitable-access","color":"yellow"}},{"ids":{"database_table_183319":590,"database_table_184385":38},"value":{"id":986019,"value":"respect-rights","color":"light-blue"}},{"ids":{"database_table_183319":585,"database_table_184385":39},"value":{"id":991258,"value":"foster-responsible-aied","color":"red"}},{"ids":{"database_table_183319":590,"database_table_184385":39},"value":{"id":991258,"value":"foster-responsible-aied","color":"red"}}],"Lookup":[{"id":585,"value":"that progress towards the use of generative artificial intelligence in the Australian education system must be human-centred, teacher-led and education department controlled, with a pedagogic focus and a diverse and inclusive social justice lens."},{"id":586,"value":"Implementation must be across all public education settings, whilst concurrently commissioning research into the impact on teaching and learning."},{"id":587,"value":"suitable controls are required for equitable provision across public schools and TAFE, for ethical considerations, addressing privacy concerns, environmental considerations and legal protection for teachers."},{"id":588,"value":"Develop a national government policy framework to provide students with broad, equal access to technology and learning and to equally protect students from any potential harm for the use of such technologies."},{"id":589,"value":"Ensure that the Department of Education engages with the teaching profession via their union to develop this national policy framework to address the use of technology and AI in teaching and learning."},{"id":590,"value":"This policy framework must: â€¢ consider the ethics, curriculum and pedagogical issues; â€¢ address occupational, health, welfare and safety issues; â€¢ ensure that the implementation of AI is equitable, accessible and inclusive; â€¢ ensure that AI tools and their implementation is free of cultural, racial and gender biases and that they should not perpetuate or amplify existing biases or discrimination; â€¢ ensure that private for-profit operators are prevented from exerting inappropriate influence via platforms and products, on the processes of teaching and learning in educational settings and systems; â€¢ ensure that a digital equity audit is undertaken to ascertain the extent of digital inequality experienced by students and educational settings; â€¢ consider the issues of data sovereignty and copyright and that the use of AI in public education must be transparent, including its applications, what data is collected and how that data is used; â€¢ ensure that the teaching profession is provided with high quality professional development, systemic support and professional autonomy; â€¢ ensure that the teaching profession and students are provided with guidance and training on the ethical use of AI tools; â€¢ ensure equitable and fair resourcing for all students, including digital access; and â€¢ undertake ongoing evaluation of AI implementation to ensure that it supports the needs of students and the teaching profession and aligns with the appropriate ethical standards and guidelines that govern teaching and learning practices."}]},{"id":43,"order":"43.00000000000000000000","submission_number":"43","Submitter":"Federation of Parents and Citizens Associations of NSW","Type of org":{"id":977968,"value":"advocacy-group","color":"darker-green"},"Notes":"","Recommendations":[],"Uses-opportunities":[],"Risks-challenges":[],"References-footnotes":[],"Processed":true,"Recco_tags":[],"Lookup":[]},{"id":44,"order":"44.00000000000000000000","submission_number":"44","Submitter":"The University of Sydney","Type of org":{"id":977279,"value":"University","color":"darker-blue"},"Notes":"","Recommendations":[{"id":93,"value":"Recommendation 1: Lead the establishment of a national cross-sector representative â€˜AI in Educationâ€™ body and knowledge- sharing hub - to guide the safe, beneficial and equitable use of generative AI in Australian education, and to develop, test and showcase outstanding innovation in the productive and responsible use of the technology in the Australian school, vocational and higher education sectors."},{"id":94,"value":"Recommendation 2: Lead the development, in consultation with cross-sector representatives (see recommendation 1), of an initial national set of minimum standards to maximise consistency in the safe and equitable development and use of generative AI in the Australian school, vocational and higher education sectors."},{"id":95,"value":"Recommendation 3: Commit, for the next 3-5 years, to prioritising funding to support research and development work into the safe and effective use of generative AI to improve evidence-based teaching, learning and assessment in the Australian school, vocational and higher education sectors."},{"id":96,"value":"Recommendation 5: Lead the development of a national set of principles and guidance materials targeted at research institutions to support and educate researchers (including research students) in the use of emerging technologies, including generative AI, in the research process. Development, for example, of a specific supporting guide for the Australian Code for the Responsible Conduct of Research (2018) addressing the benefits and risks of emerging technologies in research would enable all Australian organisations conducting research, to identify and consistently manage use of these technologies in their research and training programs."},{"id":97,"value":"Recommendation 4: Identify policy and program opportunities to encourage and support sustainable collaborations between educators in schools serving disadvantaged communities and their colleagues in Australian universities with relevant expertise and interests, to help address the digital divide, specifically in relation to access to and use of generative AI tools."}],"Uses-opportunities":[{"id":69,"value":"For educators, who are under ever-increasing workload pressures, Gen-AI has the potential to accelerate aspects of their roles. For example, Gen-AI can help educators propose new ideas for assessments, draft assessment rubrics, or generate practice questions for students. These activities are workload-intensive for an unassisted educator, but Gen-AI speeds up the process while still including the human in the loop. This frees up educatorsâ€™ time so that they can spend it on the aspects of their roles where the human value-add is more critical, such as student consultations, class time and personalised feedback."}],"Risks-challenges":[{"id":85,"value":"In teaching: â€¢  Ensuring the safe use of Gen-AI by students and educators.â€¢  Raising levels of awareness and understanding among teachers and students about the strengths, limitations and risks of Gen-AI.â€¢  Overcoming perceptions that we can out-design or out-run Gen-AI by designing creative or authentic assessments that are â€˜AI-proofâ€™.â€¢  Ensuring staff and students understand what biases in Gen-AI training data can mean for information discovery, analysis and conclusion-drawing.â€¢  Ensuring students do not develop an over-reliance on Gen-AI, nor a fear of the technology or reluctance to learn about it and engage with it.â€¢  Preventing the inappropriate use of Gen-AI in assessments.â€¢  Building studentsâ€™ ability to separate human from AI content.â€¢  Reliance, at any level, on currently available AI detection software, which are inherently flawed."},{"id":86,"value":"In research: â€¢  Privacy breaches of study participantsâ€™ personally identifiable information, through release of this information to Gen-AI tools, or the release of de-identified data in a way that allows for reidentification.â€¢  Privacy breaches of researchers/collaboratorsâ€™ personally identifiable information, through submission of this confidential information to Gen-AI tools.â€¢  Loss of control of Intellectual Property or Copyright, through the Gen-AI tools reproducing content without attribution.â€¢  Breaches of contractual obligations, including commercial contracts, data sharing agreements and material transfer agreements.â€¢  Non-compliance with the terms of funding agreements.â€¢  Inappropriate management of First Nations data.â€¢  Disclosure of sensitive environmental/ecological information.â€¢  Breach of research codes, Human Research Ethics Committee (HREC) approvals (e.g. Australian Code for the Conduct of Responsible Research).â€¢  Breach of research funding councilsâ€™ specific policies regarding Gen-AI."},{"id":87,"value":"Other key risks for research integrity centre around lack of accountability and oversight when using Gen-AI to produce research outputs, specifically: â€¢  Inability to attribute authorship where Gen-AI has contributed content from unknown sources.â€¢  Inability to reproduce or replicate consistent results when using Gen-AI to provide content for research findings â€“ results will vary at each attempt making verification of research findings impossible.â€¢  Inability to establish and evaluate accuracy and validity of content generated by Gen-AI â€“probabilistic models that generate data may be biased, or produce â€˜hallucinationsâ€™ of inaccurate content, which can be hard to identify.â€¢  Inability to have contributory IP acknowledged by others if research outputs are incorporated into data that becomes available to the Gen-AI model, and is used elsewhere. No guarantee that licences on open data, code or images are applied (e.g. Creative Commons).â€¢  Accountability and trust â€“ personal accountability by individual researchers underpins all research. Use of Gen-AI can undermine this if its capabilities and the contribution that it makes, including risks, are not understood by researchers."},{"id":88,"value":"Inquiry into the use of generative artificial intelligence in the Australian education system"},{"id":89,"value":"National security and foreign interference risks, arising from the public release through GenAI interfaces, of confidential data or research information, or from increasingly sophisticated cybersecurity attacks enabled by Gen-AI."},{"id":90,"value":"Human rights and modern slavery law breaches, arising from use of certain Gen-AI tools developed without transparency and potentially through questionable labour practices."},{"id":91,"value":"Researchers and research students who speak English as a second language may face increased pressure and risks, as they may be more likely to use LLMs that can improve written text, e.g. to help write a thesis or journal paper, in which case risk of IP loss is high."},{"id":92,"value":"Some journal publishers have introduced rules restricting use of Gen-AI in submitted manuscripts. This varies between disciplines and publications, but may prevent some researchers from being able to publish in high impact journals."},{"id":93,"value":"Detection rates of Gen-AI use are currently poor. This may have research integrity impacts in the future when new detection tools are applied to previously published research where Gen-AI may have been used to generate content. Detection tools may give erroneous results, and valid research outputs may be questioned in error."},{"id":94,"value":"Reviewers of grants and awards using Gen-AI inappropriately in the process of evaluating proposals to circumvent human thought and insight"}],"References-footnotes":[{"id":176,"value":"1 https://scholar.google.com.au"},{"id":177,"value":"Loble, L., & Hawcroft, A. (2022) Shaping AI and Edtech to Tackle Australiaâ€™s Learning Divide, University of Technology Sydney, How Important Is a College Degree Compared to Experience? (hbr.org)"},{"id":178,"value":"Scott M. Preparing Todayâ€™s Students for Tomorrowâ€™s World, in Loble L. et. al. Future Frontiers: Education for an AI World, NSW Department of Education (2018) p.98"},{"id":179,"value":"Graduate qualities - The University of Sydney"},{"id":180,"value":"See for example: The Skills Imperative 2035: An analysis of the demand for skills in the labour market in 2035 - NFER, Productivity Commission (2023) 5-year Productivity Inquiry: From Learning to"},{"id":181,"value":"Growth, Inquiry Report â€“ volume 8, University of Sydney (2023) Reimagining Australian tertiary education: 12 nation-building ideas, Submission to the Australian Universities Accord, p.13"},{"id":182,"value":"https://www.sydney.edu.au/students/academic-integrity.html"},{"id":183,"value":"Our â€˜AI in Educationâ€™ resource for students is openly accessible: https://bit.ly/students-ai"},{"id":184,"value":"https://www.sydney.edu.au/study/why-choose-sydney/employability-and-careers.html"},{"id":185,"value":"For example, the Higher Education Standards Framework (Threshold Standards) 2021 around confirming that specified learning outcomes are achieved; https://www.legislation.gov.au/Details/F2022C00105#_Toc67664702"},{"id":186,"value":"ARC Policy on the Use of Generative Artificial Intelligence in the ARC Grant Programs (7 July 2023)"},{"id":187,"value":"Here we note, for example, the valuable contribution to this aspect of the discussion made by Leslie Loble AM in, Shaping AI and edtech to tackle Australiaâ€™s learning divide, published in December 2022"},{"id":188,"value":"See Productivity Commission (2023) 5-year Productivity Inquiry: From Learning to Growth, Inquiry Report â€“ volume 8, p.iv"},{"id":189,"value":"https://www.dewr.gov.au/foundation-skills"},{"id":190,"value":"Wood, D., (2021) Thinking Big: Maintaining full employment and boosting productivity, presentation to the Australian Governmentâ€™s Jobs and Skills Summit, 1. Sept. Slide 19"},{"id":191,"value":"Productivity Commission (2023) 5-year Productivity Inquiry: From Learning to Growth, Inquiry Report â€“ volume 8, p.9"},{"id":192,"value":"NSW Department of Education Policy on AI in NSW public schools, South Australia Department of Education Guidance on AI in public schools, South Australia AI pilot"},{"id":193,"value":"KPMG and the Australian Information Industry Association (2023), Navigating AI, Analysis and guidance on the use and adoption of AI"},{"id":194,"value":"https://tech.ed.gov/ai/"},{"id":195,"value":"https://russellgroup.ac.uk/news/new-principles-on-use-of-ai-in-education/"},{"id":196,"value":"https://unesdoc.unesco.org/ark:/48223/pf0000385146"},{"id":197,"value":"https://www.gatesnotes.com/The-Age-of-AI-Has-Begun"},{"id":198,"value":"https://er.educause.edu/articles/2023/4/educause-quickpoll-results-adopting-and-adapting-to- generative-ai-in-higher-ed-tech"},{"id":199,"value":"https://www.insidehighered.com/news/2023/03/22/gpt-4-here-most-faculty-lack-ai-policies"},{"id":200,"value":"https://tytonpartners.com/generative-ai-in-higher-education-from-fear-to-experimentation- embracing-ais-potential/"},{"id":201,"value":"https://nationalcentreforai.jiscinvolve.org/wp/2023/07/03/exploring-the-significance-of-generative- ai-for-students/"},{"id":202,"value":"https://educational-innovation.sydney.edu.au/teaching@sydney/student-staff-forums-on- generative-ai-at-sydney/"},{"id":203,"value":"https://www.monash.edu/learning-teaching/teachhq/Teaching-practices/artificial-intelligence"},{"id":204,"value":"https://educational-innovation.sydney.edu.au/teaching@sydney/prompt-engineering-for-educators- making-generative-ai-work-for-you/"},{"id":206,"value":"https://educational-innovation.sydney.edu.au/teaching@sydney/chatgpt-is-old-news-how-do-we- assess-in-the-age-of-ai-writing-co-pilots/"},{"id":207,"value":"https://arxiv.org/abs/2303.10130"}],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":94,"database_table_184385":2},"value":{"id":980180,"value":"guidelines","color":"light-yellow"}},{"ids":{"database_table_183319":96,"database_table_184385":2},"value":{"id":980180,"value":"guidelines","color":"light-yellow"}},{"ids":{"database_table_183319":95,"database_table_184385":12},"value":{"id":980192,"value":"research-investment","color":"orange"}},{"ids":{"database_table_183319":97,"database_table_184385":12},"value":{"id":980192,"value":"research-investment","color":"orange"}},{"ids":{"database_table_183319":93,"database_table_184385":19},"value":{"id":980186,"value":"capacity-building","color":"light-yellow"}},{"ids":{"database_table_183319":97,"database_table_184385":22},"value":{"id":980198,"value":"marginalised-group-engagement","color":"light-pink"}}],"Lookup":[{"id":93,"value":"Recommendation 1: Lead the establishment of a national cross-sector representative â€˜AI in Educationâ€™ body and knowledge- sharing hub - to guide the safe, beneficial and equitable use of generative AI in Australian education, and to develop, test and showcase outstanding innovation in the productive and responsible use of the technology in the Australian school, vocational and higher education sectors."},{"id":94,"value":"Recommendation 2: Lead the development, in consultation with cross-sector representatives (see recommendation 1), of an initial national set of minimum standards to maximise consistency in the safe and equitable development and use of generative AI in the Australian school, vocational and higher education sectors."},{"id":95,"value":"Recommendation 3: Commit, for the next 3-5 years, to prioritising funding to support research and development work into the safe and effective use of generative AI to improve evidence-based teaching, learning and assessment in the Australian school, vocational and higher education sectors."},{"id":96,"value":"Recommendation 5: Lead the development of a national set of principles and guidance materials targeted at research institutions to support and educate researchers (including research students) in the use of emerging technologies, including generative AI, in the research process. Development, for example, of a specific supporting guide for the Australian Code for the Responsible Conduct of Research (2018) addressing the benefits and risks of emerging technologies in research would enable all Australian organisations conducting research, to identify and consistently manage use of these technologies in their research and training programs."},{"id":97,"value":"Recommendation 4: Identify policy and program opportunities to encourage and support sustainable collaborations between educators in schools serving disadvantaged communities and their colleagues in Australian universities with relevant expertise and interests, to help address the digital divide, specifically in relation to access to and use of generative AI tools."}]},{"id":45,"order":"45.00000000000000000000","submission_number":"45","Submitter":"Australian Academy of the Humanities","Type of org":{"id":977281,"value":"Peak body","color":"green"},"Notes":"","Recommendations":[{"id":106,"value":"An appraisal of Australiaâ€™s AI capability is needed with a focus on education, training, and research. The RRIR paper notes that â€œAustralia has capability in AI-related areas like computer vision and robotics, and the social and governance aspects of AI, but its core fundamental capacity in LLMs and related areas is relatively weakâ€. It is not clear whether we are producing enough â€œexpertsâ€ in core fields through research training. Nor do we have a whole-of-sector view to AI industry workforce â€“ inclusive of education as a major industry â€“ so that we can be confident we are producing cohorts of graduates with the foundational education and skills to meet the AI challenges of our time.3"},{"id":107,"value":"Tracking and evaluating the deployment and uptake of generative AI in education contexts will also be vital. The recent release of the UTS AI Governance report is a useful model.4 One of the biggest issues â€“ flagged in the Inquiryâ€™s terms of reference â€“ is the risk of entrenching social disadvantage and of perpetuating racist, homophobic and sexist stereotypes. Developing and investing in a Generative-AI index akin to the Digital Inclusion Index5 would be one way of tracking and evaluating models based on set of criteria so students, the broader public and governments can make informed choices about uptake."},{"id":108,"value":"There is a major opportunity for the development of Australian models â€“ datasets, LLMs, and significantly, small language models. This is a research infrastructure agenda and is also brings in large public datasets that could offer opportunities for generative AI in Australia. We would single out (as per the RRIR paper) large datasets such as the Bureau of Meteorology, Australian Bureau of Statistics, and the National Library of Australiaâ€™s Trove."}],"Uses-opportunities":[],"Risks-challenges":[],"References-footnotes":[],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":108,"database_table_184385":9},"value":{"id":980189,"value":"DISTINCTIVE","color":"dark-green"}},{"ids":{"database_table_183319":108,"database_table_184385":12},"value":{"id":980192,"value":"research-investment","color":"orange"}},{"ids":{"database_table_183319":106,"database_table_184385":19},"value":{"id":980186,"value":"capacity-building","color":"light-yellow"}},{"ids":{"database_table_183319":107,"database_table_184385":20},"value":{"id":980179,"value":"ongoing-and-global-monitoring","color":"dark-brown"}},{"ids":{"database_table_183319":108,"database_table_184385":23},"value":{"id":980201,"value":"Australian-tech-and-models","color":"light-orange"}}],"Lookup":[{"id":106,"value":"An appraisal of Australiaâ€™s AI capability is needed with a focus on education, training, and research. The RRIR paper notes that â€œAustralia has capability in AI-related areas like computer vision and robotics, and the social and governance aspects of AI, but its core fundamental capacity in LLMs and related areas is relatively weakâ€. It is not clear whether we are producing enough â€œexpertsâ€ in core fields through research training. Nor do we have a whole-of-sector view to AI industry workforce â€“ inclusive of education as a major industry â€“ so that we can be confident we are producing cohorts of graduates with the foundational education and skills to meet the AI challenges of our time.3"},{"id":107,"value":"Tracking and evaluating the deployment and uptake of generative AI in education contexts will also be vital. The recent release of the UTS AI Governance report is a useful model.4 One of the biggest issues â€“ flagged in the Inquiryâ€™s terms of reference â€“ is the risk of entrenching social disadvantage and of perpetuating racist, homophobic and sexist stereotypes. Developing and investing in a Generative-AI index akin to the Digital Inclusion Index5 would be one way of tracking and evaluating models based on set of criteria so students, the broader public and governments can make informed choices about uptake."},{"id":108,"value":"There is a major opportunity for the development of Australian models â€“ datasets, LLMs, and significantly, small language models. This is a research infrastructure agenda and is also brings in large public datasets that could offer opportunities for generative AI in Australia. We would single out (as per the RRIR paper) large datasets such as the Bureau of Meteorology, Australian Bureau of Statistics, and the National Library of Australiaâ€™s Trove."}]},{"id":46,"order":"46.00000000000000000000","submission_number":"46","Submitter":"Australian Industry Group Centre for Education & Training","Type of org":{"id":977281,"value":"Peak body","color":"green"},"Notes":"\"The Australian Industry Group (Ai GroupÂ®) is a peak national employer organisation representing traditional, innovative and emerging industry sectors. We have been acting on behalf of businesses across Australia for 150 years.\"\nSubmission covers general overview.","Recommendations":[],"Uses-opportunities":[],"Risks-challenges":[],"References-footnotes":[{"id":338,"value":"Campus Morning Mail, What the Accord must provide for student success, Liz Johnson, Sally Kitt, Jason Lodger and Siobhan Lenihan, May 2023 https://campusmorningmail.com.au/news/what-the-accord-must-provide-for-studentsuccess/#:~:text=lt%20will%20create%20a%20recognised,profound%20investment%20in%20their%20future."},{"id":339,"value":"Jennifer Rose, University of Manchester, ChatGPT as a teaching tool, not a cheating tool https://www.timeshighereducation.com/campus/chatgpt-teaching-tool-not-cheating-tool"},{"id":340,"value":"National Artificial Intelligence Centre's Responsible Al Network https://www.csiro.au/en/work-with-us/industries/technology/national-ai-centre"},{"id":341,"value":"Department of Industry, Science and Resources, Safe and Responsible Al in Australia, June 2023 https://storage.googleapis.com/converlens-auindustry/industry/p/prj2452c8e24d7a400c72429/public_assets/Safe-and-responsible-Al-inAustralia-discussion-paper.pdf"},{"id":342,"value":"OECD Education and Skills Today, June 2023 https://oecdedutoday.com/chatgpt-and-pisa-ensuring-our-education-systems-keep-up/"},{"id":343,"value":"Safe and Responsible Al in Australia: discussion paper, June 2023 https://storage.googleapis.com/converlens-auindustry/industry/p/prj2452c8e24d7a400c72429/public_assets/Safe-and-responsible-Al-inAustralia-discussion-paper.pdf"},{"id":344,"value":"TEQSA resources https://www.teqsa.gov.au/guides-resources/higher-education-good-practice-hub/artificialintelligence#teqsa-resources"},{"id":345,"value":"Times Higher Education, Five ways Al has already changed higher education, May 2023 https://www.google.com/search?q=five+ways+ai+has+already+changed+higher+education&rlz=1_C1_GCEB_enAU930AU930&oq=five+ways+Al+has+already+changed+higher+education&gs_lcrp=EgZjaHJvbWUqBwgAEAA YgAQyBwgAEAA YgAQyCggBEAA YhgMYigUyCggCEAA Yhg MYigUyCggDEAAYhgMYigXSAQkxNjMyNGowajSoAgCwAgA&sourceid=chrome&ie=UTF-8"}],"Processed":true,"Recco_tags":[],"Lookup":[]},{"id":47,"order":"47.00000000000000000000","submission_number":"47","Submitter":"Australian Professional Teachers AssociationÂ Â  Attachment 1","Type of org":{"id":977281,"value":"Peak body","color":"green"},"Notes":"","Recommendations":[{"id":98,"value":"Clear differentiation to be accepted or evident between the learning areas and subjects, rather than generic â€˜rulesâ€™ for generative AI use or the limitation of AI in schools. Tertiary institutions, transdisciplinary inquiry and traditional subject disciplines are demonstrating different approaches to the generative language models (LLMs), such as first steps in an effective discipline-specific or evidence-based research strategies."},{"id":99,"value":"Public support, trust and confidence must be built, and a vision communicated for the safe and effective use of generative AI software and tools in professional teaching standards, in early learning centres, schools and teacher education institutions. A human-centric vision within the anticipated draft AI framework must include the principles of inclusion, equity, access, quality, safety, and security."},{"id":100,"value":"The use of generative AI tools for learning, differentiation and assessment in automated systems and augmented intelligence systems, for a broader understanding of generative AI software should be introduced as a key element of Initial Teacher Education."},{"id":101,"value":"Education ministers and education departments in the states and territories adopt a nationally consistent approach to governance and standards and remove the current regulatory misalignment through calling for only a focus on local decision-making. Further, a continuous improvement national strategy with an agile approach is required to reduce teacher polarisation between AI users in government sectors, other jurisdictions, and education systems. There is a need to meet the national challenge and strict national control, with specific AI risk mitigation and regulation for areas such as the often- discussed â€˜guard railsâ€™ for cybersecurity, child protection, privacy, IP and consumer protection and information accuracy of student use or source attribution of generative AI tools."},{"id":102,"value":"Investigation of an equitable and accessible national funding program, such as grants, scholarships, and awards for professional teaching associations to sponsor and evaluate free professional development for Australian teachers in early childhood, school, and higher education sectors. These areas might include recommendations for classroom practice, curriculum initiatives, action research, radical changes in student assessment practices, or the use of an educative approach to anti-plagiarism as well as testing of detection software for academic honesty, originality, and attribution."}],"Uses-opportunities":[{"id":70,"value":"For example, generative AI tools are automating routine but time-consuming authentic assessment tasks, such as developing assessment rubrics, grading work for assessment, tracking studentsâ€™ progress, or providing feedback"}],"Risks-challenges":[],"References-footnotes":[{"id":208,"value":"Loble, L., & Hawcroft, A. (2022). Shaping AI and edtech to tackle Australiaâ€™s learning divide | University of Technology Sydney) University of Technology Sydney. https://doi.org/10.57956/kxye-qd93"},{"id":209,"value":"Wolfram, Stephen (2023) Wolfram|Alpha as the Way to Bring Computational Knowledge Superpowers to ChatGPT. https://writings.stephenwolfram.com/2023/01/wolframalpha-as-the-way-to-bringcomputational-knowledge-superpowers-to-chatgpt/"},{"id":210,"value":"Selwyn, N. (2023) Constructive Criticism? Working with (Rather than Against) the AIED Back-Lash. International Journal of Artificial Intelligence in Education. https://doi.org/10.1007/s40593-023-00344-3"},{"id":211,"value":"U.S. Department of Education, Office of Educational Technology, (2023) Artificial Intelligence and Future of Teaching and Learning: Insights and Recommendations, Washington, DC, 2023. https://tech.ed.gov"},{"id":212,"value":"Ian Lyell, 'What History Teachers Need to Know about ChatGPT,â€™ Agora 58:2 (2023), 3â€“7."}],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":100,"database_table_184385":1},"value":{"id":980196,"value":"PD","color":"light-red"}},{"ids":{"database_table_183319":98,"database_table_184385":10},"value":{"id":980190,"value":"curricula-changes","color":"light-green"}},{"ids":{"database_table_183319":101,"database_table_184385":11},"value":{"id":980191,"value":"new-policy","color":"dark-purple"}},{"ids":{"database_table_183319":99,"database_table_184385":16},"value":{"id":980194,"value":"communications","color":"darker-brown"}},{"ids":{"database_table_183319":102,"database_table_184385":17},"value":{"id":980195,"value":"resourcing","color":"dark-cyan"}},{"ids":{"database_table_183319":102,"database_table_184385":19},"value":{"id":980186,"value":"capacity-building","color":"light-yellow"}}],"Lookup":[{"id":98,"value":"Clear differentiation to be accepted or evident between the learning areas and subjects, rather than generic â€˜rulesâ€™ for generative AI use or the limitation of AI in schools. Tertiary institutions, transdisciplinary inquiry and traditional subject disciplines are demonstrating different approaches to the generative language models (LLMs), such as first steps in an effective discipline-specific or evidence-based research strategies."},{"id":99,"value":"Public support, trust and confidence must be built, and a vision communicated for the safe and effective use of generative AI software and tools in professional teaching standards, in early learning centres, schools and teacher education institutions. A human-centric vision within the anticipated draft AI framework must include the principles of inclusion, equity, access, quality, safety, and security."},{"id":100,"value":"The use of generative AI tools for learning, differentiation and assessment in automated systems and augmented intelligence systems, for a broader understanding of generative AI software should be introduced as a key element of Initial Teacher Education."},{"id":101,"value":"Education ministers and education departments in the states and territories adopt a nationally consistent approach to governance and standards and remove the current regulatory misalignment through calling for only a focus on local decision-making. Further, a continuous improvement national strategy with an agile approach is required to reduce teacher polarisation between AI users in government sectors, other jurisdictions, and education systems. There is a need to meet the national challenge and strict national control, with specific AI risk mitigation and regulation for areas such as the often- discussed â€˜guard railsâ€™ for cybersecurity, child protection, privacy, IP and consumer protection and information accuracy of student use or source attribution of generative AI tools."},{"id":102,"value":"Investigation of an equitable and accessible national funding program, such as grants, scholarships, and awards for professional teaching associations to sponsor and evaluate free professional development for Australian teachers in early childhood, school, and higher education sectors. These areas might include recommendations for classroom practice, curriculum initiatives, action research, radical changes in student assessment practices, or the use of an educative approach to anti-plagiarism as well as testing of detection software for academic honesty, originality, and attribution."}]},{"id":48,"order":"48.00000000000000000000","submission_number":"48","Submitter":"Department of Education","Type of org":{"id":977282,"value":"Govt","color":"orange"},"Notes":"No recommendations made","Recommendations":[],"Uses-opportunities":[{"id":120,"value":"improve student outcomes"},{"id":121,"value":"support and enhance educators and institutions"},{"id":122,"value":"address disadvantage"}],"Risks-challenges":[{"id":156,"value":"digital divide"},{"id":157,"value":"academic integrity"},{"id":158,"value":"bias and discrimination"},{"id":159,"value":"data privacy and transparency"},{"id":160,"value":"safety and wellbeing (e.g. deepfakes, exploitation of data for commercial gain..)"}],"References-footnotes":[],"Processed":true,"Recco_tags":[],"Lookup":[]},{"id":49,"order":"49.00000000000000000000","submission_number":"49","Submitter":"Industry Professor Leslie Loble","Type of org":{"id":977286,"value":"individual-academic","color":"dark-blue"},"Notes":"","Recommendations":[{"id":197,"value":"the fundamentals of good teaching and learning must come first, and edtech second"},{"id":198,"value":"Include standards for evidence to underpin education interventions"},{"id":199,"value":"Accelerate high quality, independent research and evaluation of AI tools to investigate impact on learning progress for students and to identify features that amplify positive outcomes, including implementation factors"},{"id":200,"value":"Catalyse a world-leading Australian social benefit edtech sector by investing in\npromising systems that meet high standards for evidence, efficacy, ethics and equity."},{"id":201,"value":"Work with schools to test, develop and showcase best practice integration of\nteaching and learning technology tools, including for disadvantaged and special\nneeds students"},{"id":202,"value":"Provide extra resources to disadvantaged schools to access high quality edtech\nlearning tools, with linked implementation support and professional development,\nalongside investment for equitable access to essential technological infrastructure"},{"id":203,"value":"Commission the Australian Education Research Organisation (AERO), working with\nACARA, AITSL and ESA, to provide expertise and advice on what works best when\nusing edtech to support teachers and improve student outcomes"},{"id":204,"value":"Build cross-government agency and public-private partnerships to safely share de-identified data for better traction on solving education challenges"},{"id":205,"value":"Create an accessible repository of trustworthy information on the quality and safety\nof available edtech tools so that schools, education systems and parents can make\nmore informed choices"},{"id":206,"value":"Develop education-specific standards, incorporated into procurement and\n(potentially new) public oversight systems, covering product design, data use, and\nlife cycle governance and accountability."},{"id":207,"value":"Establish an expert advisory body reflecting education, industry, social benefit, legal and other expertise to provide early insights and strategic solutions to help anticipate, develop and deliver safe, effective AI-based edtech"}],"Uses-opportunities":[{"id":71,"value":"Student-oriented applications â€“ Intelligent tutoring systems can create personalised learning paths for students that adapt as they progress and encourage them to reflect on their learning. Existing literature shows these systems can have a statistically significant positive impact on student outcomes, especially for lower achieving student"},{"id":72,"value":"Teacher-oriented applications â€“ â€˜Smartâ€™ curriculum tools use AI to bring evidencebased and â€˜proven in practiceâ€™ resources directly to teachers for lesson planning. Beyond standard search engines, AI-enabled tools built on evidence-based pedagogy and teacher-focused support can provide faster and more targeted access to quality materials that connect to required learning content and to data informed student insights. Specific purpose platforms can also focus on certain types of students, such as enabling early detection of special needs like dyslexia and dysgraphia. Adaptive assessment systems adjust questions to ascertain a studentâ€™s level of understanding and capability, offering better insight into learning areas needing attention and, in some cases, linking to targeted remediation resources"},{"id":73,"value":"System-oriented applications â€“ AI based modern data techniques (such as machine learning) can empower schools and systems to more accurately identify students at risk of disengagement and enable support in a timely and targeted way. These tools also provide useful insights about longitudinal and systemic trends for better policy and program design"}],"Risks-challenges":[{"id":161,"value":"bias and ethical harm"},{"id":162,"value":"inaccurate or false information"},{"id":163,"value":"privacy and intellectual property violations"}],"References-footnotes":[],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":201,"database_table_184385":7},"value":{"id":980187,"value":"stakeholder-engagement","color":"dark-green"}},{"ids":{"database_table_183319":203,"database_table_184385":7},"value":{"id":980187,"value":"stakeholder-engagement","color":"dark-green"}},{"ids":{"database_table_183319":207,"database_table_184385":7},"value":{"id":980187,"value":"stakeholder-engagement","color":"dark-green"}},{"ids":{"database_table_183319":206,"database_table_184385":11},"value":{"id":980191,"value":"new-policy","color":"dark-purple"}},{"ids":{"database_table_183319":199,"database_table_184385":12},"value":{"id":980192,"value":"research-investment","color":"orange"}},{"ids":{"database_table_183319":200,"database_table_184385":12},"value":{"id":980192,"value":"research-investment","color":"orange"}},{"ids":{"database_table_183319":203,"database_table_184385":12},"value":{"id":980192,"value":"research-investment","color":"orange"}},{"ids":{"database_table_183319":205,"database_table_184385":16},"value":{"id":980194,"value":"communications","color":"darker-brown"}},{"ids":{"database_table_183319":201,"database_table_184385":19},"value":{"id":980186,"value":"capacity-building","color":"light-yellow"}},{"ids":{"database_table_183319":198,"database_table_184385":21},"value":{"id":980197,"value":"evidence-generation","color":"brown"}},{"ids":{"database_table_183319":203,"database_table_184385":21},"value":{"id":980197,"value":"evidence-generation","color":"brown"}},{"ids":{"database_table_183319":204,"database_table_184385":21},"value":{"id":980197,"value":"evidence-generation","color":"brown"}},{"ids":{"database_table_183319":205,"database_table_184385":21},"value":{"id":980197,"value":"evidence-generation","color":"brown"}},{"ids":{"database_table_183319":202,"database_table_184385":22},"value":{"id":980198,"value":"marginalised-group-engagement","color":"light-pink"}},{"ids":{"database_table_183319":206,"database_table_184385":38},"value":{"id":986019,"value":"respect-rights","color":"light-blue"}},{"ids":{"database_table_183319":197,"database_table_184385":39},"value":{"id":991258,"value":"foster-responsible-aied","color":"red"}}],"Lookup":[{"id":197,"value":"the fundamentals of good teaching and learning must come first, and edtech second"},{"id":198,"value":"Include standards for evidence to underpin education interventions"},{"id":199,"value":"Accelerate high quality, independent research and evaluation of AI tools to investigate impact on learning progress for students and to identify features that amplify positive outcomes, including implementation factors"},{"id":200,"value":"Catalyse a world-leading Australian social benefit edtech sector by investing in\npromising systems that meet high standards for evidence, efficacy, ethics and equity."},{"id":201,"value":"Work with schools to test, develop and showcase best practice integration of\nteaching and learning technology tools, including for disadvantaged and special\nneeds students"},{"id":202,"value":"Provide extra resources to disadvantaged schools to access high quality edtech\nlearning tools, with linked implementation support and professional development,\nalongside investment for equitable access to essential technological infrastructure"},{"id":203,"value":"Commission the Australian Education Research Organisation (AERO), working with\nACARA, AITSL and ESA, to provide expertise and advice on what works best when\nusing edtech to support teachers and improve student outcomes"},{"id":204,"value":"Build cross-government agency and public-private partnerships to safely share de-identified data for better traction on solving education challenges"},{"id":205,"value":"Create an accessible repository of trustworthy information on the quality and safety\nof available edtech tools so that schools, education systems and parents can make\nmore informed choices"},{"id":206,"value":"Develop education-specific standards, incorporated into procurement and\n(potentially new) public oversight systems, covering product design, data use, and\nlife cycle governance and accountability."},{"id":207,"value":"Establish an expert advisory body reflecting education, industry, social benefit, legal and other expertise to provide early insights and strategic solutions to help anticipate, develop and deliver safe, effective AI-based edtech"}]},{"id":50,"order":"50.00000000000000000000","submission_number":"50","Submitter":"Griffith University","Type of org":{"id":977279,"value":"University","color":"darker-blue"},"Notes":"","Recommendations":[{"id":405,"value":"That Australiaâ€™s Higher Education curricular should embed critical evaluation of the use of AI with a specific focus on how these tools can positively impact society and its constraints and ethical considerations. Current and future students entering employment will need to have developed proficient skill sets that draw on its benefits but which are guided by a tightly bound ethical framework for its use."},{"id":406,"value":"Australiaâ€™s entire education sector must quickly move away from traditional assessment strategies and instead focus on high-quality authentic assessment strategies that engage students in their learning and personalises their assessment response"},{"id":407,"value":"Given the importance of AI as a career-ready skill, it will be important that all students have access to such tools. As pay-for-use generative AI models are becoming increasingly more prevalent, it will be important that educational institutions are in the position to establish fairness of access so that ability to pay does not influence studentsâ€™ learning opportunities. Currently stretched library and digital budget make this a genuine risk."},{"id":408,"value":"AI is a rapidly developing field; thus, educational institutions will need to build consideration of its most recent developments into a regular discourse to ensure they remain abreast of developments and thus can manage its opportunities and risks. At a minimum, universities should integrate such consideration within their institutionâ€™s quality assurance and enhancement processes."},{"id":409,"value":"To guide decision making on generative AIsâ€™ appropriate use, ethical standards and frameworks for its use will be required. A national response may be appropriate to prevent inconsistent responses across the sector. However, should such an approach be considered, it will be important that this work has representation from employers, educators and researchers."},{"id":410,"value":"As a collective response, universities need to explore how their administration and support functions can benefit from the use of AI, such as adopting the technology to provide tier two assistance (responses to low complexity queries), to help manage workloads, provide 24-hour response and to enable greater focus to be dedicated to complex queries and support requests."},{"id":411,"value":"students need to be aware of the fundamental limitations of these systems through the development of AI critical literacy. This needs to be an integral part of any curriculum as well as targeted learning and teaching activities."}],"Uses-opportunities":[{"id":335,"value":"Facilitation of high-engagement interactions between educators and students through AI-assisted co-teaching"},{"id":336,"value":"Assistance in developing career-ready skills, including soft skills and critical thinking"},{"id":337,"value":"Support for an agile curriculum informed by data and research"},{"id":338,"value":"Potential for generative chatbots to be more sophisticated and provide higher quality support"},{"id":339,"value":"Enhancement of overall student experience through AI chatbots in education"},{"id":340,"value":"Increased productivity and improved work satisfaction reported by software developers using AI tools like GitHub Copilot"},{"id":341,"value":"Higher levels of inclusivity for students from diverse backgrounds and locations"},{"id":342,"value":"Increased opportunities for interactivity in learning and assessment"},{"id":343,"value":"Self-paced formative assessment enabled by AI"},{"id":344,"value":"Nuanced and tailored feedback provided by AI, surpassing traditional pre-programmed feedback systems"},{"id":345,"value":"Revolutionizing teaching and learning by using AI as a cognitive aid for students"},{"id":346,"value":"Exposure to a broader body of knowledge through large language models"},{"id":347,"value":"Access to explanations and step-by-step reasoning to aid cognitive development"},{"id":348,"value":"Development of skills such as questioning, reasoning, critical evaluation, and analysis"},{"id":349,"value":"Equipping students with skills demanded in the future workforce through the use of AI tools in curriculum and assessment practices"}],"Risks-challenges":[{"id":284,"value":"the limitations of generative AI systems, including accuracy and biases in training data"},{"id":285,"value":"the quality of the output of these models\ndepends on the quality of the input they were trained on. Widely available material that reflects public opinion but\ncontradicts scientific evidence or more recent evidence can contribute to uninformed responses"}],"References-footnotes":[{"id":691,"value":"Chui, M et al., (2023). The Economic Potential of Generative AI: The Next Productivity Frontier. McKinsey & Company.\nAvailable at: https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-ofgenerative-ai-the-next-productivity-frontier#industry-impacts [Accessed: 14 July 2023]."},{"id":692,"value":"Jiao Sun, Q Vera Liao, Michael Muller, Mayank Agarwal, Stephanie Houde, Kartik Talamadupula, & Justin D Weisz. (2022).\nInvestigating Explainability of Generative AI for Code through Scenario-based Design. 27th International Conference on\nIntelligent User Interfaces. 212â€“228"},{"id":693,"value":"Kalliamvakou, E. (2022, September 7). Research: quantifying GitHub Copilotâ€™s impact on developer productivity and\nhappiness, The GitHub Blog. Available at: https://github.blog/2022-09-07-research-quantifying-github-copilots-impacton-developer-productivityand-happiness/ [Accessed 12 March 2023]"},{"id":694,"value":"Liu, D., Bridgeman, A. & Miller, B. (2023, February 28). As uni goes back, hereâ€™s how teachers and students can use\nChatGPT to save time and improve learning. The Conversation. Available at: https://theconversation.com/as-uni-goesback-heres-how-teachers-and-students-can-use-chatgpt-to-save-time-and-improve-learning-199884 [Accessed: 14\nJuly 2023]."},{"id":695,"value":"Pan, S. L., & Nishant, R. (2023). Artificial intelligence for digital sustainability: An insight into domain-specific research\nand future directions. International Journal of Information Management, 72, 102668."}],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":408,"database_table_184385":3},"value":{"id":980182,"value":"situate-with-existing-policy","color":"darker-red"}},{"ids":{"database_table_183319":406,"database_table_184385":6},"value":{"id":980185,"value":"new-assessment-models","color":"darker-pink"}},{"ids":{"database_table_183319":409,"database_table_184385":7},"value":{"id":980187,"value":"stakeholder-engagement","color":"dark-green"}},{"ids":{"database_table_183319":410,"database_table_184385":8},"value":{"id":980188,"value":"new-workforce-model","color":"light-brown"}},{"ids":{"database_table_183319":405,"database_table_184385":10},"value":{"id":980190,"value":"curricula-changes","color":"light-green"}},{"ids":{"database_table_183319":411,"database_table_184385":10},"value":{"id":980190,"value":"curricula-changes","color":"light-green"}},{"ids":{"database_table_183319":407,"database_table_184385":27},"value":{"id":980178,"value":"equitable-access","color":"yellow"}}],"Lookup":[{"id":405,"value":"That Australiaâ€™s Higher Education curricular should embed critical evaluation of the use of AI with a specific focus on how these tools can positively impact society and its constraints and ethical considerations. Current and future students entering employment will need to have developed proficient skill sets that draw on its benefits but which are guided by a tightly bound ethical framework for its use."},{"id":406,"value":"Australiaâ€™s entire education sector must quickly move away from traditional assessment strategies and instead focus on high-quality authentic assessment strategies that engage students in their learning and personalises their assessment response"},{"id":407,"value":"Given the importance of AI as a career-ready skill, it will be important that all students have access to such tools. As pay-for-use generative AI models are becoming increasingly more prevalent, it will be important that educational institutions are in the position to establish fairness of access so that ability to pay does not influence studentsâ€™ learning opportunities. Currently stretched library and digital budget make this a genuine risk."},{"id":408,"value":"AI is a rapidly developing field; thus, educational institutions will need to build consideration of its most recent developments into a regular discourse to ensure they remain abreast of developments and thus can manage its opportunities and risks. At a minimum, universities should integrate such consideration within their institutionâ€™s quality assurance and enhancement processes."},{"id":409,"value":"To guide decision making on generative AIsâ€™ appropriate use, ethical standards and frameworks for its use will be required. A national response may be appropriate to prevent inconsistent responses across the sector. However, should such an approach be considered, it will be important that this work has representation from employers, educators and researchers."},{"id":410,"value":"As a collective response, universities need to explore how their administration and support functions can benefit from the use of AI, such as adopting the technology to provide tier two assistance (responses to low complexity queries), to help manage workloads, provide 24-hour response and to enable greater focus to be dedicated to complex queries and support requests."},{"id":411,"value":"students need to be aware of the fundamental limitations of these systems through the development of AI critical literacy. This needs to be an integral part of any curriculum as well as targeted learning and teaching activities."}]},{"id":51,"order":"51.00000000000000000000","submission_number":"51","Submitter":"Australian Library and Information Association","Type of org":{"id":977281,"value":"Peak body","color":"green"},"Notes":"","Recommendations":[{"id":134,"value":"1. Commit to all students receiving instruction in AI literacy and working with library bodies on implementation."},{"id":135,"value":"2. The Department of Education to collect and report national data on school library staffing and resourcing to identify students at risk of not receiving adequate information and AI literacy resources."},{"id":136,"value":"3. Government funding for the creation of programs to upskill library and teaching staff to be AI literate, and to be able to teach AI literacy to students."},{"id":137,"value":"4. The Department of Education to work with librarians and teacher librarians on the developmentof new tools, digital platforms and programs to support AI in education."},{"id":138,"value":"5. That a research program is put in place to monitor outputs of generative AI tools deployed in an educational setting, with tool providers committing to continual improvement in response to findings."}],"Uses-opportunities":[{"id":90,"value":"1.1 Augmentation of human capacity - Artificial Intelligence, including generative AI, can increase access and value from scholarly researchand data, especially within an open access framework."},{"id":91,"value":"1.2 Addressing disadvantage and educational support - Artificial Intelligence, including generative AI, can increase access and value from scholarly researchand data, especially within an open access framework."},{"id":92,"value":"1.3 Research - Artificial Intelligence, including generative AI, can increase access and value from scholarly researchand data, especially within an open access framework."}],"Risks-challenges":[],"References-footnotes":[{"id":224,"value":"1 International Federation of Library Associations and Institutions (n.d.) Our Mission and Vision. https://www.ifla.org/vision-mission/;"},{"id":225,"value":"Australian Library and Information Association (2018) ALIA Core values policy statement. https://read.alia.org.au/alia-core-values-policy-statement"},{"id":226,"value":"2 Australian Government. Department of Industry, Science and Resources. (n.d.) Australiaâ€™s AI Ethics Principles. https://www.industry.gov.au/publications/australias-artificial-intelligence-ethics-framework/australias-aiethics-principles;"},{"id":227,"value":"UNESCO (2022) Recommendation on the Ethics of Artificial Intelligence. https://unesdoc.unesco.org/ark:/48223/pf0000381137"}],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":136,"database_table_184385":1},"value":{"id":980196,"value":"PD","color":"light-red"}},{"ids":{"database_table_183319":137,"database_table_184385":7},"value":{"id":980187,"value":"stakeholder-engagement","color":"dark-green"}},{"ids":{"database_table_183319":134,"database_table_184385":10},"value":{"id":980190,"value":"curricula-changes","color":"light-green"}},{"ids":{"database_table_183319":138,"database_table_184385":12},"value":{"id":980192,"value":"research-investment","color":"orange"}},{"ids":{"database_table_183319":136,"database_table_184385":17},"value":{"id":980195,"value":"resourcing","color":"dark-cyan"}},{"ids":{"database_table_183319":137,"database_table_184385":19},"value":{"id":980186,"value":"capacity-building","color":"light-yellow"}},{"ids":{"database_table_183319":138,"database_table_184385":21},"value":{"id":980197,"value":"evidence-generation","color":"brown"}},{"ids":{"database_table_183319":135,"database_table_184385":25},"value":{"id":980202,"value":"monitoring-impacts","color":"darker-red"}}],"Lookup":[{"id":134,"value":"1. Commit to all students receiving instruction in AI literacy and working with library bodies on implementation."},{"id":135,"value":"2. The Department of Education to collect and report national data on school library staffing and resourcing to identify students at risk of not receiving adequate information and AI literacy resources."},{"id":136,"value":"3. Government funding for the creation of programs to upskill library and teaching staff to be AI literate, and to be able to teach AI literacy to students."},{"id":137,"value":"4. The Department of Education to work with librarians and teacher librarians on the developmentof new tools, digital platforms and programs to support AI in education."},{"id":138,"value":"5. That a research program is put in place to monitor outputs of generative AI tools deployed in an educational setting, with tool providers committing to continual improvement in response to findings."}]},{"id":52,"order":"52.00000000000000000000","submission_number":"52","Submitter":"National Tertiary Education Union (NTEU)","Type of org":{"id":977284,"value":"Union","color":"darker-green"},"Notes":"\"Humans, not AI systems, need to be ethical for the AI systems to work properly, as creating and deploying AI systems is a human responsibility. Institutions must recognise that staff are best placed to lead the transformation of curriculum and assessments that will be needed to adapt to the new AI world.\"","Recommendations":[{"id":147,"value":"Staff will however need institutional support and resources to achieve this, including greater workload allocations for course design and student assessment and frameworks for considering what types of AI usage might constitute plagiarism. There should also be in place appropriate institutional policies and procedures to ensure best practice is in place and that human oversight on the use of AI is embedded."},{"id":148,"value":"The use of Artificial Intelligence in higher education should be human centric, with appropriate guardrails in place to regulate its effective use as a tool to improve access to and experience of education. It should also be seen as a mechanism to better equip our researchers, technological staff and others engaged in research activities to undertake their work more effectively and assist with innovation and knowledge discovery. However, it should not replace the human element in teaching, learning and research activities. It should also ensure human oversight remains in important student support services, and in administration and technical roles. Furthermore, both staff and students should be supported to learn and use AI technology in a responsible and ethical manner. Where it is embedded or seen as a vital component as part of the learning experience, the education provider should ensure that all students and staff have equitable access to the use of AI."},{"id":149,"value":"Support ground-up staff led assessment of AI usage in their disciplines. Staff are best placed to decide how and where AI usage is appropriate in the context of their specific discipline and course content. Blanket regulatory or institutional policy approaches to adopting AI should be avoided in relation to the delivery of teaching and research, particularly where it is deemed to be a â€˜cost savingâ€™ measure. Where AI is adopted, to ensure it is used successfully and responsibly as a tool in teaching, learning and curricular, staff need professional development opportunities to learn about AI and additional time allocation to develop and engage in new modes of assessment. This will ensure students of Australian institutions are truly attaining the desired learning outcomes."},{"id":150,"value":"Regulators of Australian Higher Education providers Education Regulators (primarily TEQSA) will need to be conscious of the implication of AI on learning pedagogies and be empowered to ensure that learning outcomes are maintained"},{"id":151,"value":"Support for higher education staff and the professional development of staff in the use of AI Staff need to be equipped with the necessary capabilities and support to effectively adapt their teaching and learning activities to the emerging AI environment, including appropriate training in AI usage. This should extend to all staff who are engaged with teaching, learning and research, as well as administrative and professional/technical staff, where there is the expectation or necessity for AI to be part of their activities. In particular, casual, sessional, contract and other staff employed non-permanently should be supported by the institution in relation to their professional development around the use of AI."},{"id":152,"value":"Implement guardrails as AI develops to provide better outcomes The NTEU supports the establishment of regulatory guardrails to direct the development and use of AI in both the education context and more broadly. The implementation of good practice principles drawing from ethical frameworks will help direct the development of AI in a positive manner and reduce the risk of adverse outcomes. Such principles should address the need for: â€¢ Equity â€¢ Accessibility and inclusion â€¢ Prevention of bias and discrimination â€¢ Transparency and accountability These principles should underpin the premise that the application of AI should be beneficial and not result in the lessening of current industrial protections, human rights and guarantees on human expression and freedoms."}],"Uses-opportunities":[{"id":93,"value":"Generative AIs have the potential to empower students to perform at a higher level than before. Using generative AIs as a tool students may outsource the extraneous cognitive load that comes with assessments like refencing or formatting and focus on the intrinsic content of their studies â€“ directly engaging with key ideas. This ability to engage with key ideas means that the bar could potentially be raised to a level above what can be achieved today or using only AIs."},{"id":94,"value":"AIs also present a new opportunity for students with diverse learning abilities or special needs to access education and to improve the quality of their learning experience. This in turn opens new pathways for skills development and career opportunities, with the advantage of improving workforce participation of these graduate cohorts."},{"id":95,"value":"The use of AI for researchers presents considerable opportunities in the collection, processing and analysis of data, as well as in comparing research and collaboration. It could also assist with the time consuming administrative and reporting processes, freeing up valuable time for more research. The use of AI in research is expanding rapidly, with researchers finding new ways to adapt AI tools in their work and to develop the technology further."}],"Risks-challenges":[{"id":102,"value":"The rise of generative AIs presents several challenges for educators. In order to ensure that students are graduating with the skills and knowledge appropriate to their program of study academic staff must devise assessments that can accurately ascertain whether or not the student has attained the relevant skills and knowledge (and to what level). This is considered a minimum requirement under TEQSAâ€™s Higher Education Standards Framework.1 There is a risk that generative AI will make this more difficult when such AIs are able to produce outputs that the student is then assessed on. For example, students can already produce short form pieces of prose using current generative AI technologies. There is a risk in this environment that over time universities may reach a point where they can no longer assure the required learning has occurred in what they claim to be teaching."},{"id":103,"value":"teaching staff will need to continuously develop new methods of assessment that assess students at a level beyond the levels of AIs. This entails a significant ongoing workload increase, as teaching staff will now be required to continuously re-tool assessments and workloads. Further, the amount of work needed to complete a degree may need to be increased, or devised differently, in an environment where students are using AIs. Put simply, the use of AIs in teaching and learning is highly likely to drive pedagogical change."},{"id":104,"value":"Ideally, students should be assessed on their capacity to critically interrogate the outputs of AIs and the learning process itself, rather than the artefacts they produce that are currently taken to be evidence that learning has occurred. This is a significant paradigm shift for teaching institutions. This type of assessment will likely require more one on one student-staff interaction to ensure that skills and knowledge have truly been attained and work completed. This will be more demanding on staff and may mean that current expectations around how many students one staff member can teach need to be completely re-se"},{"id":105,"value":"The use of AI in research also presents risks around academic integrity. While institutions will be looking to manage instances of deliberate manipulation/falsification/misrepresentation and accidental or unintended corruption of data, there is a real risk that AI applications will be considerably ahead of current research integrity processes that would detect problems or irregularities. It may be that problematic research is not detected for some time, if at all, by which time there could be widespread ramifications."},{"id":106,"value":"AI systems currently use limited sets of data that can be prone to biases based on data selection â€“ something that is opaque to staff and students. AIs can also replicate and reinforce existing social biases that are present inside of data sets, for example the underrepresentation of certain groups in certain academic fields. This is because inherent in the creation of AI is that any pre-existing bias or discrimination that is either unconsciously, or consciously, imbedded will set the â€˜learningâ€™ pattern for that AI"},{"id":107,"value":"THE RISK OF MISGUIDED TECHNOLOGICAL REDUNDANCIES There are a wide variety of tasks currently performed by staff in the academic context that institutions may look to AIs to perform partially or fully in the future.The NTEUâ€™s position is that AI is not an appropriate replacement for staff because it does not engage in critical thinking, produce genuine creativity or innovation. AI is also absent of the capacity to consider ethical component of its output â€“ it is simply using a pre-programmed ethical framework which may be structurally or systemically biased. Human staff are required to monitor and accept or reject AI outputs as appropriate."},{"id":108,"value":"There are also concerns on how AI may impact on privacy and the security of personal data (including the use of student and staff personal data â€“ for example, unauthorised access of data, through to institutional managements using AI to mine confidential data or information in workplace relations situations)."},{"id":109,"value":"Another concern is around the usage of third-party AIs and the need for this to be disclosed to staff and students. Most advanced AIs are being developed for foreign, for-profit entities, and there is little transparency about what types of data they collect about users and how they use this. With higher education institutions â€“ both public and private â€“ routinely engaging in external contractors for the delivery of teaching, student support (both academic and welfare) as well as with the administration and technical tasks, there is already little (if any) transparency around these arrangements. The use of external AI driven platforms and services by third parties to the education providers adds further complexity and increases the potential risk of adverse consequences for staff and students."}],"References-footnotes":[{"id":228,"value":"As complied in UNESCO, ChatGPT and Artificial Intelligence in higher education, 2023, https://www.iesalc.unesco.org/wpcontent/ uploads/2023/04/ChatGPT-and-Artificial-Intelligence-in-higher-education-Quick-Start-guide_EN_FINAL.pdf"}],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":151,"database_table_184385":1},"value":{"id":980196,"value":"PD","color":"light-red"}},{"ids":{"database_table_183319":149,"database_table_184385":4},"value":{"id":980183,"value":"local-responses-and-autonomy","color":"dark-cyan"}},{"ids":{"database_table_183319":147,"database_table_184385":8},"value":{"id":980188,"value":"new-workforce-model","color":"light-brown"}},{"ids":{"database_table_183319":148,"database_table_184385":8},"value":{"id":980188,"value":"new-workforce-model","color":"light-brown"}},{"ids":{"database_table_183319":150,"database_table_184385":10},"value":{"id":980190,"value":"curricula-changes","color":"light-green"}},{"ids":{"database_table_183319":152,"database_table_184385":11},"value":{"id":980191,"value":"new-policy","color":"dark-purple"}},{"ids":{"database_table_183319":147,"database_table_184385":17},"value":{"id":980195,"value":"resourcing","color":"dark-cyan"}}],"Lookup":[{"id":147,"value":"Staff will however need institutional support and resources to achieve this, including greater workload allocations for course design and student assessment and frameworks for considering what types of AI usage might constitute plagiarism. There should also be in place appropriate institutional policies and procedures to ensure best practice is in place and that human oversight on the use of AI is embedded."},{"id":148,"value":"The use of Artificial Intelligence in higher education should be human centric, with appropriate guardrails in place to regulate its effective use as a tool to improve access to and experience of education. It should also be seen as a mechanism to better equip our researchers, technological staff and others engaged in research activities to undertake their work more effectively and assist with innovation and knowledge discovery. However, it should not replace the human element in teaching, learning and research activities. It should also ensure human oversight remains in important student support services, and in administration and technical roles. Furthermore, both staff and students should be supported to learn and use AI technology in a responsible and ethical manner. Where it is embedded or seen as a vital component as part of the learning experience, the education provider should ensure that all students and staff have equitable access to the use of AI."},{"id":149,"value":"Support ground-up staff led assessment of AI usage in their disciplines. Staff are best placed to decide how and where AI usage is appropriate in the context of their specific discipline and course content. Blanket regulatory or institutional policy approaches to adopting AI should be avoided in relation to the delivery of teaching and research, particularly where it is deemed to be a â€˜cost savingâ€™ measure. Where AI is adopted, to ensure it is used successfully and responsibly as a tool in teaching, learning and curricular, staff need professional development opportunities to learn about AI and additional time allocation to develop and engage in new modes of assessment. This will ensure students of Australian institutions are truly attaining the desired learning outcomes."},{"id":150,"value":"Regulators of Australian Higher Education providers Education Regulators (primarily TEQSA) will need to be conscious of the implication of AI on learning pedagogies and be empowered to ensure that learning outcomes are maintained"},{"id":151,"value":"Support for higher education staff and the professional development of staff in the use of AI Staff need to be equipped with the necessary capabilities and support to effectively adapt their teaching and learning activities to the emerging AI environment, including appropriate training in AI usage. This should extend to all staff who are engaged with teaching, learning and research, as well as administrative and professional/technical staff, where there is the expectation or necessity for AI to be part of their activities. In particular, casual, sessional, contract and other staff employed non-permanently should be supported by the institution in relation to their professional development around the use of AI."},{"id":152,"value":"Implement guardrails as AI develops to provide better outcomes The NTEU supports the establishment of regulatory guardrails to direct the development and use of AI in both the education context and more broadly. The implementation of good practice principles drawing from ethical frameworks will help direct the development of AI in a positive manner and reduce the risk of adverse outcomes. Such principles should address the need for: â€¢ Equity â€¢ Accessibility and inclusion â€¢ Prevention of bias and discrimination â€¢ Transparency and accountability These principles should underpin the premise that the application of AI should be beneficial and not result in the lessening of current industrial protections, human rights and guarantees on human expression and freedoms."}]},{"id":53,"order":"53.00000000000000000000","submission_number":"53","Submitter":"Curtin Student Guild","Type of org":{"id":977968,"value":"advocacy-group","color":"darker-green"},"Notes":"student-body","Recommendations":[{"id":601,"value":"A regulatory environment that provides safeguards, consistency and sustainability is required to support students, academics and researchers navigate and benefit from its application"},{"id":602,"value":"Data privacy and security should be incorporated into the development and application standards of generative AI, to promote the sustainable development of generative AI."},{"id":603,"value":"Assurances about the quality, quantity and diversity of datasets used in AI are important to prevent inaccuracy, bias and ensure its applicability to a wide range of student cohorts."},{"id":604,"value":"Students should be taught how to use AI correctly and effectively to ensure the integrity of\ntheir learning journey"},{"id":605,"value":"Regulation, policy and legislation must be developed in collaboration with peak student\nrepresentative bodies."}],"Uses-opportunities":[{"id":468,"value":"Personalised learning and tutoring"},{"id":469,"value":"Making complex concepts easier to understand through the use of user-friendly\nlanguage, examples, mapping and visual interpretations"},{"id":470,"value":"Intelligent tutoring and real time feedback"},{"id":471,"value":"Improvements to the quality of hybrid and fully online learning environments with the\nuse of, for example, virtual laboratories"},{"id":472,"value":"Reducing student workload when AI is used as a support tool"},{"id":473,"value":"Reducing accessibility barriers for some student cohorts"},{"id":474,"value":"Tasks such as finding a research problem of interest in a certain field"},{"id":475,"value":"Research, data collection and interpretation"},{"id":476,"value":"Course design and improvement"},{"id":477,"value":"Innovation of teaching methods"},{"id":478,"value":"Preparation of student materials"},{"id":479,"value":"Intelligent education management"},{"id":480,"value":"The creation and improvement of hybrid and virtual learning environments"},{"id":481,"value":"Individualising course content for a personalised student experience"},{"id":482,"value":"Enhanced industry cooperation"},{"id":483,"value":"Assistance with the grading of assessments and provision of some forms of feedback"},{"id":484,"value":"Analysis of student interactions across their learning can provide the opportunity to\nsee which moments matter for student success"}],"Risks-challenges":[{"id":375,"value":"Students may not understand how to appropriately use AI tools and be subject to\nacademic penalties"},{"id":376,"value":"Teaching staff may not know how to implement the use of AI in a safe and ethical\nway given the relative infancy of the technology in education"},{"id":377,"value":"Students may become reliant on the AI tools to the exclusion of other learning\ntechniques"},{"id":378,"value":"AI generated information may contain factual errors, bias, and may not cover all\nareas of educational content which would lead jeopardise learning outcomes if\nstudents and academics are not trained to utilize generative AI effectively Bias in AI data sets could go unchecked and become amplified"},{"id":379,"value":"The quality of education and research may suffer if bias or incorrect information is\nincorporated in data sets"},{"id":380,"value":"Misuse of AI by students has the potential to damage the academic reputation of\nuniversities"},{"id":381,"value":"AI could lead to an increase in the number of low-quality research papers in\ncirculation and jeopardise the integrity of academic publications"},{"id":382,"value":"There is a danger that low quality research could be perpetuated in future AI data\nsets"},{"id":383,"value":"Tools being used to detect the misuse of AI by students can be unreliable and might\nlead to students being falsely accused of cheating â€“ especially for the international\nstudent cohort"},{"id":384,"value":"Students personal information could be included in AI data sets which have the\npotential to be hacked or misused"}],"References-footnotes":[{"id":839,"value":"Students personal information could be included in AI data sets which have the\npotential to be hacked or misused"},{"id":840,"value":"M. Abdullah, A. Madain and Y. Jararweh, \"ChatGPT: Fundamentals, Applications and Social Impacts,\" 2022 Ninth\nInternational Conference on Social Networks Analysis, Management and Security (SNAMS), Milan, Italy, 2022, pp. 1-8, doi:\n10.1109/SNAMS58071.2022.10062688."},{"id":841,"value":"AI will revolutionise education in an unexpected way. Tim Dodd. The Australian. 31 May 2023"},{"id":842,"value":"https://broneager.com/ai-and-academic-jobs"},{"id":844,"value":"Foundation Models such as ChatGPT through the prism of the UNESCO Recommendation on the Ethics of Artificial\nIntelligence"},{"id":845,"value":"M. Abdullah, A. Madain and Y. Jararweh, \"ChatGPT: Fundamentals, Applications and Social Impacts,\" 2022 Ninth\nInternational Conference on Social Networks Analysis, Management and Security (SNAMS), Milan, Italy, 2022, pp. 1-8, doi:\n10.1109/SNAMS58071.2022.10062688"},{"id":846,"value":"https://www.linkedin.com/pulse/20-human-jobs-higher-education-potentially-impacted-ai-simon-ph-d-/"},{"id":847,"value":"Yu H (2023) Reflection on whether Chat GPT should be banned by academia from the perspective of education and\nteaching. Front. Psychol. 14:1181712. doi: 10.3389/fpsyg.2023.1181712"},{"id":850,"value":"https://www.icms.edu.au/news/academic/icms-response-academic-integrity-ai/"},{"id":852,"value":"https://www.icms.edu.au/news/academic/icms-response-academic-integrity-ai/"},{"id":855,"value":"https://www.abc.net.au/news/2023-06-02/international-students-say-ai-detectors-are-inaccurate/102394894"},{"id":859,"value":"Exploring the Potential of AI in Enhancing Special Education Outcomes by Marcin FrÄ…ckiewicz in Artificial\nintelligence, TS2 Space 4 May 2023"},{"id":860,"value":"https://www.inclusivecitymaker.com/artificial-intelligence-accessibility-examples-technology-serves-people-disabilities/"},{"id":861,"value":"https://artificialintelligenceact.eu/"},{"id":862,"value":"Recommendations of the Ethics of Articifial Intelligence. UNIESCO. 2021"},{"id":864,"value":"Universities need to provide more guidance for use of AI in research. The Australian. 2/7/23. Matthew Clarke, Jeanette Fyffe,\nPeter Murphy, Kristy Fickinger"},{"id":865,"value":"https://russellgroup.ac.uk/media/6137/rg_ai_principles-final.pdf"},{"id":866,"value":"Yu H and Guo Y (2023) Generative artificial intelligence empowers educational reform: current status, issues, and\nprospects. Front. Educ. 8:1183162. doi: 10.3389/feduc.2023.1183162. Yu H (2023) Reflection on whether Chat GPT shouldbe\nbanned by academia from the perspective of education and teaching. Front. Psychol. 14:1181712. doi:\n10.3389/fpsyg.2023.1181712"}],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":605,"database_table_184385":7},"value":{"id":980187,"value":"stakeholder-engagement","color":"dark-green"}},{"ids":{"database_table_183319":604,"database_table_184385":10},"value":{"id":980190,"value":"curricula-changes","color":"light-green"}},{"ids":{"database_table_183319":601,"database_table_184385":38},"value":{"id":986019,"value":"respect-rights","color":"light-blue"}},{"ids":{"database_table_183319":602,"database_table_184385":38},"value":{"id":986019,"value":"respect-rights","color":"light-blue"}},{"ids":{"database_table_183319":603,"database_table_184385":39},"value":{"id":991258,"value":"foster-responsible-aied","color":"red"}}],"Lookup":[{"id":601,"value":"A regulatory environment that provides safeguards, consistency and sustainability is required to support students, academics and researchers navigate and benefit from its application"},{"id":602,"value":"Data privacy and security should be incorporated into the development and application standards of generative AI, to promote the sustainable development of generative AI."},{"id":603,"value":"Assurances about the quality, quantity and diversity of datasets used in AI are important to prevent inaccuracy, bias and ensure its applicability to a wide range of student cohorts."},{"id":604,"value":"Students should be taught how to use AI correctly and effectively to ensure the integrity of\ntheir learning journey"},{"id":605,"value":"Regulation, policy and legislation must be developed in collaboration with peak student\nrepresentative bodies."}]},{"id":54,"order":"54.00000000000000000000","submission_number":"54","Submitter":"Professor Phillip Dawson","Type of org":{"id":977286,"value":"individual-academic","color":"dark-blue"},"Notes":"","Recommendations":[{"id":92,"value":"That software to detect the use of generative artificial intelligence should not be used until there is evidence that it works."}],"Uses-opportunities":[],"Risks-challenges":[{"id":84,"value":"AI detecEon tools do not work sufficiently well now, and there are mathemaEcal arguments that in the long term, it will not be possible to develop effecEve generaEve AI wriEng detecEon tools, as the improvement of generaEve AI will outpace the development of the detecEon tools (see a preprint by Sankar Sadasivan et al., 2023). If students are banned from using generaEve arEficial intelligence in unsupervised tasks, but some students use it, and we donâ€™t know because the detecEon tools donâ€™t work, it becomes difficult to judge what students are capable of. As I argue in my 2021 book Defending Assessment Security in a Digital World (Dawson, 2021), if restricEons are set that are not feasible, they make the integrity and validity of assessment worse, not be/er. In addiEon, the risk of false posiEves â€“ students accused of using generaEve AI who did not actually use it â€“ creates the potenEal for harm to student wellbeing and sector reputaEon. The onus should be on the vendors of these tools to provide transparent, independently validated evidence that their tools work. This has been done in the past with other assessment integrity tools, for example, I have led a research study with a vendor of authorship verificaEon soXware for the detecEon of contract cheaEng (Dawson et al., 2020). In the absence of this sort of evidence for generaEve arEficial intelligence detecEon soXware, and given the existence of evidence that the tools are â€œneither accurate nor reliableâ€ (Weber-Wulff et al., 2023) I make the following recommendaEon:"}],"References-footnotes":[{"id":21,"value":"Dawson, P. (2021). Defending assessment security in a digital world: preventing e-cheating and supporting academic integrity in higher educa;on. Routledge."},{"id":22,"value":"Dawson, P., Sutherland-Smith, W., & Ricksen, M. (2020). Can soXware improve marker accuracy at detecting contract cheating? A pilot study of the Turnitin authorship investigate alpha. Assessment & Evalua;on in Higher Educa;on, 45(4), 473-482. doi.org/10.1080/02602938.2019.1662884"},{"id":23,"value":"Gilson, A., Safranek, C. W., Huang, T., Socrates, V., Chi, L., Taylor, R. A., & Chartash, D. (2023). How does ChatGPT perform on the United States medical licensing examinaEon? The implicaEons of large language models for medical educaEon and knowledge assessment. JMIR Medical Educa;on, 9(1), e45312."},{"id":24,"value":"Katz, D. M., Bommarito, M. J., Gao, S., & Arredondo, P. (2023). Gpt-4 passes the bar exam. Available at SSRN 4389233."},{"id":25,"value":"Nikolic, S., Daniel, S., Haque, R., Belkina, M., Hassan, G. M., Grundy, S., Lyden, S., Neal, P., & Sandison, C. (2023). ChatGPT versus engineering educaEon assessment: a mulEdisciplinary and mulE-insEtuEonal benchmarking and analysis of this generaEve arEficial intelligence tool to invesEgate assessment integrity. European Journal of Engineering Educa;on, 48(4), 559-614. h/ps://doi.org/10.1080/03043797.2023.2213169"},{"id":27,"value":"Weber-Wulff, D., Anohina-Naumeca, A., Bjelobaba, S., FoltÃ½nek, T., Guerrero-Dib, J., Popoola, O., Å igut, P., & Waddington, L. (2023). TesEng of DetecEon Tools for AI-Generated Text. arXiv preprint arXiv:2306.15666."},{"id":167,"value":"Dawson, P. (2021). Defending assessment security in a digital world: preventing e-cheating and supporting academic integrity in higher education. Routledge."},{"id":171,"value":"Katz, D. M., Bommarito, M. J., Gao, S., & Arredondo, P. (2023). Gpt-4 passes the bar exam. Available at SSRN 4389233."},{"id":172,"value":"Nikolic, S., Daniel, S., Haque, R., Belkina, M., Hassan, G. M., Grundy, S., Lyden, S., Neal, P., & Sandison, C. (2023). ChatGPT versus engineering education assessment: a multisciplinary and multi-instiutional benchmarking and analysis of this generative artificial intelligence tool to investigate assessment integrity. European Journal of Engineering Education, 48(4), 559-614. https://doi.org/10.1080/03043797.2023.2213169"},{"id":174,"value":"Sankar Sadasivan, V., Kumar, A., Balasubramanian, S., Wang, W., & Feizi, S. (2023). Can AI-Generated Text be Reliably Detected? , arXiv:2303.11156. Retrieved March 01, 2023, from h/ps://ui.adsabs.harvard.edu/abs/2023arXiv230311156S"},{"id":175,"value":"Weber-Wul?, D., Anohina-Naumeca, A., Bjelobaba, S., FoltÃ½nek, T., Guerrero-Dib, J., Popoola, O., Å igut, P., & Waddington, L. (2023). TesEng of DetecEon Tools for AI-Generated Text. arXiv preprint arXiv:2306.15666."}],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":92,"database_table_184385":21},"value":{"id":980197,"value":"evidence-generation","color":"brown"}}],"Lookup":[{"id":92,"value":"That software to detect the use of generative artificial intelligence should not be used until there is evidence that it works."}]},{"id":55,"order":"55.00000000000000000000","submission_number":"55","Submitter":"Australian Research Alliance for Children and Youth","Type of org":{"id":977968,"value":"advocacy-group","color":"darker-green"},"Notes":"","Recommendations":[{"id":87,"value":"Further consideration of the application of the recommendations of the General Comment 25 (2021) to the United Nations Convention on the Rights of the Child developed to specifically address the rights of the child in the digital age."},{"id":88,"value":"Extensive ongoing consultation with children and young people is undertaken to not only inform proposed actions but to also uncover creative child-led solutions and insights with respect to their education and the use of generative AI as well as any unintended consequences."},{"id":89,"value":"Commitment to a strong research agenda to understand the potential and risks of generative AI as well as to evaluate its use in educational settings and the reasons for its rapid uptake. This research should also include disadvantaged and marginalised groups and consider the different educational needs of each school age cohort."},{"id":90,"value":"Continued monitoring of other discourses on the risks and challenges of AI is undertaken, with a special emphasis on data quality and â€˜knowledge reservesâ€™ as well as privacy with respect to GenAI in education."},{"id":91,"value":"Commission the Australian Education Research Organisation (AERO) to provide expertise and advice on what works best when using education technology in classrooms, to support teachers and improve student outcomes."}],"Uses-opportunities":[{"id":68,"value":"Using Gen AI in education settings has the potential to develop the adaptive capacity among students through development of agile learning environments where students cultivate creative thinking and problem-solving skills through â€˜learn-explore-practiceâ€™ approaches through their interactions with AI. The learning emphasis will shift to adaptive and inquirybased learning and AI will act as â€˜objects-to-think-withâ€™."}],"Risks-challenges":[{"id":83,"value":"Another risk that may arise by using Gen AI in education is automation of the teaching function which could occur without the re-evaluation of the education system within the changing world context. In such a case the AI instrumentalises the educator rather than complementing the educatorâ€™s human skills."}],"References-footnotes":[{"id":158,"value":"https://www.aracy.org.au/the-nest-in-action/the-nest-overview"},{"id":159,"value":"https://www.unicef.org.au/united-nations-convention-on-the-rights-of-the-child"},{"id":160,"value":"https://www.ohchr.org/en/documents/general-comments-and-recommendations/general-commentno-25-2021-childrens-rights-relation"},{"id":161,"value":"https://assets-us-01.kc-usercontent.com/99f113b4-e5f7-00d2-23c0-c83ca2e4cfa2/e0b64280-dd99-4237-9c69-eaebc2ff3ce7/Australian-Childrens-Wellbeing-Index-Report.pdf"},{"id":162,"value":"https://www.frontiersin.org/articles/10.3389/fpsyg.2023.1181712/full"},{"id":163,"value":"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4439267"},{"id":164,"value":"https://www.ejmste.com/article/enhancing-stem-learning-with-chatgpt-and-bing-chat-as-objects-tothink-with-a-case-study-13313"},{"id":165,"value":"https://www.education.gov.au/quality-schools-package/resources/through-growth-achievementreport-review-achieve-educational-excellence-australian-schools"},{"id":166,"value":"https://www.uts.edu.au/partners-and-community/initiatives/social-justice-uts/centre-social-justiceinclusion/shaping-ai-and-edtech-tackle-australias-learning-divide"}],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":87,"database_table_184385":3},"value":{"id":980182,"value":"situate-with-existing-policy","color":"darker-red"}},{"ids":{"database_table_183319":88,"database_table_184385":7},"value":{"id":980187,"value":"stakeholder-engagement","color":"dark-green"}},{"ids":{"database_table_183319":89,"database_table_184385":12},"value":{"id":980192,"value":"research-investment","color":"orange"}},{"ids":{"database_table_183319":91,"database_table_184385":12},"value":{"id":980192,"value":"research-investment","color":"orange"}},{"ids":{"database_table_183319":90,"database_table_184385":20},"value":{"id":980179,"value":"ongoing-and-global-monitoring","color":"dark-brown"}},{"ids":{"database_table_183319":89,"database_table_184385":21},"value":{"id":980197,"value":"evidence-generation","color":"brown"}},{"ids":{"database_table_183319":91,"database_table_184385":21},"value":{"id":980197,"value":"evidence-generation","color":"brown"}},{"ids":{"database_table_183319":89,"database_table_184385":22},"value":{"id":980198,"value":"marginalised-group-engagement","color":"light-pink"}}],"Lookup":[{"id":87,"value":"Further consideration of the application of the recommendations of the General Comment 25 (2021) to the United Nations Convention on the Rights of the Child developed to specifically address the rights of the child in the digital age."},{"id":88,"value":"Extensive ongoing consultation with children and young people is undertaken to not only inform proposed actions but to also uncover creative child-led solutions and insights with respect to their education and the use of generative AI as well as any unintended consequences."},{"id":89,"value":"Commitment to a strong research agenda to understand the potential and risks of generative AI as well as to evaluate its use in educational settings and the reasons for its rapid uptake. This research should also include disadvantaged and marginalised groups and consider the different educational needs of each school age cohort."},{"id":90,"value":"Continued monitoring of other discourses on the risks and challenges of AI is undertaken, with a special emphasis on data quality and â€˜knowledge reservesâ€™ as well as privacy with respect to GenAI in education."},{"id":91,"value":"Commission the Australian Education Research Organisation (AERO) to provide expertise and advice on what works best when using education technology in classrooms, to support teachers and improve student outcomes."}]},{"id":56,"order":"56.00000000000000000000","submission_number":"56","Submitter":"KomplyAi Pty Ltd","Type of org":{"id":977288,"value":"Company","color":"dark-purple"},"Notes":"","Recommendations":[{"id":81,"value":"(1) consistent with international responses to AI, including the safe management of foundation models and forms of generative AI, new regulation is needed in this area and arguably a principal piece of legislation that governs AI. The regulation of AI should also be part of a wider and comprehensive review of laws that intersects with and is complimentary to this sector. We need to continue to balance risk proportionately by identifying the highest risks in this area and mechanisms for outlier issues of concern whilst continuing to encourage innovation and derive the truly significant societal benefits of AI;"},{"id":84,"value":"Australia should also closely consider prioritising its alignment with other key export markets, and avoid fragmentation, and multi-jurisdictional compliance regimes that make investment unpalatable, and research and development activity challenging. Particularly, as it intersects with our higher education institutions remaining competitive. Offering the most comprehensive training for work ready students (both domestic and international) and in research and development. Briefly, areas for current consideration from overseas countries regulating AI, include consideration of certain prohibited AI activities, exemptions for internal research and development without prejudice to commercialisation, treatment of open source software, and risk classifications for intersecting educational activities and AI, such as higher risk requirements for use of this AI in admissions and academic assessment8;"},{"id":85,"value":"AI safety research and development, and optimising innovation breadth, needs to be properly and comprehensively supported. The prioritisation of resourcing, coordination of public and private, and increasing the scale of piloting and use, and skills training in niche evaluation assessments of AI, is important. If Australia is to compete on the global stage and drive economic and productivity growth, the Governmentâ€™s continued focus on and increased investment in initiatives to support our digital strategy, and the AI ecosystem in Australia, by supporting the education sector is truly fundamental. Our global counterparts are expanding their investment in AI and capabilities and Australia cannot afford to be left behind. We have set out in the Annexure to this submission some examples of broader principles that we have developed that are education specific to help build consensus on governance frameworks to manage AI safety risks."}],"Uses-opportunities":[],"Risks-challenges":[{"id":71,"value":"(1) external factors beyond institutional control, such as the current (or lack thereof) regulation of foundation models (and their commercial providers), which arguably shapes the broader digital supply chain, including that of generative AI and its safe use and management6. The usual level of rigour and prescription in technology and risk control is presently not fully understood nor the usual level of transparency and explanation required for institutional interrogation. This may result in potential downstream liability for an institution where there is no standardisation about release controls of those foundation models;"},{"id":72,"value":"(2) current absence of universally accepted standards or metrics for risk assessment. There are many present unknowns that do not comfortably sit with the usual rigorous structures of education, for example, the potential scale of impact, and the vulnerability profile of its â€˜consumerâ€™ (e.g., children, teenagers, and young adults). For example, there is no research consensus globally about the true impact of certain forms of AI on protected categories such as children or teenagers, areas such as â€œAI-enhanced nudgingâ€™ and â€œalgorithmic influenceâ€ on children and teenagers â€“ nudging them into certain behaviours without their awareness7;"},{"id":73,"value":"(3) limited funding and resourcing in a highly competitive market where the required niche level of skills are in high demand (e.g., evaluation expertise in responsible AI), and costed accordingly. The work and research into AI has a long gestation period, and is labour intensive (e.g., data labelling and model building);"},{"id":74,"value":"(4) the intersection of AI technologies and the breadth of activities that higher education institutions and schools are responsible for, is significant. For example, their administrative use, training in AI, and research in AI. The breadth of these activities requiring the establishment of different (but interwoven) governance frameworks to manage AI safety risks; and"},{"id":75,"value":"(5) a lack of coordination to map at a sector level functions, governance, and objectives to generate models of AI good governance."}],"References-footnotes":[{"id":149,"value":"Proposal for a Regulation of the European Parliament and of the Council: Laying down harmonised rules on artificial intelligence (Artificial Intelligence Act) and amending certain Union Legislative Acts [2021], arts 3(1), (1c), (1d). (June 2023 Compromise Text and Official European Commission Link)."},{"id":150,"value":"Australian Government, Department of Industry, â€˜Australia's AI Action Plan: discussion paper - Department of Industry - Citizen Space,â€™ Forward (22 June 2021)."},{"id":151,"value":"3 Price Waterhouse Coppers, â€˜Global Artificial Intelligence Study: Sizing the Prizeâ€ Sizing the prize (pwc.com), (2017), page 3."},{"id":152,"value":"4 â€˜New Principles on Use of AI in Education,â€™ The Russell Group (04 July 2023)"},{"id":153,"value":"https://www.teqsa.gov.au/guides-resources/higher-education-good-practice-hub/artificial-intelligence"},{"id":154,"value":"Rishi Bommasani et al, â€˜Do Foundation Model Providers Comply with the Draft EU AI Act?â€™, Stanford University Center for Research on Foundation Models (2023)."},{"id":155,"value":"Marianna Ganapini and Enrico Panai, â€˜An Audit Framework for Adopting AI-Nudging on Childrenâ€™, Tech Ethics Lab (April 2023)."},{"id":156,"value":"Proposal for a Regulation of the European Parliament and of the Council: Laying down harmonised rules on artificial intelligence (Artificial Intelligence Act) and amending certain Union Legislative Acts [2021], arts 5d, annex III (1), (2). (June 2023 Compromise Text and Official European Commission Link)."},{"id":157,"value":"See also, Christiane Wendehorst and Yannic Duller, â€˜Biometric Recognition and Behavioural Detectionâ€™, Policy Department for Citizensâ€™ Rights and Constitutional Affairs (August 2021), page 19;"}],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":84,"database_table_184385":3},"value":{"id":980182,"value":"situate-with-existing-policy","color":"darker-red"}},{"ids":{"database_table_183319":81,"database_table_184385":11},"value":{"id":980191,"value":"new-policy","color":"dark-purple"}},{"ids":{"database_table_183319":85,"database_table_184385":17},"value":{"id":980195,"value":"resourcing","color":"dark-cyan"}},{"ids":{"database_table_183319":84,"database_table_184385":20},"value":{"id":980179,"value":"ongoing-and-global-monitoring","color":"dark-brown"}}],"Lookup":[{"id":81,"value":"(1) consistent with international responses to AI, including the safe management of foundation models and forms of generative AI, new regulation is needed in this area and arguably a principal piece of legislation that governs AI. The regulation of AI should also be part of a wider and comprehensive review of laws that intersects with and is complimentary to this sector. We need to continue to balance risk proportionately by identifying the highest risks in this area and mechanisms for outlier issues of concern whilst continuing to encourage innovation and derive the truly significant societal benefits of AI;"},{"id":84,"value":"Australia should also closely consider prioritising its alignment with other key export markets, and avoid fragmentation, and multi-jurisdictional compliance regimes that make investment unpalatable, and research and development activity challenging. Particularly, as it intersects with our higher education institutions remaining competitive. Offering the most comprehensive training for work ready students (both domestic and international) and in research and development. Briefly, areas for current consideration from overseas countries regulating AI, include consideration of certain prohibited AI activities, exemptions for internal research and development without prejudice to commercialisation, treatment of open source software, and risk classifications for intersecting educational activities and AI, such as higher risk requirements for use of this AI in admissions and academic assessment8;"},{"id":85,"value":"AI safety research and development, and optimising innovation breadth, needs to be properly and comprehensively supported. The prioritisation of resourcing, coordination of public and private, and increasing the scale of piloting and use, and skills training in niche evaluation assessments of AI, is important. If Australia is to compete on the global stage and drive economic and productivity growth, the Governmentâ€™s continued focus on and increased investment in initiatives to support our digital strategy, and the AI ecosystem in Australia, by supporting the education sector is truly fundamental. Our global counterparts are expanding their investment in AI and capabilities and Australia cannot afford to be left behind. We have set out in the Annexure to this submission some examples of broader principles that we have developed that are education specific to help build consensus on governance frameworks to manage AI safety risks."}]},{"id":57,"order":"57.00000000000000000000","submission_number":"57","Submitter":"QUT","Type of org":{"id":977279,"value":"University","color":"darker-blue"},"Notes":"","Recommendations":[{"id":86,"value":"Evidence informed decision making We want to encourage innovative, safe practice for the use of generative AI in education. There is significant potential for generative AI tools to be used to improve education outcomes, however we currently have no research to support any decisions. Educators need to be supported to be able to make evidence-informed decisions about how generative AI can be used in their practice."}],"Uses-opportunities":[{"id":61,"value":"Ways of learning Interacting with generative AI provides a different, more conversational approach to searching online. It builds on work in searching to learn, supports knowledge creation practices and (if supported appropriately) can support critical thinking and evaluation. It can provide personalised instruction and learning efficiencies; explain concepts in more than one way and in varying detail; and aid just-in-time learning anywhere, anytime"},{"id":63,"value":"Learning to code and program The use of generative AI may be particularly useful as a tool for learning to code and program â€“ and this is already being incorporated into practice in these professions. The Technologies Curriculum that has been implemented since 2016 required many teachers to undertake professional learning in this field and requires students to learn to program in multiple languages by the end of Year 8. Generative AI could be an effective tool to support primary and secondary teachers in their classroom practice."},{"id":66,"value":"Digital and data literacy Generative AI tools (such as Chat GPT or Midjourney) are effective examples to be able to teach data science and computer science concepts and tools such as large language models (LLMs). They are also useful to demonstrate the different meanings of terms, such as risk, and predictions that are used in different ways in different disciplines."},{"id":67,"value":"Support for teaching As in many other fields, there is potential for generative AI tools to do some of the more routine work of educators. This could be for design or planning (such as platforms to create a first draft of a unit design or lesson plan), teaching (through personalised learning models that allow just-in-time interactions with students and the provision of feedback) or assessment (although privacy should be considered)."}],"Risks-challenges":[{"id":76,"value":"Learning practices There is substantial pedagogical value to be found in the significant risk taking involved in learning without generative AI: learners often feel uncertain about a learning situation and it is precisely by overcoming this challenge that they engage and learn. The reliance on generative AI has the potential to reduce opportunities for critical thinking and problemsolving, creativity; it may promote laziness and lack of independent thought; and it may limit the development of deep knowledge. Students may lack the confidence to engage in that first step and take the essential risk on not knowing in order to further understand a topic. In addition, AI responses can be deceptively convincing, leading to an assumption that the response generated is accurate. This therefore required a deliberative approach to learning design to ensure that independent thought, critical thinking and creativity are central to the learning experience"},{"id":77,"value":"Assessment design Changes as a reaction to academic integrity considerations will most probably result in the need for substantial assessment and task redesign. Education systems and individual institutions and processes will need to budget for the time it will take practitioners to do this work. Some of the models of assessment commonly used (for example multiple choice questions) have been adopted because educators need to be able to implement the assessment, generate marks, and provide feedback at scale and in a reasonable timeframe. If generative AI could be used to achieve different types of marking at scale then this provides us with an opportunity to consider other approaches to assessment that may better represent student learning. A risk and challenge in relation to this is that education systems including universities can be slow to change. The policies developed need to be flexible enough to adapt as the technology changes."},{"id":78,"value":"Academic Integrity The immediate reaction by education institutions and sectors has been in relation to academic integrity. This is appropriate, however it should be noted that any tools that claim to be able to automatically detect the use of generative AI in the creation of assessment submissions (e.g. text, images, videos) will need to be continually updated as the tools and accuracy of the underlying model(s) continue to improve. In addition to tools, education policies need to be developed in relation to the acceptable use of generative AI in assessment. Some regulations can be a good thing â€“ even if itâ€™s only to help people understand how to be safe â€“ because people are not always sure what they are and are not allowed to do. Yet, these regulations will need to be dynamic to some extent and be continuously adapted to changing contexts. The use of AI tools can present a risk to academic integrity, similar to contract cheating and other more traditional forms of cheating that some learners may engage in. Educating students in the use of AI, in how it works and in understanding its impact in terms of their learning and integrity is the key way forward. Educators must design assessment that minimises the risk of AI tools supplanting the learner, to ensure that the learner can demonstrate mastery of the learning outcomes. The growth in detection tools is unlikely to completely ensure integrity while introducing risks to the student experience, for example, the risk of false positives that have the potential for serious detrimental impact"},{"id":79,"value":"Ethical data practices There are risks associated with the data that the large language models are using. Whether this data has been acquired ethically is still being challenged, with implications for multiple considerations including privacy, copyright, structural bias, data integrity and cultural safety. Also, using data and models owned by multinationals for education and then giving our studentsâ€™ data to them entails inherent risk. Students should be asked for their consent to share their documents with generative AI. In many journals, they do not allow reviews to be written by generative AI because they do not have the permission of the authors to do that. Ethics and integrity go hand in hand, but teaching students the ethical use of AI will require more than teaching them about academic integrity. Understanding the ethics would involve considering privacy, copyright, bias, misrepresentation and deception. Perhaps the use of AI tools is more about the ethics and understanding the risks than it is about technology."},{"id":80,"value":"Models built on representative data Education needs to ensure that generative AI tools and models that are accessed are built using data that is representative and diverse. For the most part, large language models are built on data that is from English-speaking countries. There needs to be consideration of other languages, the impact that this has on ways of thinking and framing questions. Consideration particularly needs to be given to Indigenous languages and ways of knowing, the privacy of this data, the impact on the responses generated and the potential for assessment and teaching practices to further minimise the experiences and ways of knowing of Aboriginal and Torres Strait Islander peoples. These models are also largely built using data generated from contributions to text available on the internet. This does preference the ways of writing and the opinions of mostly white, male, middle and upper class professionals. Education needs to advocate to ensure that children, students and families experiencing disadvantage have a voice and that their experiences are included in the way that generative AI produces responses"},{"id":81,"value":"Access to generative AI tools Education needs to ensure that the gap that already exists for children, students and families experiencing disadvantage in terms of access to technology does not grow further through the growth and spread of generative AI. There are challenges in terms of access to technology, to reliable internet, and access to data. Any education that builds on the use of generative AI needs to consider support for students who cannot continue the connection with the technology when they leave the schoolhouse. This is particularly relevant considering the nation-wide bans on the use of mobile phones in schools. These bans have significant implications for students experiencing disadvantage to be able to seamlessly transition their learning with technology in and out of school"},{"id":82,"value":"Tools and platforms for the use of generative AI Education also needs to consider the implications of age restrictions on access to generative AI tools, with most primary school students being too young to consent to using the tools."}],"References-footnotes":[],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":86,"database_table_184385":12},"value":{"id":980192,"value":"research-investment","color":"orange"}},{"ids":{"database_table_183319":86,"database_table_184385":21},"value":{"id":980197,"value":"evidence-generation","color":"brown"}}],"Lookup":[{"id":86,"value":"Evidence informed decision making We want to encourage innovative, safe practice for the use of generative AI in education. There is significant potential for generative AI tools to be used to improve education outcomes, however we currently have no research to support any decisions. Educators need to be supported to be able to make evidence-informed decisions about how generative AI can be used in their practice."}]},{"id":58,"order":"58.00000000000000000000","submission_number":"58","Submitter":"Australasian Academic Integrity Network","Type of org":{"id":977281,"value":"Peak body","color":"green"},"Notes":"Students and educators need a more comprehensive understanding of the capabilities, limitations and permissible uses of generative AI. Staff development, including induction and continuing professional development is required for effective integration of generative AI into learning and teaching. Realisation of the benefits of generative AI will also require effective and systematic leadership at sector and institutional levels, regulatory frameworks, and consideration of accessibility for students and staff. \nThe assumption that generative AI will benefit students and educators and improve learning outcomes for students is yet to be supported by clear evidence. Resourcing is needed at all levels across the sector â€“ by regulatory and peak bodies as well as higher education providers â€“ for ongoing monitoring and research into the effectiveness and impact of generative AI in learning, teaching and assessment.","Recommendations":[{"id":62,"value":"That TEQSA, as the national body for regulating and assuring the quality of higher education providers, assumes national leadership in developing standards and frameworks to guide and support the higher education sector in maintaining academic integrity in the context of generative AI. This aligns with TEQSAâ€™s national leadership in the promotion of academic integrity and effective responses to other threats to integrity through its publications, partnerships and professional development activities."},{"id":63,"value":"The House Standing Committee on Employment, Education and Training (the Committee) should consider whether AI tools that explicitly (and as their primary business model) market or provide cheating services are within the purview of the TEQSA Act in relation to the provision of contract cheating services."},{"id":64,"value":"That the Department of Education undertakes a review of the Higher Education Standards Framework (Threshold Standards) 2021 to ensure effective sector-wide responses to the use of generative AI in higher education, in consultation with key stakeholders, including Universities Australia, bodies representing non-university providers and key experts in this field."},{"id":65,"value":"That the Committee considers the significant shift that the integration of generative AI technologies in education represents for educators and makes recommendations regarding the need to invest in this workforce transformation. In particular, the Committee should recommend investment by government and the higher education sector in the reconceptualization of teaching, learning and assessment to leverage the benefits of generative AI and address the risk posed to assessment integrity and potential data security and privacy issues. Options for developing resources, guidelines and training for educators at a national level need to be considered."},{"id":66,"value":"That the Committee recommends a national agenda for ongoing research and collaboration and educational initiatives that seek to maximise the benefits of generative AI across different disciplines, address risks, evaluate the impact of generative AI on learning, and support development of AI literacy among staff and students."},{"id":67,"value":"That the Committee recommends future initiatives, programs and projects addressing the use of generative AI in the education sector incorporate consultation with academics and researchers from a range of discipline areas, as well as key stakeholders outside the education sector, especially professional associations, accreditation bodies, registration bodies and employers."},{"id":68,"value":"That the Committeeâ€™s findings and recommendations provide the basis for a coherent and cohesive national approach to the use of generative AI that covers all levels and types of education providers, from primary school through to the higher education sector."},{"id":71,"value":"That the Committee makes recommendations to higher education providers on the curation and sharing of best practice, including case studies and exemplars to build capability and awareness of ways to engage with generative AI."},{"id":72,"value":"That the Committee makes specific recommendations addressing current and anticipated intellectual property issues related to the use of generative AI by students and staff, which includes issues under relevant Australian and international laws and intellectual property agreements."},{"id":73,"value":"That any development of generative AI standards in Australia include reference to Indigenous Cultural and Intelletual Property (ICIP) and Indigenous Data Sovereignty (IDS) and that risks that Indigenous knowledges and intellectual property will be incorporated into generative AI and used without appropriate attribution or acknowledgement are minimised."},{"id":74,"value":"That the Committee highlights the need for a diverse range of interested parties and stakeholders to be included in future decisions and actions related to the use of generative AI, in particular the perspectives of those who may be underrepresented in government and education decision-making bodies, including students, people from Aboriginal and Torres Strait Islander and culturally and linguistically diverse backgrounds, those experiencing social and economic disadvantage, and people with disabilities."},{"id":75,"value":"That the Committee considers equity of access to generative AI and the ways that institutional policies and resource allocation for AI will impact on student capabilities, opportunities and outcomes."},{"id":76,"value":"That the Committee provide recommendations to higher education providers regarding licensing agreements for relevant generative AI tools to ensure ready access for students and staff."},{"id":77,"value":"That the Committee consider any inequities in access to basic infrastructure in Australia including access to and costs associated with internet and mobile telephony services, and how these will impact any recommendations for the use of generative AI in education, including levels of government investment required."},{"id":78,"value":"The Parliamentary Inquiry recommend the use of the current HEPPP (Higher Education Participation and Partnerships Program) to address the needs of students experiencing social disadvantage in relation to digital skills and digital access to generative AI tools."},{"id":79,"value":"That the Committee make recommendations on national regulation of the use of generative AI in the Australian context, where its use in education is just one aspect of its broader use in Australian society."},{"id":80,"value":"That the Committee recognise that evolution of generative AI in the education system is in its early stages, with AI developing at an exponentially rapid rate, and guide the formulation of a strategic vision for Australiaâ€™s management, regulation and effective use of generative AI in this rapidly changing environment."},{"id":82,"value":"That Australia follow international leads to consider national regulation on the use of generative AI."},{"id":83,"value":"That any national recommendations on generative AI in higher education be developed after broad consultation with key stakeholders, including accreditation and registration bodies given their role in curriculum, assessment and assurance of learning."}],"Uses-opportunities":[{"id":50,"value":"â–ª Development of cognitive skills, critical thinking, and information literacy"},{"id":51,"value":"â–ª Increased digital and AI literacy and experience in the use of generative AI tools to enhance employability"},{"id":53,"value":"â–ª Tailored, adaptable, personalised learning experience and feedback based on individual needs"},{"id":54,"value":"â–ª Better access to feedback on learning"},{"id":55,"value":"â–ª 24/7 access to educational resources and personalised tutoring e.g. summaries to simplify complex concepts in documents and key texts and practice assessment questions"},{"id":56,"value":"â–ª Assistive technology to enhance equity for students with diverse learning needs."},{"id":57,"value":"â–ª Tools to promote higher order learning"},{"id":58,"value":"â–ª Efficiencies in curriculum and learning design including design of rubrics, formative and multimodal assessment tasks, exemplars and generation of practice assessment questions"},{"id":60,"value":"â–ª Tools to support learning design for equity, access and student engagement, and the design of interactive and engaging learning activities"},{"id":62,"value":"â–ª Improved capacity to analyse student performance and support for the provision of detailed and tailored feedback"},{"id":64,"value":"â–ª Assistance with everyday writing tasks and organisation of learning materials"},{"id":65,"value":"â–ª Professional development opportunities including digital and AI literacy."}],"Risks-challenges":[{"id":47,"value":"Educators will need to review what is assessed, whether knowledge or the process of learning is assessed, and revise learning outcomes. This will require further review of the ways in which knowledge is assessed in different disciplines. A broader implication is that the higher education sector will need to collectively rethink the nature and purposes of assessment."},{"id":48,"value":"Expectations of acceptable use and forms of knowledge production vary across disciplines. Staff in teaching and assessment roles may also have different expectations."},{"id":49,"value":"Levels of understanding, knowledge and skills related to the use of generative AI vary among staff and students and across cohorts. Threshold standards of AI literacy are recommended for higher education staff and students."},{"id":50,"value":"Generative AI may promote a shift towards oral assessments or other forms of assessment with administrative and practical resourcing implications. These forms of assessment may also be less appropriate to meet diverse learning needs."},{"id":51,"value":"Generative AI may have a negative impact on the development of writing and academic skills, knowledge acquisition and application and critical thinking. The widespread use of AI tools could influence the development of social and interpersonal skills and lead to dependence on generative AI to solve complex problems without considerations of the potential limitations of or risks associated with generated content. Generative AI also has potential implications for student civic development and democratic engagement, given the process of generating material through generative AI without broader personal or professional engagement, and the potential of AI generated material to reinforce biases and stereotypes."},{"id":52,"value":"Institutional guidelines are needed to protect the privacy of student data and their intellectual property."},{"id":53,"value":"Generative AI has potential to contribute to work insecurity and reductions in the education workforce."},{"id":54,"value":"Provision of clear and consistent standards for using generative AI, guidelines for acceptable and unacceptable use and development of AI literacy are key challenges for higher education providers."},{"id":55,"value":"The need for institutional academic integrity policies and documentation to provide clear guidance to students and staff in the appropriate and inappropriate use of generative AI is increasingly evident. The AAIN publication released in March 2023 provides initial guidelines. The AAIN publication released in May 2023 summarises institutional responses to the use of"},{"id":56,"value":"generative AI and provides examples of good practice."},{"id":57,"value":"Strategies and resourcing are needed to address significant risks of misuse and falsification by students claiming the outputs of generative AI as their original work. The capacity of the sector to identify inappropriate use of generative AI is currently limited, particularly given the emergent nature and widespread accessibility of generative AI tools and large size of many higher education classes. While a number of companies have software that is designed to detect work generated by AI, these tools are still in early stages of development. Where they are used, they may not provide educators and institutions with robust evidence of breaches of academic integrity. Many universities have made the decision not to use detection tools until they are more mature."},{"id":58,"value":"Inappropriate use of generative AI in assessment tasks may pose risks to the reputations of individual students, institutions, and the sector. Studentsâ€™ professional careers may be at risk."},{"id":59,"value":"Risks of factual inaccuracies and biases in AI-generated work including the tendency for"},{"id":60,"value":"generative AI to produce plausible but incorrect responses, and its inability to join discrete concepts in ways that appear to be logical may have an impact on student learning or conceptions of knowledge in different fields of study. Outputs from generative AI tools may reinforce bias, prejudice, and misinformation as â€˜truthâ€™. Detecting inaccuracies may be difficult due to systems, processes, and limitations of existing software."},{"id":61,"value":"Biases within generative AI models may produce factual inaccuracies about Indigenous peoples, cultural practices and equivalent issues affecting other cultural groups."},{"id":62,"value":"Any development of generative AI standards in Australia should include reference to Indigenous Cultural and Intellectual Property (ICIP) as well as Indigenous Data Sovereignty (IDS). Risks that Indigenous knowledges and intellectual property will be incorporated into generative AI and used without appropriate attribution or acknowledgement should be minimised. The sector standard for ICIP is Terri Janke's True Tracks and for IDS, Maiam Nayri Wingara"},{"id":63,"value":"Standards for the safe and secure use of generative AI tools in relation to intellectual property, and the potential for data and privacy breaches including online data tracking have not yet been established. Likewise consistent standards for the storage of personal data and interactions with generative AI have not yet been established."},{"id":64,"value":"Generative AI tools create potential risks for transnational exposure of data which may have future implications for data regulation."},{"id":65,"value":"The use of generative AI to produce artifacts that appear to meet learning outcomes or provide evidence of knowledge and skills has potential to undermine the reputation of higher education. A lack of public confidence in the development of knowledge and skills and assurance of learning could undermine the value of qualifications."},{"id":66,"value":"Many staff and students lack a detailed understanding of how generative AI models operate. This includes understanding the centrality of â€˜temperatureâ€™ in generative AI models. Temperature determines the plausibility of responses produced by generative AI from the knowledge it has stored from different devices and information sources, and how this knowledge frames the plausibility of its outputs on a scale between factual information and creativity. Each generative AI tool has a particular â€˜temperatureâ€™ between 0 and 1, which for Chat GPT is reported to be 0.7, indicating a level of â€˜creativityâ€™ in its outputs."},{"id":67,"value":"The use of generative AI in institutional systems and processes may create redundancies, and a divided workforce in relation to new skills and literacies."},{"id":68,"value":"Higher education providers may not yet have established clear privacy and permissions guidelines relating to the use of generative AI tools in higher education contexts, for example in relation to the submission of student information or work into generative AI tools. Standards and/or guidelines are needed for the use of student work and sensitive information."},{"id":69,"value":"Guidelines and processes to support academic and research integrity may need to be more closely integrated in response to generative AI, especially in terms of what constitutes appropriate and ethical practice in sourcing and acknowledging information."},{"id":70,"value":"Access to generative AI tools depends on studentsâ€™ financial circumstances which may limit access to hardware and software requirements, education and training programs. Although free access to some generative AI tools may have some impact on democratisation, students from lower-income backgrounds may still face challenges in accessing these technologies. This may lead to a two-tier system, potentially increasing inequities among students. Inclusive approaches to teaching and support and equitable access for all students is key. The HEPPP (Higher Education Participation and Partnerships Program) provides a potential framework to address the disadvantage in relation to digital and AI literacy and digital access As generative AI tools mature and set subscription or purchase costs, higher education providers may need to purchase institutional licences to provide access to students and staff, in the same way that access is currently provided to generalist software, such as the Microsoft Office suite, and specialist software such as statistical analysis, modelling software, CAD software, and software for creative arts such as music production. The potential costs and scale of regular use of generative AI tools in the future is unknown and a consideration for providers and the sector more broadly."}],"References-footnotes":[{"id":29,"value":"https://academicintegrity.edu.au/"},{"id":30,"value":"https://academicintegrity.edu.au/wp-content/uploads/sites/290/2023/06/AAIN-Generative-AI-Guidelines.pdf"},{"id":31,"value":"https://wordpress-ms.deakin.edu.au/academicintegrity/wp-content/uploads/sites/290/2023/06/AAIN-Institutional-Responses-to-the-use-of-Generative-Artificial-Intelligence-V1.1.pdf"},{"id":34,"value":"https://www.terrijanke.com.au/icip"},{"id":35,"value":"https://www.maiamnayriwingara.org/"},{"id":36,"value":"https://www.education.gov.au/heppp"},{"id":37,"value":"https://legalinstruments.oecd.org/en/instruments/OECD-LEGAL-0449"},{"id":39,"value":"https://www.oecd-ilibrary.org/science-and-technology/oecd-framework-for-the-classification-of-ai-systems_cb6d9eca-en"},{"id":40,"value":"https://www.oecd-ilibrary.org/science-and-technology/ai-language-models_13d38f92-en"},{"id":41,"value":"https://www.montrealdeclaration-responsibleai.com/the-declaration"},{"id":42,"value":"https://apo.org.au/node/322938"},{"id":45,"value":"https://www.industry.gov.au/publications/australias-artificial-intelligence-ethics-framework"},{"id":46,"value":"https://www.arc.gov.au/sites/default/files/2023-07/Policy%20on%20Use%20of%20Generative%20Artificial%20Intelligence%20in%20the%20ARCs%20grants%20programs%202023.pdf"},{"id":48,"value":"https://www.europarl.europa.eu/RegData/etudes/BRIE/2021/698792/EPRS_BRI(2021)698792_EN.pdf"},{"id":49,"value":"https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/1020402/National_AI_Strategy_-_PDF_version.pdf"},{"id":50,"value":"https://www.nist.gov/itl/ai-risk-management-framework"},{"id":51,"value":"https://www.nsf.gov/cise/national-ai.jsp"},{"id":52,"value":"https://www.nsf.gov/cise/national-ai.jsp"},{"id":53,"value":"https://www.whitehouse.gov/ostp/ai-bill-of-rights/"},{"id":54,"value":"https://www.legislation.gov.au/Details/F2022C00105"},{"id":55,"value":"https://www.teqsa.gov.au/guides-resources/resources/guidance-notes"},{"id":56,"value":"https://www.asqa.gov.au/guidance-resources/resources-providers/guidance-providers"},{"id":58,"value":"https://www.qilt.edu.au/"},{"id":59,"value":"https://www.teqsa.gov.au/guides-resources/higher-education-good-practice-hub/artificial-intelligence"},{"id":60,"value":"https://www.teqsa.gov.au/guides-resources/resources/guidance-notes/guidance-note-academic-integrity"},{"id":61,"value":"https://www.teqsa.gov.au/guides-resources/resources/guidance-notes/guidance-note-academic-quality-assurance"},{"id":62,"value":"https://www.teqsa.gov.au/guides-resources/resources/guidance-notes/guidance-note-admissions-coursework"},{"id":63,"value":"https://www.teqsa.gov.au/guides-resources/resources/guidance-notes/guidance-note-course-design-including-learning-outcomes-and-assessment"},{"id":64,"value":"https://www.teqsa.gov.au/guides-resources/resources/guidance-notes/guidance-note-research-and-research-training"},{"id":65,"value":"https://www.teqsa.gov.au/guides-resources/resources/guidance-notes/guidance-note-technology-enhanced-learning"},{"id":67,"value":"https://www.qaa.ac.uk/docs/qaa/members/maintaining-quality-and-standards-in-the-chatgpt-era.pdf?sfvrsn=2408aa81_10"},{"id":68,"value":"https://www.qaa.ac.uk/docs/qaa/members/the-rise-of-artificial-intelligence-software-and-potential-risks-for-academic-integrity.pdf?sfvrsn=ebb0a981_6"},{"id":71,"value":"https://www.solaresearch.org/"},{"id":76,"value":"https://publications.ascilite.org/index.php/APUB/article/view/401/378"},{"id":77,"value":"https://apo.org.au/node/322951"},{"id":80,"value":"https://apo.org.au/node/322937"},{"id":81,"value":"https://www.advance-he.ac.uk/news-and-views/higher-education-era-ai"},{"id":82,"value":"https://publicationethics.org/news/artificial-intelligence-and-authorship"},{"id":83,"value":"https://edintegrity.biomedcentral.com/articles/10.1007/s40979-023-00133-4"},{"id":85,"value":"https://nationalcentreforai.jiscinvolve.org/wp/2023/05/11/generative-ai-primer/\" \\l \"1"},{"id":86,"value":"https://aiindex.stanford.edu/report/"},{"id":88,"value":"https://tech.ed.gov/ai-future-of-teaching-and-learning/"},{"id":89,"value":"https://www.uts.edu.au/about/uts-governance/policies/uts-policy/artificial-intelligence-operations-policy"},{"id":90,"value":"https://www.uts.edu.au/about/uts-governance/policies/uts-policy/artificial-intelligence-operations-procedure"},{"id":91,"value":"https://communitystandards.stanford.edu/generative-ai-policy-guidance"},{"id":92,"value":"https://teaching.weblogs.anu.edu.au/2023/02/17/chatgpt-what-anu-academics-need-to-know/"},{"id":93,"value":"https://policy.federation.edu.au/learning_and_teaching/compliance/academic_integrity/ch01.php?_ga=2.255008459.2139483057.1679887035-66963753.1678850572"},{"id":94,"value":"https://www.monash.edu/learning-teaching/teachhq/Teaching-practices/artificial-intelligence"},{"id":95,"value":"https://melbourne-cshe.unimelb.edu.au/__data/assets/pdf_file/0008/4533218/ChatGPT-and-Academic-Integrity.pdf"},{"id":96,"value":"https://www.teaching.unsw.edu.au/chatgpt-ai-in-teaching"},{"id":97,"value":"https://educational-innovation.sydney.edu.au/teaching%40sydney/how-ai-can-be-used-meaningfully-by-teachers-and-students-in-2023/"},{"id":98,"value":"https://educational-innovation.sydney.edu.au/teaching%40sydney/how-ai-can-be-used-meaningfully-by-teachers-and-students-in-2023/"},{"id":99,"value":"https://policy.deakin.edu.au/document/view-current.php?id=107"},{"id":100,"value":"https://ecu.au.libguides.com/referencing/reference-examples\" \\l \"ai-tools"},{"id":102,"value":"https://policies.latrobe.edu.au/download.php?id=221&version=2"},{"id":103,"value":"https://www.monash.edu/policy-bank/search?query=generative%2B"},{"id":104,"value":"https://murdoch.navexone.com/content/dotNet/documents/?docid=2987&public=true"},{"id":106,"value":"https://i.unisa.edu.au/siteassets/policies-and-procedures/docs/academic/ab-69-academic-integrity-policy.pdf"},{"id":107,"value":"https://aus01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fwww.uwa.edu.au%2Fpolicy%2F-%2Fmedia%2FProject%2FUWA%2FUWA%2FPolicy-Library%2FPolicy%2FStudent-Administration%2FAcademic-Integrity%2FAcademic-Integrity-Policy.doc&data=05%7C01%7Cbernie.marshall%40deakin.edu.au%7C24d9d98b61604fb0653308db462c3d64%7Cd02378ec168846d585401c28b5f470f6%7C0%7C0%7C638180928187242951%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C3000%7C%7C%7C&sdata=SWNtz9UVdLos8W6Ro3E3POJT%2FgKedAT1KBna7TWONBA%3D&reserved=0"},{"id":108,"value":"https://policies.westernsydney.edu.au/view.current.php?id=00304"},{"id":109,"value":"https://www.cdu.edu.au/current-students/student-code-conduct/academic-integrity"},{"id":111,"value":"https://www.adelaide.edu.au/student/academic-skills/academic-integrity-for-students"},{"id":112,"value":"https://www.curtin.edu.au/students/essentials/rights/academic-integrity/"},{"id":113,"value":"https://ecu.au.libguides.com/information-essentials/generative-ai"},{"id":114,"value":"https://library.flinders.edu.au/students/ai"},{"id":115,"value":"https://www.jcu.edu.au/students/learningcentre/academic-integrity/using-artificial-intelligence"},{"id":116,"value":"https://students.mq.edu.au/study/assessment-exams/academic-integrity/ai-tools"},{"id":117,"value":"https://www.rmit.edu.au/students/my-course/assessment-results/academic-integrity"},{"id":118,"value":"https://web.library.uq.edu.au/research-tools-techniques/digital-essentials/artificial-intelligence"},{"id":120,"value":"https://libguides.acu.edu.au/referencing/artificial-intelligence-tools"},{"id":122,"value":"https://libguides.adelaide.edu.au/artificial_intel"},{"id":123,"value":"https://deakin.libguides.com/generative-AI/homepage"},{"id":124,"value":"https://federation.edu.au/library/study/fedcite/content/ieee/artificial-intelligence-tools2/artificial-intelligence-tools"},{"id":125,"value":"https://search.griffith.edu.au/s/search.html?collection=on-campus-search&form=simple&query=chatgpt"},{"id":126,"value":"https://latrobe.libguides.com/c.php?g=929104&p=6959520"},{"id":128,"value":"https://www.citewrite.qut.edu.au/cite/qutcite.html\" \\l \"apa-internet-ai"},{"id":129,"value":"https://guides.library.uwa.edu.au/strategicpublishing/draftpapercheck"},{"id":130,"value":"https://www.vu.edu.au/library/get-help/library-guides-course-resources"},{"id":133,"value":"https://cte.utah.edu/instructor-education/ai-generative-tools.php"},{"id":134,"value":"https://www.montclair.edu/faculty-excellence/teaching-resources/clear-course-design/practical-responses-to-chat-gpt/"},{"id":135,"value":"https://teaching.washington.edu/topics/preparing-to-teach/academic-integrity/chatgpt/"},{"id":137,"value":"https://www.bu.edu/cds-faculty/culture-community/conduct/gaia-policy/"},{"id":138,"value":"https://www.york.ac.uk/students/studying/assessment-and-examination/ai/"},{"id":139,"value":"https://www.education.gov.au/heppp"},{"id":140,"value":"https://doi.org/10.1007/s40979-023-00133-4"},{"id":141,"value":"https://doi.org/10.1038/s42256-019-0088-2"},{"id":142,"value":"https://doi.org/10.1145/3313831.3376727"},{"id":143,"value":"https://doi.org/10.1787/b5fd1b8f-en"},{"id":144,"value":"https://pursuit.unimelb.edu.au/articles/university-students-are-using-ai-but-not-how-you-think"},{"id":145,"value":"https://doi.org/10.1287/isre.2023.ed.v34.n2"},{"id":146,"value":"https://www.bcs.org/articles-opinion-and-research/ai-versus-ip-how-could-generative-artificial-intelligence-impact-intellectual-ownership/"},{"id":148,"value":"https://www.whitehouse.gov/ostp/ai-bill-of-rights/"}],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":62,"database_table_184385":2},"value":{"id":980180,"value":"guidelines","color":"light-yellow"}},{"ids":{"database_table_183319":72,"database_table_184385":3},"value":{"id":980182,"value":"situate-with-existing-policy","color":"darker-red"}},{"ids":{"database_table_183319":83,"database_table_184385":3},"value":{"id":980182,"value":"situate-with-existing-policy","color":"darker-red"}},{"ids":{"database_table_183319":64,"database_table_184385":7},"value":{"id":980187,"value":"stakeholder-engagement","color":"dark-green"}},{"ids":{"database_table_183319":67,"database_table_184385":7},"value":{"id":980187,"value":"stakeholder-engagement","color":"dark-green"}},{"ids":{"database_table_183319":74,"database_table_184385":7},"value":{"id":980187,"value":"stakeholder-engagement","color":"dark-green"}},{"ids":{"database_table_183319":83,"database_table_184385":7},"value":{"id":980187,"value":"stakeholder-engagement","color":"dark-green"}},{"ids":{"database_table_183319":64,"database_table_184385":10},"value":{"id":980190,"value":"curricula-changes","color":"light-green"}},{"ids":{"database_table_183319":63,"database_table_184385":11},"value":{"id":980191,"value":"new-policy","color":"dark-purple"}},{"ids":{"database_table_183319":68,"database_table_184385":11},"value":{"id":980191,"value":"new-policy","color":"dark-purple"}},{"ids":{"database_table_183319":79,"database_table_184385":11},"value":{"id":980191,"value":"new-policy","color":"dark-purple"}},{"ids":{"database_table_183319":66,"database_table_184385":12},"value":{"id":980192,"value":"research-investment","color":"orange"}},{"ids":{"database_table_183319":71,"database_table_184385":16},"value":{"id":980194,"value":"communications","color":"darker-brown"}},{"ids":{"database_table_183319":65,"database_table_184385":17},"value":{"id":980195,"value":"resourcing","color":"dark-cyan"}},{"ids":{"database_table_183319":75,"database_table_184385":17},"value":{"id":980195,"value":"resourcing","color":"dark-cyan"}},{"ids":{"database_table_183319":76,"database_table_184385":17},"value":{"id":980195,"value":"resourcing","color":"dark-cyan"}},{"ids":{"database_table_183319":77,"database_table_184385":17},"value":{"id":980195,"value":"resourcing","color":"dark-cyan"}},{"ids":{"database_table_183319":78,"database_table_184385":17},"value":{"id":980195,"value":"resourcing","color":"dark-cyan"}},{"ids":{"database_table_183319":71,"database_table_184385":19},"value":{"id":980186,"value":"capacity-building","color":"light-yellow"}},{"ids":{"database_table_183319":80,"database_table_184385":20},"value":{"id":980179,"value":"ongoing-and-global-monitoring","color":"dark-brown"}},{"ids":{"database_table_183319":82,"database_table_184385":20},"value":{"id":980179,"value":"ongoing-and-global-monitoring","color":"dark-brown"}},{"ids":{"database_table_183319":74,"database_table_184385":22},"value":{"id":980198,"value":"marginalised-group-engagement","color":"light-pink"}},{"ids":{"database_table_183319":73,"database_table_184385":37},"value":{"id":980209,"value":"Indigenous-ICIP-IDIP","color":"dark-orange"}}],"Lookup":[{"id":62,"value":"That TEQSA, as the national body for regulating and assuring the quality of higher education providers, assumes national leadership in developing standards and frameworks to guide and support the higher education sector in maintaining academic integrity in the context of generative AI. This aligns with TEQSAâ€™s national leadership in the promotion of academic integrity and effective responses to other threats to integrity through its publications, partnerships and professional development activities."},{"id":63,"value":"The House Standing Committee on Employment, Education and Training (the Committee) should consider whether AI tools that explicitly (and as their primary business model) market or provide cheating services are within the purview of the TEQSA Act in relation to the provision of contract cheating services."},{"id":64,"value":"That the Department of Education undertakes a review of the Higher Education Standards Framework (Threshold Standards) 2021 to ensure effective sector-wide responses to the use of generative AI in higher education, in consultation with key stakeholders, including Universities Australia, bodies representing non-university providers and key experts in this field."},{"id":65,"value":"That the Committee considers the significant shift that the integration of generative AI technologies in education represents for educators and makes recommendations regarding the need to invest in this workforce transformation. In particular, the Committee should recommend investment by government and the higher education sector in the reconceptualization of teaching, learning and assessment to leverage the benefits of generative AI and address the risk posed to assessment integrity and potential data security and privacy issues. Options for developing resources, guidelines and training for educators at a national level need to be considered."},{"id":66,"value":"That the Committee recommends a national agenda for ongoing research and collaboration and educational initiatives that seek to maximise the benefits of generative AI across different disciplines, address risks, evaluate the impact of generative AI on learning, and support development of AI literacy among staff and students."},{"id":67,"value":"That the Committee recommends future initiatives, programs and projects addressing the use of generative AI in the education sector incorporate consultation with academics and researchers from a range of discipline areas, as well as key stakeholders outside the education sector, especially professional associations, accreditation bodies, registration bodies and employers."},{"id":68,"value":"That the Committeeâ€™s findings and recommendations provide the basis for a coherent and cohesive national approach to the use of generative AI that covers all levels and types of education providers, from primary school through to the higher education sector."},{"id":71,"value":"That the Committee makes recommendations to higher education providers on the curation and sharing of best practice, including case studies and exemplars to build capability and awareness of ways to engage with generative AI."},{"id":72,"value":"That the Committee makes specific recommendations addressing current and anticipated intellectual property issues related to the use of generative AI by students and staff, which includes issues under relevant Australian and international laws and intellectual property agreements."},{"id":73,"value":"That any development of generative AI standards in Australia include reference to Indigenous Cultural and Intelletual Property (ICIP) and Indigenous Data Sovereignty (IDS) and that risks that Indigenous knowledges and intellectual property will be incorporated into generative AI and used without appropriate attribution or acknowledgement are minimised."},{"id":74,"value":"That the Committee highlights the need for a diverse range of interested parties and stakeholders to be included in future decisions and actions related to the use of generative AI, in particular the perspectives of those who may be underrepresented in government and education decision-making bodies, including students, people from Aboriginal and Torres Strait Islander and culturally and linguistically diverse backgrounds, those experiencing social and economic disadvantage, and people with disabilities."},{"id":75,"value":"That the Committee considers equity of access to generative AI and the ways that institutional policies and resource allocation for AI will impact on student capabilities, opportunities and outcomes."},{"id":76,"value":"That the Committee provide recommendations to higher education providers regarding licensing agreements for relevant generative AI tools to ensure ready access for students and staff."},{"id":77,"value":"That the Committee consider any inequities in access to basic infrastructure in Australia including access to and costs associated with internet and mobile telephony services, and how these will impact any recommendations for the use of generative AI in education, including levels of government investment required."},{"id":78,"value":"The Parliamentary Inquiry recommend the use of the current HEPPP (Higher Education Participation and Partnerships Program) to address the needs of students experiencing social disadvantage in relation to digital skills and digital access to generative AI tools."},{"id":79,"value":"That the Committee make recommendations on national regulation of the use of generative AI in the Australian context, where its use in education is just one aspect of its broader use in Australian society."},{"id":80,"value":"That the Committee recognise that evolution of generative AI in the education system is in its early stages, with AI developing at an exponentially rapid rate, and guide the formulation of a strategic vision for Australiaâ€™s management, regulation and effective use of generative AI in this rapidly changing environment."},{"id":82,"value":"That Australia follow international leads to consider national regulation on the use of generative AI."},{"id":83,"value":"That any national recommendations on generative AI in higher education be developed after broad consultation with key stakeholders, including accreditation and registration bodies given their role in curriculum, assessment and assurance of learning."}]},{"id":59,"order":"59.00000000000000000000","submission_number":"59","Submitter":"OECD","Type of org":{"id":977850,"value":"inter-govt-org","color":"dark-brown"},"Notes":"Links to a set of OECD projects (hyperlinks appear to have been removed at some point), no direct reference to opportunities/risks/recommendations. Key note: \"evidence-based answers to the Committeesâ€™ questions on best practices for implementation, evaluation of outcomes, and specific lessons of AI use for the Australian context are beyond our current understanding of what AI can and cannot do\"","Recommendations":[],"Uses-opportunities":[],"Risks-challenges":[],"References-footnotes":[],"Processed":true,"Recco_tags":[],"Lookup":[]},{"id":60,"order":"60.00000000000000000000","submission_number":"60","Submitter":"Australasian Council on Open, Distance and eLearning","Type of org":{"id":977283,"value":"HE-network","color":"dark-green"},"Notes":"To fully present ACODEs expertise within the Australasian context, the Council ran an open survey for their institutional representatives in late June 2023, of which 34 Universities responded. This represents three quarters of all Australian Universities. ACODE also hosted a small focus group of its members at their business meeting, held on the 14 July.","Recommendations":[{"id":58,"value":"1. a more coherent approach be adopted to the dissemination of information relating to the impacts of Generative Al on Academic Integrity from bodies such as TEQSA and the Federal Department of Education."},{"id":59,"value":"2. an allocation of dedicated workload commensurate to the need for Additional professional development to support academic staff understand the options that may be available to them to accommodate generative Al in their units/courses, particularly in relation to assessment. This is particularly critical for staff on sessional contracts. Thus, consideration should be given to one off grants for institutions to support their staff in this way."},{"id":60,"value":"3. TEQSA and ASQA, or the Department of Education, monitor the different impacts of Generative Al on specific groups of students, such as, First Nations, International and those with a disability."},{"id":61,"value":"4. the Department of Education or Universities Australia establish an information hub for the sector, to coordinate relevant information for staff and students and that pathways be developed that coherently supports and extend this information."}],"Uses-opportunities":[],"Risks-challenges":[],"References-footnotes":[{"id":28,"value":"https://www.tegsa.gov.au/guides-resources/higher-education-good-practicehub/artificial-intelligence"}],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":58,"database_table_184385":16},"value":{"id":980194,"value":"communications","color":"darker-brown"}},{"ids":{"database_table_183319":61,"database_table_184385":16},"value":{"id":980194,"value":"communications","color":"darker-brown"}},{"ids":{"database_table_183319":59,"database_table_184385":17},"value":{"id":980195,"value":"resourcing","color":"dark-cyan"}},{"ids":{"database_table_183319":60,"database_table_184385":25},"value":{"id":980202,"value":"monitoring-impacts","color":"darker-red"}}],"Lookup":[{"id":58,"value":"1. a more coherent approach be adopted to the dissemination of information relating to the impacts of Generative Al on Academic Integrity from bodies such as TEQSA and the Federal Department of Education."},{"id":59,"value":"2. an allocation of dedicated workload commensurate to the need for Additional professional development to support academic staff understand the options that may be available to them to accommodate generative Al in their units/courses, particularly in relation to assessment. This is particularly critical for staff on sessional contracts. Thus, consideration should be given to one off grants for institutions to support their staff in this way."},{"id":60,"value":"3. TEQSA and ASQA, or the Department of Education, monitor the different impacts of Generative Al on specific groups of students, such as, First Nations, International and those with a disability."},{"id":61,"value":"4. the Department of Education or Universities Australia establish an information hub for the sector, to coordinate relevant information for staff and students and that pathways be developed that coherently supports and extend this information."}]},{"id":61,"order":"61.00000000000000000000","submission_number":"61","Submitter":"Australian Technology Network of Universities (ATN)","Type of org":{"id":977283,"value":"HE-network","color":"dark-green"},"Notes":"Listed as risks, but seems to be a recommendation? \nThere are a number of strategies and practices to maximise the beneficial impact of generative AI\nand mitigate the risks and challenges:\no Exploration and guidance that promotes educative and collaborative engagement with\ngenerative AI\no Recognition of the limitations and appropriate and responsible use of tools\no Consideration of ethical issues for general practice as well as exceptions, particularly when\nvulnerable cohorts are involved and the risk and potential impact of bias is high\no Clear and ongoing narrative and discourse throughout the education sectors to guide and\nmaintain awareness of ongoing practice, expectations, conduct\no Integration of AI knowledge and skills into current education qualifications, professional\nlearning, and microcredentials offered by the sector â€“ this requires direction from key\nregulatory and governance bodies for higher education and vocational education as well\n(e.g. TEQSA and ASQA to inform consistent capability development in educators)\no Development of case studies and showcases of exemplary practice to guide appropriate\nengagement and inspire innovative practice.","Recommendations":[{"id":47,"value":"â€¢  This technology must be incorporated into education, much like the use of computers and software were originally taught as a specific class in secondary schools and then was incorporated as a basic technical skill"},{"id":49,"value":"â€¢  This exposure and digital literacy in technology must begin in secondary study and be appropriately scaffolded into tertiary study, establishing a strong foundational familiarity with tools prior to more sophisticated application in a higher education setting."},{"id":50,"value":"â€¢  Short courses (both in higher education and vocational education) in generative AI may help formalise a sufficiently structured curriculum that addresses both technical competency as well as anchoring it in ethical use, critical thinking, evaluation and scenarios for use."},{"id":52,"value":"â€¢  It is essential that generative AI is implemented and integrated across all fields of study to ensure that all students have the opportunity to build familiarity. This will ensure ethical and critical engagement with the appropriate use of such technologies in society, and preparing future workforce and cultural leadership in policy and government."},{"id":53,"value":"â€¢  Standards for generative AI use in education contexts should be considered, but also take into account the rapidly changing environment and technology. Standards should not limit and constrain institutionsâ€™ need for agility and flexibility in their responses. Standards could relate to the specific types of generative AI that are acceptable â€“ these standards could include consideration of data management, privacy, security, as well as broader terms of service, contracts (for paid tools)."},{"id":55,"value":"â€¢  The rapid development of generative AI and proliferation of companies will also prompt a range of new â€˜edtechâ€™ products and services that could create a financial pressure for educational institutions as they attempt to ensure appropriate equity and inclusion for cohorts."}],"Uses-opportunities":[{"id":6,"value":"For students the use of generative AI will be a key digital skill in all areas of work and life, so it will be essential for them to have thorough experience and awareness of the benefits, risks and appropriate and responsible use of generative AI"},{"id":7,"value":"Generative AI also has the potential to provide personalised and adaptive assistance to students. o If equity of access is ensured it could reduce the disparity between those students who have access to tutors or additional services as part of their education study. o Personalised learning has not been easily accessible for various reasons, either due to intensive labour and costs to setup suitable systems, or due to costs involved in obtaining support services either through personal or institutional provision."},{"id":8,"value":"Under the appropriate frameworks and guidelines, educators may benefit from the streamlining of automatable tasks allowing them to focus their time and energy on interacting with students. o The administrative aspects of educatorsâ€™ roles has increased over the years as well as a focus on data and evaluation metrics for teaching practice. o Generative AI has the potential to support a significant portion of educatorsâ€™ work, such as grading and feedback, generating of content or support in resource creation. o This could disrupt existing educational publishing business models and reduce costs for educators, institutions, and students."},{"id":9,"value":"With the introduction of generative AI there will be greater potential for educational providers to customise personal learning assistants with specific curated data and materials that can then support students. o This may also reduce reliance on international or more generalist educational technology services, and can facilitate more tailored curation that aligns with Australian context. This could mean institutional strategies that truly reflect the needs and interests of students in choosing to study. o On the other hand, generative AI is based on a corpus of texts drawn from primarily English language, United States-based sources so care is needed when relying on generated material"}],"Risks-challenges":[],"References-footnotes":[],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":50,"database_table_184385":1},"value":{"id":980196,"value":"PD","color":"light-red"}},{"ids":{"database_table_183319":53,"database_table_184385":4},"value":{"id":980183,"value":"local-responses-and-autonomy","color":"dark-cyan"}},{"ids":{"database_table_183319":47,"database_table_184385":14},"value":{"id":980193,"value":"prepare-learners","color":"dark-gray"}},{"ids":{"database_table_183319":49,"database_table_184385":14},"value":{"id":980193,"value":"prepare-learners","color":"dark-gray"}},{"ids":{"database_table_183319":52,"database_table_184385":14},"value":{"id":980193,"value":"prepare-learners","color":"dark-gray"}},{"ids":{"database_table_183319":55,"database_table_184385":17},"value":{"id":980195,"value":"resourcing","color":"dark-cyan"}}],"Lookup":[{"id":47,"value":"â€¢  This technology must be incorporated into education, much like the use of computers and software were originally taught as a specific class in secondary schools and then was incorporated as a basic technical skill"},{"id":49,"value":"â€¢  This exposure and digital literacy in technology must begin in secondary study and be appropriately scaffolded into tertiary study, establishing a strong foundational familiarity with tools prior to more sophisticated application in a higher education setting."},{"id":50,"value":"â€¢  Short courses (both in higher education and vocational education) in generative AI may help formalise a sufficiently structured curriculum that addresses both technical competency as well as anchoring it in ethical use, critical thinking, evaluation and scenarios for use."},{"id":52,"value":"â€¢  It is essential that generative AI is implemented and integrated across all fields of study to ensure that all students have the opportunity to build familiarity. This will ensure ethical and critical engagement with the appropriate use of such technologies in society, and preparing future workforce and cultural leadership in policy and government."},{"id":53,"value":"â€¢  Standards for generative AI use in education contexts should be considered, but also take into account the rapidly changing environment and technology. Standards should not limit and constrain institutionsâ€™ need for agility and flexibility in their responses. Standards could relate to the specific types of generative AI that are acceptable â€“ these standards could include consideration of data management, privacy, security, as well as broader terms of service, contracts (for paid tools)."},{"id":55,"value":"â€¢  The rapid development of generative AI and proliferation of companies will also prompt a range of new â€˜edtechâ€™ products and services that could create a financial pressure for educational institutions as they attempt to ensure appropriate equity and inclusion for cohorts."}]},{"id":62,"order":"62.00000000000000000000","submission_number":"62","Submitter":"School of Cybernetics, The Australian National University","Type of org":{"id":977287,"value":"University-centre","color":"orange"},"Notes":"Significant preamble positioning lens on the space.","Recommendations":[{"id":56,"value":"need to support and enable through proactive programs, First Nations inclusion and leadership"},{"id":57,"value":"The inquiry should encompass how to introduce content relating to understanding Generative AI into the national curriculum."}],"Uses-opportunities":[],"Risks-challenges":[{"id":4,"value":"Diverse teams need to be encouraged to create, test and adapt these tools for their own\nneeds and values. Many of the risks and challenges of generative AI tools go back to\nwho has created them, as well as the underlying social and environmental impacts of\ntool development and use. Generative AI, like all other models, will have inbuilt\nstructures and biases, based on the choices made in development of its building blocks\n(e.g. in data sets, sensors, models, networks, infrastructures and how they are\nconstructed and curated over time)."},{"id":5,"value":"It will be critical that students learn about and not just with Generative AI. As our\neducational programs have shown, education in an environment of rapidly changing technology must critically engage with that technology as a system to give a basic understanding of how it was made, where it is used, and where it might be going. Giving students the opportunity to learn about this context, and to provide opportunities for them to tinker with AI and imagine themselves being able to shape it in future jobs, is critical not just to better education, but also to making these systems safer, more sustainable and more responsible. We should focus more on learning about Generative AI, so that children and people of all ages have the opportunity to understand it, even if their access to it is limited."}],"References-footnotes":[{"id":5,"value":"An excellent example of this is Indigitalâ€™s Minecraft Education Challenge focussing on the development of Indigenous cultural stories through AR/VR story-telling: https://www.indigital.net.au/educators"},{"id":6,"value":"This is for example the focus of PhD research and support for early-stage Australian AI start-ups: E.g. Ruster, L.P. (2023). â€œBeing Responsibleâ€ when building GPT-powered products: cybernetic perspectives from a startup. ChatLLMâ€™23, University of Sydney."},{"id":7,"value":"ANU School of Cybernetics, (2022), Re/defining Leadership in the 21st century: the view from cybernetics. A white paper developed by the ANU School of Cybernetics powered by The Menzies Foundation, Australian National University & Menzies Foundation, Canberra, Australia."},{"id":8,"value":"M., Shaw, R., Yunkaporta, T. (2017) Out of the Black Box: Indigenous protocols for AI, https://oldwaysnew.com/news/2021/10/27/unesco-paper-published-anat-stories"},{"id":9,"value":"Our students are our teachers, and we are all learning and connecting multiple knowledges and stories in multiple ways, including those generated with AI like those Mikaela Jade works with through Indigital and talks about in her 2022 ANU Commencement Speech: https://cybernetics.anu.edu.au/news/2022/02/22/Cybernetics-an-opportunity-forconnection- and-to-help-build-our-ai-enabled-future/ Many Indigenous perspectives on AI also flow into and out of our educational experience in multiple forms through residencies, partnerships and resources such as: Abdilla, A., Kelleher"},{"id":10,"value":"Recent School of Cybernetics research on bringing together multiple knowledges, determined â€˜Licence to dreamâ€™ as one of 16 principles for facilitating effective and inclusive participatory processes, elicited from cybernetics case studies. A summary of these principles is provided in: Young, R., Daniell, K.A., Shaw, F. (2023) Making sense of complex systems: practical principles and frameworks. Project report to DSTG. National Security College Futures Hub and School of Cybernetics, The Australian National University, Canberra"},{"id":11,"value":"Many of the works developed for this exhibition remain in place: Meares, A., McLennan, A., Pegram, C., Bell, G. (2022) Australian Cybernetic: A point through time, Birch Building Exhibition Space, The Australian National University, Canberra: https://cybernetics.anu.edu.au/futures/australian-cybernetic/ A number integrate or focus on Generative AI such as â€˜System of a Soundâ€™ (e.g. Andres, J., Ocampo, R., Bown, O., Hill, C., Pegram, C., Schmidt, A., Shave, J., Wright, B. (2023) The Human-Built Environment-Natural Environment Relation - An Immersive Multisensory Exploration with 'System of a Sound', IUI '23 Companion: Companion Proceedings of the 28th International Conference on Intelligent User Interfaces, March 2023, Pages 8â€“11, https://doi.org/10.1145/3581754.3584119) and â€˜Panicâ€™ (e.g. Swift, B. (2022) Panic - A serendipity engine: interactive AI Art installation at Australian Cybernetic, 22 Nov, School of Cybernetics, https://cybernetics.anu.edu.au/news/2022/11/22/panic-a-serendipity-engine/ , which continue to be used as elements of interactive learning experiences in the School."},{"id":12,"value":"The kinds of data that make their way into AI models and their generative applications, including how these are/can be signalled or categorised are core issues for the AI community currently, and will continue to have ramifications in education contexts. One recent investigation from the school into English accent data is here: Reid, K. and Williams, E.T., 2023. Common Voice and Accent Choice: Data Contributors Self-Describe Their Spoken Accents in Diverse Ways (No. 9678). EasyChair."},{"id":13,"value":"See AAIN Generative AI Working Group (2023) AAIN Generative Artificial Intelligence Guidelines, Australian Academic Integrity Network, https://doi.org/10.26187/sbwr-kq49 for a sector-wide view on how Generative AI can be engaged with to minimise academic integrity issues"},{"id":14,"value":"Daniell, K.A. (2021) â€˜Perspectives on three years of prototyping an applied cybernetics education programâ€™ ISSS Conference (Online). https://vimeo.com/590385643/70e891fa05"},{"id":15,"value":"This active making is a core part of the year-long Masterâ€™s cohort experience and a regular aspect of shorter learning experiences the school runs. Public exhibitions of student work occur twice annually through the School of Cybernetics Demo Days. E.g. (Sem 1 2023: https://cecc.anu.edu.au/news/cybernetics-cohort-shines-demo-day and a virtual example through COVID which further developed student video-making skills: https://cybernetics.anu.edu.au/news/2021/11/17/Master-of-Applied-Cybernetics-Virtual-Demo-Day-2021-Cohort/)"},{"id":16,"value":"Frame, K. (2021) Cybernetic Tools for the Classroom (workshop) & Bell, G. Beyond the pandemic: finding hope in cybernetics (Keynote), #NewYorkSchools Tech Summit 2021 (online)"},{"id":17,"value":"Bell, G. (2021). Touching the future. In A. Hay (Ed.), Griffith Review 71: Remaking the balance essay, Griffith University. pp. 251â€“263."},{"id":18,"value":"Bell, G. (2021). After the pandemic: cybernetic systems and an approach to the future. Garran Oration, 2021. https://cybernetics.anu.edu.au/news/2022/03/29/the-garran-oration/"},{"id":19,"value":"Walsh, T., Levy, N., Bell, G., Elliott, A., Maclaurin, J., Mareels, I.M.Y., Wood, F.M., (2019) The effective and ethical development of artificial intelligence: An opportunity to improve our wellbeing. Report for the Australian Council of Learned Academies, www.acola.org."},{"id":20,"value":"Bell, G., Burgess, J., Thomas, J., and Sadiq, S. (2023, March 24). Rapid Response Information Report: Generative AI - language models (LLMs) and multimodal foundation models (MFMs). Australian Council of Learned Academies."}],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":57,"database_table_184385":10},"value":{"id":980190,"value":"curricula-changes","color":"light-green"}},{"ids":{"database_table_183319":56,"database_table_184385":15},"value":{"id":980181,"value":"Indigenous-leadership","color":"darker-pink"}}],"Lookup":[{"id":56,"value":"need to support and enable through proactive programs, First Nations inclusion and leadership"},{"id":57,"value":"The inquiry should encompass how to introduce content relating to understanding Generative AI into the national curriculum."}]},{"id":63,"order":"63.00000000000000000000","submission_number":"63","Submitter":"Group of Eight (Go8)","Type of org":{"id":977283,"value":"HE-network","color":"dark-green"},"Notes":"Focus is on integrity and research, largely in context of existing culture in g08 and policies across sector. No discernible recommendations.","Recommendations":[],"Uses-opportunities":[{"id":10,"value":"This new technology creates new possibilities for educators to create efficiencies and valueâ€add to the learning experience across a range of functions such as: ï‚· grading assignments and providing feedback to students in realâ€time, ï‚· lesson planning, ï‚· producing class discussion starters, ï‚· sourcing case studies, and ï‚· developing assessment questions3"}],"Risks-challenges":[{"id":2,"value":"One of the chief concerns expressed about the use of generative AI in higher education relates to the potential for students to misuse the technology, for example to generate entire assignments or components thereof, not referencing appropriately, relying on AI rather than generating their own ideas, or using it to complete online exams."},{"id":3,"value":"One of the key elements of research integrity that the Go8 believes needs to be addressed explicitly in the context of generative AI is that of maintaining data confidentiality. Research studies â€“ particularly in health and medical disciplines â€“ will often include patient confidential information that can only be used under strict conditions. In some cases, there are also additional and special restrictions around Australian Government medical data related to Medicare and Pharmaceutical Benefits Scheme (PBS) databases. Any use of generative AI tools such as ChatGPT for the analysis of such data runs the risk of releasing the data in an uncontrolled and unauthorised manner."}],"References-footnotes":[{"id":1,"value":"https://www.tandfonline.com/doi/full/10.1080/14703297.2023.2190148"},{"id":2,"value":"https://www.linkedin.com/pulse/chatgptâ€oldâ€newsâ€howâ€doâ€weâ€assessâ€ageâ€aiâ€writingâ€coâ€pilotsâ€dannyliu/?utm source=share&utm medium=member ios&utm campaign=share via"},{"id":3,"value":"https://www.timeshighereducation.com/news/aiâ€mustâ€acknowledgeâ€scientificâ€uncertaintyâ€saysâ€nobellaureate?utm_source=newsletter&utm_medium=email&utm_campaign=editorialdaily&spMailingID=26406366&spUserID=MTAxNzczMTc3MzE4NQS2&spJobID=2254979185&spReportId=MjI1NDk3OTE4NQS2"},{"id":4,"value":"https://www.industry.gov.au/publications/australiasâ€artificialâ€intelligenceâ€ethicsâ€framework/australiasâ€aiâ€ethicsâ€principles"}],"Processed":true,"Recco_tags":[],"Lookup":[]},{"id":64,"order":"64.00000000000000000000","submission_number":"64","Submitter":"English Teachers Association NSW","Type of org":{"id":977281,"value":"Peak body","color":"green"},"Notes":"","Recommendations":[{"id":38,"value":"To monitor plagiarism, AI generators should have an indelible watermark which can be detected by tools that recognise plagiarism. In doing this though, we create an environment where educators are having to rely on tools to recognise plagiarism, tools are not reliable. Clearly, other ways of assessing the validity of student work is needed"},{"id":39,"value":"National policy around the use of plagiarism detectors is important as well to prevent the damage that comes from the hyper-surveillance of student performance, potentially by plagiarism detectors that will continue to have a fail rate."},{"id":40,"value":"There needs to be clear policy and cross-sectoral agreement around student access to AI tools that is consistent and not determined or restricted by cost or differing licenses and agreements."},{"id":41,"value":"Consistent and Effective National and Cross-Sectoral Policy on AI: Policy, at scale, to ensure ongoing transparent, ethical access to AI in education is critical so that the access to AI tools is fair and equitable and does not perpetuate disadvantage. It is also known that AI can reinforce bias that can disadvantage learners. Policy should clearly stipulate the ongoing responsibility that creators have in ensuring that the AI tools they create meet the high standards required in learning environments to keep students safe and mitigate additional responsibility being expected of teachers to ensure the tools they are using in the classroom are effective, pedagogically sound and will not perpetuate bias."},{"id":42,"value":"Ensuring we know how these tools are working and coming up with the decisions they make is important.AI tools are pedagogical agents that will be drawing on what they may recognise as weaknesses and strengths of students and will change the way they support students accordingly. Whilst this sounds highly effective and appropriate pedagogy, this will require data capture that we, as teachers, may not see or know is happening."},{"id":43,"value":"Knowing where this data is stored and communicated is also important. English teachers need to understand the implications of using such tools and the problematic nature of any data capture of our students that may remove student agency in their life- long learning process and what it may do with data like facial recognition or other bodily data captures that can be used to determine how each individual may be perceived by the AI tool and how it may attribute bias potentially limiting the life choices of the students it â€˜teachesâ€™.\nWhile this issue is clearly one for education sectors and schools, campaigns to support parent and student understanding of the risk to student data and how parents, students and teachers can keep them safe is important. Adequate and timely professional learning for teachers is critical so they are aware of the affordances of the system and how to ensure the protection of student data."},{"id":44,"value":"There needs to be adequate and ongoing upskilling to support student digital citizenship so young people understand the risk to their data and teachers also understand their role in protecting student data. Students need to be provided with adequate understanding to make good decisions online that means they are not accessing apps or other sites where their data is potentially not secure or could be misused. More government policy and guidance are needed in this area."},{"id":45,"value":"The Cross Curriculum Priorities in the present ACARA syllabuses can be expanded to include â€˜Ethical use of Technologyâ€™ as a key area across all subjects with explanation and suggestions for teaching this."},{"id":70,"value":"Educators should be provided with clear guidelines and support to incorporate discussions of ethical considerations into their curriculum, fostering a culture of integrity and responsible technology use."},{"id":46,"value":"Decisions about the suitability of tools could be made at scale to ensure that they are trustworthy and equitable without undermining teachers' pedagogy. Teachers can advocate for the access to use specific AI tools in the classroom but there should be a cross-sectoral body that ensures the safety of such tools prior to their introduction to the classroom and checks on the ongoing quality and safety of the AI tool as it is updated. These changes will need to be accompanied by significant teacher professional development, both by the system to understand the above demands but also by the professional associations who are subject based and can help teachers maximise the effectiveness of AI for their discipline and in their classrooms"}],"Uses-opportunities":[{"id":1,"value":"enrich student learning by increasing student\naccessibility through determining student skill sets, capabilities and strengths and developing \ntheir capacity at their own pace particularly when this comes to student literacy, language \ndevelopment, even help students choose reading material and guiding them in accessing literature \naccording to their zone of proximal development. These adaptive learning platforms can analyse \nstudent performance data in real-time, identify areas of strengths and weaknesses, and provide \ntargeted feedback and\nsupport."},{"id":2,"value":"chunks of text can be entered and rewritten for a variety of age and ability levels, thereby differentiating for a large number of variables in any given student cohort. There is the possibility for texts to be rewritten for different abilities, as well as questions and activities to be differentially generated, allowing students to achieve the same outcome at their own level. This greatly assists educators in reducing time spent on the laborious task of differentiating learning for a wide range of students in the mainstream classroom. It also enhances the learning experience for students who need extra assistance."},{"id":3,"value":"For students from socially disadvantaged backgrounds and students from different cultures, AI is useful in closing some gaps in knowledge and experience of texts. Summaries written for specific age groups can close some cultural deficits."},{"id":4,"value":"parse texts at relatively rapid speed, interrogating the contents of each text in a fraction of the time and providing reliable summaries of different sections of long texts."},{"id":5,"value":"In circumstances modeled by English teachers, students can provide chatPDF with research written by others and develop their critical questioning skills. Interacting with a bot such as this requires the development of the same sorts of tools taught to students learning to interact with academic databases including the use of search terms and logical operators."}],"Risks-challenges":[{"id":1,"value":"AI provides opportunities for students to generate content worthy of submission as their own work."}],"References-footnotes":[],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":42,"database_table_184385":1},"value":{"id":980196,"value":"PD","color":"light-red"}},{"ids":{"database_table_183319":43,"database_table_184385":1},"value":{"id":980196,"value":"PD","color":"light-red"}},{"ids":{"database_table_183319":46,"database_table_184385":1},"value":{"id":980196,"value":"PD","color":"light-red"}},{"ids":{"database_table_183319":70,"database_table_184385":2},"value":{"id":980180,"value":"guidelines","color":"light-yellow"}},{"ids":{"database_table_183319":38,"database_table_184385":5},"value":{"id":980175,"value":"mandatory-watermarking","color":"brown"}},{"ids":{"database_table_183319":46,"database_table_184385":7},"value":{"id":980187,"value":"stakeholder-engagement","color":"dark-green"}},{"ids":{"database_table_183319":39,"database_table_184385":11},"value":{"id":980191,"value":"new-policy","color":"dark-purple"}},{"ids":{"database_table_183319":40,"database_table_184385":11},"value":{"id":980191,"value":"new-policy","color":"dark-purple"}},{"ids":{"database_table_183319":41,"database_table_184385":11},"value":{"id":980191,"value":"new-policy","color":"dark-purple"}},{"ids":{"database_table_183319":44,"database_table_184385":14},"value":{"id":980193,"value":"prepare-learners","color":"dark-gray"}},{"ids":{"database_table_183319":45,"database_table_184385":14},"value":{"id":980193,"value":"prepare-learners","color":"dark-gray"}}],"Lookup":[{"id":38,"value":"To monitor plagiarism, AI generators should have an indelible watermark which can be detected by tools that recognise plagiarism. In doing this though, we create an environment where educators are having to rely on tools to recognise plagiarism, tools are not reliable. Clearly, other ways of assessing the validity of student work is needed"},{"id":39,"value":"National policy around the use of plagiarism detectors is important as well to prevent the damage that comes from the hyper-surveillance of student performance, potentially by plagiarism detectors that will continue to have a fail rate."},{"id":40,"value":"There needs to be clear policy and cross-sectoral agreement around student access to AI tools that is consistent and not determined or restricted by cost or differing licenses and agreements."},{"id":41,"value":"Consistent and Effective National and Cross-Sectoral Policy on AI: Policy, at scale, to ensure ongoing transparent, ethical access to AI in education is critical so that the access to AI tools is fair and equitable and does not perpetuate disadvantage. It is also known that AI can reinforce bias that can disadvantage learners. Policy should clearly stipulate the ongoing responsibility that creators have in ensuring that the AI tools they create meet the high standards required in learning environments to keep students safe and mitigate additional responsibility being expected of teachers to ensure the tools they are using in the classroom are effective, pedagogically sound and will not perpetuate bias."},{"id":42,"value":"Ensuring we know how these tools are working and coming up with the decisions they make is important.AI tools are pedagogical agents that will be drawing on what they may recognise as weaknesses and strengths of students and will change the way they support students accordingly. Whilst this sounds highly effective and appropriate pedagogy, this will require data capture that we, as teachers, may not see or know is happening."},{"id":43,"value":"Knowing where this data is stored and communicated is also important. English teachers need to understand the implications of using such tools and the problematic nature of any data capture of our students that may remove student agency in their life- long learning process and what it may do with data like facial recognition or other bodily data captures that can be used to determine how each individual may be perceived by the AI tool and how it may attribute bias potentially limiting the life choices of the students it â€˜teachesâ€™.\nWhile this issue is clearly one for education sectors and schools, campaigns to support parent and student understanding of the risk to student data and how parents, students and teachers can keep them safe is important. Adequate and timely professional learning for teachers is critical so they are aware of the affordances of the system and how to ensure the protection of student data."},{"id":44,"value":"There needs to be adequate and ongoing upskilling to support student digital citizenship so young people understand the risk to their data and teachers also understand their role in protecting student data. Students need to be provided with adequate understanding to make good decisions online that means they are not accessing apps or other sites where their data is potentially not secure or could be misused. More government policy and guidance are needed in this area."},{"id":45,"value":"The Cross Curriculum Priorities in the present ACARA syllabuses can be expanded to include â€˜Ethical use of Technologyâ€™ as a key area across all subjects with explanation and suggestions for teaching this."},{"id":70,"value":"Educators should be provided with clear guidelines and support to incorporate discussions of ethical considerations into their curriculum, fostering a culture of integrity and responsible technology use."},{"id":46,"value":"Decisions about the suitability of tools could be made at scale to ensure that they are trustworthy and equitable without undermining teachers' pedagogy. Teachers can advocate for the access to use specific AI tools in the classroom but there should be a cross-sectoral body that ensures the safety of such tools prior to their introduction to the classroom and checks on the ongoing quality and safety of the AI tool as it is updated. These changes will need to be accompanied by significant teacher professional development, both by the system to understand the above demands but also by the professional associations who are subject based and can help teachers maximise the effectiveness of AI for their discipline and in their classrooms"}]},{"id":66,"order":"65.00000000000000000000","submission_number":"65","Submitter":"Australian Human Rights Commission","Type of org":{"id":977282,"value":"Govt","color":"orange"},"Notes":"","Recommendations":[{"id":180,"value":"Recommendation 1: Children and young people be specifically consulted in an ongoing way about policy decisions in respect of the use of generative AI in the Australian education system."},{"id":181,"value":"Recommendation 2: The principle of the â€˜best interests of the childâ€™ should be the primary test used to inform all policy decisions about the use of generative AI in Australiaâ€™s education system."},{"id":182,"value":"Recommendation 3: The principle that generative AI is to supplement and support learning, and not as a replacement for teaching staff, should be adopted as a foundational principle to inform all policy decisions about the use of generative AI in Australiaâ€™s education system."},{"id":183,"value":"Recommendation 4: The personal data of students collected by generative AI tools must not be sold to third parties or provided to interoperable services or tools outside of the product being used in the classroom for which consent has been obtained"},{"id":184,"value":"Recommendation 5: Policies should mandate rigorous and continual evaluation and validation processes, together with regular independent auditing, to identify and mitigate algorithmic bias in any generative AI tools used in the Australian education system"},{"id":185,"value":"Recommendation 6: Policies should explicitly prohibit the use of generative AI tools in educational settings to create deceptive or malicious content."},{"id":186,"value":"Recommendation 7: Policies should more broadly encourage the development and use of generative AI tools for content verification, allowing individuals to accurately identify AI-generated content."},{"id":187,"value":"Recommendation 8: The Commission supports the development of consistent national standards and guidelines to ensure the responsible and ethical use of generative AI tools in Australian schools."},{"id":188,"value":"Recommendation 9: Professional development and training should be provided to teachers to ensure that they are able to engage with generative AI tools in ways that harness its potential benefits while protecting against the recognised risks"},{"id":189,"value":"Recommendation 10: Schools should introduce comprehensive digital literacy programs to provide students with the skills needed to engage with generative AI tools in a responsible and ethical way."},{"id":190,"value":"Recommendation 11: Generative AI tools being used in an educational settings should be required to meet minimum requirements relating to privacy, data security, algorithmic bias and discrimination, and content verification, including requirements for regular audits and independent reviews of the tools."},{"id":191,"value":"Recommendation 12: The Commission recommends continued investment in research and development to support the use of generative AI tools in educational settings, and an understanding of their impact."},{"id":192,"value":"Recommendation 13: Policies should encourage partnerships to improve access to resources, expertise, and technology infrastructure, while ensuring that these are pursued in an appropriate way that recognises the particular educational context."},{"id":193,"value":"Recommendation 14: Policies should also encourage the development and use of AI-enabled educational resources that are specifically designed to address the needs of disadvantaged cohorts"},{"id":194,"value":"Recommendation 15: Policies should prioritise providing targeted training and capacity building programs for teachers and students in schools with a higher proportion of disadvantaged students"},{"id":195,"value":"Recommendation 16: Addressing the digital divide and ensuring digital equity needs to be a priority in the use of generative AI in the Australian education system. Policies should focus on removing barriers to access providing targeted training and capacity building, and encouraging community engagement and outreach."}],"Uses-opportunities":[{"id":113,"value":"5.1\tPersonalised and interactive learning 15.\tGenerative AI tools can be used to create personalised learning experiences for students that are adapted to individual needs, preferences and learning styles. This can help to create personalised learning paths, tailored content and adaptive assessments. This personalised approach can help students to learn more effectively, and gives students greater control over their own learning. Potential benefits include improved academic performance and increased student engagement."},{"id":114,"value":"5.2\tFostering creativity and innovation 16.\tStudents can also be encouraged to explore their creative potential by experimenting with AI-generated content (such as artwork, music and writing) through interactive platforms. This helps to foster innovation, problem-solving skills and the ability to think critically. These technologies will become increasingly ubiquitous in our daily lives, which means that learning to engage effectively with them from an early age will help set Australian students up for future success."},{"id":115,"value":"5.3\tAdvanced assessment and feedback 17.\tTimely and comprehensive feedback can help students to identify and correct mistakes while improving their understanding of content. Generative AI tools can be used to provide immediate and detailed feedback to students enabling continuous and formative assessment. This also benefits teachers by streamlining assessment processes, providing real-time insights into student progress, and allowing for the identification of additional support for students."},{"id":116,"value":"5.4\tAccessible and inclusive education\n18.\tGenerative AI tools have the potential to make education more accessible and inclusive by addressing the diverse needs of learners - including those with learning differences or disabilities. Examples include assistive technology such as speech-to-text or text-to-speech tools (such as Speechify), language translation tools (such as Presentation Translator), or virtual teaching assistants (such as Jill Watson at Georgia Tech).\n19.\tGenerative AI tools can be used to create more personalised learning experiences, adapt curriculum, and provide tailored assessment and feedback. This can also help to overcome geographical or distance barriers by ensuring that high quality educational opportunities are available to students in regional and remote areas."},{"id":117,"value":"5.5\tAdministrative efficiencies\n20.\tThere are a range of teaching tasks that could be automated using generative AI tools, including grading assessments and creating lesson plans.16 Reducing the administrative burden on teachers will allow them to spend more time engaging directly with students."},{"id":118,"value":"5.6\tData-driven insights\n21.\tA key strength of generative AI tools is their ability to process vast amounts of information and generate data-drive insights. Educators can use these tools to analyse student performance, engagement patterns or learning trends to make informed decisions about student learning paths, curriculum design, or resource allocation. This can potentially be applied at both the individual and systemic levels, enabling comprehensive reports on individual student progress to be produced as well as the early identification of broader trends."}],"Risks-challenges":[{"id":141,"value":"23.\tWhile generative AI tools may be able to replace some of the tasks that are currently performed by teachers, this technology is best used to enhance teaching. It cannot replace the indispensable role of human interaction and cooperation, which must remain at the heart of education in Australia.\n24.\tThe 2023 UNESCO publication, Generative AI and the future of education, emphasised the need to â€˜be watchful against the potentials of newly powerful generative AI technology, alongside older digital tools and services, to undermine the authority and status of teachers â€¦â€™. It further noted that while â€˜frontier technologyâ€™ might be part of the answer to particular challenges in education, ultimately â€˜well-run schools, enough teachers, and teachers with the requisite conditions, training and salaries that allow them to be successful remain the main ingredients of a sustainable remedyâ€™.17"},{"id":142,"value":"25.\tThe right to privacy is a cornerstone human right18 and its importance â€˜in an increasingly data-centric world is growingâ€™,19 because generative AI tools may not only facilitate privacy intrusions, but deepen those intrusions in new and concerning ways.20 Generative AI tools rely on both large data sets to train the technology and the collection of personal data to optimize the individual user experience. This creates a range of privacy risks, particularly given the increased prevalence of cyberattacks and data breaches. The Commission has highlighted these issues in a number of submissions made this year.21 These concerns are particularly relevant in the context of using generative AI tools in the education system, where many of the users will be children who will have no real option but to use the technology if it is adopted by their schools.\n26.\tThere is an urgent need to ensure that generative AI tools are only adopted where concerns related to data privacy, security and consent are being considered and actively addressed.\n27.\tThe Attorney-Generalâ€™s Department is conducting a review of the Privacy Act 1988 (Cth), having closed submissions to their Review Report in April 2023. Several proposals in the Review Report considered strengthening privacy protections for children and in respect of AI. It is likely that outcomes from the Review Report will directly impact privacy, security and data protection for children and certain AI tools.\n28.\tThere must be clear guidelines established to expressly protect student data, limit access to sensitive information, and ensure that robust privacy and security measures are in place. Standards should be established to govern the collect, storage and use of personal information in the context of generative AI tools in education."},{"id":143,"value":"29.\tA related risk that requires urgent attention is the potential commercialisation of student data obtained from the use of generative AI tools.\n \n\n\nAustralian Human Rights Commission\nUtilising Ethical AI in the Australian Education System, 14 July 2023\n\n\n30.\tPractices such as the sale or transfer of childrenâ€™s personal data to third parties should be banned, or heavily restricted, to protect childrenâ€™s rights. For example, among other things, General Comment 25 requires parties to:\n[P]rohibit by law the profiling or targeting of children of any age for commercial purposes on the basis of a digital record of their actual or inferred characteristics, including group or collective data, targeting by association or affinity profiling.\nPractices that rely on neuromarketing, emotional analytics, immersive advertising and advertising in virtual and augmented reality environments to promote products, applications and services should also be prohibited from engagement directly or indirectly with children.22\n31.\tOne example is the use of student search queries being analysed to inform targeted advertising. Another is for student data obtained via educational AI applications to be on-sold to third parties.23\n32.\tIn 2021 the National Childrenâ€™s Commissioner warned that by a childâ€™s 13th birthday advertisers will have gathered on average more than 72 million data points about them.24 It is essential that the data collected through the use of educational technology at schools should not be used for other purposes, and that children are protected from data surveillance."},{"id":144,"value":"33.\tGenerative AI tools are trained on large datasets and generate predictive outputs based on algorithms. It is widely recognised that â€˜algorithms are not neutral, they are developed using metadata that exclude information on marginalized groups and are therefore unrepresentative or biasedâ€™.25\n34.\tThis means that generative AI tools can generate output that is biased, and potentially perpetuate unfairness or even result in unlawful discrimination.26 The risks of bias and discrimination are highlighted in the AI Discussion Paper27 and were examined in detail by the Commission in the Final Report and the Technical Paper, Using artificial intelligence to make decisions: Addressing the problem of algorithmic bias. It is essential to ensure that this issue is addressed so that Australiaâ€™s education system is fair, inclusive and promotes equal opportunities for all students."},{"id":145,"value":"35.\tThe AI Discussion Paper highlighted the creation of misinformation and disinformation as one of the key challenges posed by the increased application of AI.28 The Rapid Response Information Report commissioned by Australiaâ€™s National Science and Technology Council similarly identified both large language models (LLMs) and multimodal foundation models (MFMs) as having â€˜the potential for misuse by generating high-quality, cheap and personalised content, including for harmful purposesâ€™, with the use of generative AI tools to generate deep fakes.29\n36.\tThe use of generative AI tools in educational settings necessarily raises ethical considerations in terms of their potential use to create fake or manipulated content, such as â€˜deepfakesâ€™.30"},{"id":146,"value":"37.\tIn isolation, these reforms are insufficient. There is also a need for digital literacy education and training to ensure that users are able to identify fake or manipulated content, and establish that users understand the importance of engaging with the technology in responsible and ethical ways. The importance of promoting digital literacy is discussed further below."},{"id":147,"value":"38.\tThe ease with which essays, research papers or creative works can be produced using generative AI tools creates risks of plagiarism or intellectual dishonesty. The\n \n\n\nAustralian Human Rights Commission\nUtilising Ethical AI in the Australian Education System, 14 July 2023\n\n\nrelease of ChatGPT in November last year immediately gave rise to concerns â€˜that\na tsunami of cheating was on the horizonâ€™.31\n39.\tBoth around the world, and in Australia, many schools and universities responded by initially banning these technologies from their devices and networks. The New York City public school district became one of the first to temporarily ban ChatGPT from its schoolsâ€™ devices and networks in January 2023, although this ban was reversed several months later.32 Many schools and universities in Australia have also introduced bans or restrictions on the use of generative AI tools at various points, including initial bans by the public school systems in all Australian states other than South Australia.33\n40.\tThere is now growing recognition that an absolute ban on this technology is likely unworkable and disadvantageous for students.34 In particular any ban that is not consistently applied across the Australian education system will create a digital divide between those who have been taught to use generative AI tools at school, and those who have not.35 It also forgoes an important opportunity to teach students how to responsibly use new technologies that are becoming increasingly important, and to develop necessary skills for the future.\n41.\tInstead we should aim to encourage the responsible and ethical use of generative AI tools by students, rather than simply banning them. Students should be educated about the importance of academic integrity, and clear guidelines should be established on the appropriate use of AI-generated content, citation practices, and the need for originality in student work.\n42.\tTo ensure academic integrity, there must be greater research, development and deployment of digital tools capable of identifying AI-generated content. One example is the development of Checker AI which uses its own AI models to predict if text has been written by a human, and to verify the authenticity of student work. This demonstrates the duality of AI tools being both a cause, and solution, to challenges in Australiaâ€™s education system."},{"id":148,"value":"49.\tWhile generative AI has the potential to improve educational outcomes, it is critical to address the digital divide and ensure that equitable opportunities are created for all students, regardless of their background.\n50.\tThe 2021 Australian Digital Inclusion Index shows that there remains a substantial digital divide in Australia.36 One in four people in Australia were identified as being â€˜digitally excludedâ€™ and â€˜people with low levels or income, education and\n \n\n\nAustralian Human Rights Commission\nUtilising Ethical AI in the Australian Education System, 14 July 2023\n\n\nemployment, those living in some regional areas, people aged over 65 and people\nwith a disabilityâ€™ being identified as being of particular risk of being left behind.37\n51.\tStudents who are unable to access the digital tools they need for school risk missing out on crucial learning opportunities that other students take for granted, with the risk of exacerbating educational disadvantage. The Smith Family has estimated that 1 in 6 of the families they work with cannot currently access the digital tools that their children need for school.38 Research published by the Australian Education Union in 2020 revealed a â€˜persistent long-term gap in digital access, affordability and ability experienced by many public school studentsâ€™.39 Ensuring digital inclusion and equity needs to be a key principle informing the use of generative AI in the Australian education system.\n52.\tGenerative AI tools can also potentially play a significant role in helping to level the playing field for all students, regardless of their backgrounds. These tools can provide access to high-quality educational content to students from disadvantaged or low socio-economic backgrounds, and the potential for AI- powered tutors and translators to assist students with particular needs or challenges is significant.\n53.\tIn order to both improve digital equity in the use of generative AI and harness the potential benefits of generative AI tools in reducing educational disadvantage, policies that remove barriers to access, provide targeted training and capacity building, and encourage community engagement and outreach should be pursued."},{"id":149,"value":"54.\tEnsuring equitable access to technology for students is essential to help close the digital divide. This means that public schools must be resourced to allow them to provide students with access to technology, and also ensuring that digital technology is available for use in community facilities (such as libraries).\n55.\tCollaborations between government agencies, educational institutions, not-for- profit organisations and the private sector are crucial for ensuring access to resources to benefit disadvantaged cohorts."}],"References-footnotes":[{"id":346,"value":"https://humanrights.gov.au/our-work/rights-and-freedoms/publications/human-rights-and-technology-final-report-2021"},{"id":347,"value":"https://humanrights.gov.au/sites/default/files/document/publication/ai_guidance_resource_december_2022.pdf"},{"id":348,"value":"https://humanrights.gov.au/our-work/legal/submission/human-rights-digital-age"},{"id":349,"value":"https://humanrights.gov.au/our-work/legal/submission/tackling-technology-facilitated-slavery"},{"id":350,"value":"https://humanrights.gov.au/our-work/legal/submission/safeguarding-right-privacy-australia"},{"id":351,"value":"https://humanrights.gov.au/our-work/legal/submission/inquiry-risk-posed-australias-democracy-foreign-interference-through"},{"id":353,"value":"https://consult.industry.gov.au/supporting-responsible-ai"},{"id":355,"value":"https://openai.com/blog/chatgpt"},{"id":356,"value":"https://bard.google.com/"},{"id":357,"value":"https://www.anthropic.com/index/introducing-claude"},{"id":358,"value":"https://www.synthesia.io/"},{"id":359,"value":"https://openai.com/dall-e-2"},{"id":360,"value":"https://soundful.com/"},{"id":361,"value":"https://docs.midjourney.com/"},{"id":362,"value":"https://sdgs.un.org/goals/goal4"},{"id":363,"value":"https://speechify.com/blog/how-text-to-speech-helps-iep/?landing_url=https%3A%2F%2Fspeechify.com%2Fblog%2Fhow-text-to-speech-helps-iep%2F"},{"id":364,"value":"https://www.microsoft.com/en-us/translator/APPS/PRESENTATION-TRANSLATOR/"},{"id":365,"value":"https://gvu.gatech.edu/research/projects/virtual-teaching-assistant-jill-watson"},{"id":366,"value":"https://gvu.gatech.edu/research/projects/virtual-teaching-assistant-jill-watson"},{"id":367,"value":"https://www.unesco.org/en/articles/generative-artificial-intelligence-education-what-are-opportunities-and-challenges"},{"id":368,"value":"https://www.ag.gov.au/rights-and-protections/publications/privacy-act-review-report"},{"id":370,"value":"https://humanrights.gov.au/our-work/rights-and-freedoms/publications/using-artificial-intelligence-make-decisions-addressing"},{"id":373,"value":"https://www.chiefscientist.gov.au/sites/default/files/2023-06/Rapid%20Response%20Information%20Report%20-%20Generative%20AI%20v1_1.pdf"},{"id":374,"value":"https://www.aicheatcheck.com/"},{"id":375,"value":"https://www.google.com.au/url?sa=t&rct=j&q&esrc=s&source=web&cd&ved=2ahUKEwjstL_KkP__AhUGHXAKHcR8D44QFnoECBsQAQ&url=https%3A%2F%2Fwww.education.gov.au%2Fdownload%2F16512%2Feducation-ministers-meeting-communique-july-2023%2F33714%2Fdocument%2Fpdf&usg=AOvVaw0M3TA1BIFw9T8hTPF4ns53&opi=89978449"},{"id":376,"value":"https://www.unesco.org/en/articles/international-forum-artificial-intelligence-and-education-2022"},{"id":377,"value":"https://news.un.org/en/story/2023/05/1137117"},{"id":378,"value":"https://consult.education.gov.uk/digital-strategy/generative-artificial-intelligence-in-education/"},{"id":379,"value":"https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/1146540/Generative_artificial_intelligence_in_education_.pdf"},{"id":380,"value":"https://www.russellgroup.ac.uk/news/new-principles-on-use-of-ai-in-education/"},{"id":381,"value":"https://www.teqsa.gov.au/guides-resources/higher-education-good-practice-hub/artificial-intelligence"},{"id":382,"value":"https://www.teqsa.gov.au/sites/default/files/2023-04/aain-generative-ai-guidelines.pdf"},{"id":383,"value":"https://libguides.anu.edu.au/generative-ai"},{"id":384,"value":"https://www.deakin.edu.au/research/support-for-researchers/research-integrity/generative-artificial-intelligence-ai"},{"id":385,"value":"https://www.monash.edu/learning-teaching/teachhq/Teaching-practices/artificial-intelligence/policy-and-practice-guidance-around-acceptable-and-responsible-use-of-ai-technologies"},{"id":386,"value":"https://www.education.unsw.edu.au/teaching/educational-innovation/generative-artificial-intelligence-education-teaching"},{"id":387,"value":"https://www.education.sa.gov.au/parents-and-families/curriculum-and-learning/ai"},{"id":388,"value":"https://www.sace.sa.edu.au/teaching/assessment/assessment-and-academic-integrity/guidelines-for-using-ai"},{"id":389,"value":"https://education.nsw.gov.au/teaching-and-learning/education-for-a-changing-world/guidelines-regarding-use-of-generative-ai-chatgpt"},{"id":391,"value":"https://tbinternet.ohchr.org/_layouts/15/treatybodyexternal/Download.aspx?symbolno=E%2FC.12%2F1999%2F10&Lang=en"},{"id":392,"value":"https://www.ohchr.org/en/documents/thematic-reports/ahrc5327-securing-right-education-advances-and-critical-challenges"},{"id":393,"value":"https://www.ohchr.org/en/documents/general-comments-and-recommendations/general-comment-no-25-2021-childrens-rights-relation"},{"id":394,"value":"https://digitallibrary.un.org/record/3901302?ln=en"},{"id":395,"value":"https://www.unesco.org/en/articles/generative-artificial-intelligence-education-what-are-opportunities-and-challenges"},{"id":396,"value":"https://www.ohchr.org/en/documents/thematic-reports/ahrc5117-right-privacy-digital-age"},{"id":398,"value":"https://humanrights.gov.au/our-work/legal/submission/safeguarding-right-privacy"},{"id":399,"value":"https://humanrights.gov.au/our-work/legal/submission/foreign-interference-through-social-media"},{"id":400,"value":"https://humanrights.gov.au/our-work/legal/submission/privacy-risks-metaverse"},{"id":401,"value":"https://www.washingtonpost.com/technology/2022/05/24/remote-school-app-tracking-privacy/"},{"id":402,"value":"https://humanrights.gov.au/about/news/opinions/protect-children-data-surveillance"},{"id":404,"value":"https://www.chiefscientist.gov.au/sites/default/files/2023-06/Rapid%20Response%20Information%20Report%20-%20Generative%20AI%20v1_1.pdf"},{"id":406,"value":"https://www.afr.com/technology/cheaters-beware-this-program-can-tell-if-chatgpt-did-your-homework-20230110-p5cbl1?utm_source=linkedin&utm_medium=social&utm_campaign&utm_term&utm_content"},{"id":407,"value":"https://www.wsj.com/articles/chatgpt-banned-in-new-york-city-public-schools-over-concerns-about-cheating-learning-development-11673024059"},{"id":409,"value":"https://www.nbcnews.com/tech/chatgpt-ban-dropped-new-york-city-public-schools-rcna85089https://www.nbcnews.com/tech/chatgpt-ban-dropped-new-york-city-public-schools-rcna85089"},{"id":410,"value":"https://www.sbs.com.au/language/punjabi/en/podcast-episode/amid-chatgpt-bans-in-australian-schools-educators-consider-risks-and-benefits/sh545nl1e"},{"id":412,"value":"https://www.abc.net.au/news/2023-05-26/artificial-intelligence-chatgpt-classrooms-schools/102356926"},{"id":414,"value":"https://www.nytimes.com/2023/01/12/technology/chatgpt-schools-teachers.html"},{"id":415,"value":"https://www.digitalinclusionindex.org.au/digital-inclusion-the-australian-context-in-2021/"},{"id":416,"value":"https://www.goodthingsfoundation.org.au/the-digital-divide/"},{"id":417,"value":"https://www.thesmithfamily.com.au/media/centre/releases/2021/the-digital-divide-and-other-learning-related-challenges-remain-major-issues"},{"id":418,"value":"https://www.aeufederal.org.au/application/files/5315/9372/9335/DigitalInclusion_BPreston.pdf"}],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":188,"database_table_184385":1},"value":{"id":980196,"value":"PD","color":"light-red"}},{"ids":{"database_table_183319":187,"database_table_184385":2},"value":{"id":980180,"value":"guidelines","color":"light-yellow"}},{"ids":{"database_table_183319":181,"database_table_184385":3},"value":{"id":980182,"value":"situate-with-existing-policy","color":"darker-red"}},{"ids":{"database_table_183319":186,"database_table_184385":5},"value":{"id":980175,"value":"mandatory-watermarking","color":"brown"}},{"ids":{"database_table_183319":180,"database_table_184385":7},"value":{"id":980187,"value":"stakeholder-engagement","color":"dark-green"}},{"ids":{"database_table_183319":182,"database_table_184385":8},"value":{"id":980188,"value":"new-workforce-model","color":"light-brown"}},{"ids":{"database_table_183319":189,"database_table_184385":10},"value":{"id":980190,"value":"curricula-changes","color":"light-green"}},{"ids":{"database_table_183319":191,"database_table_184385":12},"value":{"id":980192,"value":"research-investment","color":"orange"}},{"ids":{"database_table_183319":192,"database_table_184385":17},"value":{"id":980195,"value":"resourcing","color":"dark-cyan"}},{"ids":{"database_table_183319":193,"database_table_184385":22},"value":{"id":980198,"value":"marginalised-group-engagement","color":"light-pink"}},{"ids":{"database_table_183319":194,"database_table_184385":22},"value":{"id":980198,"value":"marginalised-group-engagement","color":"light-pink"}},{"ids":{"database_table_183319":195,"database_table_184385":22},"value":{"id":980198,"value":"marginalised-group-engagement","color":"light-pink"}},{"ids":{"database_table_183319":184,"database_table_184385":25},"value":{"id":980202,"value":"monitoring-impacts","color":"darker-red"}},{"ids":{"database_table_183319":193,"database_table_184385":27},"value":{"id":980178,"value":"equitable-access","color":"yellow"}},{"ids":{"database_table_183319":194,"database_table_184385":27},"value":{"id":980178,"value":"equitable-access","color":"yellow"}},{"ids":{"database_table_183319":195,"database_table_184385":27},"value":{"id":980178,"value":"equitable-access","color":"yellow"}},{"ids":{"database_table_183319":183,"database_table_184385":38},"value":{"id":986019,"value":"respect-rights","color":"light-blue"}},{"ids":{"database_table_183319":185,"database_table_184385":38},"value":{"id":986019,"value":"respect-rights","color":"light-blue"}},{"ids":{"database_table_183319":190,"database_table_184385":38},"value":{"id":986019,"value":"respect-rights","color":"light-blue"}}],"Lookup":[{"id":180,"value":"Recommendation 1: Children and young people be specifically consulted in an ongoing way about policy decisions in respect of the use of generative AI in the Australian education system."},{"id":181,"value":"Recommendation 2: The principle of the â€˜best interests of the childâ€™ should be the primary test used to inform all policy decisions about the use of generative AI in Australiaâ€™s education system."},{"id":182,"value":"Recommendation 3: The principle that generative AI is to supplement and support learning, and not as a replacement for teaching staff, should be adopted as a foundational principle to inform all policy decisions about the use of generative AI in Australiaâ€™s education system."},{"id":183,"value":"Recommendation 4: The personal data of students collected by generative AI tools must not be sold to third parties or provided to interoperable services or tools outside of the product being used in the classroom for which consent has been obtained"},{"id":184,"value":"Recommendation 5: Policies should mandate rigorous and continual evaluation and validation processes, together with regular independent auditing, to identify and mitigate algorithmic bias in any generative AI tools used in the Australian education system"},{"id":185,"value":"Recommendation 6: Policies should explicitly prohibit the use of generative AI tools in educational settings to create deceptive or malicious content."},{"id":186,"value":"Recommendation 7: Policies should more broadly encourage the development and use of generative AI tools for content verification, allowing individuals to accurately identify AI-generated content."},{"id":187,"value":"Recommendation 8: The Commission supports the development of consistent national standards and guidelines to ensure the responsible and ethical use of generative AI tools in Australian schools."},{"id":188,"value":"Recommendation 9: Professional development and training should be provided to teachers to ensure that they are able to engage with generative AI tools in ways that harness its potential benefits while protecting against the recognised risks"},{"id":189,"value":"Recommendation 10: Schools should introduce comprehensive digital literacy programs to provide students with the skills needed to engage with generative AI tools in a responsible and ethical way."},{"id":190,"value":"Recommendation 11: Generative AI tools being used in an educational settings should be required to meet minimum requirements relating to privacy, data security, algorithmic bias and discrimination, and content verification, including requirements for regular audits and independent reviews of the tools."},{"id":191,"value":"Recommendation 12: The Commission recommends continued investment in research and development to support the use of generative AI tools in educational settings, and an understanding of their impact."},{"id":192,"value":"Recommendation 13: Policies should encourage partnerships to improve access to resources, expertise, and technology infrastructure, while ensuring that these are pursued in an appropriate way that recognises the particular educational context."},{"id":193,"value":"Recommendation 14: Policies should also encourage the development and use of AI-enabled educational resources that are specifically designed to address the needs of disadvantaged cohorts"},{"id":194,"value":"Recommendation 15: Policies should prioritise providing targeted training and capacity building programs for teachers and students in schools with a higher proportion of disadvantaged students"},{"id":195,"value":"Recommendation 16: Addressing the digital divide and ensuring digital equity needs to be a priority in the use of generative AI in the Australian education system. Policies should focus on removing barriers to access providing targeted training and capacity building, and encouraging community engagement and outreach."}]},{"id":67,"order":"66.00000000000000000000","submission_number":"66","Submitter":"NT Department of Education","Type of org":{"id":977282,"value":"Govt","color":"orange"},"Notes":"NOTE: it is correct that there's no submission 67 (presumably confidentially submitted)","Recommendations":[{"id":161,"value":"The NT is actively contributing to the National Al Taskforce (the taskforce), which was established by the Education Ministers Meeting in February 2023 to scope, prioritise and sequence the activity to develop a national Al framework for schools. The inquiry would benefit from leveraging the efforts of the taskforce, which has involved high level collaboration across jurisdictions, relevant organisations and collated emerging credible research, to inform the development of a national Al framework for schools."}],"Uses-opportunities":[],"Risks-challenges":[{"id":124,"value":"Equity in education is becoming increasingly linked with digital access. The need for greater equity remains a core concern for th e NT. Many NT students do not have access to basic reliable technology and the ability to consistently connect to the internet rem ains a priority with th e digital divide further disadvantaging a signific ant number of NT students. Innovativ e technology, such as generative Al, has a dependency on connectivity and digital capability of students and staff."},{"id":125,"value":"As Al continues to advance, it is important to ensure this technology is culturally sensitive and inclusive of diverse perspectives and ex periences. This is espec ially true in the NT with a large representat ion of Aborigin a l students. Efforts are t ake n ac ross the department to ensure practices, r eso urce materials and policies are respectful of all cultures. The risks relating specifically to cultural sensitivity and Al, should be identified and mitigated wh ere possibl e to reduc e instances that may cause sadness or distress."},{"id":126,"value":"Generative Al is based on existing data to generate new and original content. There is the risk of potential bias in the data sources which may result in unfair treatment of marginalised groups and perpetuate harmful stereotypes. Standards relating to data uses should be considered to ensure a fair representation to avoid bias in relation to aspects such as race, gender, language, politics and history."}],"References-footnotes":[],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":161,"database_table_184385":3},"value":{"id":980182,"value":"situate-with-existing-policy","color":"darker-red"}}],"Lookup":[{"id":161,"value":"The NT is actively contributing to the National Al Taskforce (the taskforce), which was established by the Education Ministers Meeting in February 2023 to scope, prioritise and sequence the activity to develop a national Al framework for schools. The inquiry would benefit from leveraging the efforts of the taskforce, which has involved high level collaboration across jurisdictions, relevant organisations and collated emerging credible research, to inform the development of a national Al framework for schools."}]},{"id":68,"order":"67.00000000000000000000","submission_number":"68","Submitter":"Australian Catholic University","Type of org":{"id":977279,"value":"University","color":"darker-blue"},"Notes":"NOTE: it is correct that there's no submission 67 (presumably confidentially submitted)","Recommendations":[{"id":403,"value":"if the learning outcomes of traditional assessment items can be easily met by AI, then assessments need to be adapted so students can demonstrate higher order thinking, creative problemsolving and contextual application of knowledge and skills"},{"id":404,"value":"As generative AI becomes part of normal professional practice, students may be required to use AI generated work as an opportunity for review and critique to produce more sophisticated responses to assessment tasks"}],"Uses-opportunities":[{"id":325,"value":"present and summarise concepts for students"},{"id":326,"value":"help students organise their ideas"},{"id":327,"value":"assist students' research (remembering that students need to independently verify and critically analyse\nall information), as well as"},{"id":328,"value":"outline study plans and assist with essay structure and technique"},{"id":329,"value":"creation of educational content ideas to enrich teaching materials for staff"},{"id":330,"value":"automation of routine tasks such as data analytics and content reviews, to free up time for\ninstructional planning and individual student needs for staff"},{"id":331,"value":"For some of ACUâ€™s students drawn from disadvantaged backgrounds where there is less access to economic,\neducational, and social capital, generative AI has provided structured examples of academic genres and\nfeedback on technical aspects of text production to increase their confidence and potential for academic\nsuccess."},{"id":332,"value":"These tools can analyse vast amounts of data to understand students' strengths, weaknesses, and\nlearning styles, generating customised content and assessments"},{"id":333,"value":"They can help educators gain a deeper understanding of students' learning trajectories, enabling\ntargeted interventions, and improving overall teaching practices"},{"id":334,"value":"They may eventually provide interactive simulations and virtual reality experiences quickly and\neasily, providing a much more immersive learning process for students"}],"Risks-challenges":[{"id":279,"value":"Perpetuation of biases in generative AI, potentially inherited from training data"},{"id":280,"value":"Threat to academic and research integrity by encouraging academic misconduct"},{"id":281,"value":"Difficulty in striking a balance between AI-generated material and original work to uphold scholarly standards"},{"id":282,"value":"Increasing difficulty in detecting AI-generated work as technology improves"},{"id":283,"value":"Lack of fully reflected implications of generative AI in university policies"}],"References-footnotes":[],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":403,"database_table_184385":6},"value":{"id":980185,"value":"new-assessment-models","color":"darker-pink"}},{"ids":{"database_table_183319":404,"database_table_184385":14},"value":{"id":980193,"value":"prepare-learners","color":"dark-gray"}}],"Lookup":[{"id":403,"value":"if the learning outcomes of traditional assessment items can be easily met by AI, then assessments need to be adapted so students can demonstrate higher order thinking, creative problemsolving and contextual application of knowledge and skills"},{"id":404,"value":"As generative AI becomes part of normal professional practice, students may be required to use AI generated work as an opportunity for review and critique to produce more sophisticated responses to assessment tasks"}]},{"id":69,"order":"68.00000000000000000000","submission_number":"69","Submitter":"Australian Copyright Council","Type of org":{"id":977289,"value":"nonprofit","color":"darker-gray"},"Notes":"","Recommendations":[],"Uses-opportunities":[],"Risks-challenges":[{"id":276,"value":"AI is trained by or from materials\nthat are protected by copyright. Currently, this training ostensibly involves the copying of those\nmaterials without the permission of the copyright owners"},{"id":277,"value":"the content generated by generative AI is unlikely to be protected by copyright (because of\nthe lack of a human author)"},{"id":278,"value":"issues of copyright infringement and liability if the content generated by AI reproduces a\nâ€˜substantial partâ€™ of existing material that is protected by copyright."}],"References-footnotes":[],"Processed":true,"Recco_tags":[],"Lookup":[]},{"id":70,"order":"69.00000000000000000000","submission_number":"70","Submitter":"Claire Field","Type of org":{"id":977280,"value":"Individual","color":"gray"},"Notes":"","Recommendations":[{"id":401,"value":"Australiaâ€™s education systems need to accept that their current assessment practices, whereby they judge student performance on the basis of written assessment pieces, have to change - with more authentic assessment practices a must. \nassign prompts that state-of-the-art systems such as ChatGPT are not good at;\nrequire verifiable sources and quotations\nask students to analyse specifics from images, audio, or videos\nrequire analysis that draws on class discussion\nask for analysis of recent events not in the training data for the system\nset assignments that articulate nuanced relationships between ideas, and\nassign in-class writing as a supplement to or launching point for take-home assignments\nbe mindful of what Chat GPT3 can and cannot do\ncontinue to teach the foundations\ndeal with the cheating when testing foundational knowledge\nmimic the workplace by teaching how to evaluate a proposed plan of action\nlet students use Chat GPT3, but simultaneously raise the bar for assignments\nask students to imagine the new rather than tweaking the old\ndonâ€™t be shy using Chat GPT3 to improve the productivity of the teaching process."},{"id":402,"value":"educators will need to find ways to include it in their teaching and assessment practices â€“ but only after they have agreed on what it is that they are actually wanting/needing to teach students and how they will measure their learning in an era of generative AI."}],"Uses-opportunities":[{"id":311,"value":"Integration of generative AI into teaching coding, facilitating individual support and help for students"},{"id":312,"value":"Filtering out basic questions, allowing the lesson to flow and students to keep up with the lecturer"},{"id":313,"value":"Allowing students of varying technical expertise to keep up with the class"},{"id":314,"value":"Providing individualized support in real-time as students write code"},{"id":315,"value":"Creating more time for higher-level questions and discussions"},{"id":316,"value":"Facilitating learning by teaching for student"},{"id":317,"value":"Overcoming writer's block for student"},{"id":318,"value":"Engaging in discussions with a co-programmer for student"},{"id":319,"value":"Exploring diverse perspectives for student"},{"id":320,"value":"Writing lesson plans for teachers"},{"id":321,"value":"Designing a draft marking rubric for teachers"},{"id":322,"value":"Writing quiz questions and feedback for students for teachers"},{"id":323,"value":"Generating discussion prompts for use in class for teachers"},{"id":324,"value":"Composing exemplars for critique for teachers"}],"Risks-challenges":[{"id":270,"value":"Data privacy concerns when uploading assessments to cloud or sharing with commercial bot detection services"},{"id":271,"value":"Ethical issues surrounding the use of bot detection services, including potential bias and false-positive rates"},{"id":272,"value":"Challenges in ensuring academic integrity without changing assessment tasks to account for generative AI availability"},{"id":273,"value":"Tutory, a ChatGPT plugin designed to answer students' academic questions, raising further concerns about academic integrity"},{"id":274,"value":"Challenges in assessing student performance given ChatGPT's ability to excel in certain assessment types"},{"id":275,"value":"Difficulty in devising perfect tools to detect AI plagiarism, cautioning against over-reliance on plagiarism detection tools"}],"References-footnotes":[{"id":609,"value":"https://edugrowth.org.au/about-us/"},{"id":610,"value":"https://www.afr.com/technology/is-chatgpt-a-form-of-magic-or-the-apocalypse-20230117-p5cd4p"},{"id":611,"value":"Drew Kadel [@DrewKadel@social.coop] (2023, April 7) My daughter who has had a degree in computer science for 25 years, posted this\nobservation about ChatGPT [Mastodon Post]. Social Coop, Mastodon https://social.coop/@DrewKadel/110154048390452046"},{"id":612,"value":"] McIntyre, C (2023) Opening keynote address EdTechX Europe 2023 https://impactx2050.com/edtechx/home"},{"id":613,"value":"Scott, M [@mrsmiriamscott] (2023, June 20) As teachers, it is our responsibility to guide students through the use of generative AI in a way that\nis ethical & responsible [Tweet]. Twitter https://twitter.com/mrsmiriamscott/status/1670976320480878592"},{"id":614,"value":"Dawson, P [@phillipdawson] (2023, July 3) Useful and interesting - and to me highlights our obsession in education with the final written form of\nwork [Tweet]. Twitter https://twitter.com/phillipdawson/status/1675829754275172352"},{"id":615,"value":"https://www.nytimes.com/2023/06/08/nyregion/lawyer-chatgpt-sanctions.html"},{"id":616,"value":"Mills, A & Goodlad, L. M. (2023) Critical AI: Adapting College Writing for the Age of Large Language Models such as ChatGPT: Some Next Steps for\nEducators https://criticalai.org/2023/01/17/critical-ai-adapting-college-writing-for-the-age-of-large-language-models-such-as-chatgpt-some-nextsteps-for-educators/"},{"id":617,"value":"Rid, T (2023) Five Days in Class with ChatGPT https://alperovitch.sais.jhu.edu/five-days-in-class-with-chatgpt/\n[10] Dreibelbis, E (2023) Harvardâ€™s New Computer Science Teacher is a Chatbot https://uk.pcmag.com/ai/147451/harvards-new-computer-scienceteacher-is-a-chatbot"},{"id":618,"value":"https://edscoop.com/edx-launches-chatgpt-powered-plugin-learning-assistant/"},{"id":619,"value":"https://www.premier.sa.gov.au/media-releases/news-items/nation-leading-trial-in-sa-schools-to-focus-on-the-safe-use-of-ai"},{"id":620,"value":"https://educational-innovation.sydney.edu.au/teaching@sydney/how-ai-can-be-used-meaningfully-by-teachers-and-students-in-2023/"},{"id":621,"value":"Mills, A & Goodlad, L. M. (2023) Critical AI: Adapting College Writing for the Age of Large Language Models such as ChatGPT: Some Next Steps for\nEducators https://criticalai.org/2023/01/17/critical-ai-adapting-college-writing-for-the-age-of-large-language-models-such-as-chatgpt-some-nextsteps-for-educators/"},{"id":622,"value":"https://solutions.openlearning.com/media-release/openlearning-launches-ground-breaking-ai-powered-learning-design-tools-for-education-providers"},{"id":623,"value":"Terwiesch, C (2023) â€œWould Chat GPT3 Get a Wharton MBA? A Prediction Based on Its Performance in the Operations Management Courseâ€,\nMack Institute for Innovation Management at the Wharton School, University of Pennsylvania https://mackinstitute.wharton.upenn.edu/wpcontent/uploads/2023/01/Christian-Terwiesch-Chat-GTP.pdf"},{"id":624,"value":"Sabzalieva, E. & Valentini, A. (2023) ChatGPT and artificial intelligence in higher education: Quick start guide, UNESCO\nhttps://unesdoc.unesco.org/ark:/48223/pf0000385146"},{"id":625,"value":"Australian Government Department of Education (2023) CommuniquÃ©s from the Education Ministers Meeting 2023\nhttps://www.education.gov.au/collections/communiques-education-ministers-meeting-2023"},{"id":626,"value":"https://www.teqsa.gov.au/about-us/news-and-events/latest-news/teqsa-and-deakin-university-ai-webinars-launched"},{"id":627,"value":"Government of Western Australia Training and Accreditation Council (2023) Workshop: Generative AI â€“ The Potential and Pitfalls for VET webinar\nhttps://www.wa.gov.au/service/education-and-training/vocational-education/generative-ai-the-potential-and-pitfalls-vet-webinar"},{"id":628,"value":"OpenAI (2023) GPT-4 https://openai.com/research/gpt-4"},{"id":629,"value":"Cassidy, C (2023) Lecturer detects bot use in one-fifth of assessments as concerns mount over AI in exams, The Guardian\nhttps://www.theguardian.com/australia-news/2023/jan/17/lecturer-detects-bot-use-in-one-fifth-of-assessments-as-concerns-mount-over-ai-inexams"},{"id":630,"value":"Liang, W., Yuksekgonul, M., Mao, Y., Wu, E. & Zou, J. (2023) GPT detectors are biased against non-native English writers, Patterns 4,\nhttps://doi.org/10.1016/j.patter.2023.100779"},{"id":631,"value":"Tutory (2023) A learning companion that is ready anywhere, anytime https://www.tutory.io"},{"id":632,"value":"Nikolic, S., Daniel, S., Haque, R., Belkina, M., Hassan, G. M., Grundy, S., Lyden, S., Neal, P. & Sandison, C (2023) ChatGPT versus engineering\neducation assessment: a multidisciplinary and multi-institutional benchmarking and analysis of this generative artificial intelligence tool to\ninvestigate assessment integrity, European Journal of Engineering Education, 48:4, 559-614, https://doi.org/10.1080/03043797.2023.2213169"},{"id":633,"value":"Mok, A (2023) CEO of ChatGPT maker responds to schoolsâ€™ plagiarism concerns: â€˜We adapted to calculators and changed what we tested in math\nclassâ€™ https://news.yahoo.com/ceo-chatgpt-maker-responds-schools-174705479.html"},{"id":634,"value":"Graham, A. & Sahlberg, P (2020) Schools are moving online but not all children start out digitally equal UNSW Newsroom\nhttps://newsroom.unsw.edu.au/news/social-affairs/schools-are-moving-online-not-all-children-start-out-digitally-equal"},{"id":635,"value":"Ellis, E (2022) The potential of artificial intelligence in assessment feedback, Times Higher Education,\nhttps://www.timeshighereducation.com/campus/potential-artificial-intelligence-assessment-feedback"},{"id":636,"value":"Australian Government Department of Industry, Science and Resources (2023) Supporting responsible AI: discussion paper\nhttps://consult.industry.gov.au/supporting-responsible-ai"},{"id":637,"value":"https://www.smartnation.gov.sg/media-hub/press-releases/national-artificial-intelligence-strategy-unveiled"},{"id":638,"value":"European Commission, Directorate-General for Education, Youth, Sport and Culture (2022) Ethical guidelines on the use of artificial intelligence\n(AI) and data in teaching and learning for educators https://data.europa.eu/doi/10.2766/153756"},{"id":639,"value":"European Commission, Directorate Generale for Education, Youth, Sport and Culture (2021) Digital Education Action Plan (2021 â€“ 2027)\nhttps://education.ec.europa.eu/focus-topics/digital-education/action-plan"},{"id":640,"value":"[33] UK Department for Education (2023) Generative artificial intelligence in education: Departmental statement\nhttps://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/1146540/Generative_artificial_intelligence_in_\neducation_.pdf"},{"id":641,"value":"https://www.hepi.ac.uk/2023/03/07/2023-hepi-annual-lecture-by-andreas-schleicher-director-of-the-oecd/"},{"id":642,"value":"https://rm.coe.int/agenda-of-the-edutalks-council-of-europe-artificial-intelligence-and-a/1680aae5c8"},{"id":643,"value":"Cardona, M. A., Rodriguez, R. J. & Ishmael, K (2023) Artificial Intelligence and the Future of Teaching and Learning, Office of Educational\nTechnology https://www2.ed.gov/documents/ai-report/ai-report.pdf"},{"id":644,"value":"https://consult.education.gov.uk/digital-strategy/generative-artificial-intelligence-in-education/"},{"id":645,"value":"Potkin, F & Wongcha-um, P (2023) Exclusive: Southeast Asia to set â€˜guardrailsâ€™ on AI with new governance code, Reuters\nhttps://www.reuters.com/technology/southeast-asia-set-guardrails-ai-with-new-governance-code-sources-2023-06-16/"},{"id":646,"value":"Russell Group (2023) New principles on use of AI in education https://russellgroup.ac.uk/news/new-principles-on-use-of-ai-in-education/"},{"id":647,"value":"McIntyre, C (2023) Opening keynote address EdTechX Europe 2023 https://impactx2050.com/edtechx/home"},{"id":648,"value":"https://www.hepi.ac.uk/2023/03/07/2023-hepi-annual-lecture-by-andreas-schleicher-director-of-the-oecd/"},{"id":649,"value":"https://www.mckinsey.com/capabilities/mckinsey-digital/our-insights/the-economic-potential-of-generative-ai-the-next-productivity-frontier"},{"id":650,"value":"Field, C (2023) The future of learning: ChatGPT, EdTech and the impact on academic integrity, TAFETalks webinar for TAFE Directors Australia\nhttps://tda.edu.au/tafetalks-the-future-of-learning-chatgpt-edtech-and-the-impact-on-academic-integrity/"},{"id":651,"value":"https://www.afr.com/work-and-careers/education/old-fashioned-training-under-threat-from-ai-20230209-p5cj9j"},{"id":652,"value":"Dodd, J (2023) TAFEs must be able to self-accredit to avoid redundant qualifications: Comment by CEO Jenny Dodd\nhttps://tda.edu.au/newsletters/tafes-must-be-able-to-self-accredit-to-avoid-redundant-qualifications-comment-by-ceo-jenny-dodd/"},{"id":653,"value":"Jackson, R (2022) Skills for an Economy that is Digitalised: Submission to the Productivity Commission 5-year Productivity Inquiry\nhttps://www.pc.gov.au/__data/assets/pdf_file/0005/348071/sub171-productivity.pdf"},{"id":654,"value":"https://campusmorningmail.com.au/news/claire-field-farewells-cmm-with-calls-on-three-big-issues/"},{"id":655,"value":"https://az659834.vo.msecnd.net/eventsairaueprod/production-dg-public/9c410636c9fd45198af873c549fd4e05"},{"id":656,"value":"ITECA (2023) ITEC23 Conference https://www.iteca.edu.au/itec23/social-events.aspx"},{"id":657,"value":"The Teachers Guild of NSW (2023) VET in Schools Forum program\nhttps://www.teachersguild.nsw.edu.au/public/193/system/eventAttachments/VET%20in%20Schools%20Forum%20PROGRAM%20-\n%20Monday%2026%20June%202023v2.pdf"},{"id":658,"value":"Victorian TAFE Association (2023) TAFE Creates: Day 3 Program https://www.tafecreates.com.au/conference-days/day-3"},{"id":659,"value":"https://www.ncver.edu.au/news-and-events/events/32nd-national-vet-research-conference-no-frills/2023-national-vet-research-conference-no-frills-program"},{"id":660,"value":"https://az659834.vo.msecnd.net/eventsairseasiaprod/production-conlog-public/8be3cd00748d4d19aa61e0dc6b0bc1b0"},{"id":661,"value":"https://vdc.edu.au/professional-learning/?eventtemplate=574-webinar-ai"},{"id":662,"value":"Community Colleges Australia have asked me to present at their upcoming annual conference on the topic of â€œAIâ€™s impact on the day to day and\nthe big picture business of VETâ€. The program is still being finalised https://cca.edu.au/what-we-do/2023-cca-annual-conference/#About"},{"id":663,"value":"] Oâ€™Connor, B (2022) Simplifying VET qualifications https://ministers.dewr.gov.au/oconnor/simplifying-vet-qualifications"},{"id":664,"value":"https://www.dewr.gov.au/skills-reform/vet-qualification-reform"},{"id":665,"value":"Jaideep, G (2023) Panel session, EdTechX Europe 2023 https://impactx2050.com/edtechx/home"},{"id":666,"value":"Jesuthasan, R (2023) Here's how companies should navigate generative AI in the world of work, World Economic Forum\nhttps://www.weforum.org/agenda/2023/04/how-companies-should-navigate-generative-ai-in-future-of-work/"},{"id":667,"value":"Eloundou, T., Manning, S., Mishkin, P. & Rock, D (2023) GPTs are GPTs: An Early Look at the Labor Impact Potential of Large Language Models:\nWorking Paper https://arxiv.org/pdf/2303.10130.pdf"},{"id":668,"value":"Stevens, M (2023) What to Know About the Actorsâ€™ Strike? New York Times https://www.nytimes.com/article/actors-strike-why.html"},{"id":669,"value":"] Purtill, J (2023) How ChatGPT and other new AI tools are being used by lawyers, architects and coders, ABC\nhttps://www.abc.net.au/news/science/2023-01-25/chatgpt-midjourney-generative-ai-and-future-of-work/101882580"},{"id":670,"value":"https://www.theguardian.com/global-development/2023/may/12/why-would-we-employ-people-experts-on-five-ways-ai-will-change-work"},{"id":671,"value":"https://www.theaustralian.com.au/business/media/start-it-up-rolling-stone-to-trial-aigenerated-articles/news-story/70218626a7de73571ab89b9c8bbc5893"},{"id":672,"value":"Westfall, C (2023) BuzzFeed to use ChatGPTâ€™s AI for Content Creation, Stock Up 200%+, Forbes\nhttps://www.forbes.com/sites/chriswestfall/2023/01/26/buzzfeed-to-use-chatgpts-ai-for-content-creation-stock-up-200/?sh=d938817eaec4"},{"id":673,"value":"https://www.abc.net.au/news/2023-06-29/artificial-intelligence-chatgpt-journalism-sentinel-times/101761856"},{"id":674,"value":"https://www.allenovery.com/en-gb/global/news-and-insights/news/ao-announces-exclusive-launch-partnership-with-harvey"},{"id":675,"value":"Sweney, M (2023) â€˜Itâ€™s fundamentalâ€™: WPP chief on how AI has revolutionised advertising, The Guardian\nhttps://www.theguardian.com/technology/2023/feb/23/ai-artificial-intelligence-wpp-global-advertising-revolution-technology"},{"id":676,"value":"Hawkins, E (2023) Marketing agency enlists AI â€œinternsâ€, Axios https://www.axios.com/2023/01/11/marketing-ai-interns"},{"id":677,"value":"https://www.theatlantic.com/ideas/archive/2023/01/chatgpt-ai-economy-automation-jobs/672767"},{"id":678,"value":"Reimann, N (2023) IBM will stop hiring humans for jobs AI can do, report says, Forbes\nhttps://www.forbes.com/sites/nicholasreimann/2023/05/01/ibm-will-stop-hiring-humans-for-jobs-ai-can-do-report-says/"},{"id":679,"value":"https://restofworld.org/2023/ai-image-china-video-game-layoffs/"},{"id":680,"value":"Lu, Y (2023) As Businesses Clamor for Workplace A.I., Tech Companies Rush to Provide It, New York Times\nhttps://www.nytimes.com/2023/07/05/technology/business-ai-technology.html"},{"id":681,"value":"Smart Nation Singapore (2019) National Artificial Intelligence Strategy: Advancing Our Smart Nation Journey\nhttps://www.smartnation.gov.sg/files/publications/national-ai-strategy.pdf"},{"id":682,"value":"Adaptemy (2023) Supporting adaptive learning in Singapore https://www.adaptemy.com/supporting-adaptive-learning-in-singapore/"},{"id":683,"value":"Team EdTechX (2019) Global Startup Super League â€“ 27 Innovators Transforming Future of Learning & Work\nhttps://medium.com/edtechx360/https-medium-com-edtechxglobal-global-start-up-super-league-2019-70d2fc7f0df3"},{"id":684,"value":"Century Tech (2023) Century: Online Learning, English, Maths and Science https://www.century.tech"},{"id":685,"value":"HolonIQ (2019) Future of Education and Workforce Summit\nhttps://web.archive.org/web/20220707143313/https://www.holoniq.com/summit/sydney/"},{"id":686,"value":"Torda, R (2020) Empowering New Yorkâ€™s Nurse Heroes to Handle the Worst of the Pandemic, New York Academy of Sciences\nhttps://www.nyas.org/news-articles/academy-news/empowering-new-york-s-nurse-heroes-to-handle-the-worst-of-the-pandemic/"},{"id":687,"value":"Forbes (2021) Forbes 30 under 30 - Joel Hellermark: Founder, Sana Labs, Forbes https://www.forbes.com/profile/joel-hellermark/"},{"id":688,"value":"UNICEF (2023) Co-creating inclusive, quality learning innovations: UNICEF and Finnish National Agency for Education (EDUFI) deepen collaboration\non innovation in education https://www.unicef.org/innovation/learning-innovation-hub/edufi-finceed-collaboration"},{"id":689,"value":"Cortesi, A (2023) Panel presentation EdTechX Europe 2023 https://impactx2050.com/edtechx/home"},{"id":690,"value":"Eduten (2023) Revolutionizing Education: The Eduten Platform Shows Massive Impact in Math Learning Results Across Mongolia\nhttps://eduten.com/blog/eduten-platform-drives-impressive-learning-outcomes-in-a-12-week-pilot-in-mongolia.html"}],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":401,"database_table_184385":6},"value":{"id":980185,"value":"new-assessment-models","color":"darker-pink"}},{"ids":{"database_table_183319":402,"database_table_184385":6},"value":{"id":980185,"value":"new-assessment-models","color":"darker-pink"}},{"ids":{"database_table_183319":402,"database_table_184385":14},"value":{"id":980193,"value":"prepare-learners","color":"dark-gray"}}],"Lookup":[{"id":401,"value":"Australiaâ€™s education systems need to accept that their current assessment practices, whereby they judge student performance on the basis of written assessment pieces, have to change - with more authentic assessment practices a must. \nassign prompts that state-of-the-art systems such as ChatGPT are not good at;\nrequire verifiable sources and quotations\nask students to analyse specifics from images, audio, or videos\nrequire analysis that draws on class discussion\nask for analysis of recent events not in the training data for the system\nset assignments that articulate nuanced relationships between ideas, and\nassign in-class writing as a supplement to or launching point for take-home assignments\nbe mindful of what Chat GPT3 can and cannot do\ncontinue to teach the foundations\ndeal with the cheating when testing foundational knowledge\nmimic the workplace by teaching how to evaluate a proposed plan of action\nlet students use Chat GPT3, but simultaneously raise the bar for assignments\nask students to imagine the new rather than tweaking the old\ndonâ€™t be shy using Chat GPT3 to improve the productivity of the teaching process."},{"id":402,"value":"educators will need to find ways to include it in their teaching and assessment practices â€“ but only after they have agreed on what it is that they are actually wanting/needing to teach students and how they will measure their learning in an era of generative AI."}]},{"id":71,"order":"70.00000000000000000000","submission_number":"71","Submitter":"University of Technology Sydney (UTS)","Type of org":{"id":977279,"value":"University","color":"darker-blue"},"Notes":"","Recommendations":[{"id":139,"value":"alian education system would benefit from the enormous expertise offered by the higher education sector given that Australia is home to many of the  worldâ€™s leading researchers in AI in education, Learning Analytics, and higher education  researchers in teaching, feedback and assessment design. This expertise must be woven together.1 This could be achieved in several ways and UTS recommends consideration of the following models: â€¢  An extension of the model proposed by Ms Loble AM (described below as the Australian Forum on  Quality Digital Education) to include, where relevant, a partnership with the higher education  sector. â€¢   If separate from Ms Lobleâ€™s model, a National Centre for AI in education or an ARC Centre of  Excellence tuned to the needs of not only researchers advancing knowledge and innovation  technologically, but serving practitioners in co-designing, testing and evaluating what works in  diverse contexts. Australian Indigenous educational innovation and challenges must also be a  hallmark of this centre.2"},{"id":140,"value":"The adoption of national guidelines to maximise opportunities while safeguarding against legal risks. These guidelines should support public and private sector organisations to comply with relevant laws and encompass co- and self-regulatory measures. The consultation underway by the Commonwealth Department of Industry, Science and Resources Safe and responsible AI in Australia is a positive step in this direction"},{"id":141,"value":"Convene generative AI challenges to catalyse applied research and cross-sector collaboration. Teams of academia, industry partners, and educational institutions would be funded to explore the potential applications of generative AI in education. These projects would focus on developing innovative solutions, evaluating their effectiveness, and addressing specific challenges faced in different educational contexts."},{"id":142,"value":"Hold annual conferences on generative AI in Education. Annual conferences would bring together thought leaders and the strongest examples of practice, as a way to build Australiaâ€™s capability. These could be specialised for different stakeholders and agendas (e.g., pedagogical, technical, ethical, governance) as well as ensuring there was productive knowledge integration. A strong emphasis on translating into practice will promote innovation diffusion."},{"id":143,"value":"Establish a generative AI educational impact evidence hub to foster both domestic and international collaboration and knowledge sharing among researchers, practitioners, and policymakers. Resource the development of a collective intelligence website that assists the community in sharing, finding, and debating the emerging evidence as generative AI is evaluated in different educational contexts. UTS has experience in prototyping such infrastructures."},{"id":144,"value":"Convene an expert panel to review options for national generative AI infrastructure. Amidst concerns that generative AI is owned and driven by technology companies, we should consider developing a national capability for both research and public services, with the possibility of increased fairness, accountability, transparency and ethics when the infrastructure is completely under our own control."},{"id":145,"value":"Develop comprehensive ethical guidelines and frameworks specifically tailored for the use of generative AI in education. These guidelines should encompass aspects such as data privacy, algorithmic transparency, fairness, and accountability. They should also consider the unique ethical considerations related to student data and learner outcomes"},{"id":146,"value":"the education sector urgently needs robust responses to the following questions: â€¢ What are proven approaches to transitioning assessment practices and curriculum renewal at scale? For instance, are direct observation/oral defence sessions scalable (e.g., for hundreds of students in a cohort), does it cost more than current assessments, and if more, is this justified by the rigour of assurance of learning they provide? Does a switch to program-level assessment create the staff time and curriculum space to introduce the triangulation of student evidence now required? â€¢ How well do different ways of using generative AI tools translate across different teaching and learning contexts, and do we understand why there is inevitably variation? There are now myriad, educationally-grounded proposals for how ChatGPT might be used â€” what is missing is the coordinated tracking of evidence of how well these work across different contexts. â€¢ How do we build critical AI literacy among students of different ages and stages, such that it becomes a lifelong capability, and does not age rapidly with technical advances? â€¢ What are the most effective ways to upskill academics, short and longer term? Every university has a centre for teaching innovation bringing wide expertise, including Academic Language and Literacies, Library, Course Program Design, Assessment Design. All of these have been engaged in the rapid response to generative AI over the last 6 months, but there has not yet been time to consolidate, share and discuss innovations. â€¢ How do we tune generative AI for learning? The dominant Large Language Models and conversational interfaces were not developed for education. These can be further tuned with in-depth disciplinary texts, and prompt engineering to shape learning conversations. Some universities are beginning to build the infrastructure to conduct such applied R&D, while others will depend on them sharing the outputs in forms they can adopt and adapt, open source or via commercial products."},{"id":364,"value":"An extension of the model proposed by Ms Loble AM (described below as the Australian Forum on Quality Digital Education) to include, where relevant, a partnership with the higher education sector."},{"id":365,"value":"If separate from Ms Lobleâ€™s model, a National Centre for AI in education or an ARC Centre of Excellence tuned to the needs of not only researchers advancing knowledge and innovation technologically, but serving practitioners in co-designing, testing and evaluating what works in diverse contexts. Australian Indigenous educational innovation and challenges must also be a hallmark of this centre"},{"id":366,"value":"The adoption of national guidelines to maximise opportunities while safeguarding against legal risks. These guidelines should support public and private sector organisations to comply with relevant laws and encompass co- and self-regulatory measures. The consultation underway by the Commonwealth Department of Industry, Science and Resources Safe and responsible AI in Australia is a positive step in this direction."},{"id":367,"value":"Convene generative AI challenges to catalyse applied research and cross-sector collaboration. Teams of academia, industry partners, and educational institutions would be funded to explore the potential applications of generative AI in education. These projects would focus on developing innovative solutions, evaluating their effectiveness, and addressing specific challenges faced in different educational contexts."},{"id":368,"value":"Hold annual conferences on generative AI in Education. Annual conferences would bring together thought leaders and the strongest examples of practice, as a way to build Australiaâ€™s capability. These could be specialised for different stakeholders and agendas (e.g., pedagogical, technical, ethical, governance) as well as ensuring there was productive knowledge integration. A strong emphasis on translating into practice will promote innovation diffusion."},{"id":369,"value":"Establish a generative AI educational impact evidence hub to foster both domestic and international collaboration and knowledge sharing among researchers, practitioners, and policymakers. Resource the development of a collective intelligence website that assists the community in sharing, finding, and debating the emerging evidence as generative AI is evaluated in different educational contexts. UTS has experience in prototyping such infrastructures."},{"id":370,"value":"Convene an expert panel to review options for national generative AI infrastructure. Amidst concerns that generative AI is owned and driven by technology companies, we should consider developing a national capability for both research and public services, with the possibility of increased fairness, accountability, transparency and ethics when the infrastructure is completely under our own control."},{"id":371,"value":"Develop comprehensive ethical guidelines and frameworks specifically tailored for the use of generative AI in education. These guidelines should encompass aspects such as data privacy, algorithmic transparency, fairness, and accountability. They should also consider the unique ethical considerations related to student data and learner outcomes."},{"id":372,"value":"Emphasising the need for creation of comprehensive guidelines and policies to ensure responsible and ethical use of AI technologies in educational settings in the areas of privacy, data security, algorithmic bias, and the potential impact on student well-being."},{"id":373,"value":"Providing adequate training and professional development opportunities for teachers to effectively utilise generative AI tools in their classrooms. This includes training on the use of AI tools, understanding their limitations, and developing pedagogical strategies to integrate them into teaching practices."},{"id":374,"value":"Prioritising student learning and engagement when integrating generative AI tools. Discuss how these tools can be used to personalize learning experiences, provide targeted feedback, and foster student creativity and critical thinking skills."},{"id":375,"value":"Encouraging collaboration among educational institutions, researchers, and developers to minimise duplication, share best practices, research findings, and innovations related to the use of generative AI in education"},{"id":376,"value":"Emphasising the importance of iterative improvement and the ability to adapt AI tools to changing\neducational needs."},{"id":377,"value":"Establish the Australian Forum on Quality Digital Education to help shape the strategic agenda for using technology to target educational disadvantage and boost student outcomes and wellbeing."},{"id":378,"value":"Work with schools to test, develop and showcase best practice integration of teaching and learning technology tools for disadvantaged and special needs students, building a network of peer based support."},{"id":379,"value":"Provide extra resources to disadvantaged schools to access high quality edtech learning tools, with linked implementation support and professional development, alongside investment to secure equitable access to essential technological infrastructure."},{"id":380,"value":"Commission the Australian Education Research Organisation (AERO) to provide expertise and advice on what works best when using edtech to support teachers and improve student outcomes."},{"id":381,"value":"Include evidence standards for education interventions, including edtech, in the next quadrennial national school funding agreement, along the lines of the U.S. Every Student Succeeds Act (ESSA) federal funding guidelines."},{"id":382,"value":"Accelerate high quality, independent research and evaluation of teaching and learning tools to investigate:\nâ€“ Impact on learning progress for students facing educational disadvantage;\nâ€“ Features that amplify positive outcomes, including implementation factors"},{"id":383,"value":"Catalyse a world-leading Australian social benefit edtech sector by investing in promising systems that meet high standards for evidence, efficacy, ethics and equity. Novel forms of capital should be considered, such as impact investing, social enterprises, leveraging or partnering with venture capital funds, as well as direct public or philanthropic funding"},{"id":384,"value":"Create an accessible repository of trustworthy information on the quality and safety of available edtech tools so that schools, education systems and parents can make more informed choices"},{"id":385,"value":"Develop education-specific standards covering product design, data use, and life cycle governance and accountability to guide purchasing decisions and assist industry access to the sector."},{"id":386,"value":"Build public-private partnerships to safely share data for better traction on solving education challenges, and to apply advanced data techniques to help optimise outcomes for students at risk."}],"Uses-opportunities":[{"id":298,"value":"Evolution of assessment practices to adapt to generative AI capabilities"},{"id":299,"value":"Resilient assessment systems with verification of student identity"},{"id":300,"value":"Assurance of learning through rich and complementary evidence"},{"id":301,"value":"Shift towards programmatic assessment and robust assessment design principles"},{"id":302,"value":"Transition from product-centric to process-oriented assessment"},{"id":303,"value":"Documentation and reflection on students' task approaches aided by analytics"},{"id":304,"value":"Personalized feedback enabled by novel forms of assessment"},{"id":305,"value":"Face-to-face assessment as a hallmark of higher education"},{"id":306,"value":"Scaling direct observation in assessment with sustainable methods"},{"id":307,"value":"Equipping graduates with expertise in using state-of-the-art AI tools"},{"id":308,"value":"Understanding limitations of generative AI to avoid undermining foundational learning"},{"id":309,"value":"Ongoing learning by academics and tutors to harness the power of generative AI in teaching"},{"id":310,"value":"Utilizing generative AI as productivity aids for curriculum design, resources, and assessments."}],"Risks-challenges":[{"id":264,"value":"Risks in ensuring safe and ethical use of generative AI tools"},{"id":265,"value":"Challenges in promoting ongoing academic and research integrity"},{"id":266,"value":"Dependence on big technology companies for public education"},{"id":267,"value":"Lack of transparent and accountable models in AI implementation"},{"id":268,"value":"Concerns regarding equitable access to leading-edge technology for all students"},{"id":269,"value":"Privileged individuals retaining access to advanced tools"}],"References-footnotes":[],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":373,"database_table_184385":1},"value":{"id":980196,"value":"PD","color":"light-red"}},{"ids":{"database_table_183319":140,"database_table_184385":2},"value":{"id":980180,"value":"guidelines","color":"light-yellow"}},{"ids":{"database_table_183319":145,"database_table_184385":2},"value":{"id":980180,"value":"guidelines","color":"light-yellow"}},{"ids":{"database_table_183319":366,"database_table_184385":2},"value":{"id":980180,"value":"guidelines","color":"light-yellow"}},{"ids":{"database_table_183319":371,"database_table_184385":2},"value":{"id":980180,"value":"guidelines","color":"light-yellow"}},{"ids":{"database_table_183319":372,"database_table_184385":2},"value":{"id":980180,"value":"guidelines","color":"light-yellow"}},{"ids":{"database_table_183319":374,"database_table_184385":6},"value":{"id":980185,"value":"new-assessment-models","color":"darker-pink"}},{"ids":{"database_table_183319":139,"database_table_184385":12},"value":{"id":980192,"value":"research-investment","color":"orange"}},{"ids":{"database_table_183319":364,"database_table_184385":12},"value":{"id":980192,"value":"research-investment","color":"orange"}},{"ids":{"database_table_183319":365,"database_table_184385":12},"value":{"id":980192,"value":"research-investment","color":"orange"}},{"ids":{"database_table_183319":380,"database_table_184385":12},"value":{"id":980192,"value":"research-investment","color":"orange"}},{"ids":{"database_table_183319":382,"database_table_184385":12},"value":{"id":980192,"value":"research-investment","color":"orange"}},{"ids":{"database_table_183319":383,"database_table_184385":12},"value":{"id":980192,"value":"research-investment","color":"orange"}},{"ids":{"database_table_183319":376,"database_table_184385":14},"value":{"id":980193,"value":"prepare-learners","color":"dark-gray"}},{"ids":{"database_table_183319":141,"database_table_184385":19},"value":{"id":980186,"value":"capacity-building","color":"light-yellow"}},{"ids":{"database_table_183319":142,"database_table_184385":19},"value":{"id":980186,"value":"capacity-building","color":"light-yellow"}},{"ids":{"database_table_183319":143,"database_table_184385":19},"value":{"id":980186,"value":"capacity-building","color":"light-yellow"}},{"ids":{"database_table_183319":367,"database_table_184385":19},"value":{"id":980186,"value":"capacity-building","color":"light-yellow"}},{"ids":{"database_table_183319":368,"database_table_184385":19},"value":{"id":980186,"value":"capacity-building","color":"light-yellow"}},{"ids":{"database_table_183319":369,"database_table_184385":19},"value":{"id":980186,"value":"capacity-building","color":"light-yellow"}},{"ids":{"database_table_183319":370,"database_table_184385":19},"value":{"id":980186,"value":"capacity-building","color":"light-yellow"}},{"ids":{"database_table_183319":375,"database_table_184385":19},"value":{"id":980186,"value":"capacity-building","color":"light-yellow"}},{"ids":{"database_table_183319":377,"database_table_184385":19},"value":{"id":980186,"value":"capacity-building","color":"light-yellow"}},{"ids":{"database_table_183319":378,"database_table_184385":19},"value":{"id":980186,"value":"capacity-building","color":"light-yellow"}},{"ids":{"database_table_183319":379,"database_table_184385":19},"value":{"id":980186,"value":"capacity-building","color":"light-yellow"}},{"ids":{"database_table_183319":384,"database_table_184385":19},"value":{"id":980186,"value":"capacity-building","color":"light-yellow"}},{"ids":{"database_table_183319":143,"database_table_184385":21},"value":{"id":980197,"value":"evidence-generation","color":"brown"}},{"ids":{"database_table_183319":146,"database_table_184385":21},"value":{"id":980197,"value":"evidence-generation","color":"brown"}},{"ids":{"database_table_183319":381,"database_table_184385":21},"value":{"id":980197,"value":"evidence-generation","color":"brown"}},{"ids":{"database_table_183319":386,"database_table_184385":21},"value":{"id":980197,"value":"evidence-generation","color":"brown"}},{"ids":{"database_table_183319":144,"database_table_184385":23},"value":{"id":980201,"value":"Australian-tech-and-models","color":"light-orange"}},{"ids":{"database_table_183319":370,"database_table_184385":23},"value":{"id":980201,"value":"Australian-tech-and-models","color":"light-orange"}},{"ids":{"database_table_183319":370,"database_table_184385":39},"value":{"id":991258,"value":"foster-responsible-aied","color":"red"}},{"ids":{"database_table_183319":385,"database_table_184385":39},"value":{"id":991258,"value":"foster-responsible-aied","color":"red"}}],"Lookup":[{"id":139,"value":"alian education system would benefit from the enormous expertise offered by the higher education sector given that Australia is home to many of the  worldâ€™s leading researchers in AI in education, Learning Analytics, and higher education  researchers in teaching, feedback and assessment design. This expertise must be woven together.1 This could be achieved in several ways and UTS recommends consideration of the following models: â€¢  An extension of the model proposed by Ms Loble AM (described below as the Australian Forum on  Quality Digital Education) to include, where relevant, a partnership with the higher education  sector. â€¢   If separate from Ms Lobleâ€™s model, a National Centre for AI in education or an ARC Centre of  Excellence tuned to the needs of not only researchers advancing knowledge and innovation  technologically, but serving practitioners in co-designing, testing and evaluating what works in  diverse contexts. Australian Indigenous educational innovation and challenges must also be a  hallmark of this centre.2"},{"id":140,"value":"The adoption of national guidelines to maximise opportunities while safeguarding against legal risks. These guidelines should support public and private sector organisations to comply with relevant laws and encompass co- and self-regulatory measures. The consultation underway by the Commonwealth Department of Industry, Science and Resources Safe and responsible AI in Australia is a positive step in this direction"},{"id":141,"value":"Convene generative AI challenges to catalyse applied research and cross-sector collaboration. Teams of academia, industry partners, and educational institutions would be funded to explore the potential applications of generative AI in education. These projects would focus on developing innovative solutions, evaluating their effectiveness, and addressing specific challenges faced in different educational contexts."},{"id":142,"value":"Hold annual conferences on generative AI in Education. Annual conferences would bring together thought leaders and the strongest examples of practice, as a way to build Australiaâ€™s capability. These could be specialised for different stakeholders and agendas (e.g., pedagogical, technical, ethical, governance) as well as ensuring there was productive knowledge integration. A strong emphasis on translating into practice will promote innovation diffusion."},{"id":143,"value":"Establish a generative AI educational impact evidence hub to foster both domestic and international collaboration and knowledge sharing among researchers, practitioners, and policymakers. Resource the development of a collective intelligence website that assists the community in sharing, finding, and debating the emerging evidence as generative AI is evaluated in different educational contexts. UTS has experience in prototyping such infrastructures."},{"id":144,"value":"Convene an expert panel to review options for national generative AI infrastructure. Amidst concerns that generative AI is owned and driven by technology companies, we should consider developing a national capability for both research and public services, with the possibility of increased fairness, accountability, transparency and ethics when the infrastructure is completely under our own control."},{"id":145,"value":"Develop comprehensive ethical guidelines and frameworks specifically tailored for the use of generative AI in education. These guidelines should encompass aspects such as data privacy, algorithmic transparency, fairness, and accountability. They should also consider the unique ethical considerations related to student data and learner outcomes"},{"id":146,"value":"the education sector urgently needs robust responses to the following questions: â€¢ What are proven approaches to transitioning assessment practices and curriculum renewal at scale? For instance, are direct observation/oral defence sessions scalable (e.g., for hundreds of students in a cohort), does it cost more than current assessments, and if more, is this justified by the rigour of assurance of learning they provide? Does a switch to program-level assessment create the staff time and curriculum space to introduce the triangulation of student evidence now required? â€¢ How well do different ways of using generative AI tools translate across different teaching and learning contexts, and do we understand why there is inevitably variation? There are now myriad, educationally-grounded proposals for how ChatGPT might be used â€” what is missing is the coordinated tracking of evidence of how well these work across different contexts. â€¢ How do we build critical AI literacy among students of different ages and stages, such that it becomes a lifelong capability, and does not age rapidly with technical advances? â€¢ What are the most effective ways to upskill academics, short and longer term? Every university has a centre for teaching innovation bringing wide expertise, including Academic Language and Literacies, Library, Course Program Design, Assessment Design. All of these have been engaged in the rapid response to generative AI over the last 6 months, but there has not yet been time to consolidate, share and discuss innovations. â€¢ How do we tune generative AI for learning? The dominant Large Language Models and conversational interfaces were not developed for education. These can be further tuned with in-depth disciplinary texts, and prompt engineering to shape learning conversations. Some universities are beginning to build the infrastructure to conduct such applied R&D, while others will depend on them sharing the outputs in forms they can adopt and adapt, open source or via commercial products."},{"id":364,"value":"An extension of the model proposed by Ms Loble AM (described below as the Australian Forum on Quality Digital Education) to include, where relevant, a partnership with the higher education sector."},{"id":365,"value":"If separate from Ms Lobleâ€™s model, a National Centre for AI in education or an ARC Centre of Excellence tuned to the needs of not only researchers advancing knowledge and innovation technologically, but serving practitioners in co-designing, testing and evaluating what works in diverse contexts. Australian Indigenous educational innovation and challenges must also be a hallmark of this centre"},{"id":366,"value":"The adoption of national guidelines to maximise opportunities while safeguarding against legal risks. These guidelines should support public and private sector organisations to comply with relevant laws and encompass co- and self-regulatory measures. The consultation underway by the Commonwealth Department of Industry, Science and Resources Safe and responsible AI in Australia is a positive step in this direction."},{"id":367,"value":"Convene generative AI challenges to catalyse applied research and cross-sector collaboration. Teams of academia, industry partners, and educational institutions would be funded to explore the potential applications of generative AI in education. These projects would focus on developing innovative solutions, evaluating their effectiveness, and addressing specific challenges faced in different educational contexts."},{"id":368,"value":"Hold annual conferences on generative AI in Education. Annual conferences would bring together thought leaders and the strongest examples of practice, as a way to build Australiaâ€™s capability. These could be specialised for different stakeholders and agendas (e.g., pedagogical, technical, ethical, governance) as well as ensuring there was productive knowledge integration. A strong emphasis on translating into practice will promote innovation diffusion."},{"id":369,"value":"Establish a generative AI educational impact evidence hub to foster both domestic and international collaboration and knowledge sharing among researchers, practitioners, and policymakers. Resource the development of a collective intelligence website that assists the community in sharing, finding, and debating the emerging evidence as generative AI is evaluated in different educational contexts. UTS has experience in prototyping such infrastructures."},{"id":370,"value":"Convene an expert panel to review options for national generative AI infrastructure. Amidst concerns that generative AI is owned and driven by technology companies, we should consider developing a national capability for both research and public services, with the possibility of increased fairness, accountability, transparency and ethics when the infrastructure is completely under our own control."},{"id":371,"value":"Develop comprehensive ethical guidelines and frameworks specifically tailored for the use of generative AI in education. These guidelines should encompass aspects such as data privacy, algorithmic transparency, fairness, and accountability. They should also consider the unique ethical considerations related to student data and learner outcomes."},{"id":372,"value":"Emphasising the need for creation of comprehensive guidelines and policies to ensure responsible and ethical use of AI technologies in educational settings in the areas of privacy, data security, algorithmic bias, and the potential impact on student well-being."},{"id":373,"value":"Providing adequate training and professional development opportunities for teachers to effectively utilise generative AI tools in their classrooms. This includes training on the use of AI tools, understanding their limitations, and developing pedagogical strategies to integrate them into teaching practices."},{"id":374,"value":"Prioritising student learning and engagement when integrating generative AI tools. Discuss how these tools can be used to personalize learning experiences, provide targeted feedback, and foster student creativity and critical thinking skills."},{"id":375,"value":"Encouraging collaboration among educational institutions, researchers, and developers to minimise duplication, share best practices, research findings, and innovations related to the use of generative AI in education"},{"id":376,"value":"Emphasising the importance of iterative improvement and the ability to adapt AI tools to changing\neducational needs."},{"id":377,"value":"Establish the Australian Forum on Quality Digital Education to help shape the strategic agenda for using technology to target educational disadvantage and boost student outcomes and wellbeing."},{"id":378,"value":"Work with schools to test, develop and showcase best practice integration of teaching and learning technology tools for disadvantaged and special needs students, building a network of peer based support."},{"id":379,"value":"Provide extra resources to disadvantaged schools to access high quality edtech learning tools, with linked implementation support and professional development, alongside investment to secure equitable access to essential technological infrastructure."},{"id":380,"value":"Commission the Australian Education Research Organisation (AERO) to provide expertise and advice on what works best when using edtech to support teachers and improve student outcomes."},{"id":381,"value":"Include evidence standards for education interventions, including edtech, in the next quadrennial national school funding agreement, along the lines of the U.S. Every Student Succeeds Act (ESSA) federal funding guidelines."},{"id":382,"value":"Accelerate high quality, independent research and evaluation of teaching and learning tools to investigate:\nâ€“ Impact on learning progress for students facing educational disadvantage;\nâ€“ Features that amplify positive outcomes, including implementation factors"},{"id":383,"value":"Catalyse a world-leading Australian social benefit edtech sector by investing in promising systems that meet high standards for evidence, efficacy, ethics and equity. Novel forms of capital should be considered, such as impact investing, social enterprises, leveraging or partnering with venture capital funds, as well as direct public or philanthropic funding"},{"id":384,"value":"Create an accessible repository of trustworthy information on the quality and safety of available edtech tools so that schools, education systems and parents can make more informed choices"},{"id":385,"value":"Develop education-specific standards covering product design, data use, and life cycle governance and accountability to guide purchasing decisions and assist industry access to the sector."},{"id":386,"value":"Build public-private partnerships to safely share data for better traction on solving education challenges, and to apply advanced data techniques to help optimise outcomes for students at risk."}],"FLAG":""},{"id":72,"order":"71.00000000000000000000","submission_number":"72","Submitter":"Associate Professor Erica Southgate","Type of org":{"id":977286,"value":"individual-academic","color":"dark-blue"},"Notes":"","Recommendations":[],"Uses-opportunities":[{"id":293,"value":"Generative AI is the cool new tool for school"},{"id":294,"value":"Access to AI tools is a matter of equity"},{"id":295,"value":"AI-proofing assessment is imperative"},{"id":296,"value":"Technological solutionism will not fix the problem"},{"id":297,"value":"Forming a position on the ethics of AI and automation in education needs to happen urgently"}],"Risks-challenges":[{"id":260,"value":"AI systems may discriminate in ways that are without precedent\nand that there are currently few means of detecting or investigating this to prevent discrimination"},{"id":261,"value":"this can hinder the collection of evidence to mount\na prima facie case for new forms of discrimination"},{"id":262,"value":"AI will be\nradically disruptive to career education generally including the possible decimation of the career\npipeline for creative industries"},{"id":263,"value":"humans anthropomorphise and can overly trust machines"}],"References-footnotes":[{"id":599,"value":"Wachter, S., Mittelstadt, B., & Russell, C. (2021). Why fairness cannot be automated: Bridging the gap\nbetween EU non-discrimination law and AI. Computer Law & Security Review, 41, 105567."},{"id":600,"value":"Williams, A., Miceli, M., & Gebru, T. (2022). The exploited labor behind artificial intelligence. Noema\nMagazine, 13."},{"id":601,"value":"Southgate, E. & Judge, I. (2022). The new machine age for English teachers: The pedagogical\npossibilities and pitfalls of artificial intelligence. Metaphor, (2), pp. 10-16."},{"id":602,"value":"Southgate, E., Blackmore, K., Pieschl, S., Grimes, S., McGuire, J., & Smithers, K. (2019). Artificial\nintelligence and emerging technologies (augmented, in schools. Retrieved\nhttps://www.education.gov.au/supporting-family-school-community-partnershipslearning/resources/ai-schools-report"},{"id":603,"value":"Southgate, E. (2021). Deep fakes, authenticity and authentication in the age of artificial intelligence.\nProfessional Voice 13:3, p. 41-9. Retrieved\nhttps://www.aeuvic.asn.au/sites/default/files/Professional%20Voice/PV 13.3/PV 2021 13.3 Compl\nete.pdf#page=41"},{"id":604,"value":"Southgate, E. (2020). Artificial intelligence, ethics, equity and higher education: A â€˜beginning-of-thediscussionâ€™ paper. National Centre in Student Equity and Higher Education (Curtin University).\nRetrieved http://ncsehe.edu.au/wp-content/uploads/2020/07/Southgate AI-Equity-HigherEducation FINAL.pdf"},{"id":605,"value":"Southgate, E. (2019c) Artificial intelligence in schools: an ethical storm is brewing. The Mandarin\nRetrieved https://www.themandarin.com.au/author/erica-southgate/ and EduResearch Matters and\nhttps://www.aare.edu.au/blog/?p=4325"},{"id":606,"value":"Southgate, E. (2019b) Educator! Itâ€™s time to talk about how artificial intelligence will rock our world.\nCampus Morning Mail. Retrieved https://campusmorningmail.com.au/news/educators-its-time-totalk-about-how-artificial-intelligence-will-rock-our-world/"},{"id":607,"value":"Southgate, E. (2019a) AI did my homework. Retrieved\nhttps://ericasouthgateonline.wordpress.com/2019/03/06/ai-did-my-homework/"},{"id":608,"value":"Electronic Privacy Information Center (2023). Generating harms: Generative AIâ€™s Impact and paths\nforward. Retrieved https://epic.org/wp-content/uploads/2023/05/EPIC-Generative-AI-White-PaperMay2023.pdf"}],"Processed":true,"Recco_tags":[],"Lookup":[]},{"id":73,"order":"72.00000000000000000000","submission_number":"73","Submitter":"Charles Darwin University","Type of org":{"id":977279,"value":"University","color":"darker-blue"},"Notes":"","Recommendations":[{"id":358,"value":"where there are opportunities for TESQA to support AI-related transformation, these should also be adapted and adopted, where appropriate by ASQA."},{"id":359,"value":"TEQSA and ASQA develop modules that all students can undertake in relation to Academic Integrity, similar to what has been developed for higher education providers by TEQSA for their staff, in the â€˜Academic Integrity Masterclassâ€™ online resources."},{"id":360,"value":"AI be progressed as a potential equaliser for disadvantaged students and that techniques on appropriate use be developed, agreed on and promoted across the sector."},{"id":361,"value":"where any guidance notes and online resources are provided by TESQA, there is facility for these to keep pace with technology so that they do not become redundant."},{"id":362,"value":"there be further investment in professional development, including Microcredentials for\nacademic teaching staff on the use and usability of Generative AI."},{"id":363,"value":"the Inquiry acknowledge the funding implications arising from workload pressures associated\nwith generative AI and refer these funding implications to the Universities Accord process."}],"Uses-opportunities":[],"Risks-challenges":[],"References-footnotes":[],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":362,"database_table_184385":1},"value":{"id":980196,"value":"PD","color":"light-red"}},{"ids":{"database_table_183319":363,"database_table_184385":8},"value":{"id":980188,"value":"new-workforce-model","color":"light-brown"}},{"ids":{"database_table_183319":358,"database_table_184385":19},"value":{"id":980186,"value":"capacity-building","color":"light-yellow"}},{"ids":{"database_table_183319":359,"database_table_184385":19},"value":{"id":980186,"value":"capacity-building","color":"light-yellow"}},{"ids":{"database_table_183319":361,"database_table_184385":19},"value":{"id":980186,"value":"capacity-building","color":"light-yellow"}},{"ids":{"database_table_183319":360,"database_table_184385":22},"value":{"id":980198,"value":"marginalised-group-engagement","color":"light-pink"}}],"Lookup":[{"id":358,"value":"where there are opportunities for TESQA to support AI-related transformation, these should also be adapted and adopted, where appropriate by ASQA."},{"id":359,"value":"TEQSA and ASQA develop modules that all students can undertake in relation to Academic Integrity, similar to what has been developed for higher education providers by TEQSA for their staff, in the â€˜Academic Integrity Masterclassâ€™ online resources."},{"id":360,"value":"AI be progressed as a potential equaliser for disadvantaged students and that techniques on appropriate use be developed, agreed on and promoted across the sector."},{"id":361,"value":"where any guidance notes and online resources are provided by TESQA, there is facility for these to keep pace with technology so that they do not become redundant."},{"id":362,"value":"there be further investment in professional development, including Microcredentials for\nacademic teaching staff on the use and usability of Generative AI."},{"id":363,"value":"the Inquiry acknowledge the funding implications arising from workload pressures associated\nwith generative AI and refer these funding implications to the Universities Accord process."}]},{"id":74,"order":"73.00000000000000000000","submission_number":"74","Submitter":"Dr William Billingsley","Type of org":{"id":977286,"value":"individual-academic","color":"dark-blue"},"Notes":"","Recommendations":[{"id":355,"value":"Mapping the identity verified assessment methods that are used across degrees, to inform accrediting bodies and reviewers as they periodically inspect our offerings"},{"id":356,"value":"Focusing identity verification efforts on the assessments that are most closely tied to the learning outcomes of the degree"},{"id":357,"value":"Generating evidence of authenticity of studentsâ€™ work, rather than only seeking\nto detect misconduct"}],"Uses-opportunities":[{"id":270,"value":"Makes learning proddable by allowing users to interact and see how it behaves"},{"id":271,"value":"Builds a mental model aligned with desired problem-solving approaches"},{"id":272,"value":"Provides faster feedback loop than traditional pedagogical advice"},{"id":273,"value":"Enables live interaction with a system for effective learning"},{"id":274,"value":"Supports smart interactive education and reactive learning environments"},{"id":275,"value":"Externalizes thinking processes for better exploration and understanding"},{"id":276,"value":"Enhances cognitive apprenticeships in teaching problem-solving skills"},{"id":277,"value":"Offers intelligent tutoring systems for personalized and varied learning experiences"},{"id":278,"value":"Supports wordy and non-symbolic questions"},{"id":279,"value":"Bridges the gap between models and the nature of questions"},{"id":280,"value":"Works well with text-based tasks and broad topics"},{"id":281,"value":"Provides variety in interactive exercises"},{"id":282,"value":"Can mitigate gaps and imperfections in output through clever activity design"},{"id":283,"value":"Offers simplicity in conceptually complex problems"},{"id":284,"value":"Facilitates easier understanding of AI systems through artificial simplicity"},{"id":285,"value":"Reduces the learning burden for students"},{"id":286,"value":"Provides a good conceptualization of problems for easier understanding"},{"id":287,"value":"Enables quick development of interactive exercises"},{"id":288,"value":"Familiarity of users with generative AI reduces the learning curve"},{"id":289,"value":"Availability of APIs makes it easy to integrate generative AI models"},{"id":290,"value":"Close fit between generative AI training data and educational materials"},{"id":291,"value":"Generative AI models perform well in answering questions in courses"},{"id":292,"value":"Recognizes specific prompts and can provide answers aligned with educators' comments"}],"Risks-challenges":[{"id":259,"value":"A key risk that academics are concerned about with Generative AI is the ease with\nwhich students can use it to generate answers to questions, rather than thinking about\nthe answers themselves. Especially when they are being assessed."}],"References-footnotes":[{"id":581,"value":"William H. Billingsley. The Intelligent Book: technologies for intelligent\nand adaptive textbooks, focussing on Discrete Mathematics. Technical Report\nUCAM-CL-TR-719, University of Cambridge, Computer Laboratory, June\n2008."},{"id":582,"value":"William Billingsley and Peter Robinson. Student proof exercises using MathsTiles and Isabelle/HOL in an Intelligent Book. Journal of Automated Reasoning,\n39(2):181â€“218, 2007"},{"id":583,"value":"William Billingsley, Peter Robinson, Mark Ashdown, and Chris Hanson. Intelligent tutoring and supervised problem solving in the browser. In Proceedings\nof the IADIS International Conference WWW/Internet 2004, Madrid, Spain, pages\n806 â€“ 811, 2004"},{"id":584,"value":"John Seely Brown, R R Burton, and A G Bell. SOPHIE: A step towards a reactive learning environment. International Journal of Man-Machine Studies, 7:675â€“\n696, 1975"},{"id":585,"value":"Allan Collins, John Seely Brown, and Susan E Newman. Cognitive apprenticeship: Teaching the crafts of reading, writing, and mathematics. In Lauren B.\nResnick, editor, Knowing, learning, and instruction: Essays in honor of Robert Glaser,\npages 453â€“491. Laurence Erlbaum Associates, 1989."},{"id":586,"value":"Tobias Nipkow, Lawrence C. Paulson, and Markus Wenzel. Isabelleâ€™s Logics:\nHOL. Technische UniversitÃ¤t MÃ¼nchen, 2005."},{"id":587,"value":"William Billingsley and Peter Robinson. Searching questions, informal modelling, and massively multiple choice. In ALT-C 2007 Research Proceedings, pages\n159â€“168. Association for Learning Technology, 2007."},{"id":588,"value":"William Billingsley. Revisiting the Intelligent Book: Towards Seamless Intelligent Content and Continuously Deployed Courses. In ASCILITEâ€™s First Virtual\nConference. Proceedings ASCILITE 2020 in Armidale, pages 230â€“240, 2020."},{"id":589,"value":"William Billingsley and Jonathan Vitale. An accelerated cs0 for online matureage part-time students. In Proceedings of the 26th ACM Conference on Innovation\nand Technology in Computer Science Education V. 1, ITiCSE â€™21, page 526â€“532,New York, NY, USA, 2021. Association for Computing Machinery"},{"id":590,"value":"James Finnie-Ansley, Paul Denny, Brett A. Becker, Andrew Luxton-Reilly, and\nJames Prather. The robots are coming: Exploring the implications of openai\ncodex on introductory programming. In Proceedings of the 24th Australasian Computing Education Conference, ACE â€™22, page 10â€“19, New York, NY, USA, 2022.\nAssociation for Computing Machinery"},{"id":591,"value":"William Billingsley. Lightweight Mapping of Identify Verification Methods and\nSecondary Course Aspects: â€œSwiss Cheeseâ€ Modelling. In Reconnecting relationships through technology. Proceedings of the 39th International Conference on Innovation,\nPractice and Research in the Use of Educational Technologies in Tertiary Education, ASCILITE 2022 in Sydney, page e22199, 2022."},{"id":592,"value":"M. Baird and J. Clare. Removing the opportunity for contract cheating in business capstones: a crime prevention case study. International Journal for Educational Integrity, 13(6), 2017"},{"id":593,"value":"K. Rundle, G. Curtis, and J. Clare. Why students choose not to cheat. In\nT. Bretag, editor, A research agenda for academic integrity, pages 100â€“111. Elgar\nPublishing, 2020."},{"id":594,"value":"William Billingsley, Rosemary Torbay, Peter R. Fletcher, Richard N. Thomas,\nJim R. H. Steel, and JÃ¶rn Guy SÃ¼ÃŸ. Taking a studio course in distributed software\nengineering from a large local cohort to a small global cohort. ACM Trans.\nComput. Educ., 19(2), jan 2019."},{"id":595,"value":"https://theintelligentbook.com/thinkingaboutprogramming"},{"id":596,"value":"https://github.com/tweakedinfo/lightweight-mappings-site"},{"id":597,"value":"https://tweakedinfo.github.io/lightweight-mappings-site"},{"id":598,"value":"https://github.com/tweakedinfo/lightweight-mappings-minimal"}],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":355,"database_table_184385":6},"value":{"id":980185,"value":"new-assessment-models","color":"darker-pink"}},{"ids":{"database_table_183319":356,"database_table_184385":6},"value":{"id":980185,"value":"new-assessment-models","color":"darker-pink"}},{"ids":{"database_table_183319":357,"database_table_184385":6},"value":{"id":980185,"value":"new-assessment-models","color":"darker-pink"}}],"Lookup":[{"id":355,"value":"Mapping the identity verified assessment methods that are used across degrees, to inform accrediting bodies and reviewers as they periodically inspect our offerings"},{"id":356,"value":"Focusing identity verification efforts on the assessments that are most closely tied to the learning outcomes of the degree"},{"id":357,"value":"Generating evidence of authenticity of studentsâ€™ work, rather than only seeking\nto detect misconduct"}]},{"id":76,"order":"75.00000000000000000000","submission_number":"75","Submitter":"Monash DeepNeuron","Type of org":{"id":977287,"value":"University-centre","color":"orange"},"Notes":"","Recommendations":[{"id":348,"value":"Conducting Internal Research: Universities and other tertiary institutions should conduct comprehensive internal research studies to evaluate the scope and limitations when implementing GAI. This could include an assessment of potential biases, cautions and considerations, and also informed recommendations on suitable GAI programs to use."},{"id":349,"value":"Implementing Fact-Checking Mechanisms: Universities should place an emphasis on educating students on fact-checking techniques to combat disinformation and ensure accuracy and reliability of information"},{"id":350,"value":"Establishing Clear Usage Guidelines: Universities should develop usage guidelines for the utilisation of GAI. This should take into account the diversity between different subject matters and allow flexibility in its application. The guidelines should act as a framework which promotes responsible and ethical use of GAI systems"},{"id":351,"value":"Custom GAI Solutions: Universities can explore the idea of developing their own in-house GAI systems to address privacy concerns associated with using open-source GAI such as ChatGPT. This approach would allow universities to maintain greater control over data privacy such as private work and sensitive data"},{"id":352,"value":"Assessments with emphasis on analytical thinking: Staff should consider developing assessments that prioritise analytical thinking skills over rote memorisation, aligning with the integration of GAI. Assessments should be designed to assess higher-order cognitive skills\nthat are complemented by the use of GAI"},{"id":353,"value":"Promote education and awareness of GAI: Comprehensive education and awareness initiatives on GAI are recommended as they ensure that staff and students are well-informed about its capabilities, risks and ethical considerations"},{"id":354,"value":"Encouraging staff to automate repetitive tasks: Tasks such as attendance tracking housekeeping and template creation can be automated by staff so that they can allocate their time more efficiently to higher-value tasks"}],"Uses-opportunities":[{"id":242,"value":"Customise learning experiences"},{"id":243,"value":"Enhance student performance"},{"id":244,"value":"Boost effectiveness of teaching and learning"},{"id":245,"value":"Facilitate personalised learning"},{"id":246,"value":"Amplify strengths in delivering specialised knowledge and essential skills"},{"id":247,"value":"Foster critical and creative thinking"},{"id":248,"value":"Shift focus from rote learning to critical thinking skills"},{"id":249,"value":"Engage students more effectively"},{"id":250,"value":"Bridge the gap between theory and practice in learning design"},{"id":251,"value":"Support individualized learning designs"},{"id":252,"value":"Improve students' perceptions of their own capability, motivation, and engagement"},{"id":253,"value":"Address challenges in blended and online learning delivery"},{"id":254,"value":"Develop resources for personalised learning"},{"id":255,"value":"Save time and resources in preparing learning activities"},{"id":256,"value":"Promote inclusivity and positive interpersonal relationships"},{"id":257,"value":"Create a conducive learning environment"},{"id":258,"value":"Motivate learners to engage in critical thought and take charge of their learning journey"},{"id":259,"value":"Foster an inclusive and universally accessible educational framework"},{"id":260,"value":"Provide psychological comfort and reassurance for students"},{"id":261,"value":"Encourage students to ask questions without fear of judgment"},{"id":262,"value":"Address gaps in knowledge and help students keep up with the curriculum"},{"id":263,"value":"Break boundaries of hesitation and social discernment in learning"},{"id":264,"value":"Provide adaptive learning and personalised support"},{"id":265,"value":"Reduce teachers' workload and enable more interaction with students"},{"id":266,"value":"Equips students with AI competency as an employable skill"},{"id":267,"value":"Provides comprehension and capabilities to operate and manage AI"},{"id":268,"value":"Prepares students for future workplaces that utilize AI technology"},{"id":269,"value":"Increases awareness of AI limitations"}],"Risks-challenges":[{"id":254,"value":"Biased data"},{"id":255,"value":"Inaccuracy of output and promoting disinformation"},{"id":256,"value":"Privacy violations"},{"id":257,"value":"Diminishing face to face interaction"},{"id":258,"value":"Threat to academic integrity"}],"References-footnotes":[{"id":550,"value":"https://russellgroup.ac.uk/media/6137/rg_ai_principles-final.pdf"},{"id":551,"value":"https://qz.com/russel-uk-universities-generative-ai-students-1850603771"},{"id":552,"value":"https://fortune.com/2023/06/03/ai-to-help-teach-harvard-university-online-computer-science-course/"},{"id":553,"value":"https://educational-innovation.sydney.edu.au/teaching@sydney/frequently-asked-questions-about-generative-ai-at-sydney/"},{"id":554,"value":"https://www.monash.edu/learning-teaching/teachhq/Teaching-practices/artificial-intelligence/generative-ai-and-assessment"},{"id":555,"value":"https://www.uow.edu.au/about/governance/academic-integrity/students/ai_chatgpt/"},{"id":556,"value":"https://www.adelaide.edu.au/student/academic-skills/ua/media/234/artificial-intelligence-student-slides-v0.1.pdf"},{"id":557,"value":"https://www.monash.edu/learning-teaching/teachhq/Teaching-practices/artificial-intelligence/policy-and-practice-guidance-around-acceptable-and-responsible-use-of-ai-technologies"},{"id":558,"value":"https://educational-innovation.sydney.edu.au/teaching@sydney/how-ai-can-be-used-meaningfully-by-teachers-and-students-in-2023/"},{"id":559,"value":"https://www.canberratimes.com.au/story/8162979/how-ai-has-made-cheating-widespread-in-australian-schools/"},{"id":560,"value":"http://www.monash.edu/learning-teaching/teachhq/Teaching-practices/artificial-intelligence/policy-and-practice-guidance-around-acceptable-and-responsible-use-of-ai-technologies.%20Accessed%209%20July%202023"},{"id":561,"value":"https://arxiv.org/abs/2303.08774"},{"id":562,"value":"https://education.unimelb.edu.au/__data/assets/pdf_file/0010/4677040/Generative-AI-research-report-Ziebell-Skeat.pdf"},{"id":563,"value":"http://www.smh.com.au/education/university-cheats-on-notice-after-launch-of-chatgpt-detection-software-20230403-p5cxpc.html"},{"id":564,"value":"Page, C. (2021) Is Ai making US lazy?, ITPro. Available at:\nhttps://www.itpro.com/technology/artificial-intelligence-ai/359557/is-ai-making-us-lazy (Accessed: 10 July 2023)."},{"id":565,"value":"Anderson, J. and Rainie, L. (2018) Artificial Intelligence and the future of humans, Pew Research Center:\nInternet, Science & Tech. Available at:\nhttps://www.pewresearch.org/internet/2018/12/10/artificial-intelligence-and-the-future-of-humans/ (Accessed: 10\nJuly 2023)."},{"id":566,"value":"Kelly, S.M. (2023) CHATGPT passes exams from law and Business Schools | CNN business, CNN. Available\nat: https://edition.cnn.com/2023/01/26/tech/chatgpt-passes-exams/index.html (Accessed: 10 July 2023)."},{"id":567,"value":"Rimbar, H. (2017) The influence of spell-checkers on studentsâ€™ ability to generate ..., Journal of Nusantara\nStudies . Available at:\nhttps://www.researchgate.net/publication/326014514_THE_INFLUENCE_OF_SPELL-CHECKERS_ON_STUDE\nNTS%27_ABILITY_TO_GENERATE_REPAIRS_OF_SPELLING_ERRORS (Accessed: 10 July 2023)."},{"id":568,"value":"Henebery, B. (2023) Generative AI: The risks, strategies, and opportunities for Schools, The Educator K/12.\nAvailable at:\nhttps://www.theeducatoronline.com/k12/news/generative-ai-the-risks-strategies-and-opportunities-for-schools/282\n397 (Accessed: 10 July 2023)."},{"id":570,"value":"https://journals.sagepub.com/doi/epub/10.1177/02663821231183756"},{"id":571,"value":"Baidoo-Anu, D., & Owusu Ansah, L. (2023). Education in the era of generative artificial intelligence (AI):\nUnderstanding the potential benefits of ChatGPT in promoting teaching and learning. SSRN.\nhttp://dx.doi.org/10.2139/ssrn.4337484.\nSee for example\nhttps://www.abc.net.au/news/2023-06-09/lawyers-blame-chatgpt-for-tricking-them-into-citing-fake-cases/1024620\n28"},{"id":572,"value":"Mogali, S. R. (2023). Initial impressions of ChatGPT for anatomy education. Anatomical Sciences Education,\n1-4. https://doi.org/10.1002/ase.2261"},{"id":573,"value":"Tredinnick L (2023), The dangers of generative artificial intelligence, Business Information Review, 40(2)\nhttps://journals.sagepub.com/doi/epub/10.1177/02663821231183756"},{"id":574,"value":"Ghosh, S & Caliskan, A (2023). ChatGPT perpetuates gender bias in machine translation and ignores\nnon-gendered pronouns: finding across Bengali and five other low resource languages, Proceedings of\nAAAI/ACM Conference on AI, Ethics, and Society https://arxiv.org/pdf/2305.10510.pdf"},{"id":575,"value":"Janssen, M., & Kuk, G. (2016). The challenges and limits of big data algorithms in technocratic governance,\nGovernment Information Quarterly, 33(3) 371-377. https://doi.org/10.1016/j.giq.2016.08.011"},{"id":576,"value":"https://www.chiefscientist.gov.au/sites/default/files/2023-06/Rapid%20Response%20Information%20Report%20-%20Generative%20AI%20v1_1.pdf"},{"id":577,"value":"https://lens.monash.edu/@medicine-health/2023/01/06/1385374/rising-from-the-ashes-higher-education-in-the-age-of-ai"},{"id":578,"value":"https://ajet.org.au/index.php/AJET/article/view/3776/1529"},{"id":579,"value":"https://pdf.sciencedirectassets.com/271802/1-s2.0-S0747563221X00064/1-s2.0-S0747563221001424/main.pdf?X-Amz-Security-Token=IQoJb3JpZ2luX2VjEPv%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJIMEYCIQDmBWDs4MyDenKBexNOoWWwXuBFQRaWaW0P8J%2BOcle9AQIhAIktGEMWGR3YgqU1Uvi44SHejHD0deIjhAf4%2FN3YlRjBKrIFCHQQBRoMMDU5MDAzNTQ2ODY1IgzcW4MvLNAd%2BgpTELgqjwXxWNZTiYwtn3mnpdFtewpWnMfzjLKrW%2BbMiFS52q0QFF%2Fwgx4Qot4oWv72Yif%2BZXJx4cUil3R9esvV3ahvuf8yt64u%2Bgpl7fOeXQpqfs8H%2BlIY9IuXC%2FSWAVz7zw%2B9UqhLOGuGwEYLkxthRh6xzCb5ADJ2%2FnUQXZ%2FjgJe70bbPfFHAj622NJz0uFwF3ocmu0PzHq517OcIU9NPV8fDHbHal7gBERHZcRv4xCUCqQ2UNINERohfPH9fKKhAuxa5b8hBqMpIBX%2BGjsr8Gq3FC2s2WmlQpsUH2cuMPAccp72u1xXnekCvH%2BA%2B9mfvpoGcGRmarUltZGdFz1cFWShgpYaEnP49Kye8DGK0XgcOwQug9%2FsZAyA6tZYPpxnZ7NlKrNguvGBa010QC5NcmwW7Ff2mKCP4eDJF%2BjWcRBTmqhzhse41J40M6mdoNIp4DUrvN8PDkp8jh0EnEnYwdSBsN%2FrYBeSAV2CHajrjCoGMGvY1jIIvDnIfRI9C0sPa4yEEre5r8gR6Veqr3aWO6Jrafu1OAFmIpxR206nEaOaLzhgc%2BUNpRGL4Fz9I4tcSVPZMlTvdNEnNh%2B1puhOx6WYfoL7uYUJoB7a3QLZt20goZC8Yj1BQtprC8X%2B7g%2Bmf5kcTHU4lWelEDEL2FaJKvLofyRZ5sps6wifsYHC2ynIgQS%2BVBJzZLIN7WwNemrE3rEJxsM43Uaoz17GkhD0D0BtkaeqBkUaWSkkrEESInOAqi6hIvL09hgyy7hMR%2BJyMYCPu4l8Kt7eHQVozdb5sKqNYbQAqovL78FZY5G%2BOOTn%2BsVbRL9voVIeiH%2FpKDIxortHwsXUmOhnC15USziD2FR%2Fd29m0e3ODnn%2FNtfnbvL8JIuUQMMf8pKUGOrABe5ussyea%2BBBVaQZrtk1ibUEC%2BWGLgaEOQtJBx%2F7BoR8VqlBX7Q%2Bchs6JfwUJKqEU0yJrvXuMtDvtxKeDGyzEG2EHjlfMSfpvpLXzTLJqj9hqy4ABEJ79I4pu8Hu9%2FcDrFi7v8faHaTxYsVrn%2FnTDeq2uxeVUCtGXFpNtxUQMTFw3T6DjQDTKwCZW7qN4cVZduV5lxARRCeG878crl5BP1NIxSfC0oHGGLpQqQ%2FsIuBg%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20230708T115504Z&X-Amz-SignedHeaders=host&X-Amz-Expires=300&X-Amz-Credential=ASIAQ3PHCVTYZOMVHYXT%2F20230708%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Signature=2bfb8f383f4e38d7b28a3bb0aad02883006e51fc322062230bc2d4154b00e9e1&hash=cf494322e908a21e8a5170f05e3c1b4e2692d4cbd53ea3707a39e19cc659345a&host=68042c943591013ac2b2430a89b270f6af2c76d8dfd086a07176afe7c76c2c61&pii=S0747563221001424&tid=spdf-b424ed52-a583-4308-9b99-a149fd4cbc1c&sid=3a9437fa86e0e043f628b8997a55e52bfde3gxrqa&type=client&ua=1b1a560a5c5654540554&rr=7e3822d27b3029ba&cc=au"},{"id":580,"value":"Higher Education Standards Framework (Threshold Standards) 2021 (Cth) s 1.4(2)."}],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":350,"database_table_184385":2},"value":{"id":980180,"value":"guidelines","color":"light-yellow"}},{"ids":{"database_table_183319":352,"database_table_184385":6},"value":{"id":980185,"value":"new-assessment-models","color":"darker-pink"}},{"ids":{"database_table_183319":354,"database_table_184385":8},"value":{"id":980188,"value":"new-workforce-model","color":"light-brown"}},{"ids":{"database_table_183319":349,"database_table_184385":10},"value":{"id":980190,"value":"curricula-changes","color":"light-green"}},{"ids":{"database_table_183319":353,"database_table_184385":14},"value":{"id":980193,"value":"prepare-learners","color":"dark-gray"}},{"ids":{"database_table_183319":348,"database_table_184385":21},"value":{"id":980197,"value":"evidence-generation","color":"brown"}},{"ids":{"database_table_183319":351,"database_table_184385":23},"value":{"id":980201,"value":"Australian-tech-and-models","color":"light-orange"}}],"Lookup":[{"id":348,"value":"Conducting Internal Research: Universities and other tertiary institutions should conduct comprehensive internal research studies to evaluate the scope and limitations when implementing GAI. This could include an assessment of potential biases, cautions and considerations, and also informed recommendations on suitable GAI programs to use."},{"id":349,"value":"Implementing Fact-Checking Mechanisms: Universities should place an emphasis on educating students on fact-checking techniques to combat disinformation and ensure accuracy and reliability of information"},{"id":350,"value":"Establishing Clear Usage Guidelines: Universities should develop usage guidelines for the utilisation of GAI. This should take into account the diversity between different subject matters and allow flexibility in its application. The guidelines should act as a framework which promotes responsible and ethical use of GAI systems"},{"id":351,"value":"Custom GAI Solutions: Universities can explore the idea of developing their own in-house GAI systems to address privacy concerns associated with using open-source GAI such as ChatGPT. This approach would allow universities to maintain greater control over data privacy such as private work and sensitive data"},{"id":352,"value":"Assessments with emphasis on analytical thinking: Staff should consider developing assessments that prioritise analytical thinking skills over rote memorisation, aligning with the integration of GAI. Assessments should be designed to assess higher-order cognitive skills\nthat are complemented by the use of GAI"},{"id":353,"value":"Promote education and awareness of GAI: Comprehensive education and awareness initiatives on GAI are recommended as they ensure that staff and students are well-informed about its capabilities, risks and ethical considerations"},{"id":354,"value":"Encouraging staff to automate repetitive tasks: Tasks such as attendance tracking housekeeping and template creation can be automated by staff so that they can allocate their time more efficiently to higher-value tasks"}]},{"id":77,"order":"76.00000000000000000000","submission_number":"76","Submitter":"UNSW","Type of org":{"id":977279,"value":"University","color":"darker-blue"},"Notes":"","Recommendations":[{"id":331,"value":"We encourage the sharing of knowledge and experiences, throuqh processes such as this inquiry, so that government, education institutions and industry can work together to discuss and devise practical methods to develop best practice use of GAI in the higher education sector"},{"id":332,"value":"We do not recommend further government regulation of the sector at this stage, but encourage a principles-based approach which encourages experimentation and embraces the appropriate use of GAI. Guidance from government and resources to assist universities to train and support staff is recommended as a better option than new regulation."},{"id":333,"value":"That the Australian Government provide funding support to universities to train staff in GAI literacy."},{"id":334,"value":"That the Australian Government: encourage key vendors to enter into institutional licences with universities that have unlimited use for staff and students"},{"id":335,"value":"That the Australian Government: consider reforms to discrimination law arising as a result of GAI and other AI systems; clarify the law on copyright of outputs, inputs and prompts on GAI"},{"id":336,"value":"That University accrediting bodies such as TEQSA engage with universities to discuss the use of AI in the workforce and in assessment"},{"id":337,"value":"TEQSA needs to be supported and funded to update regulatory requirements to allow universities to innovate and adapt in the new environment."},{"id":338,"value":"That the Australian Government re-establish the Australian Learning and Teaching Council or a similar body to collate and disseminate research and insights into GAI in education"},{"id":341,"value":"Universities should also take steps to respond to the emergence of GAI by adapting governance processes and quality assurance guidelines to allow more flexibility in assessment design and experimentation"},{"id":342,"value":"Oral (or viva) assessments where students provide verbal rather than written responses; Asking students to use specific techniques when solving problems; Asking students to analyse and critique responses generated by GAI; Mixing written assessment components with aspects requiring drawing, posters or videos; In-class quizzes for core concepts; Assessments where students reflect on what they have learned rather than necessarily produce a set answer"}],"Uses-opportunities":[{"id":234,"value":"For students, tools such as ChatGPT can proyide a summary of key research in a matter of minutes, saving students hours of online research, and training them how to effectively use such tools in the workplace following their graduation."},{"id":235,"value":"GAI tools can be used to translate resources making a wider range of web-based information available to students, or translating or correcting assessment tasks for students for whom English is not their primary language."},{"id":236,"value":"Students also use GAI tools to assist with â€™professionalâ€™ skills they may not have had exposure to, such as drafting resumes or composing emails to academics or prospective employers."},{"id":237,"value":"Often students use it to seek further explanation or clarification of issues raised in a lecture."},{"id":238,"value":"With proper privacy safeguards, GAI tools can be used to assist with indicative marks and generating feedback."},{"id":239,"value":"They can also be used in administrative documents, marketing and (when used with integrity, including attribution) the preparation of academic papers"},{"id":240,"value":"The workload efficiencies GAI promises may well mean that staff have more time to generate personal connections with students, enhancing the studentsâ€™ education."},{"id":241,"value":"One of the key impacts of the emergence of GAI has been the need to focus on the process of learning, rather than relying on a single assessment to judge academic progress."}],"Risks-challenges":[{"id":251,"value":"For students, relying on GAI may provide answers which lack depth, nuance or are just incorrect."},{"id":252,"value":"If relied on without appropriate scaffolding, it could reduce opportunities to learn key research and writing skills which are fundamental building blocks for tertiary education."},{"id":253,"value":"Some academics remain fearful that the teaching profession will be devalued by the use of GAI or may eventually be rendered obsolete"}],"References-footnotes":[{"id":548,"value":"https://tech.ed.gov/"},{"id":549,"value":"https://beta.jisc.ac.uk/reports/artificial-intelligence-in-tertiary-education"}],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":333,"database_table_184385":1},"value":{"id":980196,"value":"PD","color":"light-red"}},{"ids":{"database_table_183319":332,"database_table_184385":2},"value":{"id":980180,"value":"guidelines","color":"light-yellow"}},{"ids":{"database_table_183319":332,"database_table_184385":3},"value":{"id":980182,"value":"situate-with-existing-policy","color":"darker-red"}},{"ids":{"database_table_183319":336,"database_table_184385":6},"value":{"id":980185,"value":"new-assessment-models","color":"darker-pink"}},{"ids":{"database_table_183319":342,"database_table_184385":6},"value":{"id":980185,"value":"new-assessment-models","color":"darker-pink"}},{"ids":{"database_table_183319":335,"database_table_184385":11},"value":{"id":980191,"value":"new-policy","color":"dark-purple"}},{"ids":{"database_table_183319":337,"database_table_184385":11},"value":{"id":980191,"value":"new-policy","color":"dark-purple"}},{"ids":{"database_table_183319":341,"database_table_184385":11},"value":{"id":980191,"value":"new-policy","color":"dark-purple"}},{"ids":{"database_table_183319":333,"database_table_184385":17},"value":{"id":980195,"value":"resourcing","color":"dark-cyan"}},{"ids":{"database_table_183319":334,"database_table_184385":17},"value":{"id":980195,"value":"resourcing","color":"dark-cyan"}},{"ids":{"database_table_183319":331,"database_table_184385":19},"value":{"id":980186,"value":"capacity-building","color":"light-yellow"}},{"ids":{"database_table_183319":338,"database_table_184385":19},"value":{"id":980186,"value":"capacity-building","color":"light-yellow"}},{"ids":{"database_table_183319":335,"database_table_184385":38},"value":{"id":986019,"value":"respect-rights","color":"light-blue"}}],"Lookup":[{"id":331,"value":"We encourage the sharing of knowledge and experiences, throuqh processes such as this inquiry, so that government, education institutions and industry can work together to discuss and devise practical methods to develop best practice use of GAI in the higher education sector"},{"id":332,"value":"We do not recommend further government regulation of the sector at this stage, but encourage a principles-based approach which encourages experimentation and embraces the appropriate use of GAI. Guidance from government and resources to assist universities to train and support staff is recommended as a better option than new regulation."},{"id":333,"value":"That the Australian Government provide funding support to universities to train staff in GAI literacy."},{"id":334,"value":"That the Australian Government: encourage key vendors to enter into institutional licences with universities that have unlimited use for staff and students"},{"id":335,"value":"That the Australian Government: consider reforms to discrimination law arising as a result of GAI and other AI systems; clarify the law on copyright of outputs, inputs and prompts on GAI"},{"id":336,"value":"That University accrediting bodies such as TEQSA engage with universities to discuss the use of AI in the workforce and in assessment"},{"id":337,"value":"TEQSA needs to be supported and funded to update regulatory requirements to allow universities to innovate and adapt in the new environment."},{"id":338,"value":"That the Australian Government re-establish the Australian Learning and Teaching Council or a similar body to collate and disseminate research and insights into GAI in education"},{"id":341,"value":"Universities should also take steps to respond to the emergence of GAI by adapting governance processes and quality assurance guidelines to allow more flexibility in assessment design and experimentation"},{"id":342,"value":"Oral (or viva) assessments where students provide verbal rather than written responses; Asking students to use specific techniques when solving problems; Asking students to analyse and critique responses generated by GAI; Mixing written assessment components with aspects requiring drawing, posters or videos; In-class quizzes for core concepts; Assessments where students reflect on what they have learned rather than necessarily produce a set answer"}]},{"id":78,"order":"77.00000000000000000000","submission_number":"77","Submitter":"Australian Research Council","Type of org":{"id":977282,"value":"Govt","color":"orange"},"Notes":"","Recommendations":[],"Uses-opportunities":[],"Risks-challenges":[{"id":246,"value":"Authorship and intellectual property concerns"},{"id":247,"value":"Confidentiality and privacy of information, and integrity in the peer review process"},{"id":248,"value":"use of generative AI in the conduct of research; Australiaâ€™s research integrity framework"}],"References-footnotes":[{"id":544,"value":"https://www.arc.gov.au/sites/default/files/2023-07/Policy%20on%20Use%20of%20Generative%20Artificial%20Intelligence%20in%20the%20ARCs%20grants%20programs%202023.pdf"},{"id":545,"value":"https://www.nhmrc.gov.au/about-us/publications/australian-code-responsible-conduct-research-2018"},{"id":546,"value":"https://www.arc.gov.au/about-arc/program-policies/conflict-interest-and-confidentiality-policy"},{"id":547,"value":"https://www.arc.gov.au/about-arc/program-policies/research-integrity/research-integrity-policy"}],"Processed":true,"Recco_tags":[],"Lookup":[]},{"id":79,"order":"78.00000000000000000000","submission_number":"78","Submitter":"APRA AMCOS","Type of org":{"id":977281,"value":"Peak body","color":"green"},"Notes":"","Recommendations":[],"Uses-opportunities":[],"Risks-challenges":[{"id":243,"value":"Consent and Control"},{"id":244,"value":"Lack of Transparency"},{"id":245,"value":"Impact on Australian music creators"}],"References-footnotes":[],"Processed":true,"Recco_tags":[],"Lookup":[]},{"id":80,"order":"79.00000000000000000000","submission_number":"79","Submitter":"Andrew Duval","Type of org":{"id":977280,"value":"Individual","color":"gray"},"Notes":"","Recommendations":[{"id":327,"value":"Wholesale banning and policing are a waste of time. (Though there may be specific circumstances where AI needs to be excluded or policed.)"},{"id":328,"value":"Assessment absolutely needs to change, but assessment is a complex topic and agreeing on new assessment approaches at an institutional level will take time. Probably many other aspects of school need to change too: curriculum, content, timetables, year-level structures, pedagogical methods, etc.. Change to a competency based grading structure."}],"Uses-opportunities":[],"Risks-challenges":[],"References-footnotes":[],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":328,"database_table_184385":6},"value":{"id":980185,"value":"new-assessment-models","color":"darker-pink"}},{"ids":{"database_table_183319":327,"database_table_184385":11},"value":{"id":980191,"value":"new-policy","color":"dark-purple"}}],"Lookup":[{"id":327,"value":"Wholesale banning and policing are a waste of time. (Though there may be specific circumstances where AI needs to be excluded or policed.)"},{"id":328,"value":"Assessment absolutely needs to change, but assessment is a complex topic and agreeing on new assessment approaches at an institutional level will take time. Probably many other aspects of school need to change too: curriculum, content, timetables, year-level structures, pedagogical methods, etc.. Change to a competency based grading structure."}]},{"id":81,"order":"80.00000000000000000000","submission_number":"80","Submitter":"Copyright Agency","Type of org":{"id":977289,"value":"nonprofit","color":"darker-gray"},"Notes":"Not clear in addressing TOR, although does note a key concern: \"There are particular concerns among First Nations people about maintaining authenticity in relation to their culture, and control over how aspects of their culture is used by others. Governments and other policy makers need to bear these in mind when considering how AI can be harnessed for social good.\"","Recommendations":[],"Uses-opportunities":[],"Risks-challenges":[],"References-footnotes":[],"Processed":true,"Recco_tags":[],"Lookup":[],"FLAG":""},{"id":82,"order":"81.00000000000000000000","submission_number":"81","Submitter":"National Catholic Education Commission","Type of org":{"id":977281,"value":"Peak body","color":"green"},"Notes":"","Recommendations":[{"id":309,"value":"research the impacts of AI on childrenâ€™s cognition and meta-cognition"},{"id":310,"value":"design pedagogies and learning experiences that respond to a changing world with AI"},{"id":311,"value":"help students to use Al responsibly and with care in life and learning"},{"id":312,"value":"implement strategies for developing academic integrity"},{"id":313,"value":"reconsider acceptable use of AI in assessment, for example, tasks with no access to AI, and \ntasks where AI is explicitly integrated"},{"id":314,"value":"changes to assessment cognition used in online exams such as those directly related to \nstudent's experience and/or case and scenario-based activities that are directly related to key \nlearning experiences"},{"id":315,"value":"reconsider how creativity is defined and assessed"},{"id":316,"value":"develop policies about fair, responsible and ethical use of AI"},{"id":317,"value":"articulate the social implications of AI integration into society"},{"id":318,"value":"provide useful frameworks for schools and systems to evaluate and make decisions on which tools are fit for purpose such as due diligence processes for third party applications"},{"id":319,"value":"collaborate with relevant programs and agencies (e.g., ST4S and the esafety Commissionerâ€™s Office) to provide targeted information on Australian data security standards noting standards should encompass safety, security, privacy, ethical use, and responsible handling of data"},{"id":320,"value":"provide positive messaging for parents and the wider community on how AI is helping students to learn and grow, without taking from the important connections and relationships they build in their school life"},{"id":321,"value":"provide schools with worked examples including lesson plans on how teachers have used AI to enhance learning outcomes"},{"id":322,"value":"provide teachers with secure options for reducing their workload through harnessing AI"},{"id":323,"value":"consider any implications of AI for the Australian Institute for Teaching and School Leadership Professional Standards for Teachers"},{"id":324,"value":"continuously review and assess whether generative AI tools are meeting the needs of users and are being used in an effective and ethical manner"},{"id":325,"value":"undertake independent research and gather feedback from students, educators, researchers, and industry to develop actionable insights and ensure best practices are adopted"}],"Uses-opportunities":[{"id":215,"value":"A strength of generative AI for students is the ability to personalise learning and information \nto suit individual needs."},{"id":216,"value":"Providing autonomy and differentiation for learners of all ages to have content and concepts \npresented in multiple ways."},{"id":217,"value":"Generative AI tools have the capacity to act as virtual tutors and coaches for students to be \ncomplementary in learning"},{"id":218,"value":"With appropriate prompting, AI tools have the potential to reduce administrative tasks for \nteachers"},{"id":219,"value":"Assistance with ideation of learning tasks, catering to individual needs, curation of resources"},{"id":220,"value":"Whilst it will not replace the human element of teaching, it has significant promise to \nenhance the role of educators and reduce administrative burden."},{"id":221,"value":"Systems will have multiple benefits from leveraging generative AI within their own \necosystems, examples include, machine learning and analysis of data, creation of co-pilots \nand internal chat bots to assist staff and students."},{"id":222,"value":"deeper consideration of issues related to academic integrity"},{"id":223,"value":"ethical use of AI tools and age appropriateness"},{"id":224,"value":"nuanced and targeted pedagogical approaches e.g., in-class versus flexible and hybrid modes \nof learning and assessment"},{"id":225,"value":"allowing for learning to occur in collaborative classroom designs with automation supporting \nsome tasks"},{"id":226,"value":"assessment practices being more focussed on the assessment of deep learning of concepts"},{"id":227,"value":"allowing more opportunities for teachers and students to co-facilitate learning"},{"id":228,"value":"potential to both check and verify information whilst noting that AI tools can also generate \nmisleading, biased or inaccurate information"},{"id":229,"value":"there is potential for AI tools to assist those \nexperiencing disadvantage by custom-designed tools to assist with complex learning or social \nproblems"}],"Risks-challenges":[{"id":234,"value":"risks to \nthe learner-teacher relationship"},{"id":235,"value":"the ethical use of data and assessment results"},{"id":236,"value":"the data privacy \nand security of data using AI"},{"id":237,"value":"a challenge for ongoing academic and research integrity"},{"id":238,"value":"threat to using some forms of essays for assessment and for online exams"},{"id":239,"value":"reduces the social aspect of \nlearning and the agency of educators"},{"id":240,"value":"AI lacks an \nunderstanding of the context of learning"},{"id":241,"value":"o become a distraction and reduce a productive focus on \neffective teaching and learning"},{"id":242,"value":"Over reliance on AI may reduce opportunities for critical thinking and problem solving, and \ncreativity"}],"References-footnotes":[],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":318,"database_table_184385":2},"value":{"id":980180,"value":"guidelines","color":"light-yellow"}},{"ids":{"database_table_183319":319,"database_table_184385":3},"value":{"id":980182,"value":"situate-with-existing-policy","color":"darker-red"}},{"ids":{"database_table_183319":323,"database_table_184385":3},"value":{"id":980182,"value":"situate-with-existing-policy","color":"darker-red"}},{"ids":{"database_table_183319":312,"database_table_184385":6},"value":{"id":980185,"value":"new-assessment-models","color":"darker-pink"}},{"ids":{"database_table_183319":313,"database_table_184385":6},"value":{"id":980185,"value":"new-assessment-models","color":"darker-pink"}},{"ids":{"database_table_183319":314,"database_table_184385":6},"value":{"id":980185,"value":"new-assessment-models","color":"darker-pink"}},{"ids":{"database_table_183319":315,"database_table_184385":6},"value":{"id":980185,"value":"new-assessment-models","color":"darker-pink"}},{"ids":{"database_table_183319":322,"database_table_184385":8},"value":{"id":980188,"value":"new-workforce-model","color":"light-brown"}},{"ids":{"database_table_183319":310,"database_table_184385":14},"value":{"id":980193,"value":"prepare-learners","color":"dark-gray"}},{"ids":{"database_table_183319":311,"database_table_184385":14},"value":{"id":980193,"value":"prepare-learners","color":"dark-gray"}},{"ids":{"database_table_183319":317,"database_table_184385":16},"value":{"id":980194,"value":"communications","color":"darker-brown"}},{"ids":{"database_table_183319":320,"database_table_184385":16},"value":{"id":980194,"value":"communications","color":"darker-brown"}},{"ids":{"database_table_183319":321,"database_table_184385":19},"value":{"id":980186,"value":"capacity-building","color":"light-yellow"}},{"ids":{"database_table_183319":309,"database_table_184385":21},"value":{"id":980197,"value":"evidence-generation","color":"brown"}},{"ids":{"database_table_183319":325,"database_table_184385":21},"value":{"id":980197,"value":"evidence-generation","color":"brown"}},{"ids":{"database_table_183319":324,"database_table_184385":25},"value":{"id":980202,"value":"monitoring-impacts","color":"darker-red"}},{"ids":{"database_table_183319":316,"database_table_184385":39},"value":{"id":991258,"value":"foster-responsible-aied","color":"red"}}],"Lookup":[{"id":309,"value":"research the impacts of AI on childrenâ€™s cognition and meta-cognition"},{"id":310,"value":"design pedagogies and learning experiences that respond to a changing world with AI"},{"id":311,"value":"help students to use Al responsibly and with care in life and learning"},{"id":312,"value":"implement strategies for developing academic integrity"},{"id":313,"value":"reconsider acceptable use of AI in assessment, for example, tasks with no access to AI, and \ntasks where AI is explicitly integrated"},{"id":314,"value":"changes to assessment cognition used in online exams such as those directly related to \nstudent's experience and/or case and scenario-based activities that are directly related to key \nlearning experiences"},{"id":315,"value":"reconsider how creativity is defined and assessed"},{"id":316,"value":"develop policies about fair, responsible and ethical use of AI"},{"id":317,"value":"articulate the social implications of AI integration into society"},{"id":318,"value":"provide useful frameworks for schools and systems to evaluate and make decisions on which tools are fit for purpose such as due diligence processes for third party applications"},{"id":319,"value":"collaborate with relevant programs and agencies (e.g., ST4S and the esafety Commissionerâ€™s Office) to provide targeted information on Australian data security standards noting standards should encompass safety, security, privacy, ethical use, and responsible handling of data"},{"id":320,"value":"provide positive messaging for parents and the wider community on how AI is helping students to learn and grow, without taking from the important connections and relationships they build in their school life"},{"id":321,"value":"provide schools with worked examples including lesson plans on how teachers have used AI to enhance learning outcomes"},{"id":322,"value":"provide teachers with secure options for reducing their workload through harnessing AI"},{"id":323,"value":"consider any implications of AI for the Australian Institute for Teaching and School Leadership Professional Standards for Teachers"},{"id":324,"value":"continuously review and assess whether generative AI tools are meeting the needs of users and are being used in an effective and ethical manner"},{"id":325,"value":"undertake independent research and gather feedback from students, educators, researchers, and industry to develop actionable insights and ensure best practices are adopted"}]},{"id":83,"order":"82.00000000000000000000","submission_number":"82","Submitter":"Association of Heads of Independent Schools of Australia","Type of org":{"id":977281,"value":"Peak body","color":"green"},"Notes":"","Recommendations":[{"id":307,"value":"The need for high-level government engagement in generative AI issues to establish an ethical framework for product providers and users and to address issues such as copyright, privacy of usersâ€™ data and cyber security. Government guidelines are also sought to help maintain the academic integrity of Australiaâ€™s education system"},{"id":308,"value":"The need for governments to directly engage with upskilling of Australian teachers to build the capacity of the sector to harness the potential benefits of generative AI and to ensure equity in distribution of these benefits for both teachers and students"}],"Uses-opportunities":[{"id":191,"value":"Improvements in drafting, creative inputs, brainstorming in creative work, generating \nideas"},{"id":192,"value":"Assistance for students in research"},{"id":193,"value":"Improvements in the calibre of studentsâ€™ work"},{"id":194,"value":"Greater understanding of concepts"},{"id":195,"value":"Gains for students with literacy difficulties"},{"id":196,"value":"Improvement in student engagement"},{"id":197,"value":"Support student research"},{"id":198,"value":"Generate ideas for creative projects"},{"id":199,"value":"Offer feedback to improve written text"},{"id":200,"value":"Draft or check coding"},{"id":201,"value":"Find definitions of concepts that are more relevant or accessible"},{"id":202,"value":"Check mathematical calculations"},{"id":203,"value":"Generate presentation slides"},{"id":204,"value":"Generate illustrations"},{"id":205,"value":"Lesson plans or learning design"},{"id":206,"value":"Learning resources"},{"id":207,"value":"Ideas for curriculum unit outlines"},{"id":208,"value":"Discussion questions"},{"id":209,"value":"Rubrics for assessing student work"},{"id":210,"value":"Questions for Q&A sessions"},{"id":211,"value":"Summaries of articles"},{"id":212,"value":"Student assessment tasks eg quizzes, essay topics"},{"id":213,"value":"Articles for the school newsletter or school website"},{"id":214,"value":"Differentiated learning tasks"}],"Risks-challenges":[],"References-footnotes":[{"id":535,"value":"https://v9.australiancurriculum.edu.au/"},{"id":536,"value":"Recorded in the communique of the Education Ministers Meeting, 6 July 2023. Accessed at \nhttps://www.education.gov.au/collections/communiques-education-ministers-meeting-2023"},{"id":537,"value":"EdSurge Biz e-newsletter #609, 28 June 2023. Accessed at https://info.iste.org/more-shakeup\u0002in-the-market-to-help-colleges-run-online"},{"id":538,"value":"https://www.edresearch.edu.au/practice-hub/ochre-education."},{"id":539,"value":"South Australian Department for Education media release, 5 July 2023, â€˜Nation-leading trial in \nSA schools to focus on the safe use of AIâ€™. Accessed at \nhttps://www.education.sa.gov.au/department/media-centre/our-news/nation-leading-trial-in-sa\u0002schools-to-focus-on-the-safe-use-of-ai."}],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":308,"database_table_184385":1},"value":{"id":980196,"value":"PD","color":"light-red"}},{"ids":{"database_table_183319":307,"database_table_184385":2},"value":{"id":980180,"value":"guidelines","color":"light-yellow"}}],"Lookup":[{"id":307,"value":"The need for high-level government engagement in generative AI issues to establish an ethical framework for product providers and users and to address issues such as copyright, privacy of usersâ€™ data and cyber security. Government guidelines are also sought to help maintain the academic integrity of Australiaâ€™s education system"},{"id":308,"value":"The need for governments to directly engage with upskilling of Australian teachers to build the capacity of the sector to harness the potential benefits of generative AI and to ensure equity in distribution of these benefits for both teachers and students"}]},{"id":84,"order":"83.00000000000000000000","submission_number":"83","Submitter":"Centre for Digital Wellbeing","Type of org":{"id":977289,"value":"nonprofit","color":"darker-gray"},"Notes":"","Recommendations":[{"id":288,"value":"That the Government address privacy and data risks in the Privacy Act review by establishing a robust data protection framework that outlines the rights of students in relation to personal data as well as establishing limitations to the collection, use and retention of data of minors."},{"id":289,"value":"That the Government puts in place requirements for educational institutions and AI developers to have clear and transparent data use policies. These policies should outline the types of data collected, the purposes for which the data will be used, how long the data will be retained, and the measures taken to protect data privacy. These policies should be presented to users in a way that is age-appropriate and easy to understand."},{"id":290,"value":"That the Government provides specific powers to the Office of the Australian Information Commissioner to assess AI tools used in education should for their privacy impact. The assessment would identify potential risks to data privacy and outline measures to mitigate them before the tool can be implemented. The Office of the Australian Information Commissioner should be given the power to ban the implementation of AI tools if the risk to a usersâ€™ data privacy is too high."},{"id":291,"value":"That the Government requires AI developers and educational institutions to implement strong encryption and secure data storage practices. Government should provide support - both technical and financial â€“ to educational institutions to assist with meeting this requirement."},{"id":292,"value":"That the Government strengthens the role of and financial support to the Australian Information Commissioner to assist with the safe implementation and overseeing the use of AI tools in education settings in relation to data privacy."},{"id":293,"value":"That the Government considers the development of comprehensive legislation in relation to Generative AI drawing on international best-practice, like the European Union AI Act. It is crucial that a risk-based approach is taken which includes third party and independent impact and audit assessments, mandatory transparency reports, the human oversight of certain AI systems depending on level of risk, and accountability measures."},{"id":294,"value":"That the Government consider the establishment of a dedicated AI regulatory body assist regulators, policy makers and government in developing, enforcing and implementing legislation, in line with submissions made to â€œPositioning Australia as a Leader in Digital Economy Regulationâ€ and the Australian Human Rights Commissionâ€™s Human Rights and Technology Final Report (2021)."},{"id":295,"value":"That the Government increases public awareness and education programs to inform users about AIâ€™s potential implications and risks, to improve the ability of the users to hold companies and developers accountable and make informed decisions."},{"id":296,"value":"Educational institutions and AI developers should be required to have clear and transparent data use policies. These policies should outline the types of data collected, the purposes for which the data will be used, how long the data will be retained, and the measures taken to protect data privacy. These policies should be presented to users in a way that is age â€“ appropriate and easy to understand."},{"id":297,"value":"AI tools used in education should be assessed for their privacy impact by the Office of the Australian Information Commissioner. The assessment would identify potential risks to data privacy and outline measures to mitigate them before the tool can be implemented. The Office of the Australian Information Commissioner should be given the power to ban the implementation of AI tools if the risk to a usersâ€™ data privacy is too high."},{"id":298,"value":"Government can require AI developers and educational institutions to implement strong encryption and secure data storage practices. Government should provide support - both technical and financial â€“ to educational institutions to assist with meeting this requirement."},{"id":299,"value":"Government should strengthen the role of and financial support to the Australian Information Commissioner to assist with overseeing the use of AI tools in education settings in relation to data privacy."},{"id":300,"value":"Organisations developing AI tools should be required to conduct regular audits or impact assessments of their AI systems to address potential biases or unintended consequences. In order to ensure accountability, these assessments should be subject to external scrutiny."},{"id":301,"value":"Legislation should require organisations to publish transparency reports detailing how their AI systems are used, including any cases of significant impact on individuals or society. These reports would provide insights into how algorithms function in practice and how they affect users."},{"id":302,"value":"Legislation can grant users the right to access and understand the data collected about them and the algorithms used to make decisions based on that data. Users should have the opportunity to challenge or correct inaccurate information."},{"id":303,"value":"Legislation should mandate third party evaluations of AI tools and systems to ensure they meet certain criteria for transparency, fairness, and accountability. These evaluations should be conducted by independent auditors and regulatory bodies."},{"id":304,"value":"Legislation should require that critical decisions made by AI systems to have a human-in-the-loop component, where a human reviewer can examine and validate the systemâ€™s outputs before final decisions are implemented."},{"id":305,"value":"Legislation should establish accountability measures for organisations that deploy AI systems that lead to biased, discriminatory or harmful outcomes to help deter irresponsible AI development and use."},{"id":306,"value":"Government should also support public awareness campaigns and educational programs to inform the general public about AI technology and its potential implications to improve the ability of the public to hold organisations accountable and make informed decisions."}],"Uses-opportunities":[],"Risks-challenges":[{"id":228,"value":"concerns about data privacy \nand security regarding sensitive student information, parallel to similar challenges faced in recent years \nwith the integration of education technology into the classroom."},{"id":229,"value":"put childrenâ€™s rights at risk, monitoring them without their consent and allowing access from \nor selling the data to third parties"},{"id":230,"value":"making children particularly vulnerable to content and \nmicrotargeted marketing from brands trying to sell dangerous products such as alcohol, vapes or \ngambling"},{"id":231,"value":"it can cause severe anxiety, \na culture of distrust and symptoms similar to post-traumatic stress disorder"},{"id":232,"value":"Generative AI tools, like some EdTech applications, continuously gather data exposing children to the \nsame risks."},{"id":233,"value":"Generative AI models use machine learning models (MLM) which are trained using large datasets to \nperform a programmed function. If the training data predominantly represents a specific demographic, \nculture, or perspective, the generated output may reflect those biases and further entrench and exacerbate\ninequalities and stereotypes present in our societies"}],"References-footnotes":[{"id":503,"value":"eSafety Commissioner, Safety by Design. Available at https://www.esafety.gov.au/industry/safety-by-design\n[Accessed 10 July]"},{"id":504,"value":"Human Rights Watch. â€˜How Dare They Peep into My Private Life?â€™ â€“ Childrenâ€™s Rights Violations by Governments \nthat Endorsed Online Learning During the Covid-19 Pandemic. Available at \nhttps://www.hrw.org/report/2022/05/25/how-dare-they-peep-my-private-life/childrens-rights-violations\u0002governments. [Accessed 11 July"},{"id":505,"value":"The Conversation, How children are being targeted with hidden ads on social media, November 3, 2021. Available \nat https://theconversation.com/how-children-are-being-targeted-with-hidden-ads-on-social-media-170502. \n[Accessed 17 July]"},{"id":506,"value":"UNICEF. The childrenâ€™s rights-by-design standard for data use by tech companies, Issue brief no. 5, November 2020 \nGood Governance of Childrenâ€™s Data project Office of Global Insight and Policy. [Accessed 12 July]"},{"id":507,"value":"Vice, What Constant Surveillance Does to Your Brain, 14 November 2018. Available at \nhttps://www.vice.com/en/article/pa5d9g/what-constant-surveillance-does-to-your-brain. [Accessed 18 July]"},{"id":508,"value":"M Torres, A Mullins, & N Thompson, â€˜Education Cybersecurity Assessment Tool: A cybersecurity self-assessment \ntool for the Australian K-12 sectorâ€™, 2022. ACIS 2022 Proceedings. Available at https://aisel.aisnet.org/acis2022/96. \n[Accessed 12 July]"},{"id":509,"value":"The Conversation, What is a black box? A computer scientist explains what it means when the inner workings of \nAis are hidden, 22 May 2023. Available at https://theconversation.com/what-is-a-black-box-a-computer-scientist\u0002explains-what-it-means-when-the-inner-workings-of-ais-are-hidden-203888. [Accessed 11 July"},{"id":510,"value":"Innovation Australia, Inquiry to probe generative AI use in schools, higher ed, 25 May 2023. Available at \nhttps://www.innovationaus.com/inquiry-to-probe-ai-use-in-schools-higher\u0002ed/#:~:text=A%20parliamentary%20inquiry%20will%20examine,technology%20is%20here%20to%20stay.\n[Accessed 15 July]"},{"id":511,"value":"Pursuit, The Flawed Algorithm at the Heart of Robodebt, 10 July 2023. Available at \nhttps://pursuit.unimelb.edu.au/articles/the-flawed-algorithm-at-the-heart-of-robodebt. [Accessed 20 July]"},{"id":512,"value":"The Age, Kathleen Madgwich tells Robodebt royal commission about her son Jarred and the damage the scheme \ncaused, 10 March 2023. Available at https://www.abc.net.au/news/2023-03-10/qld-robodebt-scheme\u0002government-royal-commission-fraud/102027838. [Accessed 17 July"},{"id":513,"value":"The Age, Workload, lack of respect among key causes of why teachers leave profession, research finds, 26 April \n2023. Available at https://www.abc.net.au/news/2023-04-26/teaching-crisis-studied-in-national-research-by\u0002federation-uni/102254252. [Accessed 9 July"},{"id":514,"value":"Australian Education Union, South Australian Branch, Fix the Crisis. Available at https://www.fixthecrisis.com.au/. \n[Accessed 9 July]"},{"id":515,"value":"Australian Education Union, Tasmanian Branch, The real state of Tasmanian Education. Available at \nhttps://aeutas.sgp1.digitaloceanspaces.com/2023/02/Real-State-of-Tasmanian-Education.pdf. [Accessed 9 July"},{"id":516,"value":"T P Ivanec, The Lack of Academic Social Interactions and Studentsâ€™ Learning Difficulties during the COVID-19 \nFaculty Lockdowns in Croatia: The Mediating Role of the Perceived Sense of Life Disruption Caused by the Pandemic \nand the Adjustment to Online Studying, 2022. Available at https://www.mdpi.com/2076-0760/11/2/42. [Accessed \n17 July]"},{"id":517,"value":"UNESCO, Artificial Intelligence: examples of ethical dilemmas, 21 April 2023. Available at\nhttps://www.unesco.org/en/artificial-intelligence/recommendation-\n.ethics/cases#:~:text=But%20there%20are%20many%20ethical,and%20privacy%20of%20court%20users. [Accessed \n10 July]"},{"id":518,"value":"Reuters, Amazon scrapes secret AI recruiting tool that showed bias against women, 11 October 2018. Available at \nhttps://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-ai-recruiting\u0002tool-that-showed-bias-against-women-idUSKCN1MK08G. [Accessed 11 Jul"},{"id":519,"value":"N Gaskins, Interrogating Algorithmic Bias: From Speculative Fiction to Liberatory Design, 2022. Available at \nhttps://link.springer.com/article/10.1007/s11528-022-00783-\n0#:~:text=Section%202%3A%20Algorithmic%20Bias%20in,AI%20and%20machine%20learning%20systems. \n[Accessed 10 July]"},{"id":520,"value":"Axios, How an AI grading system ignited a national controversy in the UK, 20 August 2020. Available at \nhttps://www.axios.com/2020/08/19/england-exams-algorithm-grading. [Accessed 11 July]"},{"id":521,"value":"European Commission, Europeâ€™s Digital Decade: digital targets for 2030. Available at \nhttps://commission.europa.eu/strategy-and-policy/priorities-2019-2024/europe-fit-digital-age/europes-digital\u0002decade-digital-targets-2030_en. [Accessed 17 July"},{"id":522,"value":"European Commission, Shaping Europeâ€™s digital future - Regulatory framework proposal on artificial intelligence, \n20 June 2023. Available at https://digital-strategy.ec.europa.eu/en/policies/regulatory-framework-ai. [Accessed 17 \nJuly]"},{"id":523,"value":"European Commission, Shaping Europeâ€™s digital future - Regulatory framework proposal on artificial intelligence, \n20 June 2023. Available at https://digital-strategy.ec.europa.eu/en/policies/regulatory-framework-ai. [Accessed 17 \nJuly]"},{"id":524,"value":"M Kop, EU Artificial Intelligence Act: The European Approach to AI, Stanford - Vienna Transatlantic Technology \nLaw Forum, Transatlantic Antitrust and IPR Developments, Stanford University, Issue No. 2/2021. Available at \nhttps://futurium.ec.europa.eu/sites/default/files/2021-10/Kop_EU%20Artificial%20Intelligence%20Act%20-\n%20The%20European%20Approach%20to%20AI_21092021_0.pdf."},{"id":527,"value":"King & Wood Malleson, Developments in the Regulations of Artificial Intelligence, 19 April 2023. Available at \nhttps://www.kwm.com/global/en/insights/latest-thinking/developments-in-the-regulation-of-artificial\u0002intelligence.html. [Accessed 16 J"},{"id":528,"value":"M Kop, EU Artificial Intelligence Act: The European Approach to AI, Stanford - Vienna Transatlantic Technology \nLaw Forum, Transatlantic Antitrust and IPR Developments, Stanford University, Issue No. 2/2021. Available at \nhttps://futurium.ec.europa.eu/sites/default/files/2021-10/Kop_EU%20Artificial%20Intelligence%20Act%20-\n%20The%20European%20Approach%20to%20AI_21092021_0.pdf."},{"id":529,"value":"King & Wood Malleson, Developments in the Regulations of Artificial Intelligence, 19 April 2023. Available at \nhttps://www.kwm.com/global/en/insights/latest-thinking/developments-in-the-regulation-of-artificial\u0002intelligence.html. [Accessed 16 July]"},{"id":530,"value":"28 The White House, Blueprint for an AI Bill of Rights. Available at https://www.whitehouse.gov/ostp/ai-bill-of\u0002rights/. [Accessed 19 July"},{"id":531,"value":"Brookings, Opportunities and blind spots in the White Houseâ€™s blueprints for an AI Bill of Rights, 19 December \n2022. Available at https://www.brookings.edu/articles/opportunities-and-blind-spots-in-the-white-houses\u0002blueprint-for-an-ai-bill-of-rights/. [Accessed 20 July"},{"id":532,"value":"IAPP, Whatâ€™s next for potential global AI regulation, best practices, 23 April 2023. Available at \nhttps://iapp.org/news/a/iapp-gps-2023-whats-next-for-potential-global-ai-regulations-best-practices-for\u0002governing-automated-systems/. [Accessed 21 Ju"},{"id":533,"value":"National Conference of State Legislatures, Legislation Related to Artificial Intelligence, 26 August 2022. Available \nat https://www.ncsl.org/technology-and-communication/legislation-related-to-artificial-intelligence. [Accessed 20 \nJuly]"},{"id":534,"value":"National Conference of State Legislatures, Legislation Related to Artificial Intelligence, 26 August 2022. Available \nat https://www.ncsl.org/technology-and-communication/legislation-related-to-artificial-intelligence. [Accessed 20 \nJuly]"}],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":288,"database_table_184385":11},"value":{"id":980191,"value":"new-policy","color":"dark-purple"}},{"ids":{"database_table_183319":289,"database_table_184385":11},"value":{"id":980191,"value":"new-policy","color":"dark-purple"}},{"ids":{"database_table_183319":290,"database_table_184385":11},"value":{"id":980191,"value":"new-policy","color":"dark-purple"}},{"ids":{"database_table_183319":291,"database_table_184385":11},"value":{"id":980191,"value":"new-policy","color":"dark-purple"}},{"ids":{"database_table_183319":293,"database_table_184385":11},"value":{"id":980191,"value":"new-policy","color":"dark-purple"}},{"ids":{"database_table_183319":294,"database_table_184385":11},"value":{"id":980191,"value":"new-policy","color":"dark-purple"}},{"ids":{"database_table_183319":296,"database_table_184385":11},"value":{"id":980191,"value":"new-policy","color":"dark-purple"}},{"ids":{"database_table_183319":297,"database_table_184385":11},"value":{"id":980191,"value":"new-policy","color":"dark-purple"}},{"ids":{"database_table_183319":298,"database_table_184385":11},"value":{"id":980191,"value":"new-policy","color":"dark-purple"}},{"ids":{"database_table_183319":301,"database_table_184385":11},"value":{"id":980191,"value":"new-policy","color":"dark-purple"}},{"ids":{"database_table_183319":302,"database_table_184385":11},"value":{"id":980191,"value":"new-policy","color":"dark-purple"}},{"ids":{"database_table_183319":303,"database_table_184385":11},"value":{"id":980191,"value":"new-policy","color":"dark-purple"}},{"ids":{"database_table_183319":304,"database_table_184385":11},"value":{"id":980191,"value":"new-policy","color":"dark-purple"}},{"ids":{"database_table_183319":305,"database_table_184385":11},"value":{"id":980191,"value":"new-policy","color":"dark-purple"}},{"ids":{"database_table_183319":295,"database_table_184385":16},"value":{"id":980194,"value":"communications","color":"darker-brown"}},{"ids":{"database_table_183319":306,"database_table_184385":16},"value":{"id":980194,"value":"communications","color":"darker-brown"}},{"ids":{"database_table_183319":292,"database_table_184385":17},"value":{"id":980195,"value":"resourcing","color":"dark-cyan"}},{"ids":{"database_table_183319":298,"database_table_184385":17},"value":{"id":980195,"value":"resourcing","color":"dark-cyan"}},{"ids":{"database_table_183319":299,"database_table_184385":17},"value":{"id":980195,"value":"resourcing","color":"dark-cyan"}},{"ids":{"database_table_183319":303,"database_table_184385":21},"value":{"id":980197,"value":"evidence-generation","color":"brown"}},{"ids":{"database_table_183319":289,"database_table_184385":38},"value":{"id":986019,"value":"respect-rights","color":"light-blue"}},{"ids":{"database_table_183319":291,"database_table_184385":38},"value":{"id":986019,"value":"respect-rights","color":"light-blue"}},{"ids":{"database_table_183319":293,"database_table_184385":38},"value":{"id":986019,"value":"respect-rights","color":"light-blue"}},{"ids":{"database_table_183319":294,"database_table_184385":38},"value":{"id":986019,"value":"respect-rights","color":"light-blue"}},{"ids":{"database_table_183319":296,"database_table_184385":38},"value":{"id":986019,"value":"respect-rights","color":"light-blue"}},{"ids":{"database_table_183319":297,"database_table_184385":38},"value":{"id":986019,"value":"respect-rights","color":"light-blue"}},{"ids":{"database_table_183319":298,"database_table_184385":38},"value":{"id":986019,"value":"respect-rights","color":"light-blue"}},{"ids":{"database_table_183319":301,"database_table_184385":38},"value":{"id":986019,"value":"respect-rights","color":"light-blue"}},{"ids":{"database_table_183319":302,"database_table_184385":38},"value":{"id":986019,"value":"respect-rights","color":"light-blue"}},{"ids":{"database_table_183319":303,"database_table_184385":38},"value":{"id":986019,"value":"respect-rights","color":"light-blue"}},{"ids":{"database_table_183319":305,"database_table_184385":38},"value":{"id":986019,"value":"respect-rights","color":"light-blue"}},{"ids":{"database_table_183319":300,"database_table_184385":39},"value":{"id":991258,"value":"foster-responsible-aied","color":"red"}},{"ids":{"database_table_183319":304,"database_table_184385":39},"value":{"id":991258,"value":"foster-responsible-aied","color":"red"}}],"Lookup":[{"id":288,"value":"That the Government address privacy and data risks in the Privacy Act review by establishing a robust data protection framework that outlines the rights of students in relation to personal data as well as establishing limitations to the collection, use and retention of data of minors."},{"id":289,"value":"That the Government puts in place requirements for educational institutions and AI developers to have clear and transparent data use policies. These policies should outline the types of data collected, the purposes for which the data will be used, how long the data will be retained, and the measures taken to protect data privacy. These policies should be presented to users in a way that is age-appropriate and easy to understand."},{"id":290,"value":"That the Government provides specific powers to the Office of the Australian Information Commissioner to assess AI tools used in education should for their privacy impact. The assessment would identify potential risks to data privacy and outline measures to mitigate them before the tool can be implemented. The Office of the Australian Information Commissioner should be given the power to ban the implementation of AI tools if the risk to a usersâ€™ data privacy is too high."},{"id":291,"value":"That the Government requires AI developers and educational institutions to implement strong encryption and secure data storage practices. Government should provide support - both technical and financial â€“ to educational institutions to assist with meeting this requirement."},{"id":292,"value":"That the Government strengthens the role of and financial support to the Australian Information Commissioner to assist with the safe implementation and overseeing the use of AI tools in education settings in relation to data privacy."},{"id":293,"value":"That the Government considers the development of comprehensive legislation in relation to Generative AI drawing on international best-practice, like the European Union AI Act. It is crucial that a risk-based approach is taken which includes third party and independent impact and audit assessments, mandatory transparency reports, the human oversight of certain AI systems depending on level of risk, and accountability measures."},{"id":294,"value":"That the Government consider the establishment of a dedicated AI regulatory body assist regulators, policy makers and government in developing, enforcing and implementing legislation, in line with submissions made to â€œPositioning Australia as a Leader in Digital Economy Regulationâ€ and the Australian Human Rights Commissionâ€™s Human Rights and Technology Final Report (2021)."},{"id":295,"value":"That the Government increases public awareness and education programs to inform users about AIâ€™s potential implications and risks, to improve the ability of the users to hold companies and developers accountable and make informed decisions."},{"id":296,"value":"Educational institutions and AI developers should be required to have clear and transparent data use policies. These policies should outline the types of data collected, the purposes for which the data will be used, how long the data will be retained, and the measures taken to protect data privacy. These policies should be presented to users in a way that is age â€“ appropriate and easy to understand."},{"id":297,"value":"AI tools used in education should be assessed for their privacy impact by the Office of the Australian Information Commissioner. The assessment would identify potential risks to data privacy and outline measures to mitigate them before the tool can be implemented. The Office of the Australian Information Commissioner should be given the power to ban the implementation of AI tools if the risk to a usersâ€™ data privacy is too high."},{"id":298,"value":"Government can require AI developers and educational institutions to implement strong encryption and secure data storage practices. Government should provide support - both technical and financial â€“ to educational institutions to assist with meeting this requirement."},{"id":299,"value":"Government should strengthen the role of and financial support to the Australian Information Commissioner to assist with overseeing the use of AI tools in education settings in relation to data privacy."},{"id":300,"value":"Organisations developing AI tools should be required to conduct regular audits or impact assessments of their AI systems to address potential biases or unintended consequences. In order to ensure accountability, these assessments should be subject to external scrutiny."},{"id":301,"value":"Legislation should require organisations to publish transparency reports detailing how their AI systems are used, including any cases of significant impact on individuals or society. These reports would provide insights into how algorithms function in practice and how they affect users."},{"id":302,"value":"Legislation can grant users the right to access and understand the data collected about them and the algorithms used to make decisions based on that data. Users should have the opportunity to challenge or correct inaccurate information."},{"id":303,"value":"Legislation should mandate third party evaluations of AI tools and systems to ensure they meet certain criteria for transparency, fairness, and accountability. These evaluations should be conducted by independent auditors and regulatory bodies."},{"id":304,"value":"Legislation should require that critical decisions made by AI systems to have a human-in-the-loop component, where a human reviewer can examine and validate the systemâ€™s outputs before final decisions are implemented."},{"id":305,"value":"Legislation should establish accountability measures for organisations that deploy AI systems that lead to biased, discriminatory or harmful outcomes to help deter irresponsible AI development and use."},{"id":306,"value":"Government should also support public awareness campaigns and educational programs to inform the general public about AI technology and its potential implications to improve the ability of the public to hold organisations accountable and make informed decisions."}]},{"id":85,"order":"84.00000000000000000000","submission_number":"84","Submitter":"eSafety Commissioner","Type of org":{"id":977282,"value":"Govt","color":"orange"},"Notes":"","Recommendations":[{"id":275,"value":"Tech companies have a responsibility to ensure that chatbots operating with children or young people have appropriate safeguards in place to ensure there is no intentional or accidental risk of harm to children and young people."},{"id":276,"value":"a related issue concerns the capacity of chatbots to appropriately identify, respond to and report concerns for the safety and welfare of children and young people."},{"id":277,"value":"We recommend the Committee refer to the Department of Industry, Science and Resourcesâ€™ Safe and responsible AI in Australia discussion paper, which includes a comprehensive summary of international developments in regulating AI technologies."},{"id":278,"value":"Ongoing review and adaption of curriculum materials, including the Australian Curriculum and supporting materials, to explicitly teach the technical knowledge and social and emotional skills to safely use new and emerging technologies. This could include reviewing the Online Safety Curriculum Connection to address specific AI-related scenarios."},{"id":279,"value":"Continuing to raise awareness of eSafetyâ€™s Toolkit for Schools and Best Practice Framework for Online Safety Education so that schools and education sectors are better prepared to support students, families and communities, and periodic review of these resources to ensure emerging technologies like generative AI are accounted for."},{"id":280,"value":"Delivering relevant and engaging education programs and resources for, and in consultation with, priority audiences â€“ including children, young people and families, First Nations communities, culturally and linguistically diverse communities, and LGBTIQ+ Australians â€“ and professional learning for educators."},{"id":281,"value":"Partnering with our education stakeholders to raise awareness and build community understanding of generative AI and associated online safety risks. This includes through our National Online Safety Education Council and eSafety Youth Council, and relationships with government agencies, education bodies and providers of online safety education."},{"id":282,"value":"ensuring generative systems are sourcing high-quality data and information which has been cleaned of illegal, exploitative, and otherwise harmful material"},{"id":283,"value":"policies and processes prevent users from generating harmful content"},{"id":284,"value":"watermarks and detection tools are used to identify AI-generated materials"},{"id":285,"value":"features are evaluated to identify and mitigate risks for diverse user groups"},{"id":286,"value":"companies design clear reporting mechanisms and well-defined triage and escalation \nprocesses"},{"id":287,"value":"system and model cards are used to promote the improvement of models and the \nenhancement of their understanding by regulators, researchers, and the public"}],"Uses-opportunities":[{"id":186,"value":"immense potential to promote \nproductivity, wellbeing and quality of life"},{"id":187,"value":"personalising and targeting education \ninitiatives and scaling up support services."},{"id":188,"value":"provide relevant and timely \ninformation, such as physical and mental health and wellbeing advice, offer referral \nservices or assist with reporting harm and abuse at any time of the day and regardless of \nstaffing or resource limitations"},{"id":189,"value":"AI has \nthe potential to be a facilitator of access rather than a barrier to it. For example, UNESCO \nhas noted that AI systems such as Google Voice Assistant at the Global Digital Library, \nDytective and StorySign provide a range of accessibility benefits for people with disability \n(literacy difficulties, dyslexia and deafness, respectively)"},{"id":190,"value":"AI technologies may enhance and improve access \nto online safety education for those experiencing disadvantage."}],"Risks-challenges":[{"id":215,"value":"online abuse involving the education workforce."},{"id":216,"value":"online safety"},{"id":217,"value":"being filmed \nwithout consent"},{"id":218,"value":"sexual abuse"},{"id":219,"value":"digitally \nmanipulated image-based abuse"},{"id":220,"value":"AI technology may be used \nto create more sophisticated and realistic images, or do so at larger scale, as the \ntechnology becomes more widespread"},{"id":221,"value":"Generative AI tools may allow bad actors with malicious intent to create authentic looking, \nhigh quality deepfakes of individuals without requiring this repository of images to build on"},{"id":222,"value":"age-inappropriate conversations or content, including sexual or violent content, when \nchildren and young people engage with a chatbot. This includes where no age assurance \nis present, where a user can enter an incorrect age, or where the display of content is \ninadvertent (e.g., a failure of an age estimation algorithm)."},{"id":223,"value":"the potential for chatbots to be used as a tool for \ngrooming by starting conversations through social media or gaming platforms to manipulate \nchildren and young people."},{"id":224,"value":"a related issue concerns the capacity of chatbots to appropriately identify, respond to \nand report concerns for the safety and welfare of children and young people."},{"id":225,"value":"produce â€˜human-likeâ€™ interaction combined with novel high \nquality personalised content could lead to an amplification of existing cyberbullying and \ncyber abuse harms"},{"id":226,"value":"certain groups are especially vulnerable to the impact of online harms and experience \nhigher rates of online targeted abuse (Aboriginal and Torres Strait Islander children and young people)"},{"id":227,"value":"replicate any existing stereotypes, biases and discriminatory \nviewpoints contained in their training datasets"}],"References-footnotes":[{"id":483,"value":"https://www.esafety.gov.au/industry/basic-online-safety-expectations/responses-to-transparency-notices"},{"id":484,"value":"https://www.education.gov.au/education-ministers-meeting/resources/education-ministers-meeting-communique-july-2023"},{"id":485,"value":"Common Sense Media, Common Sense Media Announces New Ratings and Reviews System for AI Products, \nhttps://www.commonsensemedia.org/press-releases/common-sense-media-announces-new-ratings-and-reviews\u0002system-for-ai-products (accessed 21/07/2023)"},{"id":486,"value":"Education Ministerâ€™s meeting communique July 2023, https://www.education.gov.au/education-ministers\u0002meeting/resources/education-ministers"},{"id":487,"value":"Department of Industry, Science and Resources, Safe and Responsible AI in Australia, \nhttps://consult.industry.gov.au/supporting-responsible-ai (accessed 20/07/2023)"},{"id":488,"value":"UNESCO, AI and education, guidance for policy-makers, https://doi.org/10.54675/PCSP7350, 2021, p13 (accessed \n06/07/23)"},{"id":489,"value":"Worrell, S., 2021, From Language Brokering to Digital Brokering: Refugee Settlement in a Smartphone Age. Social \nMedia + Society, 7(2). https://doi.org/10.1177/20563051211012365"},{"id":490,"value":"Kenny, Edmee, 2016, Settlement in the digital age: Digital inclusion and newly arrived young people from refugee and \nmigrant backgrounds, Centre for Multicultural Youth (CMY)"},{"id":491,"value":"eSafety Commissioner, Online experiences of Aboriginal and Torres Strait Islander children and their parents and \ncaregivers, https://www.esafety.gov.au/research/online-experiences-aboriginal-torres-strait-islander-children\u0002parents-caregivers (accessed 05/07/2023)"},{"id":493,"value":"Thomas, J, Barraket, J, Wilson, CK, Holcombe-James, I, Kennedy, J, Rennie, E, Ewing, S, MacDonald, T, 2020, \nMeasuring Australiaâ€™s Digital Divide: The Australian Digital Inclusion Index 2020, \nhttps://doi.org/10.25916/5f6eb9949c832"},{"id":494,"value":"CSIRO Data 61, Diversity and Inclusion in Artificial Intelligence, https://research.csiro.au/ss/team/diai/ (accessed \n05/07/2023)"},{"id":495,"value":"eSafety Commissioner, Online experiences of Aboriginal and Torres Strait Islander children and their parents and \ncaregivers, https://www.esafety.gov.au/research/online-experiences-aboriginal-torres-strait-islander-children\u0002parents-caregivers (accessed 05/07/2023)."},{"id":496,"value":"THORN, Generative AI: Now is the time for Safety by Design, https://www.thorn.org/blog/now-is-the-time-for\u0002safety-by-design (accessed 20/07/2023)"},{"id":497,"value":"Department of Industry, Science and Resources, Australiaâ€™s AI Ethics Principles, \nhttps://www.industry.gov.au/publications/australias-artificial-intelligence-ethics-framework/australias-ai-ethics\u0002principles (accessed 14/07/2023)"},{"id":498,"value":"eSafety Commissioner, Protecting voices at risk online, https://www.esafety.gov.au/communities/protecting-voices\u0002risk-online (accessed 19/07/2023)"},{"id":499,"value":"InnovationAus.com, SA public schools trial â€˜safeâ€™ AI-powered chatbot in nation first, \nhttps://www.innovationaus.com/sa-public-schools-trial-safe-ai-powered-chatbot-in-nation-first/ (accessed"},{"id":500,"value":"Education Ministerâ€™s meeting communique July 2023, https://www.education.gov.au/education-ministers\u0002meeting/resources/education-ministers-meeting-communique-july-2023 (acce"},{"id":501,"value":"Department of Industry, Science and Resources, Safe and Responsible AI in Australia, \nhttps://consult.industry.gov.au/supporting-responsible-ai (accessed 20/07/2023)"},{"id":502,"value":"eSafety Commissioner, eSafety Strategy 2022-25, https://www.esafety.gov.au/about-us/who-we-are/strategy \n(accessed 14/07/2023)"}],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":277,"database_table_184385":3},"value":{"id":980182,"value":"situate-with-existing-policy","color":"darker-red"}},{"ids":{"database_table_183319":279,"database_table_184385":3},"value":{"id":980182,"value":"situate-with-existing-policy","color":"darker-red"}},{"ids":{"database_table_183319":284,"database_table_184385":5},"value":{"id":980175,"value":"mandatory-watermarking","color":"brown"}},{"ids":{"database_table_183319":281,"database_table_184385":7},"value":{"id":980187,"value":"stakeholder-engagement","color":"dark-green"}},{"ids":{"database_table_183319":278,"database_table_184385":10},"value":{"id":980190,"value":"curricula-changes","color":"light-green"}},{"ids":{"database_table_183319":280,"database_table_184385":22},"value":{"id":980198,"value":"marginalised-group-engagement","color":"light-pink"}},{"ids":{"database_table_183319":286,"database_table_184385":25},"value":{"id":980202,"value":"monitoring-impacts","color":"darker-red"}},{"ids":{"database_table_183319":287,"database_table_184385":25},"value":{"id":980202,"value":"monitoring-impacts","color":"darker-red"}},{"ids":{"database_table_183319":285,"database_table_184385":27},"value":{"id":980178,"value":"equitable-access","color":"yellow"}},{"ids":{"database_table_183319":275,"database_table_184385":38},"value":{"id":986019,"value":"respect-rights","color":"light-blue"}},{"ids":{"database_table_183319":276,"database_table_184385":38},"value":{"id":986019,"value":"respect-rights","color":"light-blue"}},{"ids":{"database_table_183319":282,"database_table_184385":38},"value":{"id":986019,"value":"respect-rights","color":"light-blue"}},{"ids":{"database_table_183319":283,"database_table_184385":38},"value":{"id":986019,"value":"respect-rights","color":"light-blue"}}],"Lookup":[{"id":275,"value":"Tech companies have a responsibility to ensure that chatbots operating with children or young people have appropriate safeguards in place to ensure there is no intentional or accidental risk of harm to children and young people."},{"id":276,"value":"a related issue concerns the capacity of chatbots to appropriately identify, respond to and report concerns for the safety and welfare of children and young people."},{"id":277,"value":"We recommend the Committee refer to the Department of Industry, Science and Resourcesâ€™ Safe and responsible AI in Australia discussion paper, which includes a comprehensive summary of international developments in regulating AI technologies."},{"id":278,"value":"Ongoing review and adaption of curriculum materials, including the Australian Curriculum and supporting materials, to explicitly teach the technical knowledge and social and emotional skills to safely use new and emerging technologies. This could include reviewing the Online Safety Curriculum Connection to address specific AI-related scenarios."},{"id":279,"value":"Continuing to raise awareness of eSafetyâ€™s Toolkit for Schools and Best Practice Framework for Online Safety Education so that schools and education sectors are better prepared to support students, families and communities, and periodic review of these resources to ensure emerging technologies like generative AI are accounted for."},{"id":280,"value":"Delivering relevant and engaging education programs and resources for, and in consultation with, priority audiences â€“ including children, young people and families, First Nations communities, culturally and linguistically diverse communities, and LGBTIQ+ Australians â€“ and professional learning for educators."},{"id":281,"value":"Partnering with our education stakeholders to raise awareness and build community understanding of generative AI and associated online safety risks. This includes through our National Online Safety Education Council and eSafety Youth Council, and relationships with government agencies, education bodies and providers of online safety education."},{"id":282,"value":"ensuring generative systems are sourcing high-quality data and information which has been cleaned of illegal, exploitative, and otherwise harmful material"},{"id":283,"value":"policies and processes prevent users from generating harmful content"},{"id":284,"value":"watermarks and detection tools are used to identify AI-generated materials"},{"id":285,"value":"features are evaluated to identify and mitigate risks for diverse user groups"},{"id":286,"value":"companies design clear reporting mechanisms and well-defined triage and escalation \nprocesses"},{"id":287,"value":"system and model cards are used to promote the improvement of models and the \nenhancement of their understanding by regulators, researchers, and the public"}]},{"id":86,"order":"85.00000000000000000000","submission_number":"85","Submitter":"Amazon Web Services","Type of org":{"id":977288,"value":"Company","color":"dark-purple"},"Notes":"","Recommendations":[{"id":274,"value":"In order to unlock the potential of generative AI in the Australian education system, Government must enable and promote digital literacy, skilling and responsible use of AI/ML tools among our children, students, educators, academic communities, and the wider workforce. AI/ML and other emerging technologies will only be appropriately assimilated by the Australian education system if our educators, students and the wider population are aware of its potential and understand how to use it."}],"Uses-opportunities":[{"id":184,"value":"generative AI provides a profound opportunity for the sector to critically and creatively \nreflect on the nature of assessment and meaningful learning outcomes"},{"id":185,"value":"improve educational outcomes and even develop a framework to address complex, long\u0002standing problems across the Australian education landscape"}],"Risks-challenges":[],"References-footnotes":[],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":274,"database_table_184385":16},"value":{"id":980194,"value":"communications","color":"darker-brown"}}],"Lookup":[{"id":274,"value":"In order to unlock the potential of generative AI in the Australian education system, Government must enable and promote digital literacy, skilling and responsible use of AI/ML tools among our children, students, educators, academic communities, and the wider workforce. AI/ML and other emerging technologies will only be appropriately assimilated by the Australian education system if our educators, students and the wider population are aware of its potential and understand how to use it."}],"FLAG":""},{"id":87,"order":"86.00000000000000000000","submission_number":"86","Submitter":"Shipping Australia Limited","Type of org":{"id":977281,"value":"Peak body","color":"green"},"Notes":"","Recommendations":[{"id":272,"value":"It is vital to Australiaâ€™s national interest that any generative AI-related maritime education rules, laws, systems, and standards etc to ought to align with global maritime education rules, laws, systems, and standards."},{"id":273,"value":"consideration should be given to directing funding to further research at elite Australian maritime educational institutions into matters relating to the use of generative AI in Australian maritime educational and training policy."}],"Uses-opportunities":[{"id":181,"value":"Generative AI is revolutionising learning, education, and work processes. It can benefit \ncurrent and future maritime students, workers, and trainees, by enriching their educational\nexperience. It could, for instance, create personalised learning by incorporating different, \ninteractive, and flexible forms of tailored content, such as text, video, and computer code\ninto educational material. This should, in theory, help the learner to understand the material \nmore thoroughly and efficiently."},{"id":182,"value":"Generative AI is a transformative technology that can help improve connectivity among \ntrainees and trainers around the world, who have differing abilities and competency levels, \nand who are working in different industries. Generative AI can help overcome various \nkinds of obstacles, such as language or knowledge barriers."},{"id":183,"value":"Generative AI could be considered a virtual assistant and work partner for trainees and \ntrainers that could provide feedback, resources, guidance, and insight."}],"Risks-challenges":[{"id":210,"value":"potentially providing incorrect, biased, or fake information. It may also potentially result in \nbreaches of privacy. Other issues include potential breaches of copyright and risks of \nplagiarism"},{"id":211,"value":"One possible socio-economic ethical risk is the possibility that persons of higher income or \ndisposable assets could pay for access to generative AI services, whereas persons of lesser \nmeans would be unable to do so. In such a scenario, persons of higher means would clearly \nbe advantaged â€“ possibly in breach of rules around academic integrity (so-called AI\u0002assisted cheating). Consideration should be given as to the socio-economic challenges of \npotentially entrenching, or increasing, inequality in education and our society generally."},{"id":212,"value":"Socio-economic, and socio-cultural ethical challenges of generative AI ought to be \nconsidered by the Australian government."},{"id":213,"value":"The gradual advancement of generative AI could change the roles and responsibilities of \neducators and students, and perhaps, even the concept of schooling, academic qualification,\nand certification. For instance, technological advancement could possibly change the role \nof teachers from educators to facilitators."}],"References-footnotes":[],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":272,"database_table_184385":3},"value":{"id":980182,"value":"situate-with-existing-policy","color":"darker-red"}},{"ids":{"database_table_183319":273,"database_table_184385":12},"value":{"id":980192,"value":"research-investment","color":"orange"}}],"Lookup":[{"id":272,"value":"It is vital to Australiaâ€™s national interest that any generative AI-related maritime education rules, laws, systems, and standards etc to ought to align with global maritime education rules, laws, systems, and standards."},{"id":273,"value":"consideration should be given to directing funding to further research at elite Australian maritime educational institutions into matters relating to the use of generative AI in Australian maritime educational and training policy."}],"FLAG":""},{"id":88,"order":"87.00000000000000000000","submission_number":"87","Submitter":"Australian College of Nursing (ACN)","Type of org":{"id":977281,"value":"Peak body","color":"green"},"Notes":"","Recommendations":[{"id":262,"value":"Australian educational institutions (including the Australian Council of Deans of Health Sciences) form Advisory Committees to formulate strategies and goals for implementing AI in the clinical curriculum (high level decision-making regarding the ethics and principles of AI use by nurses in clinical settings)."},{"id":263,"value":"The Advisory Committee develop best practice guidelines and a governance framework for AI in Australia. This must include extensive consultation with both healthcare consumers and education consumers."},{"id":264,"value":"Educational institutions come to a consensus on a standard of digital literacy across all curriculums, from school and VET to higher education. Specific digital literacy needs in healthcare must be examined and benchmarks established."},{"id":265,"value":"The Australian Government and its relevant agencies provide supplementary grants to implement further research into how AI can be effectively and imaginatively utilised in clinical and nurse education in Australia."},{"id":266,"value":"Ongoing investments be made to develop, review, and update effective plagiarism detection \ntechnologies"},{"id":267,"value":"The Australian Government establishes funding models to support nurse-led initiatives to investigate and establish the development of regulatory standards for AI in education."},{"id":268,"value":"The rights of educational AI content creators, individual images, and personal identifiers be protected from re-creation and use without permission."},{"id":269,"value":"Collaboration between the Australian Government, its associated agencies and nurse education institutions to establish funding models to support nurse-led initiatives to investigate and establish the development of standards for AI tools and resources in clinical and nurse education."},{"id":270,"value":"Collaboration between the Australian Government, its relevant agencies (e.g., Digital Health), health professional colleges, appropriate university faculties, and others, as  determined, mandates co-design methodologies to be used when developing AI tools for health education to ensure biases are adequately addressed."},{"id":271,"value":"The Australian Government and relevant agencies ensure that nurses are adequately represented on all committees determining AI's future use in healthcare and healthcare education."}],"Uses-opportunities":[{"id":166,"value":"Enhancing learning experiences for nursing students through AI in clinical education"},{"id":167,"value":"Revolutionizing patient-centered care through the use of AI in nursing education"},{"id":168,"value":"Creating educational equity for students in geographically dispersed locations"},{"id":169,"value":"Reducing educator burnout rates by leveraging AI in nursing education"},{"id":170,"value":"Redesigning the nursing curriculum to be more student-centered and authentic with the help of AI"},{"id":171,"value":"Providing simulated clinical experiences for students through chatbots"},{"id":172,"value":"Enabling students to gain skills in taking clinical histories through AI-powered chatbot applications"},{"id":173,"value":"Allowing students to experience complex and rare cases not typically encountered in clinical settings"},{"id":174,"value":"Increasing interest in education and fostering positive learning experiences through chatbot applications"},{"id":175,"value":"Enhancing self-directed learning and skill proficiency for nursing students"},{"id":176,"value":"Providing immediate feedback and error correction to improve the accuracy and quality of nursing knowledge"},{"id":177,"value":"Transforming how clinical education is delivered and supporting clinical educator roles"},{"id":178,"value":"Expanding access to higher education through AI tutoring systems and personalized guidance"},{"id":179,"value":"Saving educators time by answering simple and repetitive questions through AI-powered chatbots"},{"id":180,"value":"No significant difference in learning achievements with the support of chatbots, but higher motivation levels reported for learners interacting with chatbots."}],"Risks-challenges":[{"id":196,"value":"Concerns about evaluating student work when AI is used in healthcare education"},{"id":197,"value":"Impact of AI on future professionals' clinical decision-making skills and professional language of nursing"},{"id":198,"value":"Challenges of incorporating digital literacy into an already stretched health curriculum"},{"id":199,"value":"Academic integrity challenges, including plagiarism and reliance on misleading or biased information when using AI"},{"id":200,"value":"Difficulties in detecting AI use in formulating assessments and identifying cases of plagiarism"},{"id":201,"value":"Inadequacy of existing detection tools like Turnitin in keeping up with AI tools"},{"id":202,"value":"Need for developing more responsive detection tools for identifying plagiarism"},{"id":203,"value":"Development of educational policies surrounding the use of AI in higher education"},{"id":204,"value":"Redesigning assessments to ensure students provide drafts to benchmark their work"},{"id":205,"value":"Additional costs and labor for educational organizations to implement interventions addressing AI-related challenges"},{"id":206,"value":"Risks of relying on AI shortcuts for obtaining a clinical education, potentially endangering patient care"},{"id":207,"value":"Concerns about the quality of information produced by AI interventions"},{"id":208,"value":"Reliability issues with current data retrieval due to the need for integration between healthcare digital systems"},{"id":209,"value":"Requirement of significant investment in national digital infrastructure for wider use of generative AI in educational systems."}],"References-footnotes":[{"id":446,"value":"Phillips, J. (n.d.) Health Workforce. Parliament of Australia. Australian Government, Canberra \nhttps://www.aph.gov.au/About_Parliament/Parliamentary_Departments/Parliamentary_Library/pubs/Briefing\nBook46p/HealthWorkforce"},{"id":447,"value":"World Health Organization (n.d.) Health Workforce. https://www.who.int/health-topics/health\u0002workforce#tab=tab_1"},{"id":449,"value":"Australian College of Nursing (ACN), 2023. â€˜Impact of COVID-19 on the nursing profession: managing repercussions, enabling \nopportunitiesâ€™ A Position Statement by ACN. ACN, Canberra."},{"id":451,"value":"Corral, J. (2021) Artificially intelligent chatbots for health professions education. Digital Innovations in Healthcare Education and Training. \nEds: Stathis Th. Konstantinidis, Panagiotis D. Bamidis, Nabil Zary. Academic Press pp 127-135."},{"id":453,"value":"Co, M., Tsz, Y, H.J.Y., Cheung, H.H.H. (2022) Using clinical history taking chatbot mobile app for clinical bedside teachingsâ€“A prospective \ncase control study."},{"id":455,"value":"Rodriguezâ€Arrastia, M., Martinezâ€Ortigosa, A., Ruizâ€Gonzalez, C., Roperoâ€Padilla, C., Roman, P. & Sanchezâ€Labraca, N. (2022) Experiences \nand perceptions of finalâ€year nursing students of using a chatbot in a simulated emergency situation. Journal of Nursing \nManagement, 30 (8), 3874-3884. doi: 10.1111/jonm.13630"},{"id":456,"value":"Han, JW., Park, J. & Lee, H. Analysis of the effect of an artificial intelligence chatbot educational program on non-face-to-face classes: a \nquasi-experimental study. BMC Med Educ 22, 830 (2022). https://doi.org/10.1186/s12909-022-03898-3"},{"id":459,"value":"Randhawa, G., Jackson, M. (2020). The role of artificial intelligence in learning and professional development for healthcare\nprofessionals. Healthcare Management Forum. 33 (1) 19-24"},{"id":463,"value":"Hwang et al., 2020 Hwang, G. J., Xie, H., Wah, B. W., & GaÅ¡eviÄ‡, D. (2020). Vision, challenges, roles, and research issues of Artificial \nIntelligence in Education. Computers and Education: Artificial Intelligence, 1, 100001."},{"id":464,"value":"Goel, A. K., & Polepeddi, L. (2016). Jill Watson: A virtual teaching assistant for online education. Georgia Institute of Technology.)"},{"id":465,"value":"Yin, J., Goh, T. T., Yang, B., & Xiaobin, Y. (2021). Conversation technology with micro-learning: The impact of chatbot-based learning on \nstudentsâ€™ learning motivation and performance. Journal of Educational Computing Research, 59(1), 154â€“177. \nhttps://doi.org/10.1177/073563312095206"},{"id":466,"value":"Shang, Z. (2021) A concept analysis on the use of artificial intelligence in nursing. Cureus, 13(5)."},{"id":467,"value":"Irwin, P., Jones, D., Fealy, S. (2023) What is ChatGPT and what do we do with it? Implications of the age of AI for nursing and midwifery \npractice and education: An editorial. Nurse Education Today, 127 (105835)."},{"id":469,"value":"Cotton, D.R.E., Cotton, P.A., Shipway, R.J. (2023) Chatting and cheating: Ensuring academic integrity in the era of ChatGPT. Innovations \nin Education and Teaching International, DOI: 10.1080/14703297.2023.2190148"},{"id":470,"value":"Australian College of Nursing (ACN). (2019) Person-Centred Care. ACN, Canberra."},{"id":473,"value":"Gurupur, V., & Wan, T. T. H. (2020) Inherent Bias in Artificial Intelligence-Based Decision Support Systems for \nHealthcare. Medicina, 56(3), 141. https://doi.org/10.3390/medicina56030141"},{"id":474,"value":"Owens, K., Walker, A. (2020) Those designing healthcare algorithms must become actively anti-racist. Nat Med 26, 1327â€“1328. \nhttps://doi.org/10.1038/s41591-020-1020-3"},{"id":476,"value":"Buchanan C., Howitt M.L., Wilson R., Booth R.G., Risling T., Bamford M. (2020) Predicted Influences of Artificial Intelligence on the \nDomains of Nursing: Scoping Review. JMIR Nursing 3(1): e23939 doi: 10.2196/23939"},{"id":478,"value":"Australian College of Nursing (ACN). (2019) Person-Centred Care. ACN, Canberra."},{"id":479,"value":"Woods L, Duff J, Roehrer E, Walker K, Cummings E. (2019) Design of a Consumer Mobile Health App for Heart Failure: Findings from the \nNurse-Led Co-Design of Care4myHeart JMIR Nursing 2019;2(1): e14633 doi: 10.2196/14633"},{"id":480,"value":"Ronquillo, C. E., Peltonen, L., Pruinelli, L., Chu, C. H., Bakken, S., Beduschi, A., Cato, K., Hardiker, N., Junger, A., Michalowski, M., Nyrup, \nR., Rahimi, S., Reed, D. N., Salakoski, T., SalanterÃ¤, S., Walton, N., Weber, P., Wiegand, T., & Topaz, M. (2021). Artificial intelligence in \nnursing: Priorities and opportunities from an international invitational thinkâ€tank of the Nursing and Artificial Intelligence Leadership \nCollaborative. Journal of Advanced Nursing, 77(9), 3707â€“3717. https://doi.org/10.1111/jan.14855"}],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":263,"database_table_184385":2},"value":{"id":980180,"value":"guidelines","color":"light-yellow"}},{"ids":{"database_table_183319":270,"database_table_184385":7},"value":{"id":980187,"value":"stakeholder-engagement","color":"dark-green"}},{"ids":{"database_table_183319":271,"database_table_184385":7},"value":{"id":980187,"value":"stakeholder-engagement","color":"dark-green"}},{"ids":{"database_table_183319":262,"database_table_184385":10},"value":{"id":980190,"value":"curricula-changes","color":"light-green"}},{"ids":{"database_table_183319":264,"database_table_184385":10},"value":{"id":980190,"value":"curricula-changes","color":"light-green"}},{"ids":{"database_table_183319":265,"database_table_184385":12},"value":{"id":980192,"value":"research-investment","color":"orange"}},{"ids":{"database_table_183319":266,"database_table_184385":17},"value":{"id":980195,"value":"resourcing","color":"dark-cyan"}},{"ids":{"database_table_183319":267,"database_table_184385":17},"value":{"id":980195,"value":"resourcing","color":"dark-cyan"}},{"ids":{"database_table_183319":269,"database_table_184385":17},"value":{"id":980195,"value":"resourcing","color":"dark-cyan"}},{"ids":{"database_table_183319":268,"database_table_184385":38},"value":{"id":986019,"value":"respect-rights","color":"light-blue"}}],"Lookup":[{"id":262,"value":"Australian educational institutions (including the Australian Council of Deans of Health Sciences) form Advisory Committees to formulate strategies and goals for implementing AI in the clinical curriculum (high level decision-making regarding the ethics and principles of AI use by nurses in clinical settings)."},{"id":263,"value":"The Advisory Committee develop best practice guidelines and a governance framework for AI in Australia. This must include extensive consultation with both healthcare consumers and education consumers."},{"id":264,"value":"Educational institutions come to a consensus on a standard of digital literacy across all curriculums, from school and VET to higher education. Specific digital literacy needs in healthcare must be examined and benchmarks established."},{"id":265,"value":"The Australian Government and its relevant agencies provide supplementary grants to implement further research into how AI can be effectively and imaginatively utilised in clinical and nurse education in Australia."},{"id":266,"value":"Ongoing investments be made to develop, review, and update effective plagiarism detection \ntechnologies"},{"id":267,"value":"The Australian Government establishes funding models to support nurse-led initiatives to investigate and establish the development of regulatory standards for AI in education."},{"id":268,"value":"The rights of educational AI content creators, individual images, and personal identifiers be protected from re-creation and use without permission."},{"id":269,"value":"Collaboration between the Australian Government, its associated agencies and nurse education institutions to establish funding models to support nurse-led initiatives to investigate and establish the development of standards for AI tools and resources in clinical and nurse education."},{"id":270,"value":"Collaboration between the Australian Government, its relevant agencies (e.g., Digital Health), health professional colleges, appropriate university faculties, and others, as  determined, mandates co-design methodologies to be used when developing AI tools for health education to ensure biases are adequately addressed."},{"id":271,"value":"The Australian Government and relevant agencies ensure that nurses are adequately represented on all committees determining AI's future use in healthcare and healthcare education."}]},{"id":89,"order":"88.00000000000000000000","submission_number":"88","Submitter":"Cooperative Research Australia","Type of org":{"id":977283,"value":"HE-network","color":"dark-green"},"Notes":"","Recommendations":[{"id":227,"value":"The strengths and benefits of AI to improve education outcomes include: personalised learning, enhanced critical thinking, accessibility and inclusivity, data-driven insights, streamlined administrative process and future ready skills"},{"id":228,"value":"The future impacts of generative tools on Education can be turned into positives if we focus our efforts on continuous professional development, emphasising human value, clear policy guidelines and collaboration between different stakeholders"},{"id":229,"value":"The implementation of AI tools encompasses risks and challenges which need to be carefully considered, in order to develop the right strategies to address them"},{"id":230,"value":"We can draw on past/current experiences that represent a parallel to AI on Education. The experience of a virtual classroom rollout and the learnings from the Health sector on setting up the pathways for a successful implementation of AI tools, are cases that can serve as guidelines for best practice"},{"id":231,"value":"A collaboration between educators, researchers, policymakers, and technology developers is needed to ensure that generative AI tools are developed based on evidence-based research and aligned with educational goals"},{"id":232,"value":"Clear ethical guidelines and standards for the use of generative AI tools in education."},{"id":233,"value":"Promote AI models that are transparent and explainable, allowing educators and students to understand how AI-generated content or assessments are produced."},{"id":234,"value":"Encourage methods to identify and mitigate biases in generative AI tools. Curate training data carefully, monitor for potential bias, and conduct regular AI system audits to ensure fairness."},{"id":235,"value":"Ensure educators review and validate AI-generated content to maintain appropriateness and accuracy."},{"id":236,"value":"Promote responsible data collection, storage, and use in AI implementations. Ensure data is used only for educational purposes and is adequately protected from unauthorized access."},{"id":237,"value":"Extend the cyber security national strategy to protect AI models and educational data from cyber threats and potential misuse. Implement privacy-preserving techniques to safeguard individual student data."},{"id":238,"value":"Promote collaboration or forums of educational institutions to develop and enforce academic integrity policies that address potential misuse of AI tools, including plagiarism detection and cheating prevention."},{"id":239,"value":"Encourage rigorous validation of AI tools for educational purposes. Promote peer-reviewed and transparently published studies to ensure effectiveness and reliability."},{"id":240,"value":"Develop ongoing education and awareness programs about the opportunities and challenges of using generative AI tools for educators, students, and stakeholders. Promote discussions on ethical considerations and responsible AI use."},{"id":241,"value":"Enable collaboration between experts in education, AI development, ethics, and policy to collectively address the complex challenges posed by generative AI in education."},{"id":242,"value":"Professional development programs to equip educators with the necessary skills and knowledge to effectively integrate generative AI tools into their teaching practices. This includes an emphasis on ongoing training and support to keep educators updated with the latest advancements in AI."},{"id":243,"value":"To future-proofing the education workforce, a focus is needed on initiatives related to reskilling and upskilling to prepare them for the changing landscape of education with the integration of AI technologies."},{"id":244,"value":"Generative AI tools may augment and enhance the role of educators, rather than replace them. The unique abilities of human educators, such as emotional intelligence, empathy, and adaptability, are not easily replicated by AI."},{"id":245,"value":"Generative AI tools have the potential to provide continuous assessment and timely feedback to both students and teachers. This can support formative assessment practices and enable educators to intervene when needed to address learning gaps."},{"id":246,"value":"With the automation of administrative tasks, such as grading and lesson planning, can free up educators' time, allowing them to focus on building meaningful connections with students and designing innovative learning experiences."},{"id":247,"value":"With the help of AI, the current frontier of education can be extended to reach wider audiences. This can help towards ensuring all students, regardless of their background or location, have equal access to quality education."},{"id":248,"value":"A collaboration between educators, researchers, policymakers, and technology  developers is needed to ensure that generative AI tools are developed based on evidence-based research and aligned with educational goals."},{"id":249,"value":"Clear policy guidelines can provide the confidence needed to rollout AI in education, including but not limited to ethical frameworks, privacy and intellectual property regulation."},{"id":250,"value":"The future impacts of generative tools on Education can be turned into positives if we focus our efforts on continuous professional development, emphasising human value, clear policy guidelines and collaboration between different stakeholders"},{"id":251,"value":"The implementation of AI tools encompasses risks and challenges which need to be carefully considered, in order to develop the right strategies to address them."},{"id":252,"value":"We can draw on past/current experiences that represent a parallel to AI on Education. The experience of a virtual classroom rollout and the learnings from the Health sector on setting up the pathways for a successful implementation of AI tools, are cases that can serve as guidelines for best practice."},{"id":253,"value":"A collaboration between educators, researchers, policymakers, and technology developers is needed to ensure that generative AI tools are developed based on evidence-based research and aligned with educational goals."},{"id":255,"value":"Digital Infrastructure and Access: Invest in improving digital infrastructure and internet connectivity in disadvantaged communities, including rural and remote areas. Ensure that schools and educational institutions in these areas have access to reliable internet and necessary technology to use AI tools effectively."},{"id":256,"value":"Affordable Technology: Research providers to procure or support negotiations with technology companies to provide low-cost or subsidized devices for disadvantaged students and families."},{"id":257,"value":"Community Engagement: Engage with local communities and families to raise awareness about the benefits of AI in education and address any concerns or misconceptions they may have."},{"id":258,"value":"Training and Support: Provide comprehensive training and support for educators, parents, and students on how to use AI tools effectively. Ensure that educators are equipped with the necessary skills to integrate AI into their teaching practices and that parents understand how AI can support their child's learning."},{"id":259,"value":"Research and Evaluation: Invest in research and evaluation of AI implementations in disadvantaged communities to understand their effectiveness and identify areas for improvement. This data-driven approach will help optimize AI use for these cohorts."},{"id":260,"value":"Policy Strategy: Prioritise policies that grant equitable access to AI technologies and educational resources for disadvantaged communities."},{"id":261,"value":"AI for Personalized Learning: Promote the use of AI-driven personalized learning platforms that adapt to each student's needs and learning pace. These platforms can help address individual learning gaps and cater to diverse learning styles."}],"Uses-opportunities":[{"id":158,"value":"Personalized Learning: Generative AI tools can tailor educational content and \nexperiences based on individual learning styles, preferences, and capabilities. This \npersonalisation can lead to more effective and engaging learning experiences for \nstudents, as it addresses their specific needs"},{"id":159,"value":"Enhanced Creativity and Critical Thinking: Generative AI tools can stimulate \ncreativity by providing students with new and unique challenges. These tools can \nencourage critical thinking and problem-solving skills as students interact with AI\u0002generated scenarios and content."},{"id":160,"value":"Accessibility and Inclusivity: AI can help bridge the educational gap by providing \naccessible content to learners with disabilities or those in remote areas. Generative \nAI tools can adapt materials to different learning needs and ensure a more inclusive \neducational environment."},{"id":161,"value":"Data-Driven Insights: AI tools can analyse vast amounts of educational data to \nidentify patterns and trends, providing educators with valuable insights into student \nprogress and learning behaviours. This data-driven approach can inform targeted \ninterventions and support personalised teaching strategies."},{"id":162,"value":"Teacher Support and Professional Development: AI can assist educators in \nmanaging administrative tasks, grading, and providing instant feedback to students. \nAdditionally, AI can support teachers in their professional development by offering \npersonalised learning opportunities and resources."},{"id":163,"value":"Adaptability and Continuous Improvement: Generative AI tools can adapt and \nevolve based on user interactions and feedback, continuously improving their \neffectiveness in supporting education outcomes."},{"id":164,"value":"Streamlined Administrative Processes: AI-powered tools can streamline \nadministrative tasks, reducing the burden on educators and allowing them to focus \nmore on teaching and student engagement."},{"id":165,"value":"Future-Ready Skills: Exposure to AI tools can help students develop the skills \nnecessary for the digital age, preparing them for future careers in technology and \ndata-driven fields."}],"Risks-challenges":[{"id":186,"value":"AI technologies \ncan potentially be used in ways that compromise \nindividual privacy, perpetuate biases, or lead to \nunethical outcomes. Lacking appropriate guidelines \nmay result in unintended consequences, such as the \nmisuse of AI-generated content or assessments"},{"id":187,"value":"The lack of it may \nlead to a lack of trust and understanding among \neducators and students. If users cannot comprehend \nhow AI-generated content is produced, they may be \nhesitant to adopt AI tools or question their \nreliability."},{"id":188,"value":"Generative AI tools trained on \nbiased data can perpetuate those biases in the \ncontent they generate, leading to unfair or \ndiscriminatory educational experiences. Addressing \nand mitigating bias is a crucial challenge in ensuring \nequitable access to quality education for all \nstudents."},{"id":189,"value":"While AI can enhance educational \nexperiences, excessive reliance on AI without human \noversight poses a risk. Human educators play a \ncritical role in reviewing and validating AI-generated \ncontent to ensure accuracy, appropriateness, and \nalignment with educational goals."},{"id":190,"value":"The risk of irresponsible data \nuse arises when AI tools collect and process student \ndata without adequate safeguards. Mismanagement \nof data can lead to privacy breaches, misuse of \ninformation, or unauthorized access, compromising the trust between educational institutions and \nstakeholders"},{"id":191,"value":"The integration of AI \nin education requires robust security measures to \nprotect AI models and educational data from cyber \nthreats. Failing to implement proper security \nprotocols can lead to data breaches, compromising \nstudent privacy and the integrity of the education \nsystem."},{"id":192,"value":"With the introduction of \nAI in education, the risk of academic misconduct \nmay evolve, including AI-generated content used for \nplagiarism or cheating. Establishing academic \nintegrity policies to address these new challenges is\nessential to maintain the credibility and \ntrustworthiness of educational institutions."},{"id":193,"value":"The lack of rigorous \nvalidation of AI tools for education can lead to the \nadoption of ineffective or unreliable tools. Proper \nresearch and validation are essential to understand \nthe impact of AI on learning outcomes and ensure \nthat educators make informed decisions about \nintegrating AI in classrooms."},{"id":194,"value":"Educators, students, and \nstakeholders need to be aware of the opportunities \nand challenges posed by generative AI tools in \neducation. Lack of education and awareness can \nhinder the responsible and effective integration of AI \nin classrooms"},{"id":195,"value":"Addressing the complex challenges of AI in \neducation requires a collaborative effort from \nexperts in education, AI development, ethics, and \npolicy. A lack of collaboration can result in \nfragmented approaches and limited perspectives on \nethical and practical considerations."}],"References-footnotes":[],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":228,"database_table_184385":1},"value":{"id":980196,"value":"PD","color":"light-red"}},{"ids":{"database_table_183319":240,"database_table_184385":1},"value":{"id":980196,"value":"PD","color":"light-red"}},{"ids":{"database_table_183319":242,"database_table_184385":1},"value":{"id":980196,"value":"PD","color":"light-red"}},{"ids":{"database_table_183319":243,"database_table_184385":1},"value":{"id":980196,"value":"PD","color":"light-red"}},{"ids":{"database_table_183319":250,"database_table_184385":1},"value":{"id":980196,"value":"PD","color":"light-red"}},{"ids":{"database_table_183319":258,"database_table_184385":1},"value":{"id":980196,"value":"PD","color":"light-red"}},{"ids":{"database_table_183319":230,"database_table_184385":2},"value":{"id":980180,"value":"guidelines","color":"light-yellow"}},{"ids":{"database_table_183319":232,"database_table_184385":2},"value":{"id":980180,"value":"guidelines","color":"light-yellow"}},{"ids":{"database_table_183319":249,"database_table_184385":2},"value":{"id":980180,"value":"guidelines","color":"light-yellow"}},{"ids":{"database_table_183319":252,"database_table_184385":2},"value":{"id":980180,"value":"guidelines","color":"light-yellow"}},{"ids":{"database_table_183319":237,"database_table_184385":3},"value":{"id":980182,"value":"situate-with-existing-policy","color":"darker-red"}},{"ids":{"database_table_183319":245,"database_table_184385":6},"value":{"id":980185,"value":"new-assessment-models","color":"darker-pink"}},{"ids":{"database_table_183319":261,"database_table_184385":6},"value":{"id":980185,"value":"new-assessment-models","color":"darker-pink"}},{"ids":{"database_table_183319":231,"database_table_184385":7},"value":{"id":980187,"value":"stakeholder-engagement","color":"dark-green"}},{"ids":{"database_table_183319":241,"database_table_184385":7},"value":{"id":980187,"value":"stakeholder-engagement","color":"dark-green"}},{"ids":{"database_table_183319":248,"database_table_184385":7},"value":{"id":980187,"value":"stakeholder-engagement","color":"dark-green"}},{"ids":{"database_table_183319":253,"database_table_184385":7},"value":{"id":980187,"value":"stakeholder-engagement","color":"dark-green"}},{"ids":{"database_table_183319":257,"database_table_184385":7},"value":{"id":980187,"value":"stakeholder-engagement","color":"dark-green"}},{"ids":{"database_table_183319":246,"database_table_184385":8},"value":{"id":980188,"value":"new-workforce-model","color":"light-brown"}},{"ids":{"database_table_183319":260,"database_table_184385":11},"value":{"id":980191,"value":"new-policy","color":"dark-purple"}},{"ids":{"database_table_183319":259,"database_table_184385":12},"value":{"id":980192,"value":"research-investment","color":"orange"}},{"ids":{"database_table_183319":238,"database_table_184385":19},"value":{"id":980186,"value":"capacity-building","color":"light-yellow"}},{"ids":{"database_table_183319":239,"database_table_184385":21},"value":{"id":980197,"value":"evidence-generation","color":"brown"}},{"ids":{"database_table_183319":259,"database_table_184385":21},"value":{"id":980197,"value":"evidence-generation","color":"brown"}},{"ids":{"database_table_183319":259,"database_table_184385":22},"value":{"id":980198,"value":"marginalised-group-engagement","color":"light-pink"}},{"ids":{"database_table_183319":234,"database_table_184385":25},"value":{"id":980202,"value":"monitoring-impacts","color":"darker-red"}},{"ids":{"database_table_183319":255,"database_table_184385":27},"value":{"id":980178,"value":"equitable-access","color":"yellow"}},{"ids":{"database_table_183319":256,"database_table_184385":27},"value":{"id":980178,"value":"equitable-access","color":"yellow"}},{"ids":{"database_table_183319":260,"database_table_184385":27},"value":{"id":980178,"value":"equitable-access","color":"yellow"}},{"ids":{"database_table_183319":236,"database_table_184385":38},"value":{"id":986019,"value":"respect-rights","color":"light-blue"}},{"ids":{"database_table_183319":233,"database_table_184385":39},"value":{"id":991258,"value":"foster-responsible-aied","color":"red"}},{"ids":{"database_table_183319":235,"database_table_184385":39},"value":{"id":991258,"value":"foster-responsible-aied","color":"red"}},{"ids":{"database_table_183319":244,"database_table_184385":39},"value":{"id":991258,"value":"foster-responsible-aied","color":"red"}}],"Lookup":[{"id":227,"value":"The strengths and benefits of AI to improve education outcomes include: personalised learning, enhanced critical thinking, accessibility and inclusivity, data-driven insights, streamlined administrative process and future ready skills"},{"id":228,"value":"The future impacts of generative tools on Education can be turned into positives if we focus our efforts on continuous professional development, emphasising human value, clear policy guidelines and collaboration between different stakeholders"},{"id":229,"value":"The implementation of AI tools encompasses risks and challenges which need to be carefully considered, in order to develop the right strategies to address them"},{"id":230,"value":"We can draw on past/current experiences that represent a parallel to AI on Education. The experience of a virtual classroom rollout and the learnings from the Health sector on setting up the pathways for a successful implementation of AI tools, are cases that can serve as guidelines for best practice"},{"id":231,"value":"A collaboration between educators, researchers, policymakers, and technology developers is needed to ensure that generative AI tools are developed based on evidence-based research and aligned with educational goals"},{"id":232,"value":"Clear ethical guidelines and standards for the use of generative AI tools in education."},{"id":233,"value":"Promote AI models that are transparent and explainable, allowing educators and students to understand how AI-generated content or assessments are produced."},{"id":234,"value":"Encourage methods to identify and mitigate biases in generative AI tools. Curate training data carefully, monitor for potential bias, and conduct regular AI system audits to ensure fairness."},{"id":235,"value":"Ensure educators review and validate AI-generated content to maintain appropriateness and accuracy."},{"id":236,"value":"Promote responsible data collection, storage, and use in AI implementations. Ensure data is used only for educational purposes and is adequately protected from unauthorized access."},{"id":237,"value":"Extend the cyber security national strategy to protect AI models and educational data from cyber threats and potential misuse. Implement privacy-preserving techniques to safeguard individual student data."},{"id":238,"value":"Promote collaboration or forums of educational institutions to develop and enforce academic integrity policies that address potential misuse of AI tools, including plagiarism detection and cheating prevention."},{"id":239,"value":"Encourage rigorous validation of AI tools for educational purposes. Promote peer-reviewed and transparently published studies to ensure effectiveness and reliability."},{"id":240,"value":"Develop ongoing education and awareness programs about the opportunities and challenges of using generative AI tools for educators, students, and stakeholders. Promote discussions on ethical considerations and responsible AI use."},{"id":241,"value":"Enable collaboration between experts in education, AI development, ethics, and policy to collectively address the complex challenges posed by generative AI in education."},{"id":242,"value":"Professional development programs to equip educators with the necessary skills and knowledge to effectively integrate generative AI tools into their teaching practices. This includes an emphasis on ongoing training and support to keep educators updated with the latest advancements in AI."},{"id":243,"value":"To future-proofing the education workforce, a focus is needed on initiatives related to reskilling and upskilling to prepare them for the changing landscape of education with the integration of AI technologies."},{"id":244,"value":"Generative AI tools may augment and enhance the role of educators, rather than replace them. The unique abilities of human educators, such as emotional intelligence, empathy, and adaptability, are not easily replicated by AI."},{"id":245,"value":"Generative AI tools have the potential to provide continuous assessment and timely feedback to both students and teachers. This can support formative assessment practices and enable educators to intervene when needed to address learning gaps."},{"id":246,"value":"With the automation of administrative tasks, such as grading and lesson planning, can free up educators' time, allowing them to focus on building meaningful connections with students and designing innovative learning experiences."},{"id":247,"value":"With the help of AI, the current frontier of education can be extended to reach wider audiences. This can help towards ensuring all students, regardless of their background or location, have equal access to quality education."},{"id":248,"value":"A collaboration between educators, researchers, policymakers, and technology  developers is needed to ensure that generative AI tools are developed based on evidence-based research and aligned with educational goals."},{"id":249,"value":"Clear policy guidelines can provide the confidence needed to rollout AI in education, including but not limited to ethical frameworks, privacy and intellectual property regulation."},{"id":250,"value":"The future impacts of generative tools on Education can be turned into positives if we focus our efforts on continuous professional development, emphasising human value, clear policy guidelines and collaboration between different stakeholders"},{"id":251,"value":"The implementation of AI tools encompasses risks and challenges which need to be carefully considered, in order to develop the right strategies to address them."},{"id":252,"value":"We can draw on past/current experiences that represent a parallel to AI on Education. The experience of a virtual classroom rollout and the learnings from the Health sector on setting up the pathways for a successful implementation of AI tools, are cases that can serve as guidelines for best practice."},{"id":253,"value":"A collaboration between educators, researchers, policymakers, and technology developers is needed to ensure that generative AI tools are developed based on evidence-based research and aligned with educational goals."},{"id":255,"value":"Digital Infrastructure and Access: Invest in improving digital infrastructure and internet connectivity in disadvantaged communities, including rural and remote areas. Ensure that schools and educational institutions in these areas have access to reliable internet and necessary technology to use AI tools effectively."},{"id":256,"value":"Affordable Technology: Research providers to procure or support negotiations with technology companies to provide low-cost or subsidized devices for disadvantaged students and families."},{"id":257,"value":"Community Engagement: Engage with local communities and families to raise awareness about the benefits of AI in education and address any concerns or misconceptions they may have."},{"id":258,"value":"Training and Support: Provide comprehensive training and support for educators, parents, and students on how to use AI tools effectively. Ensure that educators are equipped with the necessary skills to integrate AI into their teaching practices and that parents understand how AI can support their child's learning."},{"id":259,"value":"Research and Evaluation: Invest in research and evaluation of AI implementations in disadvantaged communities to understand their effectiveness and identify areas for improvement. This data-driven approach will help optimize AI use for these cohorts."},{"id":260,"value":"Policy Strategy: Prioritise policies that grant equitable access to AI technologies and educational resources for disadvantaged communities."},{"id":261,"value":"AI for Personalized Learning: Promote the use of AI-driven personalized learning platforms that adapt to each student's needs and learning pace. These platforms can help address individual learning gaps and cater to diverse learning styles."}]},{"id":90,"order":"89.00000000000000000000","submission_number":"89","Submitter":"John Seddon","Type of org":{"id":977280,"value":"Individual","color":"gray"},"Notes":"Flags Asimov's four laws","Recommendations":[],"Uses-opportunities":[],"Risks-challenges":[],"References-footnotes":[],"Processed":true,"Recco_tags":[],"Lookup":[],"FLAG":""},{"id":91,"order":"90.00000000000000000000","submission_number":"90","Submitter":"Tech Council of Australia","Type of org":{"id":977281,"value":"Peak body","color":"green"},"Notes":"","Recommendations":[{"id":220,"value":"Support the development of a national principles-based framework for the safe and effective use of AI in schools"},{"id":221,"value":"Encourage a whole-of-government approach to coordinate and align GenAI use in the education system with other policy development processes"},{"id":222,"value":"Ensure that the draft framework developed by the Education Ministers AI in Schools Taskforce undergoes thorough consultation"},{"id":224,"value":"Establish clear legal and ethical responsibilities for GenAI use in schools"},{"id":225,"value":"Encourage Australian governments to aim for coherence and interoperability between Australian AI policy and emerging frameworks and international standards for AI"}],"Uses-opportunities":[{"id":123,"value":"Enriched and personalized learning experiences for students"},{"id":124,"value":"Improved equity in education for students"},{"id":125,"value":"Practical hands-on experience with technology tools for students"},{"id":126,"value":"Essential digital skills development for students"},{"id":127,"value":"Opportunity for differentiated learning experiences for students"},{"id":128,"value":"Adapting to each student's unique needs and learning styles for students"},{"id":129,"value":"Increased student motivation and engagement for students"},{"id":130,"value":"Enhanced retention and learning outcomes for students"},{"id":131,"value":"Access to a dedicated 'assistant' or 'tutor' for prompt inspiration and creativity for students"},{"id":132,"value":"Knowledge discovery and exploration of various topics for students"},{"id":133,"value":"Simplification or expansion of challenging concepts for students"},{"id":134,"value":"Presenting information in different ways or languages to encourage better understanding for students"},{"id":136,"value":"Providing feedback and suggesting ways to improve students' work"},{"id":137,"value":"Cultivating digital skills, literacy, and awareness for students"},{"id":138,"value":"Uplifting digital literacy and awareness of technology use for students"},{"id":139,"value":"Prompting critical engagement and questioning of technology for students"},{"id":140,"value":"Ensuring safe and responsible use of technology for students"},{"id":141,"value":"Empowering students to embrace technology as an enabling force"},{"id":142,"value":"Enhancing equity in education for students"},{"id":143,"value":"Offering translation tools for refugees and migrants to enhance learning"},{"id":144,"value":"Preserving and sharing cultural knowledge for First Nations communities"},{"id":145,"value":"Facilitating learning for neurodiverse students through technology tools"},{"id":146,"value":"Reducing teacher workload and alleviating administrative pressures"},{"id":149,"value":"Assisting educators with tasks such as lesson design, planning, and assessment drafting"},{"id":150,"value":"Creating learning resources and developing model answers for educators"},{"id":151,"value":"Supporting differentiated learning and teaching for educators"},{"id":153,"value":"Turning teachers' focus on developing students' core intrinsic learning skills"},{"id":154,"value":"Fostering critical thinking, logical reasoning, and inspiring creativity for teachers"},{"id":155,"value":"Helping teachers in providing adequate learning interventions to support students"}],"Risks-challenges":[{"id":182,"value":"Potential for data leakage"},{"id":183,"value":"Potential for inaccurate information"},{"id":184,"value":"Potential for harmful content"},{"id":185,"value":"Potential for bias in generated content"}],"References-footnotes":[],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":220,"database_table_184385":2},"value":{"id":980180,"value":"guidelines","color":"light-yellow"}},{"ids":{"database_table_183319":224,"database_table_184385":2},"value":{"id":980180,"value":"guidelines","color":"light-yellow"}},{"ids":{"database_table_183319":221,"database_table_184385":3},"value":{"id":980182,"value":"situate-with-existing-policy","color":"darker-red"}},{"ids":{"database_table_183319":222,"database_table_184385":3},"value":{"id":980182,"value":"situate-with-existing-policy","color":"darker-red"}},{"ids":{"database_table_183319":225,"database_table_184385":20},"value":{"id":980179,"value":"ongoing-and-global-monitoring","color":"dark-brown"}}],"Lookup":[{"id":220,"value":"Support the development of a national principles-based framework for the safe and effective use of AI in schools"},{"id":221,"value":"Encourage a whole-of-government approach to coordinate and align GenAI use in the education system with other policy development processes"},{"id":222,"value":"Ensure that the draft framework developed by the Education Ministers AI in Schools Taskforce undergoes thorough consultation"},{"id":224,"value":"Establish clear legal and ethical responsibilities for GenAI use in schools"},{"id":225,"value":"Encourage Australian governments to aim for coherence and interoperability between Australian AI policy and emerging frameworks and international standards for AI"}]},{"id":92,"order":"92.00000000000000000000","submission_number":"91","Submitter":"School of Education, La Trobe University","Type of org":{"id":977287,"value":"University-centre","color":"orange"},"Notes":"","Recommendations":[{"id":213,"value":"Provide system-level support for educators to integrate Generative AI opportunities into teaching practice."},{"id":214,"value":"Anticipate copyright issues raised by Generative AI and develop appropriate policies to address potential impacts on educators, students, and learning environments"},{"id":215,"value":"Collaborate with teacher educators, Higher Education, and First Nations communities to mitigate limited visibility of culturally diverse populations, decontextualization of cultural knowledge, and amplification of racism, abusive content, and online hate through Generative AI tools"},{"id":216,"value":"Support the establishment of research centers to explore the opportunities and challenges of emerging technologies like Generative AI on education systems and teaching and learning practices"},{"id":217,"value":"Initiate assessment reform in the school curriculum emphasizing a strengths-based approach that recognizes the potential applications and future integrations of Generative AI while promoting critical and creative thinking skills in teachers and students to differentiate between productive and non-productive uses of AI"},{"id":218,"value":"Prioritize digital literacy training incorporating AI literacy for pre-service teachers and professional development of teachers."}],"Uses-opportunities":[],"Risks-challenges":[{"id":164,"value":"opacity and unexplainability"},{"id":165,"value":"data privacy and security"},{"id":166,"value":"personalisation and fairness"},{"id":167,"value":"effectiveness and reliability"},{"id":168,"value":"Lack of indicators of fabricated sources"},{"id":169,"value":"Blindness to the relationality of sources"},{"id":170,"value":"Impeded traceability to original content creators and authors"},{"id":171,"value":"Obfuscation of copyright conditions"},{"id":172,"value":"Legal and integrity risks related to consent, compensation, cultural sensitivity, and output quality"},{"id":173,"value":"Uncertainty about the integrity of Generative AI tools and copyright ramifications for teaching practice"},{"id":174,"value":"Potential increase in costs for schools accessing Generative AI tools"},{"id":175,"value":"Restructuring of access to copyrighted content through micropayments and platform-based deals"},{"id":176,"value":"Data degradation over time due to the use of mixed original and AI-generated data"},{"id":177,"value":"Risk of algorithmic bias and underrepresentation of students from diverse backgrounds"},{"id":178,"value":"Lack of cultural understanding and reproduction of colonialist paradigms"},{"id":179,"value":"Risk of isolation or invisibility for First Nations students and the need for cultural visibility protocols"},{"id":180,"value":"Augmentation of online abuse and challenges in identification and moderation"},{"id":181,"value":"Ownership and consent issues regarding human-generated data"}],"References-footnotes":[],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":218,"database_table_184385":1},"value":{"id":980196,"value":"PD","color":"light-red"}},{"ids":{"database_table_183319":217,"database_table_184385":6},"value":{"id":980185,"value":"new-assessment-models","color":"darker-pink"}},{"ids":{"database_table_183319":215,"database_table_184385":7},"value":{"id":980187,"value":"stakeholder-engagement","color":"dark-green"}},{"ids":{"database_table_183319":216,"database_table_184385":12},"value":{"id":980192,"value":"research-investment","color":"orange"}},{"ids":{"database_table_183319":213,"database_table_184385":19},"value":{"id":980186,"value":"capacity-building","color":"light-yellow"}},{"ids":{"database_table_183319":214,"database_table_184385":38},"value":{"id":986019,"value":"respect-rights","color":"light-blue"}}],"Lookup":[{"id":213,"value":"Provide system-level support for educators to integrate Generative AI opportunities into teaching practice."},{"id":214,"value":"Anticipate copyright issues raised by Generative AI and develop appropriate policies to address potential impacts on educators, students, and learning environments"},{"id":215,"value":"Collaborate with teacher educators, Higher Education, and First Nations communities to mitigate limited visibility of culturally diverse populations, decontextualization of cultural knowledge, and amplification of racism, abusive content, and online hate through Generative AI tools"},{"id":216,"value":"Support the establishment of research centers to explore the opportunities and challenges of emerging technologies like Generative AI on education systems and teaching and learning practices"},{"id":217,"value":"Initiate assessment reform in the school curriculum emphasizing a strengths-based approach that recognizes the potential applications and future integrations of Generative AI while promoting critical and creative thinking skills in teachers and students to differentiate between productive and non-productive uses of AI"},{"id":218,"value":"Prioritize digital literacy training incorporating AI literacy for pre-service teachers and professional development of teachers."}]},{"id":94,"order":"93.00000000000000000000","submission_number":"92","Submitter":"Moodle","Type of org":{"id":977288,"value":"Company","color":"dark-purple"},"Notes":"","Recommendations":[{"id":606,"value":"We should, and IMO we must invest better in our education if we want to truly create a leading country in the future."},{"id":607,"value":"1) We need to be planning for large shifts in emphasis around skills training and funding of such, both for young people coming through the system and for adults who need to change direction throughout life in response to automation. 2) As automation progresses, it seems 100% clear to me that our government needs to be planning and budgeting for a world where our current underlying economic assumption that every able-bodied person should work for a living is no longer true. Some form of Universal Basic Income or at least changes to the monetary system needs to be worked out. This is not just a response to a crisis, as COVID was, but is actually planning for a (hopefully) positive golden age where we really do have robots (both software and hardware) taking care of a lot of the work involved in running society."},{"id":608,"value":"The power of AI in the next decade means we have a real opportunity here to use AI to help us reshape education in a way that the very best available education for every citizen is the CLOSEST SCHOOL available with well-paid teachers, excellent resources, and no fees. Note that Iâ€™m not saying AI needs to do all the teaching (it shouldnâ€™t) but that use of AI can help us optimise the use of education funds to support our educators better. Education of people is much more than writing essays, obviously, itâ€™s a whole-body experience that helps the enculturation of our next generations. Our overarching goal (and this really should be apolitical) must be to maximise opportunities for our citizens, propelling us towards a brighter future where all UN Sustainability Goals are achieved."}],"Uses-opportunities":[],"Risks-challenges":[{"id":385,"value":"OECD studies (https://oecd.org/employment-outlook/2023/) and others point to a loss of 27% jobs worldwide being replaced by AI in the next few years or so, and it will only increase after that. On top of that, most of the remaining jobs will be affected/changed by AI"},{"id":386,"value":"A lot of current state of the art in AI is controlled by big tech (such as Microsoft, Amazon, Google, Apple etc), due to the huge budgets they have as well as control over many of the popular infrastructure systems we use. However, itâ€™s wise for Australia to be cautious about recommending any of these particular large commercial systems to form the basis of any of our education infrastructure in the long term. As AI systems are embedded into education, their influence over what is taught and how itâ€™s taught can grow, and quite apart from the privacy concerns which are well-known already, there is a real danger to allowing large profit-focussed global companies to have this kind of control over the curriculum and education of our future generations. Even when accuracy of information is less of a problem, there are certainly many cultural biases and curation of knowledge inherent in their design that can have possibly negative consequences for us here in Australia"}],"References-footnotes":[{"id":889,"value":"https://openedtech.global"}],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":607,"database_table_184385":8},"value":{"id":980188,"value":"new-workforce-model","color":"light-brown"}},{"ids":{"database_table_183319":606,"database_table_184385":17},"value":{"id":980195,"value":"resourcing","color":"dark-cyan"}},{"ids":{"database_table_183319":608,"database_table_184385":38},"value":{"id":986019,"value":"respect-rights","color":"light-blue"}}],"Lookup":[{"id":606,"value":"We should, and IMO we must invest better in our education if we want to truly create a leading country in the future."},{"id":607,"value":"1) We need to be planning for large shifts in emphasis around skills training and funding of such, both for young people coming through the system and for adults who need to change direction throughout life in response to automation. 2) As automation progresses, it seems 100% clear to me that our government needs to be planning and budgeting for a world where our current underlying economic assumption that every able-bodied person should work for a living is no longer true. Some form of Universal Basic Income or at least changes to the monetary system needs to be worked out. This is not just a response to a crisis, as COVID was, but is actually planning for a (hopefully) positive golden age where we really do have robots (both software and hardware) taking care of a lot of the work involved in running society."},{"id":608,"value":"The power of AI in the next decade means we have a real opportunity here to use AI to help us reshape education in a way that the very best available education for every citizen is the CLOSEST SCHOOL available with well-paid teachers, excellent resources, and no fees. Note that Iâ€™m not saying AI needs to do all the teaching (it shouldnâ€™t) but that use of AI can help us optimise the use of education funds to support our educators better. Education of people is much more than writing essays, obviously, itâ€™s a whole-body experience that helps the enculturation of our next generations. Our overarching goal (and this really should be apolitical) must be to maximise opportunities for our citizens, propelling us towards a brighter future where all UN Sustainability Goals are achieved."}],"FLAG":"-"},{"id":95,"order":"94.00000000000000000000","submission_number":"93","Submitter":"Pymble Ladiesâ€™ College","Type of org":{"id":995198,"value":"School","color":"purple"},"Notes":"45 pages cover various possible uses and challenges; these are not extracted here. p.47 gives recommendations.","Recommendations":[{"id":609,"value":"Professional Development for Educators: Provide professional development opportunities for educators on AI, including understanding its strengths, limitations, data interpretation, and integration into lesson planning and delivery."},{"id":610,"value":"Promotion of AI Literacy: Incorporate AI literacy into the curriculum, which includes understanding how AI works, its ethical implications, and how to effectively use AI systems. This also involves developing an AI-Skills Continuum for progressively enhancing students' AI abilities from basic comprehension to problem-solving."},{"id":611,"value":"Investment in AI Infrastructure: Provide necessary resources, such as high-speed internet connectivity, robust hardware, and AI software, to support AI integration into education."},{"id":612,"value":"Ethical Standards and Privacy Protection: Establish robust ethical standards and guidelines for AI use in education, including stringent student data privacy protection measures and clear rules for AI application in learning and assessments."},{"id":613,"value":"Encourage Collaboration: Foster collaboration among tech companies, educators, and policymakers to ensure AI tools meet educational needs effectively and ethically."},{"id":614,"value":"Regulation of AI Tools: Implement strict regulations and quality standards for AI tools in education, including a rigorous certification process for new AI applications."},{"id":615,"value":"Shift in Learning Paradigms: Advocate for a transition from traditional outcome-based education to a problem-solving, learner-centric approach, facilitated by AI. This includes adjusting pedagogical and assessment strategies to suit the capabilities of AI."},{"id":616,"value":"Inclusive and Accessible AI Design: Prioritise inclusivity and accessibility in AI tool design, catering to students with diverse abilities, learning styles, and backgrounds."},{"id":617,"value":"Continuous Research and Evaluation: Encourage ongoing research into AI's impact on educational outcomes, including longitudinal studies to understand its long-term effects."},{"id":618,"value":"Promotion of Mastery and Engagement: Use AI to create personalised, engaging learning experiences, including game-based learning and real-world problem-solving tasks."},{"id":619,"value":"Increased Student Autonomy: Encourage greater student control over their learning journey through the use of AI tools."},{"id":620,"value":"Reduced Curriculum Content Load: Shift focus from covering extensive content to mastering key concepts and skills, facilitated by AI's personalised learning capabilities. This may require a review and potential revision of existing curricula"}],"Uses-opportunities":[],"Risks-challenges":[],"References-footnotes":[],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":609,"database_table_184385":1},"value":{"id":980196,"value":"PD","color":"light-red"}},{"ids":{"database_table_183319":612,"database_table_184385":2},"value":{"id":980180,"value":"guidelines","color":"light-yellow"}},{"ids":{"database_table_183319":618,"database_table_184385":6},"value":{"id":980185,"value":"new-assessment-models","color":"darker-pink"}},{"ids":{"database_table_183319":619,"database_table_184385":6},"value":{"id":980185,"value":"new-assessment-models","color":"darker-pink"}},{"ids":{"database_table_183319":610,"database_table_184385":10},"value":{"id":980190,"value":"curricula-changes","color":"light-green"}},{"ids":{"database_table_183319":620,"database_table_184385":10},"value":{"id":980190,"value":"curricula-changes","color":"light-green"}},{"ids":{"database_table_183319":614,"database_table_184385":11},"value":{"id":980191,"value":"new-policy","color":"dark-purple"}},{"ids":{"database_table_183319":615,"database_table_184385":14},"value":{"id":980193,"value":"prepare-learners","color":"dark-gray"}},{"ids":{"database_table_183319":611,"database_table_184385":17},"value":{"id":980195,"value":"resourcing","color":"dark-cyan"}},{"ids":{"database_table_183319":613,"database_table_184385":19},"value":{"id":980186,"value":"capacity-building","color":"light-yellow"}},{"ids":{"database_table_183319":617,"database_table_184385":21},"value":{"id":980197,"value":"evidence-generation","color":"brown"}},{"ids":{"database_table_183319":616,"database_table_184385":27},"value":{"id":980178,"value":"equitable-access","color":"yellow"}}],"Lookup":[{"id":609,"value":"Professional Development for Educators: Provide professional development opportunities for educators on AI, including understanding its strengths, limitations, data interpretation, and integration into lesson planning and delivery."},{"id":610,"value":"Promotion of AI Literacy: Incorporate AI literacy into the curriculum, which includes understanding how AI works, its ethical implications, and how to effectively use AI systems. This also involves developing an AI-Skills Continuum for progressively enhancing students' AI abilities from basic comprehension to problem-solving."},{"id":611,"value":"Investment in AI Infrastructure: Provide necessary resources, such as high-speed internet connectivity, robust hardware, and AI software, to support AI integration into education."},{"id":612,"value":"Ethical Standards and Privacy Protection: Establish robust ethical standards and guidelines for AI use in education, including stringent student data privacy protection measures and clear rules for AI application in learning and assessments."},{"id":613,"value":"Encourage Collaboration: Foster collaboration among tech companies, educators, and policymakers to ensure AI tools meet educational needs effectively and ethically."},{"id":614,"value":"Regulation of AI Tools: Implement strict regulations and quality standards for AI tools in education, including a rigorous certification process for new AI applications."},{"id":615,"value":"Shift in Learning Paradigms: Advocate for a transition from traditional outcome-based education to a problem-solving, learner-centric approach, facilitated by AI. This includes adjusting pedagogical and assessment strategies to suit the capabilities of AI."},{"id":616,"value":"Inclusive and Accessible AI Design: Prioritise inclusivity and accessibility in AI tool design, catering to students with diverse abilities, learning styles, and backgrounds."},{"id":617,"value":"Continuous Research and Evaluation: Encourage ongoing research into AI's impact on educational outcomes, including longitudinal studies to understand its long-term effects."},{"id":618,"value":"Promotion of Mastery and Engagement: Use AI to create personalised, engaging learning experiences, including game-based learning and real-world problem-solving tasks."},{"id":619,"value":"Increased Student Autonomy: Encourage greater student control over their learning journey through the use of AI tools."},{"id":620,"value":"Reduced Curriculum Content Load: Shift focus from covering extensive content to mastering key concepts and skills, facilitated by AI's personalised learning capabilities. This may require a review and potential revision of existing curricula"}],"FLAG":"-"},{"id":96,"order":"95.00000000000000000000","submission_number":"94","Submitter":"Grok Academy","Type of org":{"id":977289,"value":"nonprofit","color":"darker-gray"},"Notes":"Discursive piece, there are implied risks and opportunities throughout.","Recommendations":[],"Uses-opportunities":[],"Risks-challenges":[],"References-footnotes":[],"Processed":false,"Recco_tags":[],"Lookup":[],"FLAG":"Y"},{"id":97,"order":"96.00000000000000000000","submission_number":"96","Submitter":"The Tasmanian Department for Education, Children and Young People","Type of org":{"id":977282,"value":"Govt","color":"orange"},"Notes":"","Recommendations":[{"id":621,"value":"DECYP believes there is a need for a sustainable and adaptable response to generative AI in learning, teaching and assessment, and academic integrity policies and procedures. There will need to be ongoing education and training for students on how to appropriately use generative AI, should use become more commonplace. Detection technology capable of discerning between human and generative AI, e.g. Turnitin, will also need to continue developing and adapting."}],"Uses-opportunities":[{"id":485,"value":"It is in the best interests of Tasmanian students that AI be harnessed as a learning and teaching tool. AI in education has the potential to improve student engagement and promote personalised learning. For teachers, AI in schools can relieve administrative burden, freeing up more time to focus on teaching and providing support to students and families. In other areas of the education system, AI may increase efficiency, enhancing teaching and learning design, learning outcomes and student and teacher experience."}],"Risks-challenges":[{"id":390,"value":"One of the major concerns regarding the use of generative AI in education is ensuring that students maintain the core principles of academic integrity through their work. There are legitimate concerns about the use of generative AI such as ChatGPT for plagiarism. Generative AI is not unique in its disruption of education. Shortcuts facilitated by various social and technological innovations, whilst often being beneficial, can also be a hindrance to learning. DECYP, like other jurisdictions, is concerned about the potential for new tools to be misused."},{"id":391,"value":"DECYP recognises that there are also challenges and risks associated with AI. Privacy and security is a significant risk, particularly when it comes to collecting and storing personal data. Also, with some AI platforms, it is recognised that users must be 18 years or older, precluding many school-aged children from using it. Bias in algorithms or incorrect information is also a concern, as the outcomes produced by generative AI are only as good as the data it has been trained on. Accountability is another factor â€“ if something goes wrong, who is held accountable? These challenges must be considered and addressed before any school can successfully implement AI in teaching and learning"}],"References-footnotes":[],"Processed":true,"Recco_tags":[{"ids":{"database_table_183319":621,"database_table_184385":6},"value":{"id":980185,"value":"new-assessment-models","color":"darker-pink"}}],"Lookup":[{"id":621,"value":"DECYP believes there is a need for a sustainable and adaptable response to generative AI in learning, teaching and assessment, and academic integrity policies and procedures. There will need to be ongoing education and training for students on how to appropriately use generative AI, should use become more commonplace. Detection technology capable of discerning between human and generative AI, e.g. Turnitin, will also need to continue developing and adapting."}],"FLAG":"-"}]
