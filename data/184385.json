[{"id":1,"order":"1.00000000000000000000","Name":{"id":980196,"value":"PD","color":"light-red"},"Notes":"","Recommendations":[{"id":1,"value":"Teacher Professional Development"},{"id":13,"value":"Education/professional development;"},{"id":24,"value":"â—    that teachers, school leaders and principals be educated about the risks and opportunities presented by AI through a nationally consistent approach."},{"id":33,"value":"AI Literacy for Teachers;"},{"id":34,"value":"Focus on ITE"},{"id":42,"value":"Ensuring we know how these tools are working and coming up with the decisions they make is important.AI tools are pedagogical agents that will be drawing on what they may recognise as weaknesses and strengths of students and will change the way they support students accordingly. Whilst this sounds highly effective and appropriate pedagogy, this will require data capture that we, as teachers, may not see or know is happening."},{"id":43,"value":"Knowing where this data is stored and communicated is also important. English teachers need to understand the implications of using such tools and the problematic nature of any data capture of our students that may remove student agency in their life- long learning process and what it may do with data like facial recognition or other bodily data captures that can be used to determine how each individual may be perceived by the AI tool and how it may attribute bias potentially limiting the life choices of the students it â€˜teachesâ€™.\nWhile this issue is clearly one for education sectors and schools, campaigns to support parent and student understanding of the risk to student data and how parents, students and teachers can keep them safe is important. Adequate and timely professional learning for teachers is critical so they are aware of the affordances of the system and how to ensure the protection of student data."},{"id":46,"value":"Decisions about the suitability of tools could be made at scale to ensure that they are trustworthy and equitable without undermining teachers' pedagogy. Teachers can advocate for the access to use specific AI tools in the classroom but there should be a cross-sectoral body that ensures the safety of such tools prior to their introduction to the classroom and checks on the ongoing quality and safety of the AI tool as it is updated. These changes will need to be accompanied by significant teacher professional development, both by the system to understand the above demands but also by the professional associations who are subject based and can help teachers maximise the effectiveness of AI for their discipline and in their classrooms"},{"id":50,"value":"â€¢  Short courses (both in higher education and vocational education) in generative AI may help formalise a sufficiently structured curriculum that addresses both technical competency as well as anchoring it in ethical use, critical thinking, evaluation and scenarios for use."},{"id":100,"value":"The use of generative AI tools for learning, differentiation and assessment in automated systems and augmented intelligence systems, for a broader understanding of generative AI software should be introduced as a key element of Initial Teacher Education."},{"id":121,"value":"more work is required to understand how such tools can be best leveraged to improve outcomes. To facilitate this transition, further and significant investment in comprehensive professional development programs for educators,is necessary to equip them with the necessary skills in data analysis and digital and AI literacy."},{"id":132,"value":"â€¢ Establish training/fellowship programs specific to Gen-AI to help staff upskills and innovate."},{"id":136,"value":"3. Government funding for the creation of programs to upskill library and teaching staff to be AI literate, and to be able to teach AI literacy to students."},{"id":151,"value":"Support for higher education staff and the professional development of staff in the use of AI Staff need to be equipped with the necessary capabilities and support to effectively adapt their teaching and learning activities to the emerging AI environment, including appropriate training in AI usage. This should extend to all staff who are engaged with teaching, learning and research, as well as administrative and professional/technical staff, where there is the expectation or necessity for AI to be part of their activities. In particular, casual, sessional, contract and other staff employed non-permanently should be supported by the institution in relation to their professional development around the use of AI."},{"id":153,"value":"Understanding the potential and risks of genAI is a cross-sector, cross-discipline, societal concern; national priorities should reflect this through recognition of and support for interdisciplinarity and the social sciences in genAI innovation across sectors. - Recommendation 1: support interdisciplinary and cross -sector learning for ethical engagement with genAI, in the short term through support for targeted professional learning or microcredentials, and in the mid-term through addressing concerns raised regarding the jobs ready graduates package of reforms"},{"id":159,"value":"Recommendation 7: Provide support for Professional Learning to target skills for staff across institutions serving diverse communities, to support communities in effectively (dis)engaging with tools, and to target support of vulnerable populations and specific risks"},{"id":164,"value":"Recommendation 3: Provide professional development opportunities, supported by professional development leave and other incentives, to teach existing educators how to engage with AI both inside and outside the classroom."},{"id":165,"value":"Recommendation 4: Require the inclusion of AI literacy training as part of initial teacher training programs."},{"id":167,"value":"Recommendation 6: Develop and provide ethics and AI data privacy training for educators."},{"id":169,"value":"ACARA understands the parallels that exist between curriculum implementation and teacher professional development in building capacity for teaching and learning with and about AI. Through the provision of professional development, with a focus on the intent of the curriculum, teachers will gain an equivalent understanding to that of their students about the purpose, use, structure and risks of using generative AI and other types of AI more broadly. ACARA will be developing some professional learning modules and would be keen to partner with jurisdictions and sectors and teacher professional associations to support teachers to plan and implement the curriculum relevant to understanding AI"},{"id":172,"value":"ACARA is currently providing information to key educational stakeholders to support them with questions about AI in the Australian Curriculum and is planning to develop more detailed information to show why it is important to teach about AI while recognising that teachers and students are using it, in and out of the classroom. The ability to have discussions about the ethical consideration (eg cheating) and the potential limitations (eg if you donâ€™t know the content how will you know whether Chat GPT is correct), but also the benefits of AI (eg retrieving and synthesising a large volume of information) is essential."},{"id":188,"value":"Recommendation 9: Professional development and training should be provided to teachers to ensure that they are able to engage with generative AI tools in ways that harness its potential benefits while protecting against the recognised risks"},{"id":218,"value":"Prioritize digital literacy training incorporating AI literacy for pre-service teachers and professional development of teachers."},{"id":228,"value":"The future impacts of generative tools on Education can be turned into positives if we focus our efforts on continuous professional development, emphasising human value, clear policy guidelines and collaboration between different stakeholders"},{"id":240,"value":"Develop ongoing education and awareness programs about the opportunities and challenges of using generative AI tools for educators, students, and stakeholders. Promote discussions on ethical considerations and responsible AI use."},{"id":242,"value":"Professional development programs to equip educators with the necessary skills and knowledge to effectively integrate generative AI tools into their teaching practices. This includes an emphasis on ongoing training and support to keep educators updated with the latest advancements in AI."},{"id":243,"value":"To future-proofing the education workforce, a focus is needed on initiatives related to reskilling and upskilling to prepare them for the changing landscape of education with the integration of AI technologies."},{"id":250,"value":"The future impacts of generative tools on Education can be turned into positives if we focus our efforts on continuous professional development, emphasising human value, clear policy guidelines and collaboration between different stakeholders"},{"id":258,"value":"Training and Support: Provide comprehensive training and support for educators, parents, and students on how to use AI tools effectively. Ensure that educators are equipped with the necessary skills to integrate AI into their teaching practices and that parents understand how AI can support their child's learning."},{"id":308,"value":"The need for governments to directly engage with upskilling of Australian teachers to build the capacity of the sector to harness the potential benefits of generative AI and to ensure equity in distribution of these benefits for both teachers and students"},{"id":333,"value":"That the Australian Government provide funding support to universities to train staff in GAI literacy."},{"id":362,"value":"there be further investment in professional development, including Microcredentials for\nacademic teaching staff on the use and usability of Generative AI."},{"id":373,"value":"Providing adequate training and professional development opportunities for teachers to effectively utilise generative AI tools in their classrooms. This includes training on the use of AI tools, understanding their limitations, and developing pedagogical strategies to integrate them into teaching practices."},{"id":417,"value":"Provide professional learning and development to educators"},{"id":446,"value":"Professional Learning: Educators working with EAL/D cohorts need access to high-quality professional learning programs related to the use of generative Al in educational settings. We recommend that professional learning programs familiarise and develop teachers' expertise with Al tools and relevant pedagogies. It is particularly important to consider the changing role of EAL/D teachers given the enormous potential of Al for new and creative ways for learning languages"},{"id":449,"value":"ISA recommends investigation and implementation of funded initiatives to support the national teacher workforce in all education sectors in the effective use of AI technology."},{"id":463,"value":"Develop data literacy skills to effectively analyze and interpret AI-generated data"},{"id":467,"value":"Provide ongoing professional development for educators to integrate AI tools effectively"},{"id":479,"value":"It is critically important that education systems provide the resourcing that supports teachersâ€™ access to appropriate, high-quality and ongoing professional development (PD) regarding use of new and emerging digital technologies."},{"id":503,"value":"Invest in structured training for classroom staff on the use of GenAI in the classroom and how to educate students about using the technology."},{"id":506,"value":"Upskill and train regulators and policymakers about the opportunities and risks of AI in education, as well as best practice policy and regulatory approaches."},{"id":516,"value":"Teachersâ— Require guidance on how assessment and teaching can be delivered in a way which achieves the desired educational outcomes, but also ensures that students use GenAI in a productive way."},{"id":521,"value":"Policymakers and regulators â— Require upskilling regarding the risks and opportunities presented by GenAI, and the specific implications it has for the education system."},{"id":544,"value":"Adopt ACODE recommendations: https://publications.ascilite.org/index.php/APUB/article/view/401 \nRecommendations1.Embrace AI in learning, teaching, and assessment, but consider potential risks and challenges that come with it, such as academic integrity concerns and workload issues.2.Foster a culture of transparency, collaboration, and partnership between educators, students, and AI experts, to ensure that AI is used ethically and effectively.3.Develop evidence-based support systems and guidelines for AI use in education, and regularly update them to keep up with the latest developments and challenges.4.Identify and provide appropriate training and professional development opportunities for educators to build their AI competencies, confidence and fluency.5.Consider the potential impact of AI on equity and accessibility and ensure that AI solutions are designed to benefit all students, regardless of their background or circumstances.6.Collaborate with external bodies, such as accrediting bodies and regulatory agencies, to align educational responses to AI across primary, secondary, and tertiary education sectors.7.Continuously monitor and evaluate the impact of AI on learning, teaching, and assessment, and be open to making necessary adjustments based on the evidence.8.Institutions prioritise assessment redesign, by adopting more authentic forms of assessment to minimise the option for students to use AI based tools in generating assessment content"},{"id":579,"value":"Development of resources to support upskilling of educators to take in to account generative AI in learning and assessments."},{"id":609,"value":"Professional Development for Educators: Provide professional development opportunities for educators on AI, including understanding its strengths, limitations, data interpretation, and integration into lesson planning and delivery."},{"id":622,"value":"OES recommends the Australian Government funds a sector-wide re-skilling and upskilling program to ensure educators are given opportunities to become AI literate, and conversant with general technologies and specific programs. This in turn will enable educators to become confident in understanding the equity and ethical issues and how best to integrate AI tools and capabilities into emerging pedagogic practices."}],"Tag_group":{"id":993948,"value":"People","color":"darker-pink"}},{"id":2,"order":"2.00000000000000000000","Name":{"id":980180,"value":"guidelines","color":"light-yellow"},"Notes":"","Recommendations":[{"id":69,"value":"Comprehensive ethical guidelines and regulations need to be established to govern the use of generative AI in the education system and protect the rights and well-being of students."},{"id":6,"value":"Clarity around the responsible use of GenAI in assessment is necessary to help students navigate uncertainty and to make them responsible for their own academic conduct."},{"id":11,"value":"Usage guidelines, preferably consistent throughout the sector;"},{"id":14,"value":"Privacy and data protection â€“ need a clear understanding of whether data is used to improve the AI and where data is stored."},{"id":18,"value":"â–ª  Develop ethical principles and guidelines for Generative AI in higher education."},{"id":23,"value":"â–ª  By addressing ethical issues and limitations, educators can harness Generative AI as a valuable educational resource."},{"id":26,"value":"â—   That Principals be involved in the design of national guidelines, policy and protocol related to this issue and its implementation in schools."},{"id":27,"value":"Suggestion of guidelines needed"},{"id":37,"value":"A cohesive and collaborative approach to the development of AI guidelines is critical to ensure adequate school and sector-wide safeguards for teachers and students."},{"id":70,"value":"Educators should be provided with clear guidelines and support to incorporate discussions of ethical considerations into their curriculum, fostering a culture of integrity and responsible technology use."},{"id":62,"value":"That TEQSA, as the national body for regulating and assuring the quality of higher education providers, assumes national leadership in developing standards and frameworks to guide and support the higher education sector in maintaining academic integrity in the context of generative AI. This aligns with TEQSAâ€™s national leadership in the promotion of academic integrity and effective responses to other threats to integrity through its publications, partnerships and professional development activities."},{"id":94,"value":"Recommendation 2: Lead the development, in consultation with cross-sector representatives (see recommendation 1), of an initial national set of minimum standards to maximise consistency in the safe and equitable development and use of generative AI in the Australian school, vocational and higher education sectors."},{"id":96,"value":"Recommendation 5: Lead the development of a national set of principles and guidance materials targeted at research institutions to support and educate researchers (including research students) in the use of emerging technologies, including generative AI, in the research process. Development, for example, of a specific supporting guide for the Australian Code for the Responsible Conduct of Research (2018) addressing the benefits and risks of emerging technologies in research would enable all Australian organisations conducting research, to identify and consistently manage use of these technologies in their research and training programs."},{"id":125,"value":"â€¢ Universities and industry need to agree on a set of guidelines on the use of Gen-AI."},{"id":126,"value":"â€¢ Universities should help direct what agencies are going to be responsible for implementing some of these guidelines."},{"id":140,"value":"The adoption of national guidelines to maximise opportunities while safeguarding against legal risks. These guidelines should support public and private sector organisations to comply with relevant laws and encompass co- and self-regulatory measures. The consultation underway by the Commonwealth Department of Industry, Science and Resources Safe and responsible AI in Australia is a positive step in this direction"},{"id":145,"value":"Develop comprehensive ethical guidelines and frameworks specifically tailored for the use of generative AI in education. These guidelines should encompass aspects such as data privacy, algorithmic transparency, fairness, and accountability. They should also consider the unique ethical considerations related to student data and learner outcomes"},{"id":158,"value":"Recommendation 6: The concerns of applying genAI in education in Australia specifically are unclear, with few practical guidelines available for stakeholders to understand or navigate these issues. Support should be provided for development of practical guidelines for a range of stakeholders regarding use of genAI in Australian learning contexts."},{"id":166,"value":"Recommendation 5: Encourage the development of assessment guidance by education departments that is both resilient to AI developments and embraces opportunities presented by AI."},{"id":170,"value":"ACARA recommends that all materials designed to guide educators about the use of AI should provide clear definitions of what we mean by AI and generative AI, and make it clear that there are a range of AI types; for example, Chat GPT is only one example of generative AI."},{"id":187,"value":"Recommendation 8: The Commission supports the development of consistent national standards and guidelines to ensure the responsible and ethical use of generative AI tools in Australian schools."},{"id":220,"value":"Support the development of a national principles-based framework for the safe and effective use of AI in schools"},{"id":224,"value":"Establish clear legal and ethical responsibilities for GenAI use in schools"},{"id":230,"value":"We can draw on past/current experiences that represent a parallel to AI on Education. The experience of a virtual classroom rollout and the learnings from the Health sector on setting up the pathways for a successful implementation of AI tools, are cases that can serve as guidelines for best practice"},{"id":232,"value":"Clear ethical guidelines and standards for the use of generative AI tools in education."},{"id":249,"value":"Clear policy guidelines can provide the confidence needed to rollout AI in education, including but not limited to ethical frameworks, privacy and intellectual property regulation."},{"id":252,"value":"We can draw on past/current experiences that represent a parallel to AI on Education. The experience of a virtual classroom rollout and the learnings from the Health sector on setting up the pathways for a successful implementation of AI tools, are cases that can serve as guidelines for best practice."},{"id":263,"value":"The Advisory Committee develop best practice guidelines and a governance framework for AI in Australia. This must include extensive consultation with both healthcare consumers and education consumers."},{"id":307,"value":"The need for high-level government engagement in generative AI issues to establish an ethical framework for product providers and users and to address issues such as copyright, privacy of usersâ€™ data and cyber security. Government guidelines are also sought to help maintain the academic integrity of Australiaâ€™s education system"},{"id":318,"value":"provide useful frameworks for schools and systems to evaluate and make decisions on which tools are fit for purpose such as due diligence processes for third party applications"},{"id":332,"value":"We do not recommend further government regulation of the sector at this stage, but encourage a principles-based approach which encourages experimentation and embraces the appropriate use of GAI. Guidance from government and resources to assist universities to train and support staff is recommended as a better option than new regulation."},{"id":350,"value":"Establishing Clear Usage Guidelines: Universities should develop usage guidelines for the utilisation of GAI. This should take into account the diversity between different subject matters and allow flexibility in its application. The guidelines should act as a framework which promotes responsible and ethical use of GAI systems"},{"id":366,"value":"The adoption of national guidelines to maximise opportunities while safeguarding against legal risks. These guidelines should support public and private sector organisations to comply with relevant laws and encompass co- and self-regulatory measures. The consultation underway by the Commonwealth Department of Industry, Science and Resources Safe and responsible AI in Australia is a positive step in this direction."},{"id":371,"value":"Develop comprehensive ethical guidelines and frameworks specifically tailored for the use of generative AI in education. These guidelines should encompass aspects such as data privacy, algorithmic transparency, fairness, and accountability. They should also consider the unique ethical considerations related to student data and learner outcomes."},{"id":372,"value":"Emphasising the need for creation of comprehensive guidelines and policies to ensure responsible and ethical use of AI technologies in educational settings in the areas of privacy, data security, algorithmic bias, and the potential impact on student well-being."},{"id":444,"value":"Pedagogic Resources: Educational institutions and teachers need to be supported in the implementation of learning programs dedicated to Al literacies in settings with EAL/D learners. Such support entails the development of relevant policies, syllabuses and teaching/learning resources. We recommend collaboration between industry, academia, policymakers, and the wider public to develop resources and guidelines for the deployment of generative Al with EAL/D learners."},{"id":451,"value":"ISA recommends that safeguarding, ethical use,\nequity and integrity are core principles of a national AI framework for education."},{"id":460,"value":"Independent schools are seeking clear guidelines and sample policies to govern the use of generative AI tools in schools."},{"id":502,"value":"Support schools with standards of use for AI."},{"id":505,"value":"Formulate strategic priorities and policy for GenAI at the Department level and school level to provide tailored guidance to staff and students."},{"id":516,"value":"Teachersâ— Require guidance on how assessment and teaching can be delivered in a way which achieves the desired educational outcomes, but also ensures that students use GenAI in a productive way."},{"id":523,"value":"Consider soft law"},{"id":534,"value":"Develop and implement ethical frameworks and guidelines in consultation with Learned Academies, and accreditation and sector peak bodies including Indigenous Australian peak bodies and organisations â€“ e.g Maiam nayri Wingara"},{"id":560,"value":"Engineers Australia recommends the development of standards on how Generative Al can be used to develop critical thinking and evaluative judgement should be an immediate focus. Unfortunately, the pace of change will make it hard for these standards to be maintained. Therefore, it would seem essential to develop a standards framework that has adaptability asits core, some examples of what could be included:\nâ€¢  Development of education around generative Al:\no  fundamental principles on effective and ethical engagement with generative Al\no  appropriate acknowledgement of, and guidance on how to evidence critical engagement with generative Al tools\no  development of prompt engineering skills to enable generative Al to be used to develop critical  thinking skills and evaluative judgement,\no  tuning learning outcome specifications to the generative Al era,\no  assessment designed to test human capability. ie. why would something that can be generated by Al be assessed? - a more robust assessment might require the student to critique the responses from a tool like ChatGPT.\nâ€¢  Ethical implications of uploading student work for assessment.\n\nwe are likely to see the development of discipline-specific Generative Al tools, which are not only trained on a generalised large language model, but specifically in a discipline ecosystem. The development of guidelines on how these tools should be developed and utilised to ensure some standardisation would be useful. For example, appropriately declared use/acknowledgement of Generative Al tools, just as is the case with referencing the use of published work of others, needs to be a critical element in the developing ethical attitudes and practices for graduates entering any field of professional practice."},{"id":563,"value":"We support a robust, inclusive approach to developing further recommendations and guidelines in this area - libraries and open access advocates can play a key role in this due to our provision of both content and information skills, and our experience in the complex landscape of open access."},{"id":571,"value":"An agreed higher education response to communicating expectations regarding the use of AI in assessments, supported by broader professional learning opportunities for educators and clear guidelines for students, should be developed."},{"id":577,"value":"Jobs and Skills Australia to investigate and develop a national skills framework for students working with generative AI."},{"id":582,"value":"Provision of best practice guidelines and advice through TEQSA would support universities in implementing proactive approaches, particularly in assessment, academic integrity, ethics, and data security."},{"id":612,"value":"Ethical Standards and Privacy Protection: Establish robust ethical standards and guidelines for AI use in education, including stringent student data privacy protection measures and clear rules for AI application in learning and assessments."}],"Tag_group":{"id":993949,"value":"Materials","color":"dark-pink"}},{"id":3,"order":"3.00000000000000000000","Name":{"id":980182,"value":"situate-with-existing-policy","color":"darker-red"},"Notes":"","Recommendations":[{"id":2,"value":"education ministers from all Australian states and territories have agreed that responding to the risks and harnessing opportunities from generative AI technologies is a national education priority. [...] agreed to develop the Australian Framework for Generative Artificial Intelligence in Schools, which will cover elements of human and social wellbeing, transparency, fairness, accountability and privacy and security. [...] The Inquiry should factor the work of the taskforce and the framework it has developed in making its recommendations."},{"id":3,"value":"While there will undoubtedly be generally accepted standards and practices across the education sector nationally and globally, many of the opportunities and risks of GenAI in education fall within existing policies and procedures of individual institutions."},{"id":10,"value":"Institutional governance and policy positions need to consider the context of use, responsibility for errors and consider alternative definitions, or categorisation of attributes, such as â€˜authorâ€™ â€˜collaboratorâ€™ which have an inherent meaning and subject position that may not be appropriate to apply to GenAI content.\n\nIn light of the above, we are confident that managing the risks and seizing the opportunities can be accomplished within ards Framework (Threshold Standards) 2021 and our own institutional policies."},{"id":12,"value":"Clear internal use policies;"},{"id":72,"value":"That the Committee makes specific recommendations addressing current and anticipated intellectual property issues related to the use of generative AI by students and staff, which includes issues under relevant Australian and international laws and intellectual property agreements."},{"id":83,"value":"That any national recommendations on generative AI in higher education be developed after broad consultation with key stakeholders, including accreditation and registration bodies given their role in curriculum, assessment and assurance of learning."},{"id":84,"value":"Australia should also closely consider prioritising its alignment with other key export markets, and avoid fragmentation, and multi-jurisdictional compliance regimes that make investment unpalatable, and research and development activity challenging. Particularly, as it intersects with our higher education institutions remaining competitive. Offering the most comprehensive training for work ready students (both domestic and international) and in research and development. Briefly, areas for current consideration from overseas countries regulating AI, include consideration of certain prohibited AI activities, exemptions for internal research and development without prejudice to commercialisation, treatment of open source software, and risk classifications for intersecting educational activities and AI, such as higher risk requirements for use of this AI in admissions and academic assessment8;"},{"id":87,"value":"Further consideration of the application of the recommendations of the General Comment 25 (2021) to the United Nations Convention on the Rights of the Child developed to specifically address the rights of the child in the digital age."},{"id":161,"value":"The NT is actively contributing to the National Al Taskforce (the taskforce), which was established by the Education Ministers Meeting in February 2023 to scope, prioritise and sequence the activity to develop a national Al framework for schools. The inquiry would benefit from leveraging the efforts of the taskforce, which has involved high level collaboration across jurisdictions, relevant organisations and collated emerging credible research, to inform the development of a national Al framework for schools."},{"id":181,"value":"Recommendation 2: The principle of the â€˜best interests of the childâ€™ should be the primary test used to inform all policy decisions about the use of generative AI in Australiaâ€™s education system."},{"id":221,"value":"Encourage a whole-of-government approach to coordinate and align GenAI use in the education system with other policy development processes"},{"id":222,"value":"Ensure that the draft framework developed by the Education Ministers AI in Schools Taskforce undergoes thorough consultation"},{"id":237,"value":"Extend the cyber security national strategy to protect AI models and educational data from cyber threats and potential misuse. Implement privacy-preserving techniques to safeguard individual student data."},{"id":272,"value":"It is vital to Australiaâ€™s national interest that any generative AI-related maritime education rules, laws, systems, and standards etc to ought to align with global maritime education rules, laws, systems, and standards."},{"id":277,"value":"We recommend the Committee refer to the Department of Industry, Science and Resourcesâ€™ Safe and responsible AI in Australia discussion paper, which includes a comprehensive summary of international developments in regulating AI technologies."},{"id":279,"value":"Continuing to raise awareness of eSafetyâ€™s Toolkit for Schools and Best Practice Framework for Online Safety Education so that schools and education sectors are better prepared to support students, families and communities, and periodic review of these resources to ensure emerging technologies like generative AI are accounted for."},{"id":319,"value":"collaborate with relevant programs and agencies (e.g., ST4S and the esafety Commissionerâ€™s Office) to provide targeted information on Australian data security standards noting standards should encompass safety, security, privacy, ethical use, and responsible handling of data"},{"id":323,"value":"consider any implications of AI for the Australian Institute for Teaching and School Leadership Professional Standards for Teachers"},{"id":332,"value":"We do not recommend further government regulation of the sector at this stage, but encourage a principles-based approach which encourages experimentation and embraces the appropriate use of GAI. Guidance from government and resources to assist universities to train and support staff is recommended as a better option than new regulation."},{"id":408,"value":"AI is a rapidly developing field; thus, educational institutions will need to build consideration of its most recent developments into a regular discourse to ensure they remain abreast of developments and thus can manage its opportunities and risks. At a minimum, universities should integrate such consideration within their institutionâ€™s quality assurance and enhancement processes."},{"id":458,"value":"Independent schools will require support to ensure adequate measures are in place to safeguard personal information and comply with relevant privacy regulations."},{"id":459,"value":"Independent schools promote digital well-being and provide support mechanisms to address any negative impacts on students, but generative AI adds another level of complexity to this role."},{"id":487,"value":"Under the Workplace Health and Safety (WH&S) Act, education systems must engage in active consultation with workers and develop ongoing systems of review and consultation to address the impacts of new digital technologies and AI on education leaders, teachers, and students, as mandated by the Act."},{"id":491,"value":"These workplace health and safety concerns must be taken into account when developing and reviewing work systems that incorporate AI."},{"id":495,"value":"Implemented well, GAI has the potential to improve access to and the accessibility of learning and enhanced learning outcomes for disadvantaged learners. It has the potential to complement classroom teaching with smart, adaptive, and personalised formative feedback at scale and high frequency for individual learners, in modes that suit individual circumstances. It will be important to work with experts, advocates, and communities to understand the potential for different groups of students experiencing disadvantage. GAI is best delivered at scale via Australiaâ€™s strong, existing education infrastructure as part of enrolment. Australiaâ€™s education institutions already include a wide ecosystem of expertise and resourcing that comes from teachers, administrators, student mentors, families, and scaffolding by others, including education scholarship programs. Students in Australian education institutions should receive equal access to quality-assured GAI tools via these existing channels, including equal-access to the associated personal scaffolding required to use GAI ethically and effectively, including critical and digital literacy. Further, partners in Australian education - including scholarship managers, advocates, and community leaders for First Nations students, refugees, learners with disability, and socio-economically disadvantaged groups - can provide valuable connections to studentsâ€™ communities in combination with teaching and learning ecosystems within institutions."},{"id":509,"value":"Ensure existing policy and regulatory frameworks are fit-for-purpose and are able to deliver adequate protections for the use of GenAI in the education system. This should be underpinned by the regulatory principles of harmonisation, diversity, and necessity."},{"id":518,"value":"School\nleadershipâ— Requires a fit-for-purpose AI\nstrategy for the school."},{"id":519,"value":"School\nleadershipâ— Requires an integrated,\ncomprehensive AI\ngovernance system within\nthe school."},{"id":522,"value":"Any regulation that is developed should be consistent with existing state and federal laws, as well as education-specific laws and frameworks."},{"id":524,"value":"New regulation only where necessary"},{"id":540,"value":"Develop risk frameworks and undertake risk assessment and impact analysis"},{"id":564,"value":"We believe that Al can make responsible reuse of open access scholarly research, but it is critical that licensing and acknowledgement issues around Al are  clarified."},{"id":566,"value":"Any national approach to open access will need to consider the implications for Al/GAi."},{"id":573,"value":"TEQSA, as the regulator of higher education, should continue to provide timely resources for institutional use on academic integrity as generative AI evolves"},{"id":580,"value":"Swinburne values resources such as Country Education Profiles. The Country Education Profiles needs to be maintained. Nations, including Australia, need to ensure that education systems are up front about how they are managing artificial intelligence in their context"}],"Tag_group":{"id":993950,"value":"Policy-and-evaluation","color":"dark-orange"}},{"id":4,"order":"4.00000000000000000000","Name":{"id":980183,"value":"local-responses-and-autonomy","color":"dark-cyan"},"Notes":"","Recommendations":[{"id":4,"value":"The principle of institutional autonomy should be consistent with other risks in education.  The principle of institutional autonomy should be consistent with other risks in education. GenAI is new but we recommend the government response is consistent with other issues in education such as academic integrity, cyber security, etc, by setting a threshold and allowing institutions to respond in a way that best supports their own operations and communities. This does not preclude facilitated cross-sector engagement and the hosting of sector-wide working groups to discuss and prepare best practice guidelines, both for responsible use and for incorporating GenAI into existing policies and practices."},{"id":10,"value":"Institutional governance and policy positions need to consider the context of use, responsibility for errors and consider alternative definitions, or categorisation of attributes, such as â€˜authorâ€™ â€˜collaboratorâ€™ which have an inherent meaning and subject position that may not be appropriate to apply to GenAI content.\n\nIn light of the above, we are confident that managing the risks and seizing the opportunities can be accomplished within ards Framework (Threshold Standards) 2021 and our own institutional policies."},{"id":53,"value":"â€¢  Standards for generative AI use in education contexts should be considered, but also take into account the rapidly changing environment and technology. Standards should not limit and constrain institutionsâ€™ need for agility and flexibility in their responses. Standards could relate to the specific types of generative AI that are acceptable â€“ these standards could include consideration of data management, privacy, security, as well as broader terms of service, contracts (for paid tools)."},{"id":149,"value":"Support ground-up staff led assessment of AI usage in their disciplines. Staff are best placed to decide how and where AI usage is appropriate in the context of their specific discipline and course content. Blanket regulatory or institutional policy approaches to adopting AI should be avoided in relation to the delivery of teaching and research, particularly where it is deemed to be a â€˜cost savingâ€™ measure. Where AI is adopted, to ensure it is used successfully and responsibly as a tool in teaching, learning and curricular, staff need professional development opportunities to learn about AI and additional time allocation to develop and engage in new modes of assessment. This will ensure students of Australian institutions are truly attaining the desired learning outcomes."},{"id":176,"value":"UA recommends that universities retain the autonomy to manage the opportunities and risks associated with generative AI within their own institutions. Coordination across the sector could be encouraged through the development of best practice guidance and sector-specific standards for the use of generative AI in academia. Importantly, students need to be educated in the practical and ethical implications of generative AI to be adequately prepared for the future workforce. Work to equip students with these skills is already underway across UAâ€™s member institutions."},{"id":583,"value":"Institutions should have the flexibility and autonomy to make decisions regarding generative AI without strict regulation specific to higher education environments."}],"Tag_group":{"id":993950,"value":"Policy-and-evaluation","color":"dark-orange"}},{"id":5,"order":"5.00000000000000000000","Name":{"id":980175,"value":"mandatory-watermarking","color":"brown"},"Notes":"","Recommendations":[{"id":5,"value":"It is recommended that a responsible use approach to the incorporation of GenAI is encouraged. Beyond a desire to encourage responsible experimentation and the development of an informed and critical awareness of the benefits and risks of GenAI, an important factor in taking this position is that detection of AI-generated content is unlikely to be feasible. Emerging evidence suggests that humans are not reliable in detecting AI- generated content. Equally, AI detection tools are non-transparent and unreliable in their testing and reporting of their own accuracy, and are likely to generate an intolerably high proportion of both false positives and false negatives. The exception to detection difficulties is where watermarks are injected. Watermarks are coded patterns of output that are intentionally detectable to AI detection systems. To make this system feasible would require the regulation of all GenAI technologies to mandate the injection of watermarks into their content. Unregulated GenAI technologies would allow students to avoid this. Other GenAI technologies can be used to parse watermarked content to remove the watermark. Humans can inject watermarks into human-generated content to discredit detection technologies."},{"id":38,"value":"To monitor plagiarism, AI generators should have an indelible watermark which can be detected by tools that recognise plagiarism. In doing this though, we create an environment where educators are having to rely on tools to recognise plagiarism, tools are not reliable. Clearly, other ways of assessing the validity of student work is needed"},{"id":186,"value":"Recommendation 7: Policies should more broadly encourage the development and use of generative AI tools for content verification, allowing individuals to accurately identify AI-generated content."},{"id":284,"value":"watermarks and detection tools are used to identify AI-generated materials"}],"Tag_group":{"id":993950,"value":"Policy-and-evaluation","color":"dark-orange"}},{"id":6,"order":"6.00000000000000000000","Name":{"id":980185,"value":"new-assessment-models","color":"darker-pink"},"Notes":"","Recommendations":[{"id":7,"value":"Alternative approaches to assessment will be needed, in which a combination of assessment of process, closer working relationships with students, and more complex assessments will need to be developed. As a related issue, care should be taken when adapting GenAI into marking or feedback practices. Use of GenAI in assessing student work and/or providing feedback without specialist training entails a reduction in established human expertise and, potentially, a reduction in human connection and trust relations. Thus, institutions need a clear framework for making decisions about how to incorporate GenAI into these powerful practices."},{"id":9,"value":"In relation to academic misconduct, recognising GenAI as a collaboration tool intentionally separates it from plagiarism, collusion and contract cheating. At the same time, we need to maintain mechanisms to restrict GenAI use in assessments that require students to demonstrate human capacities. Therefore, we are exploring a â€˜restorative practiceâ€™ approach to suspected academic integrity breaches."},{"id":17,"value":"â–ª  Incorporate proctored, in-person assessments alongside AI tools."},{"id":19,"value":"â–ª  Promote originality and creativity in assignments."},{"id":20,"value":"â–ª  Implement strategies to prevent plagiarism when using Generative AI."},{"id":21,"value":"â–ª  Provide personalized feedback to students."},{"id":22,"value":"â–ª  Use formative assessment practices like self-assessment and peer feedback."},{"id":32,"value":"Bank of approved tasks developed by AI"},{"id":114,"value":"appropriate use of generative AI, including open acknowledgement that it has been used (and why). Most students (and staff) will come to appreciate that moderate use of generative AI (for example, producing literature summaries) is appropriate, but blanket use (such as churning out an entire essay) is not â€“ though even moderate use should, for the foreseeable future, be acknowledged even in situations where the use of AI is sanctioned. A comparable situation is the use of online tools like Wikipedia: good students know, or quickly realise, that it should be regarded as a source of information, and not necessarily a definitive one."},{"id":173,"value":"There is considerable concern about students using AI to cheat on tasks set by the teacher, and particularly assessment tasks. ACARA as the assessment authority could consider developing a range of strategies/suggestions to use AI without the concern about cheating."},{"id":217,"value":"Initiate assessment reform in the school curriculum emphasizing a strengths-based approach that recognizes the potential applications and future integrations of Generative AI while promoting critical and creative thinking skills in teachers and students to differentiate between productive and non-productive uses of AI"},{"id":245,"value":"Generative AI tools have the potential to provide continuous assessment and timely feedback to both students and teachers. This can support formative assessment practices and enable educators to intervene when needed to address learning gaps."},{"id":261,"value":"AI for Personalized Learning: Promote the use of AI-driven personalized learning platforms that adapt to each student's needs and learning pace. These platforms can help address individual learning gaps and cater to diverse learning styles."},{"id":312,"value":"implement strategies for developing academic integrity"},{"id":313,"value":"reconsider acceptable use of AI in assessment, for example, tasks with no access to AI, and \ntasks where AI is explicitly integrated"},{"id":314,"value":"changes to assessment cognition used in online exams such as those directly related to \nstudent's experience and/or case and scenario-based activities that are directly related to key \nlearning experiences"},{"id":315,"value":"reconsider how creativity is defined and assessed"},{"id":328,"value":"Assessment absolutely needs to change, but assessment is a complex topic and agreeing on new assessment approaches at an institutional level will take time. Probably many other aspects of school need to change too: curriculum, content, timetables, year-level structures, pedagogical methods, etc.. Change to a competency based grading structure."},{"id":336,"value":"That University accrediting bodies such as TEQSA engage with universities to discuss the use of AI in the workforce and in assessment"},{"id":342,"value":"Oral (or viva) assessments where students provide verbal rather than written responses; Asking students to use specific techniques when solving problems; Asking students to analyse and critique responses generated by GAI; Mixing written assessment components with aspects requiring drawing, posters or videos; In-class quizzes for core concepts; Assessments where students reflect on what they have learned rather than necessarily produce a set answer"},{"id":352,"value":"Assessments with emphasis on analytical thinking: Staff should consider developing assessments that prioritise analytical thinking skills over rote memorisation, aligning with the integration of GAI. Assessments should be designed to assess higher-order cognitive skills\nthat are complemented by the use of GAI"},{"id":355,"value":"Mapping the identity verified assessment methods that are used across degrees, to inform accrediting bodies and reviewers as they periodically inspect our offerings"},{"id":356,"value":"Focusing identity verification efforts on the assessments that are most closely tied to the learning outcomes of the degree"},{"id":357,"value":"Generating evidence of authenticity of studentsâ€™ work, rather than only seeking\nto detect misconduct"},{"id":374,"value":"Prioritising student learning and engagement when integrating generative AI tools. Discuss how these tools can be used to personalize learning experiences, provide targeted feedback, and foster student creativity and critical thinking skills."},{"id":401,"value":"Australiaâ€™s education systems need to accept that their current assessment practices, whereby they judge student performance on the basis of written assessment pieces, have to change - with more authentic assessment practices a must. \nassign prompts that state-of-the-art systems such as ChatGPT are not good at;\nrequire verifiable sources and quotations\nask students to analyse specifics from images, audio, or videos\nrequire analysis that draws on class discussion\nask for analysis of recent events not in the training data for the system\nset assignments that articulate nuanced relationships between ideas, and\nassign in-class writing as a supplement to or launching point for take-home assignments\nbe mindful of what Chat GPT3 can and cannot do\ncontinue to teach the foundations\ndeal with the cheating when testing foundational knowledge\nmimic the workplace by teaching how to evaluate a proposed plan of action\nlet students use Chat GPT3, but simultaneously raise the bar for assignments\nask students to imagine the new rather than tweaking the old\ndonâ€™t be shy using Chat GPT3 to improve the productivity of the teaching process."},{"id":402,"value":"educators will need to find ways to include it in their teaching and assessment practices â€“ but only after they have agreed on what it is that they are actually wanting/needing to teach students and how they will measure their learning in an era of generative AI."},{"id":403,"value":"if the learning outcomes of traditional assessment items can be easily met by AI, then assessments need to be adapted so students can demonstrate higher order thinking, creative problemsolving and contextual application of knowledge and skills"},{"id":406,"value":"Australiaâ€™s entire education sector must quickly move away from traditional assessment strategies and instead focus on high-quality authentic assessment strategies that engage students in their learning and personalises their assessment response"},{"id":464,"value":"Use AI-generated assessments as a complement to in-person assessments and qualitative feedback from educators"},{"id":465,"value":"Monitor collaborative learning environments to ensure students develop essential teamwork and communication skills"},{"id":466,"value":"Focus on cultivating higher-order cognitive skills alongside AI tools, emphasizing limitations and ethical considerations"},{"id":493,"value":"GAI will form part of a wider system of assessment that collectively gives educatorsâ€™ evidence of each studentâ€™s authentic, multi-faceted learning journey. Studentsâ€™ use of GAI in education settings will therefore need to be scaffolded with new skills, including universal delivery of: critical thinking, digital literacy, personal communication and writing style, and opportunities to develop higher-order thinking skills. Teachers will also need to be (re)skilled to provide this scaffolding. In higher education, there is a need for the sector to work closely with professional and accreditation bodies to understand current and future learning and assessment requirements in the context of competency certification."},{"id":496,"value":"There is extensive evidence in the Australian context for the impact of personal feedback on student confidence and other academic success metrics. Studiosity can offer the Minister for Education this evidence, and access to early evidence within the higher education sector for the use of GAI on student engagement, confidence, and outcomes."},{"id":498,"value":"Learning activities and assessment must be designed with AI in mind, so that AI is less able to be used to do all the thinking for students."},{"id":499,"value":"Allow increased flexibility in assessments (particularly at higher grade levels, as lower ones are quite flexible) so schools have the freedom to design assessments and conditions to reduce unethical use of generative AI by students."},{"id":560,"value":"Engineers Australia recommends the development of standards on how Generative Al can be used to develop critical thinking and evaluative judgement should be an immediate focus. Unfortunately, the pace of change will make it hard for these standards to be maintained. Therefore, it would seem essential to develop a standards framework that has adaptability asits core, some examples of what could be included:\nâ€¢  Development of education around generative Al:\no  fundamental principles on effective and ethical engagement with generative Al\no  appropriate acknowledgement of, and guidance on how to evidence critical engagement with generative Al tools\no  development of prompt engineering skills to enable generative Al to be used to develop critical  thinking skills and evaluative judgement,\no  tuning learning outcome specifications to the generative Al era,\no  assessment designed to test human capability. ie. why would something that can be generated by Al be assessed? - a more robust assessment might require the student to critique the responses from a tool like ChatGPT.\nâ€¢  Ethical implications of uploading student work for assessment.\n\nwe are likely to see the development of discipline-specific Generative Al tools, which are not only trained on a generalised large language model, but specifically in a discipline ecosystem. The development of guidelines on how these tools should be developed and utilised to ensure some standardisation would be useful. For example, appropriately declared use/acknowledgement of Generative Al tools, just as is the case with referencing the use of published work of others, needs to be a critical element in the developing ethical attitudes and practices for graduates entering any field of professional practice."},{"id":572,"value":"Universities should re-evaluate existing assessments to ensure that they are aligned with desired student learning outcomes and are responsive to the capabilities of generative AI tools."},{"id":618,"value":"Promotion of Mastery and Engagement: Use AI to create personalised, engaging learning experiences, including game-based learning and real-world problem-solving tasks."},{"id":619,"value":"Increased Student Autonomy: Encourage greater student control over their learning journey through the use of AI tools."},{"id":621,"value":"DECYP believes there is a need for a sustainable and adaptable response to generative AI in learning, teaching and assessment, and academic integrity policies and procedures. There will need to be ongoing education and training for students on how to appropriately use generative AI, should use become more commonplace. Detection technology capable of discerning between human and generative AI, e.g. Turnitin, will also need to continue developing and adapting."}],"Tag_group":{"id":993951,"value":"Learning","color":"cyan"}},{"id":7,"order":"7.00000000000000000000","Name":{"id":980187,"value":"stakeholder-engagement","color":"dark-green"},"Notes":"","Recommendations":[{"id":8,"value":"We see GenAI as an opportunity for greater engagement with students in the design of learning. To facilitate AI literacies, Monash will use a Students as Partners approach, in which student representatives work directly with academics to collaboratively co-design learning and teaching approaches and assessments. There may be scope to develop generic course-level outcomes which align with Monash Graduate Attributes, in recognition of the importance to invest in teaching students about AI literacy."},{"id":26,"value":"â—   That Principals be involved in the design of national guidelines, policy and protocol related to this issue and its implementation in schools."},{"id":36,"value":"Timely and ongoing consultation with the profession in their workplaces and through their unions is critical to establishing guidelines that protect both teachers and students, without diminishing the educative potential of AI;"},{"id":37,"value":"A cohesive and collaborative approach to the development of AI guidelines is critical to ensure adequate school and sector-wide safeguards for teachers and students."},{"id":46,"value":"Decisions about the suitability of tools could be made at scale to ensure that they are trustworthy and equitable without undermining teachers' pedagogy. Teachers can advocate for the access to use specific AI tools in the classroom but there should be a cross-sectoral body that ensures the safety of such tools prior to their introduction to the classroom and checks on the ongoing quality and safety of the AI tool as it is updated. These changes will need to be accompanied by significant teacher professional development, both by the system to understand the above demands but also by the professional associations who are subject based and can help teachers maximise the effectiveness of AI for their discipline and in their classrooms"},{"id":64,"value":"That the Department of Education undertakes a review of the Higher Education Standards Framework (Threshold Standards) 2021 to ensure effective sector-wide responses to the use of generative AI in higher education, in consultation with key stakeholders, including Universities Australia, bodies representing non-university providers and key experts in this field."},{"id":67,"value":"That the Committee recommends future initiatives, programs and projects addressing the use of generative AI in the education sector incorporate consultation with academics and researchers from a range of discipline areas, as well as key stakeholders outside the education sector, especially professional associations, accreditation bodies, registration bodies and employers."},{"id":74,"value":"That the Committee highlights the need for a diverse range of interested parties and stakeholders to be included in future decisions and actions related to the use of generative AI, in particular the perspectives of those who may be underrepresented in government and education decision-making bodies, including students, people from Aboriginal and Torres Strait Islander and culturally and linguistically diverse backgrounds, those experiencing social and economic disadvantage, and people with disabilities."},{"id":83,"value":"That any national recommendations on generative AI in higher education be developed after broad consultation with key stakeholders, including accreditation and registration bodies given their role in curriculum, assessment and assurance of learning."},{"id":88,"value":"Extensive ongoing consultation with children and young people is undertaken to not only inform proposed actions but to also uncover creative child-led solutions and insights with respect to their education and the use of generative AI as well as any unintended consequences."},{"id":104,"value":"Recommendation 2: There needs to be meaningful, participatory and collective approaches to address the complexity of AI in education policy making Involving a diverse range of community members and education stakeholders at all stages of policy development and implementation will help to anticipate risks, build trust and co-create principles to inform complex decision-making measures. This is particularly important in anticipatory policymaking which must be responsive to local, regional, and national needs. This genuinely multi-scalar and multi-stakeholder approach throughout the entire process will lead to more timely decisions in the future. Part of this will require distributing socio-technical expertise and embedding opportunities for collective learning, experimentation, and policymaking about the development and use of AI and emerging technologies in education. In particular, there is a need to distribute expertise and embed these opportunities in a way that is accessible to and involves those from underrepresented backgrounds who might otherwise lack the opportunity and resources to participate in policy co-creation processes. To ensure that this collaborative work (which is systemic, collective, and cross-sectoral) becomes embedded across research, policy, and practice - there is a need for long-term government funding to sustain this initiative."},{"id":137,"value":"4. The Department of Education to work with librarians and teacher librarians on the developmentof new tools, digital platforms and programs to support AI in education."},{"id":156,"value":"Learning environments are one space where genAI will clearly have significant impact; understanding this impact and appropriate (dis)engagement with genAI in learning requires a focus on the fundamental purposes and processes of learning. - Recommendation 4: Values underpin both our aims in education, and our aims for genAI, shaping what we learn (e.g., â€˜AI literacyâ€™), and how we learn (e.g., new AI tools). Support the convening of public fora and engagement activities to develop collective, democratic, values-led responses regarding the kinds of futures Australians want in use of genAI in education."},{"id":157,"value":"Recommendation 5: Understanding, evaluating, and sharing effective practices: There can be no strengths of genAI in education without teachers who will work with, create approaches for, and thus need to learn about genAI. This has implications, drawing on our other recommendations. o Any consideration of and planning cycles towards use of genAI in education should be with respect to the values and aims identified in Recommendation 4 o Resourcing should be provided to develop models to assess AI literacy across the range of stakeholders, and identify needs and strategies to develop this literacy; resources derived from this activity can feed into guidelines to help navigate the ethics of genAI (Recommendation 6) o Support should be provided for bespoke professional learning for teachers from all sectors, to develop algorithmic literacy to learn to engage with genAI and capacity for designing to learn with genAI tools Recommendation 1; Recommendation 7). o Evidence should underpin any incorporation of genAI (see Recommendation 3). This evidence should be shared and co-developed with and by teachers, informed by student voice, and in mentoring and partnerships with research universities and education institutions. It may also be appropriate to target resourcing to creation of evidence-informed models that encode shared values (Recommendation 4), and the body of existing evidence regarding learning technologies, to create tuned models or/and educationally-tailored system prompts (prompts that modify user input to provide context). Sharing among teachers has been shown to be an effective mechanism for supporting innovative approaches, particularly through creation of toolkit resources that provide practical guidance for design for learning alongside evidence and high-level principles."},{"id":180,"value":"Recommendation 1: Children and young people be specifically consulted in an ongoing way about policy decisions in respect of the use of generative AI in the Australian education system."},{"id":201,"value":"Work with schools to test, develop and showcase best practice integration of\nteaching and learning technology tools, including for disadvantaged and special\nneeds students"},{"id":203,"value":"Commission the Australian Education Research Organisation (AERO), working with\nACARA, AITSL and ESA, to provide expertise and advice on what works best when\nusing edtech to support teachers and improve student outcomes"},{"id":207,"value":"Establish an expert advisory body reflecting education, industry, social benefit, legal and other expertise to provide early insights and strategic solutions to help anticipate, develop and deliver safe, effective AI-based edtech"},{"id":215,"value":"Collaborate with teacher educators, Higher Education, and First Nations communities to mitigate limited visibility of culturally diverse populations, decontextualization of cultural knowledge, and amplification of racism, abusive content, and online hate through Generative AI tools"},{"id":231,"value":"A collaboration between educators, researchers, policymakers, and technology developers is needed to ensure that generative AI tools are developed based on evidence-based research and aligned with educational goals"},{"id":241,"value":"Enable collaboration between experts in education, AI development, ethics, and policy to collectively address the complex challenges posed by generative AI in education."},{"id":248,"value":"A collaboration between educators, researchers, policymakers, and technology  developers is needed to ensure that generative AI tools are developed based on evidence-based research and aligned with educational goals."},{"id":253,"value":"A collaboration between educators, researchers, policymakers, and technology developers is needed to ensure that generative AI tools are developed based on evidence-based research and aligned with educational goals."},{"id":257,"value":"Community Engagement: Engage with local communities and families to raise awareness about the benefits of AI in education and address any concerns or misconceptions they may have."},{"id":270,"value":"Collaboration between the Australian Government, its relevant agencies (e.g., Digital Health), health professional colleges, appropriate university faculties, and others, as  determined, mandates co-design methodologies to be used when developing AI tools for health education to ensure biases are adequately addressed."},{"id":271,"value":"The Australian Government and relevant agencies ensure that nurses are adequately represented on all committees determining AI's future use in healthcare and healthcare education."},{"id":281,"value":"Partnering with our education stakeholders to raise awareness and build community understanding of generative AI and associated online safety risks. This includes through our National Online Safety Education Council and eSafety Youth Council, and relationships with government agencies, education bodies and providers of online safety education."},{"id":409,"value":"To guide decision making on generative AIsâ€™ appropriate use, ethical standards and frameworks for its use will be required. A national response may be appropriate to prevent inconsistent responses across the sector. However, should such an approach be considered, it will be important that this work has representation from employers, educators and researchers."},{"id":444,"value":"Pedagogic Resources: Educational institutions and teachers need to be supported in the implementation of learning programs dedicated to Al literacies in settings with EAL/D learners. Such support entails the development of relevant policies, syllabuses and teaching/learning resources. We recommend collaboration between industry, academia, policymakers, and the wider public to develop resources and guidelines for the deployment of generative Al with EAL/D learners."},{"id":448,"value":"ISA recommends the formation of a federal education advisory body of key stakeholders and cross sectoral school education representatives and academics to examine the benefits and risk of generative AI to inform education policy."},{"id":474,"value":"ensure that decisions made related to new and emerging digital technologies are undertaken after rigorous consultation with the teaching profession. Given the rapid pace of change in digital technologies, consultation processes must be ongoing, to ensure the approaches adopted meet the needs of the profession."},{"id":487,"value":"Under the Workplace Health and Safety (WH&S) Act, education systems must engage in active consultation with workers and develop ongoing systems of review and consultation to address the impacts of new digital technologies and AI on education leaders, teachers, and students, as mandated by the Act."},{"id":507,"value":"Initiate strong strategic partnerships with relevant government and private stakeholders to codesign solutions for deploying responsible GenAI in classrooms"},{"id":508,"value":"Consult widely on education system reform with a focus on the impact of emerging technologies on education delivery and assessment."},{"id":561,"value":"The student voice will enable the development of standards that meets their needs, therefore the establishment of a student reference group to help define and maintain the standards is crucial."},{"id":570,"value":"Universities should be required to work with both students and staff to co-create approaches to the ethical use of generative AI tools with a focus on academic integrity."},{"id":589,"value":"Ensure that the Department of Education engages with the teaching profession via their union to develop this national policy framework to address the use of technology and AI in teaching and learning."},{"id":605,"value":"Regulation, policy and legislation must be developed in collaboration with peak student\nrepresentative bodies."}],"Tag_group":{"id":993948,"value":"People","color":"darker-pink"}},{"id":8,"order":"8.00000000000000000000","Name":{"id":980188,"value":"new-workforce-model","color":"light-brown"},"Notes":"","Recommendations":[{"id":16,"value":"â–ª  Use Generative AI as a complementary tool, not a substitute for human researchers."},{"id":28,"value":"Many duties of teachers and resource developers can be separated into a special department where a limited number of persons supervise/ coordinate AI in those duties;"},{"id":112,"value":"4. Professional accreditation bodies, industry and universities will need to be aligned in their positions in order to enable responsive and coherent courses."},{"id":147,"value":"Staff will however need institutional support and resources to achieve this, including greater workload allocations for course design and student assessment and frameworks for considering what types of AI usage might constitute plagiarism. There should also be in place appropriate institutional policies and procedures to ensure best practice is in place and that human oversight on the use of AI is embedded."},{"id":148,"value":"The use of Artificial Intelligence in higher education should be human centric, with appropriate guardrails in place to regulate its effective use as a tool to improve access to and experience of education. It should also be seen as a mechanism to better equip our researchers, technological staff and others engaged in research activities to undertake their work more effectively and assist with innovation and knowledge discovery. However, it should not replace the human element in teaching, learning and research activities. It should also ensure human oversight remains in important student support services, and in administration and technical roles. Furthermore, both staff and students should be supported to learn and use AI technology in a responsible and ethical manner. Where it is embedded or seen as a vital component as part of the learning experience, the education provider should ensure that all students and staff have equitable access to the use of AI."},{"id":182,"value":"Recommendation 3: The principle that generative AI is to supplement and support learning, and not as a replacement for teaching staff, should be adopted as a foundational principle to inform all policy decisions about the use of generative AI in Australiaâ€™s education system."},{"id":246,"value":"With the automation of administrative tasks, such as grading and lesson planning, can free up educators' time, allowing them to focus on building meaningful connections with students and designing innovative learning experiences."},{"id":322,"value":"provide teachers with secure options for reducing their workload through harnessing AI"},{"id":354,"value":"Encouraging staff to automate repetitive tasks: Tasks such as attendance tracking housekeeping and template creation can be automated by staff so that they can allocate their time more efficiently to higher-value tasks"},{"id":363,"value":"the Inquiry acknowledge the funding implications arising from workload pressures associated\nwith generative AI and refer these funding implications to the Universities Accord process."},{"id":410,"value":"As a collective response, universities need to explore how their administration and support functions can benefit from the use of AI, such as adopting the technology to provide tier two assistance (responses to low complexity queries), to help manage workloads, provide 24-hour response and to enable greater focus to be dedicated to complex queries and support requests."},{"id":461,"value":"Maintain a balance between leveraging AI insights and the value of teacher instruction and support"},{"id":462,"value":"Exercise caution when relying solely on AI-generated data and consider other factors in decision-making"},{"id":472,"value":"Student learning, teaching/assessment processes and academic integrity must remain central considerations in decision making. Business models that outsource learning to for-profit providers or edu-tech platforms are not a feature of these decision-making frameworks."},{"id":473,"value":"It is critical to acknowledge that equity is not realised through access to digital resources and programs alone.There is a need for careful and considered selection and curation of the resources and to blend these with real-world interactions in ways that facilitate and enable meaningful engagement with the broader educational process."},{"id":476,"value":"Pedagogical decisions regarding resources and learning experiences provided for any given cohort of students must rest with classroom teachers and, crucially, cannot be replicated by AI or other technologies."},{"id":477,"value":"academic integrity must be maintained, with a particular focus upon the assessment cycle. Teachers must be resourced with sufficient time to interrogate the learning process and the assess the artifacts produced by their students"},{"id":478,"value":"The use of digital technology in this process must take place under the oversight of the teaching profession. Any deployment of technology must not undermine teachersâ€™ central role in assessment, moderation and reporting, and must not inhibit beginning teachers from developing the professional knowledge and skills required to make sound pedagogical and assessment decisions."},{"id":488,"value":"adoption of technology  should be carefully considered to avoid exacerbating workload issues and should include considerations of time, professional development, and workplace health and safety implications."},{"id":607,"value":"1) We need to be planning for large shifts in emphasis around skills training and funding of such, both for young people coming through the system and for adults who need to change direction throughout life in response to automation. 2) As automation progresses, it seems 100% clear to me that our government needs to be planning and budgeting for a world where our current underlying economic assumption that every able-bodied person should work for a living is no longer true. Some form of Universal Basic Income or at least changes to the monetary system needs to be worked out. This is not just a response to a crisis, as COVID was, but is actually planning for a (hopefully) positive golden age where we really do have robots (both software and hardware) taking care of a lot of the work involved in running society."}],"Tag_group":{"id":993948,"value":"People","color":"darker-pink"}},{"id":9,"order":"9.00000000000000000000","Name":{"id":980189,"value":"DISTINCTIVE","color":"dark-green"},"Notes":"","Recommendations":[{"id":28,"value":"Many duties of teachers and resource developers can be separated into a special department where a limited number of persons supervise/ coordinate AI in those duties;"},{"id":108,"value":"There is a major opportunity for the development of Australian models â€“ datasets, LLMs, and significantly, small language models. This is a research infrastructure agenda and is also brings in large public datasets that could offer opportunities for generative AI in Australia. We would single out (as per the RRIR paper) large datasets such as the Bureau of Meteorology, Australian Bureau of Statistics, and the National Library of Australiaâ€™s Trove."}],"Tag_group":{}},{"id":10,"order":"10.00000000000000000000","Name":{"id":980190,"value":"curricula-changes","color":"light-green"},"Notes":"","Recommendations":[{"id":25,"value":"â—    That any intent to implement AI in schools be accompanied by appropriate and realistic timeframes, resourcing and training. It should not be added to existing curriculum must be explicit licensing from ACCARA to â€˜make roomâ€™ for any new content."},{"id":29,"value":"Higher level of centralisation of the curriculum with specific norms (not guidelines) still with a focus on modern practices of student-centered education;"},{"id":31,"value":"Compulsory curriculum around AI use for all;"},{"id":57,"value":"The inquiry should encompass how to introduce content relating to understanding Generative AI into the national curriculum."},{"id":64,"value":"That the Department of Education undertakes a review of the Higher Education Standards Framework (Threshold Standards) 2021 to ensure effective sector-wide responses to the use of generative AI in higher education, in consultation with key stakeholders, including Universities Australia, bodies representing non-university providers and key experts in this field."},{"id":98,"value":"Clear differentiation to be accepted or evident between the learning areas and subjects, rather than generic â€˜rulesâ€™ for generative AI use or the limitation of AI in schools. Tertiary institutions, transdisciplinary inquiry and traditional subject disciplines are demonstrating different approaches to the generative language models (LLMs), such as first steps in an effective discipline-specific or evidence-based research strategies."},{"id":109,"value":"1. Universities should be supported to lead public debate about the ethics of AI, as university graduates should be equipped not just as users of AI, but future leaders of ethical AI development and adoption. Educational programs for educators and students should therefore include all known ethical issues, risks and challenges."},{"id":112,"value":"4. Professional accreditation bodies, industry and universities will need to be aligned in their positions in order to enable responsive and coherent courses."},{"id":124,"value":"Universities will inevitably need to adapt their offerings to respond to generative AI. This will include reconsidering assessment to include more authentic, continuous forms of assessment where the opportunity for academic misconduct is reduced. Universities will need to ensure Higher Degree by Research (HDR) candidates, for example, understand the importance of generating their own content, noting that writing is intimately linked with cognition. Universities will also need to ensure their students and staff are AI literate."},{"id":127,"value":"â€¢ In the short-term focus more on education and prevention programs to help learners and educators understand ethical, legal and responsible use of Gen-AI."},{"id":134,"value":"1. Commit to all students receiving instruction in AI literacy and working with library bodies on implementation."},{"id":150,"value":"Regulators of Australian Higher Education providers Education Regulators (primarily TEQSA) will need to be conscious of the implication of AI on learning pedagogies and be empowered to ensure that learning outcomes are maintained"},{"id":163,"value":"Recommendation 2: Introduce age-appropriate AI instruction in Australian classrooms, supported by appropriate educator training and purpose-built AI tools or institutional access licences for commercial AI products."},{"id":175,"value":"ACARA could provide more explicit advice on how the English curriculum can support students to be more critical of information they read and are exposed to when using digital systems. This could also include highlighting how the critical and creative thinking general capability can be addressed as part of this approach."},{"id":189,"value":"Recommendation 10: Schools should introduce comprehensive digital literacy programs to provide students with the skills needed to engage with generative AI tools in a responsible and ethical way."},{"id":262,"value":"Australian educational institutions (including the Australian Council of Deans of Health Sciences) form Advisory Committees to formulate strategies and goals for implementing AI in the clinical curriculum (high level decision-making regarding the ethics and principles of AI use by nurses in clinical settings)."},{"id":264,"value":"Educational institutions come to a consensus on a standard of digital literacy across all curriculums, from school and VET to higher education. Specific digital literacy needs in healthcare must be examined and benchmarks established."},{"id":278,"value":"Ongoing review and adaption of curriculum materials, including the Australian Curriculum and supporting materials, to explicitly teach the technical knowledge and social and emotional skills to safely use new and emerging technologies. This could include reviewing the Online Safety Curriculum Connection to address specific AI-related scenarios."},{"id":349,"value":"Implementing Fact-Checking Mechanisms: Universities should place an emphasis on educating students on fact-checking techniques to combat disinformation and ensure accuracy and reliability of information"},{"id":405,"value":"That Australiaâ€™s Higher Education curricular should embed critical evaluation of the use of AI with a specific focus on how these tools can positively impact society and its constraints and ethical considerations. Current and future students entering employment will need to have developed proficient skill sets that draw on its benefits but which are guided by a tightly bound ethical framework for its use."},{"id":411,"value":"students need to be aware of the fundamental limitations of these systems through the development of AI critical literacy. This needs to be an integral part of any curriculum as well as targeted learning and teaching activities."},{"id":416,"value":"Support students to develop critical literacy"},{"id":424,"value":"Teach (and assess) critical digital literacies to our students and educators across all curricula"},{"id":425,"value":"Promote educational experiences that promote open horizons and allow students to flourish"},{"id":428,"value":"Learning programs specifically tailored to the needs of EAL/D learners are essential for helping them to become confident and capable to access benefits and mitigate the risks of generative Al. Such programs need to focus on Al literacies which we define as a set of technical, linguistic and socio-cultural capabilities required for meaningful, creative, ethical and critical use of Al for different purposes and in different settings. These programs need to be age and sector appropriate. We recommend that institutions, teachers and educational researchers with expertise in EAL/D approaches are included in shaping these programs, considering the needs and strengths of EAL/D students as well as the specificities of learning contexts."},{"id":453,"value":"ISA recommends that the importance of culture, play-based learning, social connection, teacher/student relationships and protecting the holistic development of children and young people informs and is at the core of generative AI education policy"},{"id":455,"value":"Independent schools need to continue to educate students about the ethical use of AI tools and implement more robust plagiarism detection strategies to maintain academic integrity. T"},{"id":456,"value":"Independent schools continue to teach students media literacy and critical evaluation techniques but need to be explicit in teaching generative AI discernment between authentic and manipulated generative AI content."},{"id":457,"value":"Independent schools are aware of these biases and are actively engaged in finding ways to teach students how to be critical when utilising and interpreting outputs from generative AI tools."},{"id":468,"value":"Address ethical considerations such as data privacy, algorithmic bias, and the impact on human relationships in education"},{"id":475,"value":"There is an onus on both state and federal governments to ensure that the curriculum itself is contemporary in terms of content and delivery options"},{"id":492,"value":"It is clear that the strengths and benefits of GAI will need to be combined with the creative input, lived experience, and personal accountability of humans. We need to understand and articulate the potential and evolving role that GAI can play in the teaching and learning experience."},{"id":504,"value":"Invest in training and demonstrations for students in the classroom to build literacy and understanding about the benefits and limitations of GenAI and how to best use GenAI tools responsibly."},{"id":513,"value":"Students â— Require an understanding of the risks, limitations and potential of GenAI in both the education context, but also beyond it. It is critical to build literacy and familiarity as a fundamental digital skill"},{"id":514,"value":"Studentsâ— Require an understanding of the idea that GenAI has incredible potential as a tool to enhance and augment\nlearning, but not replace fundamental skills in literacy and critical thinking"},{"id":530,"value":"In the long term, we recommend the Government undertake a detailed review of Australiaâ€™s education system to identify challenges and gaps posed by emerging technologies such as GenAI, the impacts such technologies have on the education system and ways to ensure the system remains prepared and fit-for-purpose."},{"id":560,"value":"Engineers Australia recommends the development of standards on how Generative Al can be used to develop critical thinking and evaluative judgement should be an immediate focus. Unfortunately, the pace of change will make it hard for these standards to be maintained. Therefore, it would seem essential to develop a standards framework that has adaptability asits core, some examples of what could be included:\nâ€¢  Development of education around generative Al:\no  fundamental principles on effective and ethical engagement with generative Al\no  appropriate acknowledgement of, and guidance on how to evidence critical engagement with generative Al tools\no  development of prompt engineering skills to enable generative Al to be used to develop critical  thinking skills and evaluative judgement,\no  tuning learning outcome specifications to the generative Al era,\no  assessment designed to test human capability. ie. why would something that can be generated by Al be assessed? - a more robust assessment might require the student to critique the responses from a tool like ChatGPT.\nâ€¢  Ethical implications of uploading student work for assessment.\n\nwe are likely to see the development of discipline-specific Generative Al tools, which are not only trained on a generalised large language model, but specifically in a discipline ecosystem. The development of guidelines on how these tools should be developed and utilised to ensure some standardisation would be useful. For example, appropriately declared use/acknowledgement of Generative Al tools, just as is the case with referencing the use of published work of others, needs to be a critical element in the developing ethical attitudes and practices for graduates entering any field of professional practice."},{"id":569,"value":"Universities, as educators of the future workforce, must equip graduates with the critical thinking skills and reflective practices required to navigate the effective, responsible and ethical use of generative AI in the future workplace. This reflects both the need of industry for AI-literate graduates and the influential role such graduates will have on future workplace practices involving the use of generative AI."},{"id":578,"value":"Regulatory bodies to develop processes that take in to account generative AI when accredited training packages are updated and to enable vocational education providers to include local learning outcomes that respond to rapid technological change."},{"id":581,"value":"Universities should educate students and staff on the safe and ethical use of generative AI tools and ensure the integrity and authenticity of assessments."},{"id":604,"value":"Students should be taught how to use AI correctly and effectively to ensure the integrity of\ntheir learning journey"},{"id":610,"value":"Promotion of AI Literacy: Incorporate AI literacy into the curriculum, which includes understanding how AI works, its ethical implications, and how to effectively use AI systems. This also involves developing an AI-Skills Continuum for progressively enhancing students' AI abilities from basic comprehension to problem-solving."},{"id":620,"value":"Reduced Curriculum Content Load: Shift focus from covering extensive content to mastering key concepts and skills, facilitated by AI's personalised learning capabilities. This may require a review and potential revision of existing curricula"}],"Tag_group":{"id":993951,"value":"Learning","color":"cyan"}},{"id":11,"order":"11.00000000000000000000","Name":{"id":980191,"value":"new-policy","color":"dark-purple"},"Notes":"","Recommendations":[{"id":30,"value":"To have a governing body around the use of AI technology in Education Sectors;"},{"id":39,"value":"National policy around the use of plagiarism detectors is important as well to prevent the damage that comes from the hyper-surveillance of student performance, potentially by plagiarism detectors that will continue to have a fail rate."},{"id":40,"value":"There needs to be clear policy and cross-sectoral agreement around student access to AI tools that is consistent and not determined or restricted by cost or differing licenses and agreements."},{"id":41,"value":"Consistent and Effective National and Cross-Sectoral Policy on AI: Policy, at scale, to ensure ongoing transparent, ethical access to AI in education is critical so that the access to AI tools is fair and equitable and does not perpetuate disadvantage. It is also known that AI can reinforce bias that can disadvantage learners. Policy should clearly stipulate the ongoing responsibility that creators have in ensuring that the AI tools they create meet the high standards required in learning environments to keep students safe and mitigate additional responsibility being expected of teachers to ensure the tools they are using in the classroom are effective, pedagogically sound and will not perpetuate bias."},{"id":63,"value":"The House Standing Committee on Employment, Education and Training (the Committee) should consider whether AI tools that explicitly (and as their primary business model) market or provide cheating services are within the purview of the TEQSA Act in relation to the provision of contract cheating services."},{"id":68,"value":"That the Committeeâ€™s findings and recommendations provide the basis for a coherent and cohesive national approach to the use of generative AI that covers all levels and types of education providers, from primary school through to the higher education sector."},{"id":79,"value":"That the Committee make recommendations on national regulation of the use of generative AI in the Australian context, where its use in education is just one aspect of its broader use in Australian society."},{"id":81,"value":"(1) consistent with international responses to AI, including the safe management of foundation models and forms of generative AI, new regulation is needed in this area and arguably a principal piece of legislation that governs AI. The regulation of AI should also be part of a wider and comprehensive review of laws that intersects with and is complimentary to this sector. We need to continue to balance risk proportionately by identifying the highest risks in this area and mechanisms for outlier issues of concern whilst continuing to encourage innovation and derive the truly significant societal benefits of AI;"},{"id":101,"value":"Education ministers and education departments in the states and territories adopt a nationally consistent approach to governance and standards and remove the current regulatory misalignment through calling for only a focus on local decision-making. Further, a continuous improvement national strategy with an agile approach is required to reduce teacher polarisation between AI users in government sectors, other jurisdictions, and education systems. There is a need to meet the national challenge and strict national control, with specific AI risk mitigation and regulation for areas such as the often- discussed â€˜guard railsâ€™ for cybersecurity, child protection, privacy, IP and consumer protection and information accuracy of student use or source attribution of generative AI tools."},{"id":111,"value":"3. The Australian Qualifications Framework must be capable of enabling the necessary curriculum renewal, particularly in its framings, definitions and specifications for knowledge and skills."},{"id":152,"value":"Implement guardrails as AI develops to provide better outcomes The NTEU supports the establishment of regulatory guardrails to direct the development and use of AI in both the education context and more broadly. The implementation of good practice principles drawing from ethical frameworks will help direct the development of AI in a positive manner and reduce the risk of adverse outcomes. Such principles should address the need for: â€¢ Equity â€¢ Accessibility and inclusion â€¢ Prevention of bias and discrimination â€¢ Transparency and accountability These principles should underpin the premise that the application of AI should be beneficial and not result in the lessening of current industrial protections, human rights and guarantees on human expression and freedoms."},{"id":162,"value":"Recommendation 1: Reverse bans on generative AI systems in schools introduced by state education departments and establish institutional access licencing agreements across the education sector."},{"id":206,"value":"Develop education-specific standards, incorporated into procurement and\n(potentially new) public oversight systems, covering product design, data use, and\nlife cycle governance and accountability."},{"id":260,"value":"Policy Strategy: Prioritise policies that grant equitable access to AI technologies and educational resources for disadvantaged communities."},{"id":288,"value":"That the Government address privacy and data risks in the Privacy Act review by establishing a robust data protection framework that outlines the rights of students in relation to personal data as well as establishing limitations to the collection, use and retention of data of minors."},{"id":289,"value":"That the Government puts in place requirements for educational institutions and AI developers to have clear and transparent data use policies. These policies should outline the types of data collected, the purposes for which the data will be used, how long the data will be retained, and the measures taken to protect data privacy. These policies should be presented to users in a way that is age-appropriate and easy to understand."},{"id":290,"value":"That the Government provides specific powers to the Office of the Australian Information Commissioner to assess AI tools used in education should for their privacy impact. The assessment would identify potential risks to data privacy and outline measures to mitigate them before the tool can be implemented. The Office of the Australian Information Commissioner should be given the power to ban the implementation of AI tools if the risk to a usersâ€™ data privacy is too high."},{"id":291,"value":"That the Government requires AI developers and educational institutions to implement strong encryption and secure data storage practices. Government should provide support - both technical and financial â€“ to educational institutions to assist with meeting this requirement."},{"id":293,"value":"That the Government considers the development of comprehensive legislation in relation to Generative AI drawing on international best-practice, like the European Union AI Act. It is crucial that a risk-based approach is taken which includes third party and independent impact and audit assessments, mandatory transparency reports, the human oversight of certain AI systems depending on level of risk, and accountability measures."},{"id":294,"value":"That the Government consider the establishment of a dedicated AI regulatory body assist regulators, policy makers and government in developing, enforcing and implementing legislation, in line with submissions made to â€œPositioning Australia as a Leader in Digital Economy Regulationâ€ and the Australian Human Rights Commissionâ€™s Human Rights and Technology Final Report (2021)."},{"id":296,"value":"Educational institutions and AI developers should be required to have clear and transparent data use policies. These policies should outline the types of data collected, the purposes for which the data will be used, how long the data will be retained, and the measures taken to protect data privacy. These policies should be presented to users in a way that is age â€“ appropriate and easy to understand."},{"id":297,"value":"AI tools used in education should be assessed for their privacy impact by the Office of the Australian Information Commissioner. The assessment would identify potential risks to data privacy and outline measures to mitigate them before the tool can be implemented. The Office of the Australian Information Commissioner should be given the power to ban the implementation of AI tools if the risk to a usersâ€™ data privacy is too high."},{"id":298,"value":"Government can require AI developers and educational institutions to implement strong encryption and secure data storage practices. Government should provide support - both technical and financial â€“ to educational institutions to assist with meeting this requirement."},{"id":301,"value":"Legislation should require organisations to publish transparency reports detailing how their AI systems are used, including any cases of significant impact on individuals or society. These reports would provide insights into how algorithms function in practice and how they affect users."},{"id":302,"value":"Legislation can grant users the right to access and understand the data collected about them and the algorithms used to make decisions based on that data. Users should have the opportunity to challenge or correct inaccurate information."},{"id":303,"value":"Legislation should mandate third party evaluations of AI tools and systems to ensure they meet certain criteria for transparency, fairness, and accountability. These evaluations should be conducted by independent auditors and regulatory bodies."},{"id":304,"value":"Legislation should require that critical decisions made by AI systems to have a human-in-the-loop component, where a human reviewer can examine and validate the systemâ€™s outputs before final decisions are implemented."},{"id":305,"value":"Legislation should establish accountability measures for organisations that deploy AI systems that lead to biased, discriminatory or harmful outcomes to help deter irresponsible AI development and use."},{"id":327,"value":"Wholesale banning and policing are a waste of time. (Though there may be specific circumstances where AI needs to be excluded or policed.)"},{"id":335,"value":"That the Australian Government: consider reforms to discrimination law arising as a result of GAI and other AI systems; clarify the law on copyright of outputs, inputs and prompts on GAI"},{"id":337,"value":"TEQSA needs to be supported and funded to update regulatory requirements to allow universities to innovate and adapt in the new environment."},{"id":341,"value":"Universities should also take steps to respond to the emergence of GAI by adapting governance processes and quality assurance guidelines to allow more flexibility in assessment design and experimentation"},{"id":423,"value":"Counter ethical risks through regulation of governance and policies: these should promote ethical engagement with generative AI first and foremost, as a priority, rather than an add-on"},{"id":486,"value":"Consideration is needed of the degree to which governments and school systems invest in technologies designed to detect inappropriate use of digital technologies by students"},{"id":505,"value":"Formulate strategic priorities and policy for GenAI at the Department level and school level to provide tailored guidance to staff and students."},{"id":509,"value":"Ensure existing policy and regulatory frameworks are fit-for-purpose and are able to deliver adequate protections for the use of GenAI in the education system. This should be underpinned by the regulatory principles of harmonisation, diversity, and necessity."},{"id":511,"value":"Establish regulatory sandboxes for GenAI solutions to be deployed in test educational environments before being rolled out more widely."},{"id":529,"value":"GenAI sandboxes Sandboxes enable governments and businesses to develop and test tools in a safe and controlled environment with students, teachers, and other stakeholders before they are released."},{"id":530,"value":"In the long term, we recommend the Government undertake a detailed review of Australiaâ€™s education system to identify challenges and gaps posed by emerging technologies such as GenAI, the impacts such technologies have on the education system and ways to ensure the system remains prepared and fit-for-purpose."},{"id":545,"value":"That the Copyright Act 1968 be amended to provide appropriate public interest\nexceptions to support the use of machine learning and data and text mining in\nAustralia."},{"id":558,"value":"That the Copyright Act 1968 be updated to ensure that the laws for the use of\nmaterial in the physical classroom are equally applicable to a digital classroom\nsetting, including remote learning and the sharing of material on digital platforms."},{"id":559,"value":"That the Copyright Act 1968 be amended to provide for an express exception for\nthe use of freely available internet material in education"},{"id":584,"value":"A broad, society-wide regulatory framework for AI, such as the risk-based model proposed in the EU, can help mitigate challenges and risks associated with generative AI technology."},{"id":587,"value":"suitable controls are required for equitable provision across public schools and TAFE, for ethical considerations, addressing privacy concerns, environmental considerations and legal protection for teachers."},{"id":590,"value":"This policy framework must: â€¢ consider the ethics, curriculum and pedagogical issues; â€¢ address occupational, health, welfare and safety issues; â€¢ ensure that the implementation of AI is equitable, accessible and inclusive; â€¢ ensure that AI tools and their implementation is free of cultural, racial and gender biases and that they should not perpetuate or amplify existing biases or discrimination; â€¢ ensure that private for-profit operators are prevented from exerting inappropriate influence via platforms and products, on the processes of teaching and learning in educational settings and systems; â€¢ ensure that a digital equity audit is undertaken to ascertain the extent of digital inequality experienced by students and educational settings; â€¢ consider the issues of data sovereignty and copyright and that the use of AI in public education must be transparent, including its applications, what data is collected and how that data is used; â€¢ ensure that the teaching profession is provided with high quality professional development, systemic support and professional autonomy; â€¢ ensure that the teaching profession and students are provided with guidance and training on the ethical use of AI tools; â€¢ ensure equitable and fair resourcing for all students, including digital access; and â€¢ undertake ongoing evaluation of AI implementation to ensure that it supports the needs of students and the teaching profession and aligns with the appropriate ethical standards and guidelines that govern teaching and learning practices."},{"id":614,"value":"Regulation of AI Tools: Implement strict regulations and quality standards for AI tools in education, including a rigorous certification process for new AI applications."},{"id":626,"value":"Further, as Al tools and capabilities, when properly utilised will enable the Austra lian economy to unlock greater productivity and jump-step economic growth, OES recommends the Australian Government develop a comprehensive strategy that will encourages Australian industry to integrate Al language models and tools into operations. This will incentivise employers to upskill their workforce with the general and industry-specific Al skills necessary to engage productively with Al models and tools"}],"Tag_group":{"id":993950,"value":"Policy-and-evaluation","color":"dark-orange"}},{"id":12,"order":"12.00000000000000000000","Name":{"id":980192,"value":"research-investment","color":"orange"},"Notes":"","Recommendations":[{"id":35,"value":"I strongly recommend a significant and rapid investment in research capability to provide evidence to inform responses to the issues raised in this Inquiry."},{"id":66,"value":"That the Committee recommends a national agenda for ongoing research and collaboration and educational initiatives that seek to maximise the benefits of generative AI across different disciplines, address risks, evaluate the impact of generative AI on learning, and support development of AI literacy among staff and students."},{"id":86,"value":"Evidence informed decision making We want to encourage innovative, safe practice for the use of generative AI in education. There is significant potential for generative AI tools to be used to improve education outcomes, however we currently have no research to support any decisions. Educators need to be supported to be able to make evidence-informed decisions about how generative AI can be used in their practice."},{"id":89,"value":"Commitment to a strong research agenda to understand the potential and risks of generative AI as well as to evaluate its use in educational settings and the reasons for its rapid uptake. This research should also include disadvantaged and marginalised groups and consider the different educational needs of each school age cohort."},{"id":91,"value":"Commission the Australian Education Research Organisation (AERO) to provide expertise and advice on what works best when using education technology in classrooms, to support teachers and improve student outcomes."},{"id":95,"value":"Recommendation 3: Commit, for the next 3-5 years, to prioritising funding to support research and development work into the safe and effective use of generative AI to improve evidence-based teaching, learning and assessment in the Australian school, vocational and higher education sectors."},{"id":97,"value":"Recommendation 4: Identify policy and program opportunities to encourage and support sustainable collaborations between educators in schools serving disadvantaged communities and their colleagues in Australian universities with relevant expertise and interests, to help address the digital divide, specifically in relation to access to and use of generative AI tools."},{"id":108,"value":"There is a major opportunity for the development of Australian models â€“ datasets, LLMs, and significantly, small language models. This is a research infrastructure agenda and is also brings in large public datasets that could offer opportunities for generative AI in Australia. We would single out (as per the RRIR paper) large datasets such as the Bureau of Meteorology, Australian Bureau of Statistics, and the National Library of Australiaâ€™s Trove."},{"id":138,"value":"5. That a research program is put in place to monitor outputs of generative AI tools deployed in an educational setting, with tool providers committing to continual improvement in response to findings."},{"id":139,"value":"alian education system would benefit from the enormous expertise offered by the higher education sector given that Australia is home to many of the  worldâ€™s leading researchers in AI in education, Learning Analytics, and higher education  researchers in teaching, feedback and assessment design. This expertise must be woven together.1 This could be achieved in several ways and UTS recommends consideration of the following models: â€¢  An extension of the model proposed by Ms Loble AM (described below as the Australian Forum on  Quality Digital Education) to include, where relevant, a partnership with the higher education  sector. â€¢   If separate from Ms Lobleâ€™s model, a National Centre for AI in education or an ARC Centre of  Excellence tuned to the needs of not only researchers advancing knowledge and innovation  technologically, but serving practitioners in co-designing, testing and evaluating what works in  diverse contexts. Australian Indigenous educational innovation and challenges must also be a  hallmark of this centre.2"},{"id":154,"value":"Evidence is a central requirement of ethical AI (merit in the National Statement; justification and transparency in many AI ethics frameworks). It is crucial that investments in EdTech are underpinned by evidence that any tools used will support the outcomes they claim to target. Support the critique, creation, and dissemination of evidence regarding claims of genAI supporting learning through: - Recommendation 2: Development of funding streams, and support for innovative approaches to evidence development and sharing across sectors, regarding genAI. By its nature this work must include social scientists which may require new funding streams, or/and reform of the R&D tax credit."},{"id":155,"value":"Recommendation 3: Support of interdisciplinary teams for genAI research both on fundamental evaluation of tool uses, and the dissemination of this evidence with and across education systems (including educators, learners, and developers)."},{"id":191,"value":"Recommendation 12: The Commission recommends continued investment in research and development to support the use of generative AI tools in educational settings, and an understanding of their impact."},{"id":199,"value":"Accelerate high quality, independent research and evaluation of AI tools to investigate impact on learning progress for students and to identify features that amplify positive outcomes, including implementation factors"},{"id":200,"value":"Catalyse a world-leading Australian social benefit edtech sector by investing in\npromising systems that meet high standards for evidence, efficacy, ethics and equity."},{"id":203,"value":"Commission the Australian Education Research Organisation (AERO), working with\nACARA, AITSL and ESA, to provide expertise and advice on what works best when\nusing edtech to support teachers and improve student outcomes"},{"id":216,"value":"Support the establishment of research centers to explore the opportunities and challenges of emerging technologies like Generative AI on education systems and teaching and learning practices"},{"id":259,"value":"Research and Evaluation: Invest in research and evaluation of AI implementations in disadvantaged communities to understand their effectiveness and identify areas for improvement. This data-driven approach will help optimize AI use for these cohorts."},{"id":265,"value":"The Australian Government and its relevant agencies provide supplementary grants to implement further research into how AI can be effectively and imaginatively utilised in clinical and nurse education in Australia."},{"id":273,"value":"consideration should be given to directing funding to further research at elite Australian maritime educational institutions into matters relating to the use of generative AI in Australian maritime educational and training policy."},{"id":364,"value":"An extension of the model proposed by Ms Loble AM (described below as the Australian Forum on Quality Digital Education) to include, where relevant, a partnership with the higher education sector."},{"id":365,"value":"If separate from Ms Lobleâ€™s model, a National Centre for AI in education or an ARC Centre of Excellence tuned to the needs of not only researchers advancing knowledge and innovation technologically, but serving practitioners in co-designing, testing and evaluating what works in diverse contexts. Australian Indigenous educational innovation and challenges must also be a hallmark of this centre"},{"id":380,"value":"Commission the Australian Education Research Organisation (AERO) to provide expertise and advice on what works best when using edtech to support teachers and improve student outcomes."},{"id":382,"value":"Accelerate high quality, independent research and evaluation of teaching and learning tools to investigate:\nâ€“ Impact on learning progress for students facing educational disadvantage;\nâ€“ Features that amplify positive outcomes, including implementation factors"},{"id":383,"value":"Catalyse a world-leading Australian social benefit edtech sector by investing in promising systems that meet high standards for evidence, efficacy, ethics and equity. Novel forms of capital should be considered, such as impact investing, social enterprises, leveraging or partnering with venture capital funds, as well as direct public or philanthropic funding"},{"id":422,"value":"Fund social sciences research into how generative AI is altering knowledge making"},{"id":536,"value":"Future research: There is an urgent need to support research exploring the use of generative Al by EAL/D learners and their teachers. Such research would enhance understanding about EAL/D learners' experiences, attitudes, innovative uses and challenges which, in turn, would allow the development of evidence-based research-informed policies, frameworks, approaches and practices for educational settings that specifically address their needs. Supporting research collaborations and partnerships between universities, government and educational institutions remains crucial for generation of new knowledge and pedagogical innovations associated with the use of generative Al in EAL/D settings."},{"id":528,"value":"There should be a significant increase in investment in research, development, and innovation in education technologies (particularly AI-driven EdTech), as well as quality impact and implementation research."},{"id":534,"value":"Develop and implement ethical frameworks and guidelines in consultation with Learned Academies, and accreditation and sector peak bodies including Indigenous Australian peak bodies and organisations â€“ e.g Maiam nayri Wingara"},{"id":543,"value":"Provide funding to support research and policy development"}],"Tag_group":{"id":993952,"value":"Resourcing","color":"blue"}},{"id":14,"order":"14.00000000000000000000","Name":{"id":980193,"value":"prepare-learners","color":"dark-gray"},"Notes":"","Recommendations":[{"id":44,"value":"There needs to be adequate and ongoing upskilling to support student digital citizenship so young people understand the risk to their data and teachers also understand their role in protecting student data. Students need to be provided with adequate understanding to make good decisions online that means they are not accessing apps or other sites where their data is potentially not secure or could be misused. More government policy and guidance are needed in this area."},{"id":45,"value":"The Cross Curriculum Priorities in the present ACARA syllabuses can be expanded to include â€˜Ethical use of Technologyâ€™ as a key area across all subjects with explanation and suggestions for teaching this."},{"id":47,"value":"â€¢  This technology must be incorporated into education, much like the use of computers and software were originally taught as a specific class in secondary schools and then was incorporated as a basic technical skill"},{"id":49,"value":"â€¢  This exposure and digital literacy in technology must begin in secondary study and be appropriately scaffolded into tertiary study, establishing a strong foundational familiarity with tools prior to more sophisticated application in a higher education setting."},{"id":52,"value":"â€¢  It is essential that generative AI is implemented and integrated across all fields of study to ensure that all students have the opportunity to build familiarity. This will ensure ethical and critical engagement with the appropriate use of such technologies in society, and preparing future workforce and cultural leadership in policy and government."},{"id":171,"value":"Students have preferences for using digital tools creatively and responsibly, to try new things and to fail as part of personal growth. This should be considered in the context of how the curriculum supports them to do this and how using and designing AI may play an important part in engaging students in their learning and providing opportunities for their future lives."},{"id":310,"value":"design pedagogies and learning experiences that respond to a changing world with AI"},{"id":311,"value":"help students to use Al responsibly and with care in life and learning"},{"id":353,"value":"Promote education and awareness of GAI: Comprehensive education and awareness initiatives on GAI are recommended as they ensure that staff and students are well-informed about its capabilities, risks and ethical considerations"},{"id":376,"value":"Emphasising the importance of iterative improvement and the ability to adapt AI tools to changing\neducational needs."},{"id":402,"value":"educators will need to find ways to include it in their teaching and assessment practices â€“ but only after they have agreed on what it is that they are actually wanting/needing to teach students and how they will measure their learning in an era of generative AI."},{"id":404,"value":"As generative AI becomes part of normal professional practice, students may be required to use AI generated work as an opportunity for review and critique to produce more sophisticated responses to assessment tasks"},{"id":497,"value":"Australian education is already globally renowned. There is an urgent need to adjust standards to incorporate the use of GAI to protect and augment those high standards. Use of GAI in Australian education settings should include: 1. Human oversight and quality assurance, ongoing due diligence of GAI outputs, including proactive management of associated large language models. 2. Access at scale - including investment in digital and critical literacy skills; authentic learning opportunities; higher-order thinking skills; and, peer-based learning - to ensure students donâ€™t simply have â€˜accessâ€™ to GAI but are equipped for a lifetime of considered and appropriate use as citizens."},{"id":538,"value":"Ensure institutional and sector support for developing artificial intelligence literacy among students, educators and researchers"},{"id":544,"value":"Adopt ACODE recommendations: https://publications.ascilite.org/index.php/APUB/article/view/401 \nRecommendations1.Embrace AI in learning, teaching, and assessment, but consider potential risks and challenges that come with it, such as academic integrity concerns and workload issues.2.Foster a culture of transparency, collaboration, and partnership between educators, students, and AI experts, to ensure that AI is used ethically and effectively.3.Develop evidence-based support systems and guidelines for AI use in education, and regularly update them to keep up with the latest developments and challenges.4.Identify and provide appropriate training and professional development opportunities for educators to build their AI competencies, confidence and fluency.5.Consider the potential impact of AI on equity and accessibility and ensure that AI solutions are designed to benefit all students, regardless of their background or circumstances.6.Collaborate with external bodies, such as accrediting bodies and regulatory agencies, to align educational responses to AI across primary, secondary, and tertiary education sectors.7.Continuously monitor and evaluate the impact of AI on learning, teaching, and assessment, and be open to making necessary adjustments based on the evidence.8.Institutions prioritise assessment redesign, by adopting more authentic forms of assessment to minimise the option for students to use AI based tools in generating assessment content"},{"id":567,"value":"Use of generative AI tools should be a key component of student learning and thus fostered through targeted WIL pedagogy that embeds opportunities for students to experience general as well as discipline-specific generative AI workplace applications."},{"id":568,"value":"Universities and regulatory bodies track emerging trends in the use of generative AI and its impact on workplace practices across all sectors and reflect these in course curricula"},{"id":569,"value":"Universities, as educators of the future workforce, must equip graduates with the critical thinking skills and reflective practices required to navigate the effective, responsible and ethical use of generative AI in the future workplace. This reflects both the need of industry for AI-literate graduates and the influential role such graduates will have on future workplace practices involving the use of generative AI."},{"id":615,"value":"Shift in Learning Paradigms: Advocate for a transition from traditional outcome-based education to a problem-solving, learner-centric approach, facilitated by AI. This includes adjusting pedagogical and assessment strategies to suit the capabilities of AI."},{"id":625,"value":"OES recommends the Australian Government develop an integrated and comprehensive strategy to facilitate and equip the vocational and higher education sectors to develop the organisational infrastructure and capacity and skilled workforce required to teach foundational Al language model literacy skills to the public"}],"Tag_group":{"id":993951,"value":"Learning","color":"cyan"}},{"id":15,"order":"15.00000000000000000000","Name":{"id":980181,"value":"Indigenous-leadership","color":"darker-pink"},"Notes":"","Recommendations":[{"id":56,"value":"need to support and enable through proactive programs, First Nations inclusion and leadership"},{"id":534,"value":"Develop and implement ethical frameworks and guidelines in consultation with Learned Academies, and accreditation and sector peak bodies including Indigenous Australian peak bodies and organisations â€“ e.g Maiam nayri Wingara"}],"Tag_group":{"id":993948,"value":"People","color":"darker-pink"}},{"id":16,"order":"16.00000000000000000000","Name":{"id":980194,"value":"communications","color":"darker-brown"},"Notes":"","Recommendations":[{"id":15,"value":"â–ª  Raise awareness of generative AI's potential uses and limitations."},{"id":58,"value":"1. a more coherent approach be adopted to the dissemination of information relating to the impacts of Generative Al on Academic Integrity from bodies such as TEQSA and the Federal Department of Education."},{"id":61,"value":"4. the Department of Education or Universities Australia establish an information hub for the sector, to coordinate relevant information for staff and students and that pathways be developed that coherently supports and extend this information."},{"id":71,"value":"That the Committee makes recommendations to higher education providers on the curation and sharing of best practice, including case studies and exemplars to build capability and awareness of ways to engage with generative AI."},{"id":99,"value":"Public support, trust and confidence must be built, and a vision communicated for the safe and effective use of generative AI software and tools in professional teaching standards, in early learning centres, schools and teacher education institutions. A human-centric vision within the anticipated draft AI framework must include the principles of inclusion, equity, access, quality, safety, and security."},{"id":115,"value":"â€¢ ensuring that users understand the limitations and risks of generative AI, including, for example, the recognition that some tools could involve the intentional or unintentional sharing of personal, private, or confidential information. There are also risks, at least at present, with the accuracy of AI tools. Their results â€“ including those provided by so-called â€˜expert systemsâ€™ â€“ can be very convincing, even when wrong. The limitations of facial recognition tools, for example, are well known, and are, in part, a consequence of the way they are â€˜trainedâ€™ (see below). Generative AI is subject to similar shortcomings and raises the possibility not only of inaccurate information but intentionally or unintentionally created and convincing misinformation."},{"id":205,"value":"Create an accessible repository of trustworthy information on the quality and safety\nof available edtech tools so that schools, education systems and parents can make\nmore informed choices"},{"id":274,"value":"In order to unlock the potential of generative AI in the Australian education system, Government must enable and promote digital literacy, skilling and responsible use of AI/ML tools among our children, students, educators, academic communities, and the wider workforce. AI/ML and other emerging technologies will only be appropriately assimilated by the Australian education system if our educators, students and the wider population are aware of its potential and understand how to use it."},{"id":295,"value":"That the Government increases public awareness and education programs to inform users about AIâ€™s potential implications and risks, to improve the ability of the users to hold companies and developers accountable and make informed decisions."},{"id":306,"value":"Government should also support public awareness campaigns and educational programs to inform the general public about AI technology and its potential implications to improve the ability of the public to hold organisations accountable and make informed decisions."},{"id":317,"value":"articulate the social implications of AI integration into society"},{"id":320,"value":"provide positive messaging for parents and the wider community on how AI is helping students to learn and grow, without taking from the important connections and relationships they build in their school life"},{"id":418,"value":"Maintain an open dialogue on use of generative AI"},{"id":429,"value":"Awareness: There is a need to increase broader awareness, constructive attitudes and levels of confidence about generative Al , its benefits, possibilities, and applications as well as limitations, challenges and biases. Given emerging language and literacy levels of this group both in English and sometimes in home languages, information needs to be accessible, presented in various forms (e.g. brochures, posters, videos, invited presentations, etc.) and/or translated into home languages. These resources need to be easily accessible through community centres, schools and online platforms. To promote such awareness, we recommend that different stakeholders with EAL/D expertise and experience are included in important decision making and initiatives"},{"id":500,"value":"there will need to be an education campaign highlighting the benefits of AI as a work and education tool but also the importance of independent, critical and creative thought of being a human."},{"id":515,"value":"Parentsâ— Require assurances that the education system is taking appropriate measures around GenAI in the classroom, and that it is being deployed in a safe and responsible way."}],"Tag_group":{"id":993949,"value":"Materials","color":"dark-pink"}},{"id":17,"order":"17.00000000000000000000","Name":{"id":980195,"value":"resourcing","color":"dark-cyan"},"Notes":"","Recommendations":[{"id":55,"value":"â€¢  The rapid development of generative AI and proliferation of companies will also prompt a range of new â€˜edtechâ€™ products and services that could create a financial pressure for educational institutions as they attempt to ensure appropriate equity and inclusion for cohorts."},{"id":59,"value":"2. an allocation of dedicated workload commensurate to the need for Additional professional development to support academic staff understand the options that may be available to them to accommodate generative Al in their units/courses, particularly in relation to assessment. This is particularly critical for staff on sessional contracts. Thus, consideration should be given to one off grants for institutions to support their staff in this way."},{"id":65,"value":"That the Committee considers the significant shift that the integration of generative AI technologies in education represents for educators and makes recommendations regarding the need to invest in this workforce transformation. In particular, the Committee should recommend investment by government and the higher education sector in the reconceptualization of teaching, learning and assessment to leverage the benefits of generative AI and address the risk posed to assessment integrity and potential data security and privacy issues. Options for developing resources, guidelines and training for educators at a national level need to be considered."},{"id":75,"value":"That the Committee considers equity of access to generative AI and the ways that institutional policies and resource allocation for AI will impact on student capabilities, opportunities and outcomes."},{"id":76,"value":"That the Committee provide recommendations to higher education providers regarding licensing agreements for relevant generative AI tools to ensure ready access for students and staff."},{"id":77,"value":"That the Committee consider any inequities in access to basic infrastructure in Australia including access to and costs associated with internet and mobile telephony services, and how these will impact any recommendations for the use of generative AI in education, including levels of government investment required."},{"id":78,"value":"The Parliamentary Inquiry recommend the use of the current HEPPP (Higher Education Participation and Partnerships Program) to address the needs of students experiencing social disadvantage in relation to digital skills and digital access to generative AI tools."},{"id":85,"value":"AI safety research and development, and optimising innovation breadth, needs to be properly and comprehensively supported. The prioritisation of resourcing, coordination of public and private, and increasing the scale of piloting and use, and skills training in niche evaluation assessments of AI, is important. If Australia is to compete on the global stage and drive economic and productivity growth, the Governmentâ€™s continued focus on and increased investment in initiatives to support our digital strategy, and the AI ecosystem in Australia, by supporting the education sector is truly fundamental. Our global counterparts are expanding their investment in AI and capabilities and Australia cannot afford to be left behind. We have set out in the Annexure to this submission some examples of broader principles that we have developed that are education specific to help build consensus on governance frameworks to manage AI safety risks."},{"id":102,"value":"Investigation of an equitable and accessible national funding program, such as grants, scholarships, and awards for professional teaching associations to sponsor and evaluate free professional development for Australian teachers in early childhood, school, and higher education sectors. These areas might include recommendations for classroom practice, curriculum initiatives, action research, radical changes in student assessment practices, or the use of an educative approach to anti-plagiarism as well as testing of detection software for academic honesty, originality, and attribution."},{"id":113,"value":"5. Federal sponsorship would best enable the sector-wide collaboration needed to conceptualise and guide assessment renewal while maintaining the quality and reputation of Australian higher education."},{"id":121,"value":"more work is required to understand how such tools can be best leveraged to improve outcomes. To facilitate this transition, further and significant investment in comprehensive professional development programs for educators,is necessary to equip them with the necessary skills in data analysis and digital and AI literacy."},{"id":136,"value":"3. Government funding for the creation of programs to upskill library and teaching staff to be AI literate, and to be able to teach AI literacy to students."},{"id":147,"value":"Staff will however need institutional support and resources to achieve this, including greater workload allocations for course design and student assessment and frameworks for considering what types of AI usage might constitute plagiarism. There should also be in place appropriate institutional policies and procedures to ensure best practice is in place and that human oversight on the use of AI is embedded."},{"id":160,"value":"Recommendation 8: Ensure equitable access to genAI through tackling digital divides in affordability, accessibility, and capability. Target schools that are most impacted by digital divides"},{"id":192,"value":"Recommendation 13: Policies should encourage partnerships to improve access to resources, expertise, and technology infrastructure, while ensuring that these are pursued in an appropriate way that recognises the particular educational context."},{"id":266,"value":"Ongoing investments be made to develop, review, and update effective plagiarism detection \ntechnologies"},{"id":267,"value":"The Australian Government establishes funding models to support nurse-led initiatives to investigate and establish the development of regulatory standards for AI in education."},{"id":269,"value":"Collaboration between the Australian Government, its associated agencies and nurse education institutions to establish funding models to support nurse-led initiatives to investigate and establish the development of standards for AI tools and resources in clinical and nurse education."},{"id":292,"value":"That the Government strengthens the role of and financial support to the Australian Information Commissioner to assist with the safe implementation and overseeing the use of AI tools in education settings in relation to data privacy."},{"id":298,"value":"Government can require AI developers and educational institutions to implement strong encryption and secure data storage practices. Government should provide support - both technical and financial â€“ to educational institutions to assist with meeting this requirement."},{"id":299,"value":"Government should strengthen the role of and financial support to the Australian Information Commissioner to assist with overseeing the use of AI tools in education settings in relation to data privacy."},{"id":333,"value":"That the Australian Government provide funding support to universities to train staff in GAI literacy."},{"id":334,"value":"That the Australian Government: encourage key vendors to enter into institutional licences with universities that have unlimited use for staff and students"},{"id":427,"value":"Access: It is important to ensure access to generative Al amongst EAL/0 communities. We recommend avoiding approaches which ban the use of generative Al in schools. This is particularly important for public schools which cater for the majority of EAL/D students in Australia. We also recommend increasing access, including financial support, to Al in local libraries and community centres."},{"id":454,"value":"ISA strongly recommends that funding be provided to AISs to ensure that schools in all sectors have the necessary support to implement effective and ethical generative AI strategies."},{"id":483,"value":"Schools and teachers must have access to various products and platforms. The cost associated must be factored into system budgets, rather than passed on to schools, students, parents or teachers and education leaders as individuals."},{"id":489,"value":"The decision to adopt new practices should prioritize their relevance to teaching and learning, and careful consideration should be given to the necessary resources and support for implementation."},{"id":512,"value":"Direct additional investment to incentivise the deployment of GenAI, as well as to boost research and development to build a strong ecosystem of responsible GenAI that can help achieve beneficial educational outcomes."},{"id":525,"value":"Funding and investment There are a number of initiatives which can be established with a view to enhancing innovation, adoption, and practice at the level of the ecosystem to support the longer-term sustainment of GenAI in education."},{"id":526,"value":"Funding deployment of GenAI systems Increased funding for schools would enable them to invest in and deploy responsible Artificial Intelligence for Education (AIED) technologies. This would be especially beneficial for disadvantaged schools"},{"id":542,"value":"Prioritise resourcing at institution and sector levels"},{"id":606,"value":"We should, and IMO we must invest better in our education if we want to truly create a leading country in the future."},{"id":611,"value":"Investment in AI Infrastructure: Provide necessary resources, such as high-speed internet connectivity, robust hardware, and AI software, to support AI integration into education."},{"id":624,"value":"Recommendations to manage the risks, seize the opportunities, and guide the potential development of generative AI tools including in the area of standards.\nâ€¢ OES recommends the Australian Government establish a funding mechanism to:\nâ€¢ fund AI literacy skills and knowledge development within the primary, secondary and tertiary education workforces\nâ€¢ fund the national deployment of AI software, tools and capabilities within the primary and secondary school, with a commitment to provide sufficient additional support to schools currently subject to digital disadvantage"},{"id":625,"value":"OES recommends the Australian Government develop an integrated and comprehensive strategy to facilitate and equip the vocational and higher education sectors to develop the organisational infrastructure and capacity and skilled workforce required to teach foundational Al language model literacy skills to the public"}],"Tag_group":{"id":993952,"value":"Resourcing","color":"blue"}},{"id":19,"order":"19.00000000000000000000","Name":{"id":980186,"value":"capacity-building","color":"light-yellow"},"Notes":"","Recommendations":[{"id":71,"value":"That the Committee makes recommendations to higher education providers on the curation and sharing of best practice, including case studies and exemplars to build capability and awareness of ways to engage with generative AI."},{"id":93,"value":"Recommendation 1: Lead the establishment of a national cross-sector representative â€˜AI in Educationâ€™ body and knowledge- sharing hub - to guide the safe, beneficial and equitable use of generative AI in Australian education, and to develop, test and showcase outstanding innovation in the productive and responsible use of the technology in the Australian school, vocational and higher education sectors."},{"id":102,"value":"Investigation of an equitable and accessible national funding program, such as grants, scholarships, and awards for professional teaching associations to sponsor and evaluate free professional development for Australian teachers in early childhood, school, and higher education sectors. These areas might include recommendations for classroom practice, curriculum initiatives, action research, radical changes in student assessment practices, or the use of an educative approach to anti-plagiarism as well as testing of detection software for academic honesty, originality, and attribution."},{"id":105,"value":"Recommendation 3: Establish a cross-sector representative body and knowledgesharing hub which embeds a research-policy-practice approach toward the governance of AI across all Australian education contexts. All areas of education are already and likely to be impacted by the use of AI and all stakeholders need opportunities to shape the implementation of AI in Australian education systems. A representative cross-sector independent body should include members from government, departmental agencies (e.g. Department of Education, Department of Industry, Science and Resources), regulatory bodies relating to education (e.g. TEQSA, ASQA and ACECQA), higher education (both STEM and HASS disciplines), schooling and early childhood sectors (including diverse range of students for all sectors), the education technology industry, teacher associations and parent groups. The body should be established to: (1) oversee the development of AI in Australian education with a focus on the risks and possibilities of open A.I. development; (2) produce regular issue-specific publications and events for the groups it represents; and, (3) maintain a set of iteratively revised guidelines and learning resources for the field."},{"id":106,"value":"An appraisal of Australiaâ€™s AI capability is needed with a focus on education, training, and research. The RRIR paper notes that â€œAustralia has capability in AI-related areas like computer vision and robotics, and the social and governance aspects of AI, but its core fundamental capacity in LLMs and related areas is relatively weakâ€. It is not clear whether we are producing enough â€œexpertsâ€ in core fields through research training. Nor do we have a whole-of-sector view to AI industry workforce â€“ inclusive of education as a major industry â€“ so that we can be confident we are producing cohorts of graduates with the foundational education and skills to meet the AI challenges of our time.3"},{"id":110,"value":"2. Investments will need to be made in the higher education workforce to: â€¢ develop their knowledge and skills in the productive and ethical use of AI to enable them to create relevant curricula for students; â€¢ enhance their teaching capabilities to enable the use of intentional pedagogies that develop uniquely human skills,  and â€¢ build their assessment design abilities so they can reconceptualise assessment to maintain course integrity."},{"id":128,"value":"â€¢ Work collaboratively with high schools who are already encouraging students to use Gen-AI so we can build upon the already developed capabilities is critical. o However, note that not all schools do encourage students to use Gen-AI and student may therefore come to tertiary education with different levels of competence and understanding of Gen-AI tools. This makes things even more complex for educators."},{"id":131,"value":"â€¢ Promote exchange of experience and success stories across the education sector as we navigate through this new challenge."},{"id":133,"value":"â€¢ Promote the collaboration between AI researchers and other areas."},{"id":137,"value":"4. The Department of Education to work with librarians and teacher librarians on the developmentof new tools, digital platforms and programs to support AI in education."},{"id":141,"value":"Convene generative AI challenges to catalyse applied research and cross-sector collaboration. Teams of academia, industry partners, and educational institutions would be funded to explore the potential applications of generative AI in education. These projects would focus on developing innovative solutions, evaluating their effectiveness, and addressing specific challenges faced in different educational contexts."},{"id":142,"value":"Hold annual conferences on generative AI in Education. Annual conferences would bring together thought leaders and the strongest examples of practice, as a way to build Australiaâ€™s capability. These could be specialised for different stakeholders and agendas (e.g., pedagogical, technical, ethical, governance) as well as ensuring there was productive knowledge integration. A strong emphasis on translating into practice will promote innovation diffusion."},{"id":143,"value":"Establish a generative AI educational impact evidence hub to foster both domestic and international collaboration and knowledge sharing among researchers, practitioners, and policymakers. Resource the development of a collective intelligence website that assists the community in sharing, finding, and debating the emerging evidence as generative AI is evaluated in different educational contexts. UTS has experience in prototyping such infrastructures."},{"id":157,"value":"Recommendation 5: Understanding, evaluating, and sharing effective practices: There can be no strengths of genAI in education without teachers who will work with, create approaches for, and thus need to learn about genAI. This has implications, drawing on our other recommendations. o Any consideration of and planning cycles towards use of genAI in education should be with respect to the values and aims identified in Recommendation 4 o Resourcing should be provided to develop models to assess AI literacy across the range of stakeholders, and identify needs and strategies to develop this literacy; resources derived from this activity can feed into guidelines to help navigate the ethics of genAI (Recommendation 6) o Support should be provided for bespoke professional learning for teachers from all sectors, to develop algorithmic literacy to learn to engage with genAI and capacity for designing to learn with genAI tools Recommendation 1; Recommendation 7). o Evidence should underpin any incorporation of genAI (see Recommendation 3). This evidence should be shared and co-developed with and by teachers, informed by student voice, and in mentoring and partnerships with research universities and education institutions. It may also be appropriate to target resourcing to creation of evidence-informed models that encode shared values (Recommendation 4), and the body of existing evidence regarding learning technologies, to create tuned models or/and educationally-tailored system prompts (prompts that modify user input to provide context). Sharing among teachers has been shown to be an effective mechanism for supporting innovative approaches, particularly through creation of toolkit resources that provide practical guidance for design for learning alongside evidence and high-level principles."},{"id":174,"value":"ACARA has been tasked with exploring the development and delivery of optional support resources to implement the national curriculum as part of Action 19 in the National Teacher Workforce Action Plan. There may be the opportunity to look at the synergies between future work related to AI and activities related to Action 19."},{"id":201,"value":"Work with schools to test, develop and showcase best practice integration of\nteaching and learning technology tools, including for disadvantaged and special\nneeds students"},{"id":213,"value":"Provide system-level support for educators to integrate Generative AI opportunities into teaching practice."},{"id":238,"value":"Promote collaboration or forums of educational institutions to develop and enforce academic integrity policies that address potential misuse of AI tools, including plagiarism detection and cheating prevention."},{"id":321,"value":"provide schools with worked examples including lesson plans on how teachers have used AI to enhance learning outcomes"},{"id":331,"value":"We encourage the sharing of knowledge and experiences, throuqh processes such as this inquiry, so that government, education institutions and industry can work together to discuss and devise practical methods to develop best practice use of GAI in the higher education sector"},{"id":338,"value":"That the Australian Government re-establish the Australian Learning and Teaching Council or a similar body to collate and disseminate research and insights into GAI in education"},{"id":358,"value":"where there are opportunities for TESQA to support AI-related transformation, these should also be adapted and adopted, where appropriate by ASQA."},{"id":359,"value":"TEQSA and ASQA develop modules that all students can undertake in relation to Academic Integrity, similar to what has been developed for higher education providers by TEQSA for their staff, in the â€˜Academic Integrity Masterclassâ€™ online resources."},{"id":361,"value":"where any guidance notes and online resources are provided by TESQA, there is facility for these to keep pace with technology so that they do not become redundant."},{"id":367,"value":"Convene generative AI challenges to catalyse applied research and cross-sector collaboration. Teams of academia, industry partners, and educational institutions would be funded to explore the potential applications of generative AI in education. These projects would focus on developing innovative solutions, evaluating their effectiveness, and addressing specific challenges faced in different educational contexts."},{"id":368,"value":"Hold annual conferences on generative AI in Education. Annual conferences would bring together thought leaders and the strongest examples of practice, as a way to build Australiaâ€™s capability. These could be specialised for different stakeholders and agendas (e.g., pedagogical, technical, ethical, governance) as well as ensuring there was productive knowledge integration. A strong emphasis on translating into practice will promote innovation diffusion."},{"id":369,"value":"Establish a generative AI educational impact evidence hub to foster both domestic and international collaboration and knowledge sharing among researchers, practitioners, and policymakers. Resource the development of a collective intelligence website that assists the community in sharing, finding, and debating the emerging evidence as generative AI is evaluated in different educational contexts. UTS has experience in prototyping such infrastructures."},{"id":370,"value":"Convene an expert panel to review options for national generative AI infrastructure. Amidst concerns that generative AI is owned and driven by technology companies, we should consider developing a national capability for both research and public services, with the possibility of increased fairness, accountability, transparency and ethics when the infrastructure is completely under our own control."},{"id":375,"value":"Encouraging collaboration among educational institutions, researchers, and developers to minimise duplication, share best practices, research findings, and innovations related to the use of generative AI in education"},{"id":377,"value":"Establish the Australian Forum on Quality Digital Education to help shape the strategic agenda for using technology to target educational disadvantage and boost student outcomes and wellbeing."},{"id":378,"value":"Work with schools to test, develop and showcase best practice integration of teaching and learning technology tools for disadvantaged and special needs students, building a network of peer based support."},{"id":379,"value":"Provide extra resources to disadvantaged schools to access high quality edtech learning tools, with linked implementation support and professional development, alongside investment to secure equitable access to essential technological infrastructure."},{"id":384,"value":"Create an accessible repository of trustworthy information on the quality and safety of available edtech tools so that schools, education systems and parents can make more informed choices"},{"id":536,"value":"Future research: There is an urgent need to support research exploring the use of generative Al by EAL/D learners and their teachers. Such research would enhance understanding about EAL/D learners' experiences, attitudes, innovative uses and challenges which, in turn, would allow the development of evidence-based research-informed policies, frameworks, approaches and practices for educational settings that specifically address their needs. Supporting research collaborations and partnerships between universities, government and educational institutions remains crucial for generation of new knowledge and pedagogical innovations associated with the use of generative Al in EAL/D settings."},{"id":452,"value":"ISA recommends the creation of a national generative AI in education website that is freely accessible to all educators to increase their knowledge base"},{"id":501,"value":"Publish resources that support students and teachers to become proficient users of AI, including understanding the benefits and limitations."},{"id":506,"value":"Upskill and train regulators and policymakers about the opportunities and risks of AI in education, as well as best practice policy and regulatory approaches."},{"id":510,"value":"Build a repository of current and emerging educational technology (EdTech) tools to understand the spectrum of capabilities, limitations, and impacts."},{"id":517,"value":"School\nleadershipâ— Requires capacity building\nand strategic expertise in\nAI."},{"id":527,"value":"We recommend the Government create a repository of current EdTech tools and use cases and their capabilities, limitations and impacts to improve school decision-making around EdTech procurement and use."},{"id":541,"value":"Establish a panel of experts including diverse users and a library of use cases, good practice examples and diverse user experiences"},{"id":613,"value":"Encourage Collaboration: Foster collaboration among tech companies, educators, and policymakers to ensure AI tools meet educational needs effectively and ethically."}],"Tag_group":{"id":993949,"value":"Materials","color":"dark-pink"}},{"id":20,"order":"20.00000000000000000000","Name":{"id":980179,"value":"ongoing-and-global-monitoring","color":"dark-brown"},"Notes":"","Recommendations":[{"id":80,"value":"That the Committee recognise that evolution of generative AI in the education system is in its early stages, with AI developing at an exponentially rapid rate, and guide the formulation of a strategic vision for Australiaâ€™s management, regulation and effective use of generative AI in this rapidly changing environment."},{"id":82,"value":"That Australia follow international leads to consider national regulation on the use of generative AI."},{"id":84,"value":"Australia should also closely consider prioritising its alignment with other key export markets, and avoid fragmentation, and multi-jurisdictional compliance regimes that make investment unpalatable, and research and development activity challenging. Particularly, as it intersects with our higher education institutions remaining competitive. Offering the most comprehensive training for work ready students (both domestic and international) and in research and development. Briefly, areas for current consideration from overseas countries regulating AI, include consideration of certain prohibited AI activities, exemptions for internal research and development without prejudice to commercialisation, treatment of open source software, and risk classifications for intersecting educational activities and AI, such as higher risk requirements for use of this AI in admissions and academic assessment8;"},{"id":90,"value":"Continued monitoring of other discourses on the risks and challenges of AI is undertaken, with a special emphasis on data quality and â€˜knowledge reservesâ€™ as well as privacy with respect to GenAI in education."},{"id":103,"value":"Recommendation 1: Policy making should be both anticipatory and responsive to systemically manage the risks and seize the opportunities facing the Australian education sector AI technology is being introduced before there are adequate policies for guiding productive use and mitigating harms in education. This means a lag time between the introduction of AI and policy development, which also contributes to largely reactive policy making. There needs to be both anticipatory policy making (to assess both development and potential harms and opportunities) and responsive policy making (to guide existing use). Attention to future possibilities - based on past and present needs â€“ has the potential to address the systemic risks and opportunities which the education sector currently faces at a time of unprecedented uncertainty."},{"id":107,"value":"Tracking and evaluating the deployment and uptake of generative AI in education contexts will also be vital. The recent release of the UTS AI Governance report is a useful model.4 One of the biggest issues â€“ flagged in the Inquiryâ€™s terms of reference â€“ is the risk of entrenching social disadvantage and of perpetuating racist, homophobic and sexist stereotypes. Developing and investing in a Generative-AI index akin to the Digital Inclusion Index5 would be one way of tracking and evaluating models based on set of criteria so students, the broader public and governments can make informed choices about uptake."},{"id":123,"value":"International collaborations help align regulations and processes and share best practices and learnings."},{"id":225,"value":"Encourage Australian governments to aim for coherence and interoperability between Australian AI policy and emerging frameworks and international standards for AI"},{"id":509,"value":"Ensure existing policy and regulatory frameworks are fit-for-purpose and are able to deliver adequate protections for the use of GenAI in the education system. This should be underpinned by the regulatory principles of harmonisation, diversity, and necessity."}],"Tag_group":{"id":993950,"value":"Policy-and-evaluation","color":"dark-orange"}},{"id":21,"order":"21.00000000000000000000","Name":{"id":980197,"value":"evidence-generation","color":"brown"},"Notes":"","Recommendations":[{"id":86,"value":"Evidence informed decision making We want to encourage innovative, safe practice for the use of generative AI in education. There is significant potential for generative AI tools to be used to improve education outcomes, however we currently have no research to support any decisions. Educators need to be supported to be able to make evidence-informed decisions about how generative AI can be used in their practice."},{"id":89,"value":"Commitment to a strong research agenda to understand the potential and risks of generative AI as well as to evaluate its use in educational settings and the reasons for its rapid uptake. This research should also include disadvantaged and marginalised groups and consider the different educational needs of each school age cohort."},{"id":91,"value":"Commission the Australian Education Research Organisation (AERO) to provide expertise and advice on what works best when using education technology in classrooms, to support teachers and improve student outcomes."},{"id":92,"value":"That software to detect the use of generative artificial intelligence should not be used until there is evidence that it works."},{"id":121,"value":"more work is required to understand how such tools can be best leveraged to improve outcomes. To facilitate this transition, further and significant investment in comprehensive professional development programs for educators,is necessary to equip them with the necessary skills in data analysis and digital and AI literacy."},{"id":138,"value":"5. That a research program is put in place to monitor outputs of generative AI tools deployed in an educational setting, with tool providers committing to continual improvement in response to findings."},{"id":143,"value":"Establish a generative AI educational impact evidence hub to foster both domestic and international collaboration and knowledge sharing among researchers, practitioners, and policymakers. Resource the development of a collective intelligence website that assists the community in sharing, finding, and debating the emerging evidence as generative AI is evaluated in different educational contexts. UTS has experience in prototyping such infrastructures."},{"id":146,"value":"the education sector urgently needs robust responses to the following questions: â€¢ What are proven approaches to transitioning assessment practices and curriculum renewal at scale? For instance, are direct observation/oral defence sessions scalable (e.g., for hundreds of students in a cohort), does it cost more than current assessments, and if more, is this justified by the rigour of assurance of learning they provide? Does a switch to program-level assessment create the staff time and curriculum space to introduce the triangulation of student evidence now required? â€¢ How well do different ways of using generative AI tools translate across different teaching and learning contexts, and do we understand why there is inevitably variation? There are now myriad, educationally-grounded proposals for how ChatGPT might be used â€” what is missing is the coordinated tracking of evidence of how well these work across different contexts. â€¢ How do we build critical AI literacy among students of different ages and stages, such that it becomes a lifelong capability, and does not age rapidly with technical advances? â€¢ What are the most effective ways to upskill academics, short and longer term? Every university has a centre for teaching innovation bringing wide expertise, including Academic Language and Literacies, Library, Course Program Design, Assessment Design. All of these have been engaged in the rapid response to generative AI over the last 6 months, but there has not yet been time to consolidate, share and discuss innovations. â€¢ How do we tune generative AI for learning? The dominant Large Language Models and conversational interfaces were not developed for education. These can be further tuned with in-depth disciplinary texts, and prompt engineering to shape learning conversations. Some universities are beginning to build the infrastructure to conduct such applied R&D, while others will depend on them sharing the outputs in forms they can adopt and adapt, open source or via commercial products."},{"id":154,"value":"Evidence is a central requirement of ethical AI (merit in the National Statement; justification and transparency in many AI ethics frameworks). It is crucial that investments in EdTech are underpinned by evidence that any tools used will support the outcomes they claim to target. Support the critique, creation, and dissemination of evidence regarding claims of genAI supporting learning through: - Recommendation 2: Development of funding streams, and support for innovative approaches to evidence development and sharing across sectors, regarding genAI. By its nature this work must include social scientists which may require new funding streams, or/and reform of the R&D tax credit."},{"id":155,"value":"Recommendation 3: Support of interdisciplinary teams for genAI research both on fundamental evaluation of tool uses, and the dissemination of this evidence with and across education systems (including educators, learners, and developers)."},{"id":198,"value":"Include standards for evidence to underpin education interventions"},{"id":203,"value":"Commission the Australian Education Research Organisation (AERO), working with\nACARA, AITSL and ESA, to provide expertise and advice on what works best when\nusing edtech to support teachers and improve student outcomes"},{"id":204,"value":"Build cross-government agency and public-private partnerships to safely share de-identified data for better traction on solving education challenges"},{"id":205,"value":"Create an accessible repository of trustworthy information on the quality and safety\nof available edtech tools so that schools, education systems and parents can make\nmore informed choices"},{"id":239,"value":"Encourage rigorous validation of AI tools for educational purposes. Promote peer-reviewed and transparently published studies to ensure effectiveness and reliability."},{"id":259,"value":"Research and Evaluation: Invest in research and evaluation of AI implementations in disadvantaged communities to understand their effectiveness and identify areas for improvement. This data-driven approach will help optimize AI use for these cohorts."},{"id":303,"value":"Legislation should mandate third party evaluations of AI tools and systems to ensure they meet certain criteria for transparency, fairness, and accountability. These evaluations should be conducted by independent auditors and regulatory bodies."},{"id":309,"value":"research the impacts of AI on childrenâ€™s cognition and meta-cognition"},{"id":325,"value":"undertake independent research and gather feedback from students, educators, researchers, and industry to develop actionable insights and ensure best practices are adopted"},{"id":348,"value":"Conducting Internal Research: Universities and other tertiary institutions should conduct comprehensive internal research studies to evaluate the scope and limitations when implementing GAI. This could include an assessment of potential biases, cautions and considerations, and also informed recommendations on suitable GAI programs to use."},{"id":381,"value":"Include evidence standards for education interventions, including edtech, in the next quadrennial national school funding agreement, along the lines of the U.S. Every Student Succeeds Act (ESSA) federal funding guidelines."},{"id":386,"value":"Build public-private partnerships to safely share data for better traction on solving education challenges, and to apply advanced data techniques to help optimise outcomes for students at risk."},{"id":536,"value":"Future research: There is an urgent need to support research exploring the use of generative Al by EAL/D learners and their teachers. Such research would enhance understanding about EAL/D learners' experiences, attitudes, innovative uses and challenges which, in turn, would allow the development of evidence-based research-informed policies, frameworks, approaches and practices for educational settings that specifically address their needs. Supporting research collaborations and partnerships between universities, government and educational institutions remains crucial for generation of new knowledge and pedagogical innovations associated with the use of generative Al in EAL/D settings."},{"id":485,"value":"Education leaders and teachers should leverage their expertise to evaluate technologies in the education sector, strengthening and preserving their trusted professional roles instead of relying on private entities."},{"id":494,"value":"The Australian Government needs to hold developers of publicly-used GAI resources accountable for the veracity of output in education settings. As for the use of any new technology, it will be necessary to think through regulatory compliance and broader ethical considerations. Developments internationally should be monitored carefully, particularly for regulatory responses applicable to education providers.\nQuality, ethical outputs from GAI require quality inputs. Australian higher education can help ensure GAI is fit for purpose - avoiding inaccurate, irrelevant, biased, or deceptive outputs, or information that is counter to either regulatory or teachersâ€™ pedagogical design. This can be done by undertaking ongoing due diligence to ensure the inputs of GAI are relevant to educational settings, and that the outputs of GAI in education settings are robust, ethical, increase the quality of learning outcomes, and are protecting the reputation of Australian education. GAI systems will need appropriate controls to allow educational institutions to undertake this work. Misconduct is also a known risk, where some students may pass off AI-generated work as their own. Widespread evidence from within the field of academic integrity suggests that students are well-intentioned but may be opportunistic when under pressure. Misconduct - both unintentional and intentional - can be mitigated when education institutions provide students and teachers with clear advice and guidance and sanctioned alternatives, including appropriately-trained GAI, as trusted, readily-accessible options. Risks and challenges can be mitigated with transparency of use. Policy should dictate that where a student or researcher uses GAI tools this should be disclosed to assessors, reviewers, and other audiences, just as referencing is used to disclose access to archive materials."},{"id":527,"value":"We recommend the Government create a repository of current EdTech tools and use cases and their capabilities, limitations and impacts to improve school decision-making around EdTech procurement and use."},{"id":535,"value":"Use standard terms and definitions and expand definitions of research and research codes of conduct to include â€˜originalityâ€™ and â€˜reproducibilityâ€™"},{"id":576,"value":"Support research about generative AI in education to provide an evidence base for future development of AI that supports fairness, equity and safety."},{"id":586,"value":"Implementation must be across all public education settings, whilst concurrently commissioning research into the impact on teaching and learning."},{"id":588,"value":"Develop a national government policy framework to provide students with broad, equal access to technology and learning and to equally protect students from any potential harm for the use of such technologies."},{"id":590,"value":"This policy framework must: â€¢ consider the ethics, curriculum and pedagogical issues; â€¢ address occupational, health, welfare and safety issues; â€¢ ensure that the implementation of AI is equitable, accessible and inclusive; â€¢ ensure that AI tools and their implementation is free of cultural, racial and gender biases and that they should not perpetuate or amplify existing biases or discrimination; â€¢ ensure that private for-profit operators are prevented from exerting inappropriate influence via platforms and products, on the processes of teaching and learning in educational settings and systems; â€¢ ensure that a digital equity audit is undertaken to ascertain the extent of digital inequality experienced by students and educational settings; â€¢ consider the issues of data sovereignty and copyright and that the use of AI in public education must be transparent, including its applications, what data is collected and how that data is used; â€¢ ensure that the teaching profession is provided with high quality professional development, systemic support and professional autonomy; â€¢ ensure that the teaching profession and students are provided with guidance and training on the ethical use of AI tools; â€¢ ensure equitable and fair resourcing for all students, including digital access; and â€¢ undertake ongoing evaluation of AI implementation to ensure that it supports the needs of students and the teaching profession and aligns with the appropriate ethical standards and guidelines that govern teaching and learning practices."},{"id":617,"value":"Continuous Research and Evaluation: Encourage ongoing research into AI's impact on educational outcomes, including longitudinal studies to understand its long-term effects."}],"Tag_group":{"id":993952,"value":"Resourcing","color":"blue"}},{"id":22,"order":"22.00000000000000000000","Name":{"id":980198,"value":"marginalised-group-engagement","color":"light-pink"},"Notes":"","Recommendations":[{"id":74,"value":"That the Committee highlights the need for a diverse range of interested parties and stakeholders to be included in future decisions and actions related to the use of generative AI, in particular the perspectives of those who may be underrepresented in government and education decision-making bodies, including students, people from Aboriginal and Torres Strait Islander and culturally and linguistically diverse backgrounds, those experiencing social and economic disadvantage, and people with disabilities."},{"id":89,"value":"Commitment to a strong research agenda to understand the potential and risks of generative AI as well as to evaluate its use in educational settings and the reasons for its rapid uptake. This research should also include disadvantaged and marginalised groups and consider the different educational needs of each school age cohort."},{"id":97,"value":"Recommendation 4: Identify policy and program opportunities to encourage and support sustainable collaborations between educators in schools serving disadvantaged communities and their colleagues in Australian universities with relevant expertise and interests, to help address the digital divide, specifically in relation to access to and use of generative AI tools."},{"id":193,"value":"Recommendation 14: Policies should also encourage the development and use of AI-enabled educational resources that are specifically designed to address the needs of disadvantaged cohorts"},{"id":194,"value":"Recommendation 15: Policies should prioritise providing targeted training and capacity building programs for teachers and students in schools with a higher proportion of disadvantaged students"},{"id":195,"value":"Recommendation 16: Addressing the digital divide and ensuring digital equity needs to be a priority in the use of generative AI in the Australian education system. Policies should focus on removing barriers to access providing targeted training and capacity building, and encouraging community engagement and outreach."},{"id":202,"value":"Provide extra resources to disadvantaged schools to access high quality edtech\nlearning tools, with linked implementation support and professional development,\nalongside investment for equitable access to essential technological infrastructure"},{"id":259,"value":"Research and Evaluation: Invest in research and evaluation of AI implementations in disadvantaged communities to understand their effectiveness and identify areas for improvement. This data-driven approach will help optimize AI use for these cohorts."},{"id":280,"value":"Delivering relevant and engaging education programs and resources for, and in consultation with, priority audiences â€“ including children, young people and families, First Nations communities, culturally and linguistically diverse communities, and LGBTIQ+ Australians â€“ and professional learning for educators."},{"id":360,"value":"AI be progressed as a potential equaliser for disadvantaged students and that techniques on appropriate use be developed, agreed on and promoted across the sector."},{"id":429,"value":"Awareness: There is a need to increase broader awareness, constructive attitudes and levels of confidence about generative Al , its benefits, possibilities, and applications as well as limitations, challenges and biases. Given emerging language and literacy levels of this group both in English and sometimes in home languages, information needs to be accessible, presented in various forms (e.g. brochures, posters, videos, invited presentations, etc.) and/or translated into home languages. These resources need to be easily accessible through community centres, schools and online platforms. To promote such awareness, we recommend that different stakeholders with EAL/D expertise and experience are included in important decision making and initiatives"},{"id":495,"value":"Implemented well, GAI has the potential to improve access to and the accessibility of learning and enhanced learning outcomes for disadvantaged learners. It has the potential to complement classroom teaching with smart, adaptive, and personalised formative feedback at scale and high frequency for individual learners, in modes that suit individual circumstances. It will be important to work with experts, advocates, and communities to understand the potential for different groups of students experiencing disadvantage. GAI is best delivered at scale via Australiaâ€™s strong, existing education infrastructure as part of enrolment. Australiaâ€™s education institutions already include a wide ecosystem of expertise and resourcing that comes from teachers, administrators, student mentors, families, and scaffolding by others, including education scholarship programs. Students in Australian education institutions should receive equal access to quality-assured GAI tools via these existing channels, including equal-access to the associated personal scaffolding required to use GAI ethically and effectively, including critical and digital literacy. Further, partners in Australian education - including scholarship managers, advocates, and community leaders for First Nations students, refugees, learners with disability, and socio-economically disadvantaged groups - can provide valuable connections to studentsâ€™ communities in combination with teaching and learning ecosystems within institutions."}],"Tag_group":{"id":993948,"value":"People","color":"darker-pink"}},{"id":23,"order":"23.00000000000000000000","Name":{"id":980201,"value":"Australian-tech-and-models","color":"light-orange"},"Notes":"","Recommendations":[{"id":108,"value":"There is a major opportunity for the development of Australian models â€“ datasets, LLMs, and significantly, small language models. This is a research infrastructure agenda and is also brings in large public datasets that could offer opportunities for generative AI in Australia. We would single out (as per the RRIR paper) large datasets such as the Bureau of Meteorology, Australian Bureau of Statistics, and the National Library of Australiaâ€™s Trove."},{"id":144,"value":"Convene an expert panel to review options for national generative AI infrastructure. Amidst concerns that generative AI is owned and driven by technology companies, we should consider developing a national capability for both research and public services, with the possibility of increased fairness, accountability, transparency and ethics when the infrastructure is completely under our own control."},{"id":351,"value":"Custom GAI Solutions: Universities can explore the idea of developing their own in-house GAI systems to address privacy concerns associated with using open-source GAI such as ChatGPT. This approach would allow universities to maintain greater control over data privacy such as private work and sensitive data"},{"id":370,"value":"Convene an expert panel to review options for national generative AI infrastructure. Amidst concerns that generative AI is owned and driven by technology companies, we should consider developing a national capability for both research and public services, with the possibility of increased fairness, accountability, transparency and ethics when the infrastructure is completely under our own control."},{"id":562,"value":"We recommend that Australia embrace a considered and leading role in the region with regards to the responsible use of Al in higher education."},{"id":626,"value":"Further, as Al tools and capabilities, when properly utilised will enable the Austra lian economy to unlock greater productivity and jump-step economic growth, OES recommends the Australian Government develop a comprehensive strategy that will encourages Australian industry to integrate Al language models and tools into operations. This will incentivise employers to upskill their workforce with the general and industry-specific Al skills necessary to engage productively with Al models and tools"}],"Tag_group":{"id":993950,"value":"Policy-and-evaluation","color":"dark-orange"}},{"id":24,"order":"24.00000000000000000000","Name":{"id":980200,"value":"ethics-education","color":"light-gray"},"Notes":"","Recommendations":[],"Tag_group":{}},{"id":25,"order":"25.00000000000000000000","Name":{"id":980202,"value":"monitoring-impacts","color":"darker-red"},"Notes":"","Recommendations":[{"id":60,"value":"3. TEQSA and ASQA, or the Department of Education, monitor the different impacts of Generative Al on specific groups of students, such as, First Nations, International and those with a disability."},{"id":130,"value":"â€¢ Have measures in place to prevent and detect misuses of Gen-AI."},{"id":135,"value":"2. The Department of Education to collect and report national data on school library staffing and resourcing to identify students at risk of not receiving adequate information and AI literacy resources."},{"id":184,"value":"Recommendation 5: Policies should mandate rigorous and continual evaluation and validation processes, together with regular independent auditing, to identify and mitigate algorithmic bias in any generative AI tools used in the Australian education system"},{"id":234,"value":"Encourage methods to identify and mitigate biases in generative AI tools. Curate training data carefully, monitor for potential bias, and conduct regular AI system audits to ensure fairness."},{"id":286,"value":"companies design clear reporting mechanisms and well-defined triage and escalation \nprocesses"},{"id":287,"value":"system and model cards are used to promote the improvement of models and the \nenhancement of their understanding by regulators, researchers, and the public"},{"id":324,"value":"continuously review and assess whether generative AI tools are meeting the needs of users and are being used in an effective and ethical manner"},{"id":494,"value":"The Australian Government needs to hold developers of publicly-used GAI resources accountable for the veracity of output in education settings. As for the use of any new technology, it will be necessary to think through regulatory compliance and broader ethical considerations. Developments internationally should be monitored carefully, particularly for regulatory responses applicable to education providers.\nQuality, ethical outputs from GAI require quality inputs. Australian higher education can help ensure GAI is fit for purpose - avoiding inaccurate, irrelevant, biased, or deceptive outputs, or information that is counter to either regulatory or teachersâ€™ pedagogical design. This can be done by undertaking ongoing due diligence to ensure the inputs of GAI are relevant to educational settings, and that the outputs of GAI in education settings are robust, ethical, increase the quality of learning outcomes, and are protecting the reputation of Australian education. GAI systems will need appropriate controls to allow educational institutions to undertake this work. Misconduct is also a known risk, where some students may pass off AI-generated work as their own. Widespread evidence from within the field of academic integrity suggests that students are well-intentioned but may be opportunistic when under pressure. Misconduct - both unintentional and intentional - can be mitigated when education institutions provide students and teachers with clear advice and guidance and sanctioned alternatives, including appropriately-trained GAI, as trusted, readily-accessible options. Risks and challenges can be mitigated with transparency of use. Policy should dictate that where a student or researcher uses GAI tools this should be disclosed to assessors, reviewers, and other audiences, just as referencing is used to disclose access to archive materials."},{"id":544,"value":"Adopt ACODE recommendations: https://publications.ascilite.org/index.php/APUB/article/view/401 \nRecommendations1.Embrace AI in learning, teaching, and assessment, but consider potential risks and challenges that come with it, such as academic integrity concerns and workload issues.2.Foster a culture of transparency, collaboration, and partnership between educators, students, and AI experts, to ensure that AI is used ethically and effectively.3.Develop evidence-based support systems and guidelines for AI use in education, and regularly update them to keep up with the latest developments and challenges.4.Identify and provide appropriate training and professional development opportunities for educators to build their AI competencies, confidence and fluency.5.Consider the potential impact of AI on equity and accessibility and ensure that AI solutions are designed to benefit all students, regardless of their background or circumstances.6.Collaborate with external bodies, such as accrediting bodies and regulatory agencies, to align educational responses to AI across primary, secondary, and tertiary education sectors.7.Continuously monitor and evaluate the impact of AI on learning, teaching, and assessment, and be open to making necessary adjustments based on the evidence.8.Institutions prioritise assessment redesign, by adopting more authentic forms of assessment to minimise the option for students to use AI based tools in generating assessment content"}],"Tag_group":{"id":993950,"value":"Policy-and-evaluation","color":"dark-orange"}},{"id":26,"order":"26.00000000000000000000","Name":{"id":980184,"value":"integrity","color":"light-purple"},"Notes":"","Recommendations":[],"Tag_group":{}},{"id":27,"order":"27.00000000000000000000","Name":{"id":980178,"value":"equitable-access","color":"yellow"},"Notes":"","Recommendations":[{"id":119,"value":"â€¢ equity of access, as a way to help minimise algorithmic bias but also to ensure the widest possible benefit from these tools"},{"id":193,"value":"Recommendation 14: Policies should also encourage the development and use of AI-enabled educational resources that are specifically designed to address the needs of disadvantaged cohorts"},{"id":194,"value":"Recommendation 15: Policies should prioritise providing targeted training and capacity building programs for teachers and students in schools with a higher proportion of disadvantaged students"},{"id":195,"value":"Recommendation 16: Addressing the digital divide and ensuring digital equity needs to be a priority in the use of generative AI in the Australian education system. Policies should focus on removing barriers to access providing targeted training and capacity building, and encouraging community engagement and outreach."},{"id":255,"value":"Digital Infrastructure and Access: Invest in improving digital infrastructure and internet connectivity in disadvantaged communities, including rural and remote areas. Ensure that schools and educational institutions in these areas have access to reliable internet and necessary technology to use AI tools effectively."},{"id":256,"value":"Affordable Technology: Research providers to procure or support negotiations with technology companies to provide low-cost or subsidized devices for disadvantaged students and families."},{"id":260,"value":"Policy Strategy: Prioritise policies that grant equitable access to AI technologies and educational resources for disadvantaged communities."},{"id":285,"value":"features are evaluated to identify and mitigate risks for diverse user groups"},{"id":407,"value":"Given the importance of AI as a career-ready skill, it will be important that all students have access to such tools. As pay-for-use generative AI models are becoming increasingly more prevalent, it will be important that educational institutions are in the position to establish fairness of access so that ability to pay does not influence studentsâ€™ learning opportunities. Currently stretched library and digital budget make this a genuine risk."},{"id":427,"value":"Access: It is important to ensure access to generative Al amongst EAL/0 communities. We recommend avoiding approaches which ban the use of generative Al in schools. This is particularly important for public schools which cater for the majority of EAL/D students in Australia. We also recommend increasing access, including financial support, to Al in local libraries and community centres."},{"id":450,"value":"ISA recommends the implementation of funded programs to develop and deliver safe, effective educational AI technologies which can reduce educational disadvantage and improve outcomes for students by supporting individual learning needs."},{"id":469,"value":"Address inequities in access to AI tools, particularly for students in rural or remote areas and those facing financial constraints."},{"id":470,"value":"The learning programs they deliver must support diversity and generate equitable outcomes that are independent of socioeconomic status, school location, or the wealth of the local school community. Any utilisation of AI within the education system must ensure that these principles are not undermined."},{"id":471,"value":"it is incumbent upon governments and school systems to provide this infrastructure and ensure that equitable access is a paramount consideration. This will require increased and sustained investment from the state and federal governments to ensure 21st century classrooms are available to all."},{"id":495,"value":"Implemented well, GAI has the potential to improve access to and the accessibility of learning and enhanced learning outcomes for disadvantaged learners. It has the potential to complement classroom teaching with smart, adaptive, and personalised formative feedback at scale and high frequency for individual learners, in modes that suit individual circumstances. It will be important to work with experts, advocates, and communities to understand the potential for different groups of students experiencing disadvantage. GAI is best delivered at scale via Australiaâ€™s strong, existing education infrastructure as part of enrolment. Australiaâ€™s education institutions already include a wide ecosystem of expertise and resourcing that comes from teachers, administrators, student mentors, families, and scaffolding by others, including education scholarship programs. Students in Australian education institutions should receive equal access to quality-assured GAI tools via these existing channels, including equal-access to the associated personal scaffolding required to use GAI ethically and effectively, including critical and digital literacy. Further, partners in Australian education - including scholarship managers, advocates, and community leaders for First Nations students, refugees, learners with disability, and socio-economically disadvantaged groups - can provide valuable connections to studentsâ€™ communities in combination with teaching and learning ecosystems within institutions."},{"id":497,"value":"Australian education is already globally renowned. There is an urgent need to adjust standards to incorporate the use of GAI to protect and augment those high standards. Use of GAI in Australian education settings should include: 1. Human oversight and quality assurance, ongoing due diligence of GAI outputs, including proactive management of associated large language models. 2. Access at scale - including investment in digital and critical literacy skills; authentic learning opportunities; higher-order thinking skills; and, peer-based learning - to ensure students donâ€™t simply have â€˜accessâ€™ to GAI but are equipped for a lifetime of considered and appropriate use as citizens."},{"id":526,"value":"Funding deployment of GenAI systems Increased funding for schools would enable them to invest in and deploy responsible Artificial Intelligence for Education (AIED) technologies. This would be especially beneficial for disadvantaged schools"},{"id":539,"value":"Address inequities in access to digital devices and opportunities to address AI and digital literacy across the school and higher education sectors."},{"id":574,"value":"State and federal governments should support equity of access to generative AI across educational sectors, in line with the provision of computers and the internet in primary and secondary schools. In Victoria, this should include specific funding to generate programs for Tech Schools."},{"id":575,"value":"Ensure inclusive and equitable use of generative AI in education through national/state secondary curricula that support equitable access to generative AI tools."},{"id":588,"value":"Develop a national government policy framework to provide students with broad, equal access to technology and learning and to equally protect students from any potential harm for the use of such technologies."},{"id":590,"value":"This policy framework must: â€¢ consider the ethics, curriculum and pedagogical issues; â€¢ address occupational, health, welfare and safety issues; â€¢ ensure that the implementation of AI is equitable, accessible and inclusive; â€¢ ensure that AI tools and their implementation is free of cultural, racial and gender biases and that they should not perpetuate or amplify existing biases or discrimination; â€¢ ensure that private for-profit operators are prevented from exerting inappropriate influence via platforms and products, on the processes of teaching and learning in educational settings and systems; â€¢ ensure that a digital equity audit is undertaken to ascertain the extent of digital inequality experienced by students and educational settings; â€¢ consider the issues of data sovereignty and copyright and that the use of AI in public education must be transparent, including its applications, what data is collected and how that data is used; â€¢ ensure that the teaching profession is provided with high quality professional development, systemic support and professional autonomy; â€¢ ensure that the teaching profession and students are provided with guidance and training on the ethical use of AI tools; â€¢ ensure equitable and fair resourcing for all students, including digital access; and â€¢ undertake ongoing evaluation of AI implementation to ensure that it supports the needs of students and the teaching profession and aligns with the appropriate ethical standards and guidelines that govern teaching and learning practices."},{"id":616,"value":"Inclusive and Accessible AI Design: Prioritise inclusivity and accessibility in AI tool design, catering to students with diverse abilities, learning styles, and backgrounds."},{"id":623,"value":"That the Australian Government prioritises the access to Gen AI opportunities across the population, and that students traditionally in underrepresented areas are not further disadvantaged as we seek to ramp up our literacy into this new domain."}],"Tag_group":{"id":993953,"value":"Values","color":"dark-yellow"}},{"id":28,"order":"28.00000000000000000000","Name":{"id":980176,"value":"de-professionalisation","color":"light-gray"},"Notes":"","Recommendations":[],"Tag_group":{}},{"id":29,"order":"29.00000000000000000000","Name":{"id":980203,"value":"preparing-for-fact-of-life","color":"dark-pink"},"Notes":"","Recommendations":[],"Tag_group":{}},{"id":31,"order":"31.00000000000000000000","Name":{"id":980177,"value":"administrative-offloading","color":"dark-pink"},"Notes":"","Recommendations":[],"Tag_group":{}},{"id":32,"order":"32.00000000000000000000","Name":{"id":980204,"value":"material-customisation","color":"light-orange"},"Notes":"","Recommendations":[],"Tag_group":{}},{"id":33,"order":"33.00000000000000000000","Name":{"id":980205,"value":"personalised-adaptive-learning","color":"yellow"},"Notes":"","Recommendations":[],"Tag_group":{}},{"id":34,"order":"34.00000000000000000000","Name":{"id":980206,"value":"outcome-prediction","color":"light-green"},"Notes":"","Recommendations":[],"Tag_group":{}},{"id":35,"order":"35.00000000000000000000","Name":{"id":980207,"value":"teaching-support","color":"darker-pink"},"Notes":"","Recommendations":[],"Tag_group":{}},{"id":36,"order":"36.00000000000000000000","Name":{"id":980208,"value":"intelligence-augmentation","color":"darker-blue"},"Notes":"","Recommendations":[],"Tag_group":{}},{"id":37,"order":"37.00000000000000000000","Name":{"id":980209,"value":"Indigenous-ICIP-IDIP","color":"dark-orange"},"Notes":"","Recommendations":[{"id":73,"value":"That any development of generative AI standards in Australia include reference to Indigenous Cultural and Intelletual Property (ICIP) and Indigenous Data Sovereignty (IDS) and that risks that Indigenous knowledges and intellectual property will be incorporated into generative AI and used without appropriate attribution or acknowledgement are minimised."},{"id":177,"value":"Within the field of education, the crafting of any regulatory framework should be mindful of specific risks and impacts for educational uses, such as: â€¢ the need for transparent disclosure of the training data and algorithms that underpin educational products so that they can be genuinely evaluated by government and educational institutions to ensure they are free of bias. The onus should be on EdTech developers to make this information intelligible â€¢ a requirement for humans to remain accountable for all AI-assisted decision making. That is, AI can provide input and information and even recommendations, but decision making and accountability can not be delegated to a non-human and recommendations must be able to be over-ridden by a human â€¢ an absolute requirement to respect and protect student and staff privacy, with clear legal requirements for appropriate data handling, storage and disposal to be applied in all models and uses. This requirement should be crafted in such a way as to also provide protection against surveillance usage â€¢ intellectual property considerations, particularly as they relate to sensitive research data and proposals as well as assessment design â€¢ the need for developers to ensure that they are mindful of, and seek to eliminate, bias and discrimination through the data the model is trained on, the design of the model and its suggested applications â€¢ a requirement for educational administrators and institutions to ensure models and their applications are evaluated for bias and that their use is governed by institutional policies, and that adherence is monitored. As a final point, TEQSA notes that consideration should be given the data on which AI is trained to ensure local contexts are adequately represented. This is important to avoid erasing Australian and indigenous culture in a sea of US-centric internet content. Setting down requirements for those creating AI models to be purposeful and considered about the training data can help create inclusive and diverse AI systems."}],"Tag_group":{"id":993953,"value":"Values","color":"dark-yellow"}},{"id":38,"order":"38.00000000000000000000","Name":{"id":986019,"value":"respect-rights","color":"light-blue"},"Notes":"","Recommendations":[{"id":117,"value":"â€¢ user anonymity, except in cases where the AI may be part of a subscription or fee-for-service system (in which case this will need to be made clear to users)"},{"id":120,"value":"â€¢ transparency about inputs, including those used to â€˜trainâ€™ the AI engine, those employed by the AI engine to generate outputs, and those provided by the user, especially when, in either case, proprietary content may be involved (though this would not extend to revealing information about the AIâ€™s underlying algorithms or system architecture)"},{"id":168,"value":"Recommendation 7: Develop appropriate interventions to protect young peopleâ€™s mental health, and deeply sensitive information."},{"id":183,"value":"Recommendation 4: The personal data of students collected by generative AI tools must not be sold to third parties or provided to interoperable services or tools outside of the product being used in the classroom for which consent has been obtained"},{"id":185,"value":"Recommendation 6: Policies should explicitly prohibit the use of generative AI tools in educational settings to create deceptive or malicious content."},{"id":190,"value":"Recommendation 11: Generative AI tools being used in an educational settings should be required to meet minimum requirements relating to privacy, data security, algorithmic bias and discrimination, and content verification, including requirements for regular audits and independent reviews of the tools."},{"id":206,"value":"Develop education-specific standards, incorporated into procurement and\n(potentially new) public oversight systems, covering product design, data use, and\nlife cycle governance and accountability."},{"id":214,"value":"Anticipate copyright issues raised by Generative AI and develop appropriate policies to address potential impacts on educators, students, and learning environments"},{"id":236,"value":"Promote responsible data collection, storage, and use in AI implementations. Ensure data is used only for educational purposes and is adequately protected from unauthorized access."},{"id":268,"value":"The rights of educational AI content creators, individual images, and personal identifiers be protected from re-creation and use without permission."},{"id":275,"value":"Tech companies have a responsibility to ensure that chatbots operating with children or young people have appropriate safeguards in place to ensure there is no intentional or accidental risk of harm to children and young people."},{"id":276,"value":"a related issue concerns the capacity of chatbots to appropriately identify, respond to and report concerns for the safety and welfare of children and young people."},{"id":282,"value":"ensuring generative systems are sourcing high-quality data and information which has been cleaned of illegal, exploitative, and otherwise harmful material"},{"id":283,"value":"policies and processes prevent users from generating harmful content"},{"id":289,"value":"That the Government puts in place requirements for educational institutions and AI developers to have clear and transparent data use policies. These policies should outline the types of data collected, the purposes for which the data will be used, how long the data will be retained, and the measures taken to protect data privacy. These policies should be presented to users in a way that is age-appropriate and easy to understand."},{"id":291,"value":"That the Government requires AI developers and educational institutions to implement strong encryption and secure data storage practices. Government should provide support - both technical and financial â€“ to educational institutions to assist with meeting this requirement."},{"id":293,"value":"That the Government considers the development of comprehensive legislation in relation to Generative AI drawing on international best-practice, like the European Union AI Act. It is crucial that a risk-based approach is taken which includes third party and independent impact and audit assessments, mandatory transparency reports, the human oversight of certain AI systems depending on level of risk, and accountability measures."},{"id":294,"value":"That the Government consider the establishment of a dedicated AI regulatory body assist regulators, policy makers and government in developing, enforcing and implementing legislation, in line with submissions made to â€œPositioning Australia as a Leader in Digital Economy Regulationâ€ and the Australian Human Rights Commissionâ€™s Human Rights and Technology Final Report (2021)."},{"id":296,"value":"Educational institutions and AI developers should be required to have clear and transparent data use policies. These policies should outline the types of data collected, the purposes for which the data will be used, how long the data will be retained, and the measures taken to protect data privacy. These policies should be presented to users in a way that is age â€“ appropriate and easy to understand."},{"id":297,"value":"AI tools used in education should be assessed for their privacy impact by the Office of the Australian Information Commissioner. The assessment would identify potential risks to data privacy and outline measures to mitigate them before the tool can be implemented. The Office of the Australian Information Commissioner should be given the power to ban the implementation of AI tools if the risk to a usersâ€™ data privacy is too high."},{"id":298,"value":"Government can require AI developers and educational institutions to implement strong encryption and secure data storage practices. Government should provide support - both technical and financial â€“ to educational institutions to assist with meeting this requirement."},{"id":301,"value":"Legislation should require organisations to publish transparency reports detailing how their AI systems are used, including any cases of significant impact on individuals or society. These reports would provide insights into how algorithms function in practice and how they affect users."},{"id":302,"value":"Legislation can grant users the right to access and understand the data collected about them and the algorithms used to make decisions based on that data. Users should have the opportunity to challenge or correct inaccurate information."},{"id":303,"value":"Legislation should mandate third party evaluations of AI tools and systems to ensure they meet certain criteria for transparency, fairness, and accountability. These evaluations should be conducted by independent auditors and regulatory bodies."},{"id":305,"value":"Legislation should establish accountability measures for organisations that deploy AI systems that lead to biased, discriminatory or harmful outcomes to help deter irresponsible AI development and use."},{"id":335,"value":"That the Australian Government: consider reforms to discrimination law arising as a result of GAI and other AI systems; clarify the law on copyright of outputs, inputs and prompts on GAI"},{"id":480,"value":"consideration needs to be given to whether the educational use of these products/platforms has the capacity to detrimentally impact upon teaching and learning processes. The interests of private, profit-seeking providers must not be given precedence over education considerations."},{"id":481,"value":"Government and school systems have a responsibility to ensure that educational systems operate in ways that advance the interests of schools, students, teachers and education leaders, and not those of product and platform providers."},{"id":482,"value":"Legislative protection is required to limit the activities of for-profit enterprises and restrict their capacity to take profit from government funding."},{"id":484,"value":"School systems must ensure that that the sharing of personal data meets the highest privacy thresholds"},{"id":490,"value":"Government and education systems must establish policies and protocols to provide adequate and appropriate protections against cyber attack, ensuring that safety measures are not solely dependent on individuals."},{"id":532,"value":"Establish clear legal standards and algorithmic accountability standards - Privacy, ethical use and e-safety"},{"id":545,"value":"That the Copyright Act 1968 be amended to provide appropriate public interest\nexceptions to support the use of machine learning and data and text mining in\nAustralia."},{"id":558,"value":"That the Copyright Act 1968 be updated to ensure that the laws for the use of\nmaterial in the physical classroom are equally applicable to a digital classroom\nsetting, including remote learning and the sharing of material on digital platforms."},{"id":559,"value":"That the Copyright Act 1968 be amended to provide for an express exception for\nthe use of freely available internet material in education"},{"id":590,"value":"This policy framework must: â€¢ consider the ethics, curriculum and pedagogical issues; â€¢ address occupational, health, welfare and safety issues; â€¢ ensure that the implementation of AI is equitable, accessible and inclusive; â€¢ ensure that AI tools and their implementation is free of cultural, racial and gender biases and that they should not perpetuate or amplify existing biases or discrimination; â€¢ ensure that private for-profit operators are prevented from exerting inappropriate influence via platforms and products, on the processes of teaching and learning in educational settings and systems; â€¢ ensure that a digital equity audit is undertaken to ascertain the extent of digital inequality experienced by students and educational settings; â€¢ consider the issues of data sovereignty and copyright and that the use of AI in public education must be transparent, including its applications, what data is collected and how that data is used; â€¢ ensure that the teaching profession is provided with high quality professional development, systemic support and professional autonomy; â€¢ ensure that the teaching profession and students are provided with guidance and training on the ethical use of AI tools; â€¢ ensure equitable and fair resourcing for all students, including digital access; and â€¢ undertake ongoing evaluation of AI implementation to ensure that it supports the needs of students and the teaching profession and aligns with the appropriate ethical standards and guidelines that govern teaching and learning practices."},{"id":601,"value":"A regulatory environment that provides safeguards, consistency and sustainability is required to support students, academics and researchers navigate and benefit from its application"},{"id":602,"value":"Data privacy and security should be incorporated into the development and application standards of generative AI, to promote the sustainable development of generative AI."},{"id":608,"value":"The power of AI in the next decade means we have a real opportunity here to use AI to help us reshape education in a way that the very best available education for every citizen is the CLOSEST SCHOOL available with well-paid teachers, excellent resources, and no fees. Note that Iâ€™m not saying AI needs to do all the teaching (it shouldnâ€™t) but that use of AI can help us optimise the use of education funds to support our educators better. Education of people is much more than writing essays, obviously, itâ€™s a whole-body experience that helps the enculturation of our next generations. Our overarching goal (and this really should be apolitical) must be to maximise opportunities for our citizens, propelling us towards a brighter future where all UN Sustainability Goals are achieved."}],"Tag_group":{"id":993953,"value":"Values","color":"dark-yellow"}},{"id":39,"order":"39.00000000000000000000","Name":{"id":991258,"value":"foster-responsible-aied","color":"red"},"Notes":"","Recommendations":[{"id":122,"value":"By implementing robust regulations and transparent practices, the government can foster a responsible and trustworthy educational environment that maximises the benefits of AI while preserving academic and research integrity."},{"id":197,"value":"the fundamentals of good teaching and learning must come first, and edtech second"},{"id":233,"value":"Promote AI models that are transparent and explainable, allowing educators and students to understand how AI-generated content or assessments are produced."},{"id":235,"value":"Ensure educators review and validate AI-generated content to maintain appropriateness and accuracy."},{"id":244,"value":"Generative AI tools may augment and enhance the role of educators, rather than replace them. The unique abilities of human educators, such as emotional intelligence, empathy, and adaptability, are not easily replicated by AI."},{"id":300,"value":"Organisations developing AI tools should be required to conduct regular audits or impact assessments of their AI systems to address potential biases or unintended consequences. In order to ensure accountability, these assessments should be subject to external scrutiny."},{"id":304,"value":"Legislation should require that critical decisions made by AI systems to have a human-in-the-loop component, where a human reviewer can examine and validate the systemâ€™s outputs before final decisions are implemented."},{"id":316,"value":"develop policies about fair, responsible and ethical use of AI"},{"id":370,"value":"Convene an expert panel to review options for national generative AI infrastructure. Amidst concerns that generative AI is owned and driven by technology companies, we should consider developing a national capability for both research and public services, with the possibility of increased fairness, accountability, transparency and ethics when the infrastructure is completely under our own control."},{"id":385,"value":"Develop education-specific standards covering product design, data use, and life cycle governance and accountability to guide purchasing decisions and assist industry access to the sector."},{"id":419,"value":"Age-appropriate access and design"},{"id":420,"value":"Transparency"},{"id":421,"value":"Sustainability/Environmental Costs"},{"id":450,"value":"ISA recommends the implementation of funded programs to develop and deliver safe, effective educational AI technologies which can reduce educational disadvantage and improve outcomes for students by supporting individual learning needs."},{"id":537,"value":"To maintain learning standards, GAI must be provided within a framework of human oversight. This includes: management of quality inputs and foundations for large learning models; quality assurances for ethical use, content, and academic integrity; human accountability for the technologyâ€™s appropriate and fair function; and, continual review of outputs, including continual vigilance for replication of bias."},{"id":497,"value":"Australian education is already globally renowned. There is an urgent need to adjust standards to incorporate the use of GAI to protect and augment those high standards. Use of GAI in Australian education settings should include: 1. Human oversight and quality assurance, ongoing due diligence of GAI outputs, including proactive management of associated large language models. 2. Access at scale - including investment in digital and critical literacy skills; authentic learning opportunities; higher-order thinking skills; and, peer-based learning - to ensure students donâ€™t simply have â€˜accessâ€™ to GAI but are equipped for a lifetime of considered and appropriate use as citizens."},{"id":512,"value":"Direct additional investment to incentivise the deployment of GenAI, as well as to boost research and development to build a strong ecosystem of responsible GenAI that can help achieve beneficial educational outcomes."},{"id":520,"value":"School\nleadershipâ— Requires a human-centred\nAI culture."},{"id":531,"value":"To promote responsible innovation and use of GenAI, we recommend the Government consider outlining requirements that these tools must reach based on risk mitigation and education research before these tools are deployed widely and used by teachers and students."},{"id":533,"value":"Establish regulations and centres of excellence for data governance"},{"id":565,"value":"We emphasise that the success of LLMs' contributions to higher education depends on the quality of their training data."},{"id":576,"value":"Support research about generative AI in education to provide an evidence base for future development of AI that supports fairness, equity and safety."},{"id":585,"value":"that progress towards the use of generative artificial intelligence in the Australian education system must be human-centred, teacher-led and education department controlled, with a pedagogic focus and a diverse and inclusive social justice lens."},{"id":590,"value":"This policy framework must: â€¢ consider the ethics, curriculum and pedagogical issues; â€¢ address occupational, health, welfare and safety issues; â€¢ ensure that the implementation of AI is equitable, accessible and inclusive; â€¢ ensure that AI tools and their implementation is free of cultural, racial and gender biases and that they should not perpetuate or amplify existing biases or discrimination; â€¢ ensure that private for-profit operators are prevented from exerting inappropriate influence via platforms and products, on the processes of teaching and learning in educational settings and systems; â€¢ ensure that a digital equity audit is undertaken to ascertain the extent of digital inequality experienced by students and educational settings; â€¢ consider the issues of data sovereignty and copyright and that the use of AI in public education must be transparent, including its applications, what data is collected and how that data is used; â€¢ ensure that the teaching profession is provided with high quality professional development, systemic support and professional autonomy; â€¢ ensure that the teaching profession and students are provided with guidance and training on the ethical use of AI tools; â€¢ ensure equitable and fair resourcing for all students, including digital access; and â€¢ undertake ongoing evaluation of AI implementation to ensure that it supports the needs of students and the teaching profession and aligns with the appropriate ethical standards and guidelines that govern teaching and learning practices."},{"id":603,"value":"Assurances about the quality, quantity and diversity of datasets used in AI are important to prevent inaccuracy, bias and ensure its applicability to a wide range of student cohorts."}],"Tag_group":{"id":993950,"value":"Policy-and-evaluation","color":"dark-orange"}}]
